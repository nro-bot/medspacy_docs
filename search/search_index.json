{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MedSpacy Docs","text":"<p>This documentation is autogenerated from docstrings in the source code using mkdocstrings.</p>"},{"location":"#usage","title":"Usage","text":"<p>You can refer to Single Page (Warning: takes a second to load).</p> <p>Alternatively, the individual components are broken out under <code>API Reference</code> in the sidebar to the left.</p>"},{"location":"#thanks-to","title":"Thanks to","text":"<ul> <li>https://pypi.org/project/mkdocstrings</li> <li>https://squidfunk.github.io/mkdocs-materials</li> <li>https://github.com/tlambert03/mkdocs-api-autonav</li> </ul>"},{"location":"singlepage/","title":"Single Page","text":"<p>All docs as a single page.</p>"},{"location":"singlepage/#medspacy_1","title":"MedSpaCy","text":""},{"location":"singlepage/#medspacy._extensions","title":"<code>_extensions</code>","text":"<p>This module will set extension attributes and methods for medspaCy. Examples include custom methods like span._.window()</p>"},{"location":"singlepage/#medspacy._extensions.any_context_attribute","title":"<code>any_context_attribute(span)</code>","text":"<p>Return True if any of the ConText assertion attributes (is_negated, is_historical, etc.) is True.</p> Source code in <code>medspacy/_extensions.py</code> <pre><code>def any_context_attribute(span):\n    \"Return True if any of the ConText assertion attributes (is_negated, is_historical, etc.) is True.\"\n    return any(span._.context_attributes.values())\n</code></pre>"},{"location":"singlepage/#medspacy._extensions.data_to_rows","title":"<code>data_to_rows(data)</code>","text":"<p>Unzip column-wise data from doc._.data into rows</p> Source code in <code>medspacy/_extensions.py</code> <pre><code>def data_to_rows(data):\n    \"\"\"Unzip column-wise data from doc._.data into rows\"\"\"\n    col_data = [data[key] for key in data.keys()]\n    row_data = list(zip(*col_data))\n    return row_data\n</code></pre>"},{"location":"singlepage/#medspacy._extensions.get_context_attributes","title":"<code>get_context_attributes(span)</code>","text":"<p>Return a dict of all ConText assertion attributes (is_negated, is_historical, etc.) and their values.</p> Source code in <code>medspacy/_extensions.py</code> <pre><code>def get_context_attributes(span):\n    \"\"\"Return a dict of all ConText assertion attributes (is_negated, is_historical, etc.)\n    and their values.\n    \"\"\"\n    attr_dict = dict()\n    for attr in _context_attributes:\n        attr_dict[attr] = span._.get(attr)\n    return attr_dict\n</code></pre>"},{"location":"singlepage/#medspacy._extensions.get_extensions","title":"<code>get_extensions()</code>","text":"<p>Get a list of medspaCy extensions for Token, Span, and Doc classes.</p> Source code in <code>medspacy/_extensions.py</code> <pre><code>def get_extensions():\n    \"\"\"Get a list of medspaCy extensions for Token, Span, and Doc classes.\"\"\"\n    return {\n        \"Token\": get_token_extensions(),\n        \"Span\": get_span_extensions(),\n        \"Doc\": get_doc_extensions(),\n    }\n</code></pre>"},{"location":"singlepage/#medspacy._extensions.get_span_literal","title":"<code>get_span_literal(span)</code>","text":"<p>Get the literal value from an entity's TargetRule, which is set when an entity is extracted by TargetMatcher. If the span does not have a TargetRule, it returns the lower-cased text.</p> Source code in <code>medspacy/_extensions.py</code> <pre><code>def get_span_literal(span):\n    \"\"\"Get the literal value from an entity's TargetRule, which is set when an entity is extracted by TargetMatcher.\n    If the span does not have a TargetRule, it returns the lower-cased text.\n    \"\"\"\n    target_rule = span._.target_rule\n    if target_rule is None:\n        return span.text.lower()\n    return target_rule.literal\n</code></pre>"},{"location":"singlepage/#medspacy._extensions.get_window_span","title":"<code>get_window_span(span, n=1, left=True, right=True)</code>","text":"<p>Get a Span of a window of text containing a span. Args:     n (int): Number of tokens on each side of a span to return.         Default 1.     left (bool): Whether to include the span precedinga span.         Default True.     right (bool): Whether to include the span following a span.         Default True. Returns:     a spaCy Span</p> Source code in <code>medspacy/_extensions.py</code> <pre><code>def get_window_span(span, n=1, left=True, right=True):\n    \"\"\"Get a Span of a window of text containing a span.\n    Args:\n        n (int): Number of tokens on each side of a span to return.\n            Default 1.\n        left (bool): Whether to include the span precedinga span.\n            Default True.\n        right (bool): Whether to include the span following a span.\n            Default True.\n    Returns:\n        a spaCy Span\n    \"\"\"\n    if left:\n        start = max((span.start - n, 0))\n    else:\n        start = span.start\n    if right:\n        end = min((span.end + n, len(span.doc)))\n    else:\n        end = span.end\n    return span.doc[start:end]\n</code></pre>"},{"location":"singlepage/#medspacy._extensions.get_window_token","title":"<code>get_window_token(token, n=1, left=True, right=True)</code>","text":"<p>Get a Span of a window of text containing a token. Args:     n (int): Number of tokens on each side of token to return.         Default 1.     left (bool): Whether to include the span preceding token.         Default True.     right (bool): Whether to include the span following token.         Default True. Returns:     a spaCy Span</p> Source code in <code>medspacy/_extensions.py</code> <pre><code>def get_window_token(token, n=1, left=True, right=True):\n    \"\"\"Get a Span of a window of text containing a token.\n    Args:\n        n (int): Number of tokens on each side of token to return.\n            Default 1.\n        left (bool): Whether to include the span preceding token.\n            Default True.\n        right (bool): Whether to include the span following token.\n            Default True.\n    Returns:\n        a spaCy Span\n    \"\"\"\n    if left:\n        start = max((token.i - n, 0))\n    else:\n        start = token.i\n    if right:\n        end = min((token.i + n + 1, len(token.doc)))\n    else:\n        end = token.i + 1\n    return token.doc[start:end]\n</code></pre>"},{"location":"singlepage/#medspacy._extensions.set_extensions","title":"<code>set_extensions()</code>","text":"<p>Set custom medspaCy extensions for Token, Span, and Doc classes.</p> Source code in <code>medspacy/_extensions.py</code> <pre><code>def set_extensions():\n    \"\"\"Set custom medspaCy extensions for Token, Span, and Doc classes.\"\"\"\n    set_token_extensions()\n    set_span_extensions()\n    set_doc_extensions()\n</code></pre>"},{"location":"singlepage/#medspacy.common","title":"<code>common</code>","text":""},{"location":"singlepage/#medspacy.common.base_rule","title":"<code>base_rule</code>","text":""},{"location":"singlepage/#medspacy.common.base_rule.BaseRule","title":"<code>BaseRule</code>","text":"<p>BaseRule is the basic class for the rules contained in the MedspacyMatcher class. It contains the basic structure for a rule to be used by the spaCy matchers or by the RegexMatcher class in order to produce match tuples for processing by a component such as the Sectionizer, ContextComponent or TargetMatcher</p> Source code in <code>medspacy/common/base_rule.py</code> <pre><code>class BaseRule:\n    \"\"\"\n    BaseRule is the basic class for the rules contained in the MedspacyMatcher class. It contains the basic structure\n    for a rule to be used by the spaCy matchers or by the RegexMatcher class in order to produce match tuples for\n    processing by a component such as the Sectionizer, ContextComponent or TargetMatcher\n    \"\"\"\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Base class for medspaCy rules such as TargetRule and ConTextRule.\n\n        Args:\n            literal: The plaintext form of the pattern. Can be a human-readable form of a more complex pattern or, if\n                `pattern` is None, the literal is used in a spaCy PhraseMatcher by the MedspacyMatcher.\n            category: The category for the match. Corresponds to ent.label_ for entities.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        self.literal = literal\n        self.category = category\n        self.pattern = pattern\n        self.on_match = on_match\n        self.metadata = metadata\n</code></pre>"},{"location":"singlepage/#medspacy.common.base_rule.BaseRule.__init__","title":"<code>__init__(literal, category, pattern=None, on_match=None, metadata=None)</code>","text":"<p>Base class for medspaCy rules such as TargetRule and ConTextRule.</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The plaintext form of the pattern. Can be a human-readable form of a more complex pattern or, if <code>pattern</code> is None, the literal is used in a spaCy PhraseMatcher by the MedspacyMatcher.</p> required <code>category</code> <code>str</code> <p>The category for the match. Corresponds to ent.label_ for entities.</p> required <code>pattern</code> <code>Optional[Union[str, List[Dict[str, str]]]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/common/base_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Base class for medspaCy rules such as TargetRule and ConTextRule.\n\n    Args:\n        literal: The plaintext form of the pattern. Can be a human-readable form of a more complex pattern or, if\n            `pattern` is None, the literal is used in a spaCy PhraseMatcher by the MedspacyMatcher.\n        category: The category for the match. Corresponds to ent.label_ for entities.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    self.literal = literal\n    self.category = category\n    self.pattern = pattern\n    self.on_match = on_match\n    self.metadata = metadata\n</code></pre>"},{"location":"singlepage/#medspacy.common.medspacy_matcher","title":"<code>medspacy_matcher</code>","text":""},{"location":"singlepage/#medspacy.common.medspacy_matcher.MedspacyMatcher","title":"<code>MedspacyMatcher</code>","text":"<p>MedspacyMatcher is a class which combines spaCy's Matcher and PhraseMatcher classes along with medspaCy's RegexMatcher and acts as one single matcher using 3 different types of rules:     - Exact phrases     - List of dictionaries for matching on token attributes (see https://spacy.io/usage/rule-based-matching#matcher)     - Regular expression matches. Note that regular-expression matching is not natively supported by spaCy and could             result in unexpected matched spans if match boundaries do not align with token boundaries. Rules can be defined by any class which inherits from medspacy.common.BaseRule, such as:     medspacy.target_matcher.TargetRule     medspacy.context.ConTextRule</p> Source code in <code>medspacy/common/medspacy_matcher.py</code> <pre><code>class MedspacyMatcher:\n    \"\"\"\n    MedspacyMatcher is a class which combines spaCy's Matcher and PhraseMatcher classes along with medspaCy's\n    RegexMatcher and acts as one single matcher using 3 different types of rules:\n        - Exact phrases\n        - List of dictionaries for matching on token attributes (see https://spacy.io/usage/rule-based-matching#matcher)\n        - Regular expression matches. Note that regular-expression matching is not natively supported by spaCy and could\n                result in unexpected matched spans if match boundaries do not align with token boundaries.\n    Rules can be defined by any class which inherits from medspacy.common.BaseRule, such as:\n        medspacy.target_matcher.TargetRule\n        medspacy.context.ConTextRule\n    \"\"\"\n\n    name = \"medspacy_matcher\"\n\n    def __init__(\n        self, nlp: Language, name: str = \"medspacy_matcher\", phrase_matcher_attr: str = \"LOWER\", prune: bool = True\n    ):\n        \"\"\"\n        Creates a MedspacyMatcher.\n\n        Args:\n            nlp: A spaCy Language model.\n            name: The name of the component.\n            phrase_matcher_attr: The attribute to use for spaCy's PhraseMatcher. Default is 'LOWER'.\n            prune: Whether to prune matches that overlap or are substrings of another match. For example, if \"no history\n                of\" and \"history of\" are both matches, setting prune to True would drop \"history of\". Default is True.\n        \"\"\"\n        self.nlp = nlp.tokenizer # preserve only the tokenizer for creating phrasematcher rules\n        self._rule_ids = set()\n        self._labels = set()\n        self._rule_map = dict()\n        self._prune = prune\n        self.__matcher = Matcher(nlp.vocab)\n        self.__phrase_matcher = PhraseMatcher(nlp.vocab, attr=phrase_matcher_attr)\n        self.__regex_matcher = RegexMatcher(nlp.vocab)\n\n        self.__rule_count = 0\n        self.__phrase_matcher_attr = phrase_matcher_attr\n\n    @property\n    def rules(self) -&gt; List[BaseRule]:\n        \"\"\"\n        The list of rules used by the MedspacyMatcher.\n\n        Returns:\n            A list of rules, all of which inherit from BaseRule.\n        \"\"\"\n        return list(self._rule_map.values())\n\n    @property\n    def rule_map(self) -&gt; Dict[str, BaseRule]:\n        \"\"\"\n        The dictionary mapping a rule's id to the rule object.\n\n        Returns:\n            A dictionary mapping the rule's id to the rule.\n        \"\"\"\n        return self._rule_map\n\n    @property\n    def labels(self) -&gt; Set[str]:\n        \"\"\"\n        The set of labels available to the matcher.\n\n        Returns:\n            A set of labels containing the labels for all the rules added to the matcher.\n        \"\"\"\n        return self._labels\n\n    def add(self, rules: Iterable[BaseRule]):\n        \"\"\"\n        Adds a collection of rules to the matcher. Rules must inherit from `medspacy.common.BaseRule`.\n\n        Args:\n            rules: A collection of rules. Each rule must inherit from `medspacy.common.BaseRule`.\n        \"\"\"\n        for rule in rules:\n            if not isinstance(rule, BaseRule):\n                raise TypeError(\"Rules must inherit from medspacy.common.BaseRule.\")\n            self._labels.add(rule.category)\n            rule_id = f\"{rule.category}_{self.__rule_count}\"\n            rule._rule_id = rule_id\n            self._rule_map[rule_id] = rule\n            if rule.pattern is not None:\n                # If it's a string, add a RegEx\n                if isinstance(rule.pattern, str):\n                    self.__regex_matcher.add(rule_id, [rule.pattern], rule.on_match)\n                # If it's a list, add a pattern dictionary\n                elif isinstance(rule.pattern, list):\n                    self.__matcher.add(rule_id, [rule.pattern], on_match=rule.on_match)\n                else:\n                    raise ValueError(\n                        f\"The pattern argument must be either a string or a list, not {type(rule.pattern)}\"\n                    )\n            else:\n                if self.__phrase_matcher_attr.lower() == \"lower\":\n                    # only lowercase when the phrase matcher is looking for lowercase matches.\n                    text = rule.literal.lower()\n                else:\n                    # otherwise, expect users to handle phrases as aligned with their non-default phrase matching scheme\n                    # this prevents .lower() from blocking matches on attrs like ORTH or UPPER\n                    text = rule.literal\n                doc = self.nlp(text)\n                self.__phrase_matcher.add(\n                    rule_id,\n                    [doc],\n                    on_match=rule.on_match,\n                )\n            self.__rule_count += 1\n\n    def __call__(self, doc: Doc) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Call MedspacyMatcher on a doc and return a single list of matches. If self.prune is True,\n        in the case of overlapping matches the longest will be returned.\n\n        Args:\n            doc: The spaCy Doc to process.\n\n        Returns:\n            A list of tuples, each containing 3 ints representing the individual match (match_id, start, end).\n        \"\"\"\n        matches = self.__matcher(doc)\n        matches += self.__phrase_matcher(doc)\n        matches += self.__regex_matcher(doc)\n        if self._prune:\n            matches = prune_overlapping_matches(matches)\n        return matches\n</code></pre>"},{"location":"singlepage/#medspacy.common.medspacy_matcher.MedspacyMatcher.labels","title":"<code>labels</code>  <code>property</code>","text":"<p>The set of labels available to the matcher.</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>A set of labels containing the labels for all the rules added to the matcher.</p>"},{"location":"singlepage/#medspacy.common.medspacy_matcher.MedspacyMatcher.rule_map","title":"<code>rule_map</code>  <code>property</code>","text":"<p>The dictionary mapping a rule's id to the rule object.</p> <p>Returns:</p> Type Description <code>Dict[str, BaseRule]</code> <p>A dictionary mapping the rule's id to the rule.</p>"},{"location":"singlepage/#medspacy.common.medspacy_matcher.MedspacyMatcher.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>The list of rules used by the MedspacyMatcher.</p> <p>Returns:</p> Type Description <code>List[BaseRule]</code> <p>A list of rules, all of which inherit from BaseRule.</p>"},{"location":"singlepage/#medspacy.common.medspacy_matcher.MedspacyMatcher.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call MedspacyMatcher on a doc and return a single list of matches. If self.prune is True, in the case of overlapping matches the longest will be returned.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy Doc to process.</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of tuples, each containing 3 ints representing the individual match (match_id, start, end).</p> Source code in <code>medspacy/common/medspacy_matcher.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Call MedspacyMatcher on a doc and return a single list of matches. If self.prune is True,\n    in the case of overlapping matches the longest will be returned.\n\n    Args:\n        doc: The spaCy Doc to process.\n\n    Returns:\n        A list of tuples, each containing 3 ints representing the individual match (match_id, start, end).\n    \"\"\"\n    matches = self.__matcher(doc)\n    matches += self.__phrase_matcher(doc)\n    matches += self.__regex_matcher(doc)\n    if self._prune:\n        matches = prune_overlapping_matches(matches)\n    return matches\n</code></pre>"},{"location":"singlepage/#medspacy.common.medspacy_matcher.MedspacyMatcher.__init__","title":"<code>__init__(nlp, name='medspacy_matcher', phrase_matcher_attr='LOWER', prune=True)</code>","text":"<p>Creates a MedspacyMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A spaCy Language model.</p> required <code>name</code> <code>str</code> <p>The name of the component.</p> <code>'medspacy_matcher'</code> <code>phrase_matcher_attr</code> <code>str</code> <p>The attribute to use for spaCy's PhraseMatcher. Default is 'LOWER'.</p> <code>'LOWER'</code> <code>prune</code> <code>bool</code> <p>Whether to prune matches that overlap or are substrings of another match. For example, if \"no history of\" and \"history of\" are both matches, setting prune to True would drop \"history of\". Default is True.</p> <code>True</code> Source code in <code>medspacy/common/medspacy_matcher.py</code> <pre><code>def __init__(\n    self, nlp: Language, name: str = \"medspacy_matcher\", phrase_matcher_attr: str = \"LOWER\", prune: bool = True\n):\n    \"\"\"\n    Creates a MedspacyMatcher.\n\n    Args:\n        nlp: A spaCy Language model.\n        name: The name of the component.\n        phrase_matcher_attr: The attribute to use for spaCy's PhraseMatcher. Default is 'LOWER'.\n        prune: Whether to prune matches that overlap or are substrings of another match. For example, if \"no history\n            of\" and \"history of\" are both matches, setting prune to True would drop \"history of\". Default is True.\n    \"\"\"\n    self.nlp = nlp.tokenizer # preserve only the tokenizer for creating phrasematcher rules\n    self._rule_ids = set()\n    self._labels = set()\n    self._rule_map = dict()\n    self._prune = prune\n    self.__matcher = Matcher(nlp.vocab)\n    self.__phrase_matcher = PhraseMatcher(nlp.vocab, attr=phrase_matcher_attr)\n    self.__regex_matcher = RegexMatcher(nlp.vocab)\n\n    self.__rule_count = 0\n    self.__phrase_matcher_attr = phrase_matcher_attr\n</code></pre>"},{"location":"singlepage/#medspacy.common.medspacy_matcher.MedspacyMatcher.add","title":"<code>add(rules)</code>","text":"<p>Adds a collection of rules to the matcher. Rules must inherit from <code>medspacy.common.BaseRule</code>.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Iterable[BaseRule]</code> <p>A collection of rules. Each rule must inherit from <code>medspacy.common.BaseRule</code>.</p> required Source code in <code>medspacy/common/medspacy_matcher.py</code> <pre><code>def add(self, rules: Iterable[BaseRule]):\n    \"\"\"\n    Adds a collection of rules to the matcher. Rules must inherit from `medspacy.common.BaseRule`.\n\n    Args:\n        rules: A collection of rules. Each rule must inherit from `medspacy.common.BaseRule`.\n    \"\"\"\n    for rule in rules:\n        if not isinstance(rule, BaseRule):\n            raise TypeError(\"Rules must inherit from medspacy.common.BaseRule.\")\n        self._labels.add(rule.category)\n        rule_id = f\"{rule.category}_{self.__rule_count}\"\n        rule._rule_id = rule_id\n        self._rule_map[rule_id] = rule\n        if rule.pattern is not None:\n            # If it's a string, add a RegEx\n            if isinstance(rule.pattern, str):\n                self.__regex_matcher.add(rule_id, [rule.pattern], rule.on_match)\n            # If it's a list, add a pattern dictionary\n            elif isinstance(rule.pattern, list):\n                self.__matcher.add(rule_id, [rule.pattern], on_match=rule.on_match)\n            else:\n                raise ValueError(\n                    f\"The pattern argument must be either a string or a list, not {type(rule.pattern)}\"\n                )\n        else:\n            if self.__phrase_matcher_attr.lower() == \"lower\":\n                # only lowercase when the phrase matcher is looking for lowercase matches.\n                text = rule.literal.lower()\n            else:\n                # otherwise, expect users to handle phrases as aligned with their non-default phrase matching scheme\n                # this prevents .lower() from blocking matches on attrs like ORTH or UPPER\n                text = rule.literal\n            doc = self.nlp(text)\n            self.__phrase_matcher.add(\n                rule_id,\n                [doc],\n                on_match=rule.on_match,\n            )\n        self.__rule_count += 1\n</code></pre>"},{"location":"singlepage/#medspacy.common.regex_matcher","title":"<code>regex_matcher</code>","text":""},{"location":"singlepage/#medspacy.common.regex_matcher.RegexMatcher","title":"<code>RegexMatcher</code>","text":"<p>The RegexMatcher is an alternative to spaCy's native Matcher and PhraseMatcher classes and allows matching based on typical regular expressions over the underlying doc text rather than spacy token attributes.</p> <p>This can be useful for allowing more traditional text matching methods, but can lead to issues if the matched spans in the text do not line up with spacy token boundaries. In this case, the RegexMatcher will by default resolve to the nearest token  boundaries by expanding to the left and right. This behavior can be configured using <code>resolve_start</code> and <code>resolve_end</code>. To avoid this, consider using a list of dicts, such as in a spacy Matcher. For more information, see: https://spacy.io/usage/rule-based-matching</p> <p>Examples of resolve_start/resolve_end: In the string 'SERVICE: Radiology' the pattern 'ICE: Rad' would match in the middle of the tokens 'SERVICE' and 'RADIOLOGY'. SpaCy would normally return None. The RegexMatcher will expand in the following ways: resolve_start='left': The resulting span will start at 'SERVICE' -&gt; 'SERVICE: Radiology' resolve_start='right': The resulting span will start at ':' -&gt; ': Radiology' resolve_end='left': The resulting span will end at ':': -&gt; 'SERVICE:' resolve_end='right': The resulting span will end at 'RADIOLOGY' -&gt; 'SERVICE: Radiology'</p> Source code in <code>medspacy/common/regex_matcher.py</code> <pre><code>class RegexMatcher:\n    \"\"\"\n    The RegexMatcher is an alternative to spaCy's native Matcher and PhraseMatcher classes and allows matching based on\n    typical regular expressions over the underlying doc text rather than spacy token attributes.\n\n    This can be useful for allowing more traditional text matching methods, but can lead to issues if the matched spans\n    in the text do not line up with spacy token boundaries. In this case, the RegexMatcher will by default resolve to\n    the nearest token  boundaries by expanding to the left and right. This behavior can be configured using\n    `resolve_start` and `resolve_end`. To avoid this, consider using a list of dicts, such as in a spacy Matcher.\n    For more information, see: https://spacy.io/usage/rule-based-matching\n\n    Examples of resolve_start/resolve_end:\n    In the string 'SERVICE: Radiology' the pattern 'ICE: Rad' would match in the middle of the tokens\n    'SERVICE' and 'RADIOLOGY'. SpaCy would normally return None. The RegexMatcher will expand in the following ways:\n    resolve_start='left': The resulting span will start at 'SERVICE' -&gt; 'SERVICE: Radiology'\n    resolve_start='right': The resulting span will start at ':' -&gt; ': Radiology'\n    resolve_end='left': The resulting span will end at ':': -&gt; 'SERVICE:'\n    resolve_end='right': The resulting span will end at 'RADIOLOGY' -&gt; 'SERVICE: Radiology'\n\n    \"\"\"\n\n    def __init__(\n        self,\n        vocab: Vocab,\n        flags: re.RegexFlag = re.IGNORECASE,\n        resolve_start: str = \"left\",\n        resolve_end: str = \"right\",\n    ):\n        \"\"\"\n        Creates a new RegexMatcher.\n\n        Args:\n            vocab: A spaCy model vocabulary\n            flags: Regular expression flag. Default re.IGNORECASE\n            resolve_start: How to resolve if the start character index of a match does not align with spacy token\n                boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character\n                index, leading to a longer than expected span. If 'right', will find the nearest token boundary to the\n                right of the unmatched character index, leading to a shorter than expected span.  Default 'left'.\n            resolve_end: How to resolve if the end character index of a match does not align with spacy token\n                boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character\n                index, leading to a shorter than expected span. If 'right', will find the nearest token boundary to the\n                right of the unmatched character index, leading to a longer than expected span. Default 'right'.\n        \"\"\"\n        self.vocab = vocab\n        self.flags = flags\n        self.resolve_start = resolve_start\n        self.resolve_end = resolve_end\n        self._patterns = {}\n        self._callbacks = {}\n        self.labels = set()\n        self._rule_item_mapping = dict()\n\n    def add(\n        self,\n        match_id: str,\n        regex_rules: Iterable[str],\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n    ):\n        \"\"\"\n        Add a rule with one or more regex patterns to one match id.\n\n        Args:\n            match_id: The name of the pattern.\n            regex_rules: The list of regex strings to associate with `match_id`.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        \"\"\"\n        # i am not sure if these warnings are more annoying than useful.\n        # warnings.warn(\n        #     \"You are using a TargetRule with a regex pattern, which is not \"\n        #     \"natively supported in spacy and may lead to unexpected match spans. \"\n        #     \"Consider using a list of dicts pattern instead. \"\n        #     \"See https://spacy.io/usage/rule-based-matching\",\n        #     RuntimeWarning,\n        # )\n        if match_id not in self.vocab:\n            self.vocab.strings.add(match_id)\n        self._patterns.setdefault(self.vocab.strings[match_id], [])\n        for pattern in regex_rules:\n            self._patterns[self.vocab.strings[match_id]].append(\n                re.compile(pattern, flags=self.flags)\n            )\n            self._callbacks[self.vocab.strings[match_id]] = on_match\n\n    def get(self, key):\n        return self._patterns.get(self.vocab.strings[key], [])\n\n    def __call__(self, doc: Doc) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Call the RegexMatcher on a spaCy Doc.\n\n        Args:\n            doc: The spaCy doc to process.\n\n        Returns:\n            The list of match tuples (match_id, start, end).\n        \"\"\"\n        matches = []\n        for (match_id, patterns) in self._patterns.items():\n            for pattern in patterns:\n                on_match = self._callbacks[match_id]\n                for re_match in pattern.finditer(doc.text_with_ws):\n                    span = doc.char_span(re_match.start(), re_match.end())\n                    if span is None:\n                        start = get_token_for_char(\n                            doc, re_match.start(), resolve=self.resolve_start\n                        )\n                        end = get_token_for_char(\n                            doc, re_match.end(), resolve=self.resolve_end\n                        )\n                        if end is None:\n                            end_index = len(doc)\n                        else:\n                            end_index = end.i\n                        span = doc[start.i : end_index]\n                    # If it's an empty span, then that means that the token resolution\n                    # must have resulted in no tokens being included.\n                    # Don't add the match\n                    if len(span):\n                        match = (match_id, span.start, span.end)\n                        matches.append(match)\n                    # If a callback function was defined,\n                    # call it according to the spaCy API:\n                    # https://spacy.io/usage/rule-based-matching#on_match\n                    if on_match is not None:\n                        on_match(self, doc, len(matches) - 1, matches)\n\n        return matches\n</code></pre>"},{"location":"singlepage/#medspacy.common.regex_matcher.RegexMatcher.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the RegexMatcher on a spaCy Doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy doc to process.</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>The list of match tuples (match_id, start, end).</p> Source code in <code>medspacy/common/regex_matcher.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Call the RegexMatcher on a spaCy Doc.\n\n    Args:\n        doc: The spaCy doc to process.\n\n    Returns:\n        The list of match tuples (match_id, start, end).\n    \"\"\"\n    matches = []\n    for (match_id, patterns) in self._patterns.items():\n        for pattern in patterns:\n            on_match = self._callbacks[match_id]\n            for re_match in pattern.finditer(doc.text_with_ws):\n                span = doc.char_span(re_match.start(), re_match.end())\n                if span is None:\n                    start = get_token_for_char(\n                        doc, re_match.start(), resolve=self.resolve_start\n                    )\n                    end = get_token_for_char(\n                        doc, re_match.end(), resolve=self.resolve_end\n                    )\n                    if end is None:\n                        end_index = len(doc)\n                    else:\n                        end_index = end.i\n                    span = doc[start.i : end_index]\n                # If it's an empty span, then that means that the token resolution\n                # must have resulted in no tokens being included.\n                # Don't add the match\n                if len(span):\n                    match = (match_id, span.start, span.end)\n                    matches.append(match)\n                # If a callback function was defined,\n                # call it according to the spaCy API:\n                # https://spacy.io/usage/rule-based-matching#on_match\n                if on_match is not None:\n                    on_match(self, doc, len(matches) - 1, matches)\n\n    return matches\n</code></pre>"},{"location":"singlepage/#medspacy.common.regex_matcher.RegexMatcher.__init__","title":"<code>__init__(vocab, flags=re.IGNORECASE, resolve_start='left', resolve_end='right')</code>","text":"<p>Creates a new RegexMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>vocab</code> <code>Vocab</code> <p>A spaCy model vocabulary</p> required <code>flags</code> <code>RegexFlag</code> <p>Regular expression flag. Default re.IGNORECASE</p> <code>IGNORECASE</code> <code>resolve_start</code> <code>str</code> <p>How to resolve if the start character index of a match does not align with spacy token boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character index, leading to a longer than expected span. If 'right', will find the nearest token boundary to the right of the unmatched character index, leading to a shorter than expected span.  Default 'left'.</p> <code>'left'</code> <code>resolve_end</code> <code>str</code> <p>How to resolve if the end character index of a match does not align with spacy token boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character index, leading to a shorter than expected span. If 'right', will find the nearest token boundary to the right of the unmatched character index, leading to a longer than expected span. Default 'right'.</p> <code>'right'</code> Source code in <code>medspacy/common/regex_matcher.py</code> <pre><code>def __init__(\n    self,\n    vocab: Vocab,\n    flags: re.RegexFlag = re.IGNORECASE,\n    resolve_start: str = \"left\",\n    resolve_end: str = \"right\",\n):\n    \"\"\"\n    Creates a new RegexMatcher.\n\n    Args:\n        vocab: A spaCy model vocabulary\n        flags: Regular expression flag. Default re.IGNORECASE\n        resolve_start: How to resolve if the start character index of a match does not align with spacy token\n            boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character\n            index, leading to a longer than expected span. If 'right', will find the nearest token boundary to the\n            right of the unmatched character index, leading to a shorter than expected span.  Default 'left'.\n        resolve_end: How to resolve if the end character index of a match does not align with spacy token\n            boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character\n            index, leading to a shorter than expected span. If 'right', will find the nearest token boundary to the\n            right of the unmatched character index, leading to a longer than expected span. Default 'right'.\n    \"\"\"\n    self.vocab = vocab\n    self.flags = flags\n    self.resolve_start = resolve_start\n    self.resolve_end = resolve_end\n    self._patterns = {}\n    self._callbacks = {}\n    self.labels = set()\n    self._rule_item_mapping = dict()\n</code></pre>"},{"location":"singlepage/#medspacy.common.regex_matcher.RegexMatcher.add","title":"<code>add(match_id, regex_rules, on_match=None)</code>","text":"<p>Add a rule with one or more regex patterns to one match id.</p> <p>Parameters:</p> Name Type Description Default <code>match_id</code> <code>str</code> <p>The name of the pattern.</p> required <code>regex_rules</code> <code>Iterable[str]</code> <p>The list of regex strings to associate with <code>match_id</code>.</p> required <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> Source code in <code>medspacy/common/regex_matcher.py</code> <pre><code>def add(\n    self,\n    match_id: str,\n    regex_rules: Iterable[str],\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n):\n    \"\"\"\n    Add a rule with one or more regex patterns to one match id.\n\n    Args:\n        match_id: The name of the pattern.\n        regex_rules: The list of regex strings to associate with `match_id`.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n    \"\"\"\n    # i am not sure if these warnings are more annoying than useful.\n    # warnings.warn(\n    #     \"You are using a TargetRule with a regex pattern, which is not \"\n    #     \"natively supported in spacy and may lead to unexpected match spans. \"\n    #     \"Consider using a list of dicts pattern instead. \"\n    #     \"See https://spacy.io/usage/rule-based-matching\",\n    #     RuntimeWarning,\n    # )\n    if match_id not in self.vocab:\n        self.vocab.strings.add(match_id)\n    self._patterns.setdefault(self.vocab.strings[match_id], [])\n    for pattern in regex_rules:\n        self._patterns[self.vocab.strings[match_id]].append(\n            re.compile(pattern, flags=self.flags)\n        )\n        self._callbacks[self.vocab.strings[match_id]] = on_match\n</code></pre>"},{"location":"singlepage/#medspacy.common.util","title":"<code>util</code>","text":"<p>This module will contain helper functions and classes for common clinical processing tasks which will be used in medspaCy's matcher objects.</p>"},{"location":"singlepage/#medspacy.common.util.get_token_for_char","title":"<code>get_token_for_char(doc, char_idx, resolve='left')</code>","text":"<p>Get the token index that best matches a particular character index. Because regex find returns a character index and spaCy matches must align with token boundaries, each character index must be converted into a token index.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy Doc to search in.</p> required <code>char_idx</code> <code>int</code> <p>The character index to find the corresponding token for.</p> required <code>resolve</code> <code>str</code> <p>The resolution type. \"left\" will snap character to the token index to the left which precede the</p> <code>'left'</code> <p>Returns:</p> Type Description <code>Union[Token, None]</code> <p>The token that best fits the character index based on the resolution type.</p> Source code in <code>medspacy/common/util.py</code> <pre><code>def get_token_for_char(\n    doc: Doc, char_idx: int, resolve: str = \"left\"\n) -&gt; Union[Token, None]:\n    \"\"\"\n    Get the token index that best matches a particular character index. Because regex find returns a character index and\n    spaCy matches must align with token boundaries, each character index must be converted into a token index.\n\n    Args:\n        doc: The spaCy Doc to search in.\n        char_idx: The character index to find the corresponding token for.\n        resolve: The resolution type. \"left\" will snap character to the token index to the left which precede the\n        `char_idx`. \"right\" will snap character to the token index to the right, which follows the `char_idx`.\n\n    Returns:\n        The token that best fits the character index based on the resolution type.\n    \"\"\"\n    if char_idx &lt; 0:\n        raise ValueError(\"char_idx must be &gt; 0\")\n    if char_idx &gt; len(doc.text_with_ws):\n        raise ValueError(\n            \"char_idx {0} is out of range for text with length {1}\".format(\n                char_idx, len(doc.text_with_ws)\n            )\n        )\n    for i, token in enumerate(doc):\n        if char_idx &gt; token.idx:\n            continue\n        if char_idx == token.idx:\n            return token\n        if char_idx &lt; token.idx:\n            if resolve == \"left\":\n                return doc[i - 1]\n            elif resolve == \"right\":\n                return doc[i]\n            else:\n                raise ValueError(\"resolve must be either 'left' or 'right'\")\n    # Otherwise, we've reached the end of the doc, so this must be the final token\n    # If resolving to the left, return the final token\n    # If resolving to the right, return None, meaning it should go to the end of the doc\n    if resolve == \"left\":\n        return doc[-1]\n    if resolve == \"right\":\n        return None\n</code></pre>"},{"location":"singlepage/#medspacy.common.util.matches_to_spans","title":"<code>matches_to_spans(doc, matches, set_label=True)</code>","text":"<p>Converts all identified matches to spans.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy doc corresponding to the matches.</p> required <code>matches</code> <code>List[Tuple[int, int, int]]</code> <p>The list of match Tuples (match_id, start, end).</p> required <code>set_label</code> <code>bool</code> <p>Whether to assign a label to the span based off the source rule. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>List[Span]</code> <p>A list of spacy spans corresponding to the input matches.</p> Source code in <code>medspacy/common/util.py</code> <pre><code>def matches_to_spans(\n    doc: Doc, matches: List[Tuple[int, int, int]], set_label: bool = True\n) -&gt; List[Span]:\n    \"\"\"\n    Converts all identified matches to spans.\n\n    Args:\n        doc: The spaCy doc corresponding to the matches.\n        matches: The list of match Tuples (match_id, start, end).\n        set_label: Whether to assign a label to the span based off the source rule. Default is True.\n\n    Returns:\n        A list of spacy spans corresponding to the input matches.\n    \"\"\"\n    spans = []\n    for (rule_id, start, end) in matches:\n        if set_label:\n            label = doc.vocab.strings[rule_id]\n        else:\n            label = None\n        spans.append(Span(doc, start=start, end=end, label=label))\n    return spans\n</code></pre>"},{"location":"singlepage/#medspacy.common.util.overlaps","title":"<code>overlaps(a, b)</code>","text":"<p>Checks whether two match Tuples out of spacy matchers overlap.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Tuple[int, int, int]</code> <p>A match Tuple (match_id, start, end).</p> required <code>b</code> <code>Tuple[int, int, int]</code> <p>A match Tuple (match_id, start, end).</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the tuples overlap.</p> Source code in <code>medspacy/common/util.py</code> <pre><code>def overlaps(a: Tuple[int, int, int], b: Tuple[int, int, int]) -&gt; bool:\n    \"\"\"\n    Checks whether two match Tuples out of spacy matchers overlap.\n\n    Args:\n        a: A match Tuple (match_id, start, end).\n        b: A match Tuple (match_id, start, end).\n\n    Returns:\n        Whether the tuples overlap.\n    \"\"\"\n    _, a_start, a_end = a\n    _, b_start, b_end = b\n    return tuple_overlaps((a_start, a_end), (b_start, b_end))\n</code></pre>"},{"location":"singlepage/#medspacy.common.util.prune_overlapping_matches","title":"<code>prune_overlapping_matches(matches, strategy='longest')</code>","text":"<p>Prunes overlapping matches from a list of spaCy match tuples (match_id, start, end).</p> <p>Parameters:</p> Name Type Description Default <code>matches</code> <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples of form (match_id, start, end).</p> required <code>strategy</code> <code>str</code> <p>The pruning strategy to use. At this time, the only available option is \"longest\" and will keep the longest of any two overlapping spans. Other behavior will be added in a future update.</p> <code>'longest'</code> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>The pruned list of matches.</p> Source code in <code>medspacy/common/util.py</code> <pre><code>def prune_overlapping_matches(\n    matches: List[Tuple[int, int, int]], strategy: str = \"longest\"\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Prunes overlapping matches from a list of spaCy match tuples (match_id, start, end).\n\n    Args:\n        matches: A list of match tuples of form (match_id, start, end).\n        strategy: The pruning strategy to use. At this time, the only available option is \"longest\" and will keep the\n            longest of any two overlapping spans. Other behavior will be added in a future update.\n\n    Returns:\n        The pruned list of matches.\n    \"\"\"\n    if strategy != \"longest\":\n        raise NotImplementedError(\n            \"No other filtering strategy has been implemented. Coming in a future update.\"\n        )\n\n    # Make a copy and sort\n    unpruned = sorted(matches, key=lambda x: (x[1], x[2]))\n    pruned = []\n    num_matches = len(matches)\n    if num_matches == 0:\n        return matches\n    curr_match = unpruned.pop(0)\n\n    while True:\n        if len(unpruned) == 0:\n            pruned.append(curr_match)\n            break\n        next_match = unpruned.pop(0)\n\n        # Check if they overlap\n        if overlaps(curr_match, next_match):\n            # Choose the larger span\n            longer_span = max(curr_match, next_match, key=lambda x: (x[2] - x[1]))\n            pruned.append(longer_span)\n            if len(unpruned) == 0:\n                break\n            curr_match = unpruned.pop(0)\n        else:\n            pruned.append(curr_match)\n            curr_match = next_match\n    # Recursive base point\n    if len(pruned) == num_matches:\n        return pruned\n    # Recursive function call\n    else:\n        return prune_overlapping_matches(pruned)\n</code></pre>"},{"location":"singlepage/#medspacy.common.util.span_contains","title":"<code>span_contains(span, target, regex=True, case_insensitive=True)</code>","text":"<p>Return True if a Span object contains a target phrase.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Union[Doc, Span]</code> <p>A spaCy Doc or Span, such as an entity in doc.ents</p> required <code>target</code> <code>str</code> <p>A target phrase or iterable of phrases to check in span.text.lower().</p> required <code>regex</code> <code>bool</code> <p>Whether to search the span using a regular expression rather than a literal string. Default is True.</p> <code>True</code> <code>case_insensitive</code> <code>bool</code> <p>Whether the matching is case-insensitive. Default is True.</p> <code>True</code> Source code in <code>medspacy/common/util.py</code> <pre><code>def span_contains(\n    span: Union[Doc, Span],\n    target: str,\n    regex: bool = True,\n    case_insensitive: bool = True,\n) -&gt; bool:\n    \"\"\"\n    Return True if a Span object contains a target phrase.\n\n    Args:\n        span: A spaCy Doc or Span, such as an entity in doc.ents\n        target: A target phrase or iterable of phrases to check in span.text.lower().\n        regex: Whether to search the span using a regular expression rather than\n            a literal string. Default is True.\n        case_insensitive: Whether the matching is case-insensitive. Default is True.\n    \"\"\"\n    if regex is True:\n        if case_insensitive:\n            func = lambda x: re.search(x, span.text, flags=re.IGNORECASE) is not None\n        else:\n            func = lambda x: re.search(x, span.text) is not None\n    else:\n        if case_insensitive:\n            func = lambda x: x.lower() in span.text.lower()\n        else:\n            func = lambda x: x in span.text\n\n    if isinstance(target, str):\n        return func(target)\n\n    # If it's an iterable, check if any of the strings are in sent\n    for string in target:\n        if func(string):\n            return True\n    return False\n</code></pre>"},{"location":"singlepage/#medspacy.context","title":"<code>context</code>","text":""},{"location":"singlepage/#medspacy.context.ConText","title":"<code>ConText</code>","text":"<p>The ConText for spaCy processing.</p> <p>This component matches modifiers in a Doc, defines their scope, and identifies edges between targets and modifiers. Sets two spaCy extensions:         - Span..modifiers: a list of ConTextModifier objects which modify a target Span         - Doc..context_graph: a ConText graph object which contains the targets,             modifiers, and edges between them.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@Language.factory(\"medspacy_context\")\nclass ConText:\n    \"\"\"\n    The ConText for spaCy processing.\n\n    This component matches modifiers in a Doc, defines their scope, and identifies edges between targets and modifiers.\n    Sets two spaCy extensions:\n            - Span._.modifiers: a list of ConTextModifier objects which modify a target Span\n            - Doc._.context_graph: a ConText graph object which contains the targets,\n                modifiers, and edges between them.\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_context\",\n        rules: Optional[str] = \"default\",\n        language_code: str = 'en',\n        phrase_matcher_attr: str = \"LOWER\",\n        allowed_types: Optional[Set[str]] = None,\n        excluded_types: Optional[Set[str]] = None,\n        terminating_types: Optional[Dict[str, Iterable[str]]] = None,\n        max_scope: Optional[int] = None,\n        max_targets: Optional[int] = None,\n        prune_on_modifier_overlap: bool = True,\n        prune_on_target_overlap: bool = False,\n        span_attrs: Union[\n            Literal[\"default\"], Dict[str, Dict[str, Any]], None\n        ] = \"default\",\n        input_span_type: Union[Literal[\"ents\", \"group\"]] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        \"\"\"\n        Creates a new ConText object.\n\n        Args:\n            nlp: A SpaCy Language object.\n            name: The name of the component.\n            rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n                original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If\n                None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules\n                directly through `ConText.add`.\n            language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n                and also the /resources directory to see which resources might be available in each language.\n                Default is \"en\" for English.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            allowed_types: A global list of types included by context. Rules will operate on only spans with these\n                labels.\n            excluded_types: A global list of types excluded by context. Rules will not operate on spans with these\n                labels.\n            terminating_types: A global map of types to the types that can terminate them. This can be used to apply\n                terminations to all rules of a particular type rather than adding to every rule individually in the\n                ContextRule object.\n            max_scope: The number of tokens around a modifier in a target can be modified. Default value is None,\n                Context will use the sentence boundaries. If a value greater than zero, applies the window globally.\n                Both options will be overridden by a more specific value in a ContextRule.\n            max_targets: The maximum number of targets a modifier can modify. Default value is None, context will modify\n                all targets in its scope. If a value greater than zero, applies this value globally. Both options will\n                be overridden by a more specific value in a ContextRule.\n            prune_on_modifier_overlap: Whether to prune modifiers which are substrings of another modifier. If True,\n                will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both\n                ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify\n                afib. Default True.\n            prune_on_target_overlap: Whether to remove any matched modifiers which overlap with target entities. If\n                False, any overlapping modifiers will not modify the overlapping entity but will still modify any other\n                targets in its scope. Default False.\n            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n                `DEFAULT_ATTRIBUTES`. If a dictionary, format is mapping context modifier categories to a dictionary\n                containing the attribute name and the value to set the attribute to when a  span is modified by a\n                modifier of that category. If None, no attributes will be modified.\n            input_span_type: \"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans\n                in doc.ents. \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n                \"medspacy_spans\".\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self.prune_on_modifier_overlap = prune_on_modifier_overlap\n        self.prune_on_target_overlap = prune_on_target_overlap\n        self.input_span_type = input_span_type\n        self.span_group_name = span_group_name\n        self.context_attributes_mapping = None\n\n        self.DEFAULT_RULES_FILEPATH = path.join(\n            Path(__file__).resolve().parents[2], \"resources\", language_code.lower(), \"context_rules.json\"\n        )\n\n        self.__matcher = MedspacyMatcher(\n            nlp,\n            name=name,\n            phrase_matcher_attr=phrase_matcher_attr,\n            prune=prune_on_modifier_overlap,\n        )\n\n        if span_attrs == \"default\":\n            self.context_attributes_mapping = DEFAULT_ATTRIBUTES\n            self.register_default_attributes()\n        elif span_attrs:\n            for _, attr_dict in span_attrs.items():\n                for attr_name in attr_dict.keys():\n                    if not Span.has_extension(attr_name):\n                        raise ValueError(\n                            f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                            f\"called for your pipeline's custom extensions.\"\n                        )\n            self.context_attributes_mapping = span_attrs\n\n        self.register_graph_attributes()\n\n        if max_scope is not None:\n            if not (isinstance(max_scope, int) and max_scope &gt; 0):\n                raise ValueError(\n                    f\"If 'max_scope' must be a value greater than 0, not the current value: {max_scope}\"\n                )\n        self.max_scope = max_scope\n\n        self.allowed_types = allowed_types\n        self.excluded_types = excluded_types\n        self.max_targets = max_targets\n\n        self.terminating_types = dict()\n        if terminating_types:\n            self.terminating_types = {\n                k.upper(): v for (k, v) in terminating_types.items()\n            }\n\n        rule_path = None\n        if rules == \"default\":\n            rule_path = self.DEFAULT_RULES_FILEPATH\n        else:\n            rule_path = rules\n\n        if rule_path:\n            self.add(ConTextRule.from_json(rule_path))\n\n    @property\n    def rules(self):\n        \"\"\"\n        Returns list of ConTextRules available to context.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def categories(self):\n        \"\"\"\n        Returns list of categories available that Context might produce.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules):\n        \"\"\"\n        Adds ConTextRules to Context.\n\n        Args:\n            rules: A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.\n        \"\"\"\n        if isinstance(rules, ConTextRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, ConTextRule):\n                raise TypeError(f\"Rules must type ConTextRule, not {type(rule)}.\")\n\n            # If global attributes like allowed_types and max_scope are defined,\n            # check if the ConTextRule has them defined. If not, set to the global\n            for attr in (\n                \"allowed_types\",\n                \"excluded_types\",\n                \"max_scope\",\n                \"max_targets\",\n            ):\n                value = getattr(self, attr)\n                if value is None:  # No global value set\n                    continue\n                if (\n                    getattr(rule, attr) is None\n                ):  # If the direction itself has it defined, don't override\n                    setattr(rule, attr, value)\n\n            # Check custom termination points\n            if rule.category.upper() in self.terminating_types:\n                for other_modifier in self.terminating_types[rule.category.upper()]:\n                    rule.terminated_by.add(other_modifier.upper())\n\n        self.__matcher.add(rules)\n\n    @classmethod\n    def register_graph_attributes(cls):\n        \"\"\"\n        Registers spaCy attribute extensions: Span._.modifiers and Doc._.context_graph.\n        \"\"\"\n        try:\n            Span.set_extension(\"modifiers\", default=(), force=True)\n            Doc.set_extension(\"context_graph\", default=None, force=True)\n        except ValueError:  # Extension already set\n            pass\n\n    @classmethod\n    def register_default_attributes(cls):\n        \"\"\"\n        Registers the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n        \"\"\"\n        for attr_name in [\n            \"is_negated\",\n            \"is_uncertain\",\n            \"is_historical\",\n            \"is_hypothetical\",\n            \"is_family\",\n        ]:\n            try:\n                Span.set_extension(attr_name, default=False)\n            except ValueError:  # Extension already set\n                pass\n\n    def set_context_attributes(self, edges):\n        \"\"\"\n        Adds Span-level attributes to targets with modifiers.\n\n        Args:\n            edges: The edges of the ContextGraph to modify.\n        \"\"\"\n        for (target, modifier) in edges:\n            if modifier.category in self.context_attributes_mapping:\n                attr_dict = self.context_attributes_mapping[modifier.category]\n                for attr_name, attr_value in attr_dict.items():\n                    setattr(target._, attr_name, attr_value)\n\n    def __call__(self, doc, targets: str = None) -&gt; Doc:\n        \"\"\"\n        Applies the ConText algorithm to a Doc.\n\n        Args:\n            doc: The spaCy Doc to process.\n            targets: The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects\n\n        Returns:\n            The processed spaCy Doc.\n        \"\"\"\n        if not targets and self.input_span_type == \"ents\":\n            targets = doc.ents\n        elif not targets and self.input_span_type == \"group\":\n            targets = doc.spans[self.span_group_name]\n        elif targets:\n            targets = getattr(doc._, targets)\n        # Store data in ConTextGraph object\n        # TODO: move some of this over to ConTextGraph\n        context_graph = ConTextGraph(\n            prune_on_modifier_overlap=self.prune_on_target_overlap\n        )\n\n        context_graph.targets = targets\n\n        context_graph.modifiers = []\n        matches = self.__matcher(doc)\n\n        for (match_id, start, end) in matches:\n            # Get the ConTextRule object defining this modifier\n            rule = self.__matcher.rule_map[self.nlp.vocab[match_id].text]\n            modifier = ConTextModifier(rule, start, end, doc, max_scope=self.max_scope)\n            context_graph.modifiers.append(modifier)\n\n        context_graph.update_scopes()\n        context_graph.apply_modifiers()\n\n        # Link targets to their modifiers\n        for target, modifier in context_graph.edges:\n            target._.modifiers += (modifier,)\n\n        # If attributes need to be modified\n        if self.context_attributes_mapping:\n            self.set_context_attributes(context_graph.edges)\n\n        doc._.context_graph = context_graph\n\n        return doc\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConText.categories","title":"<code>categories</code>  <code>property</code>","text":"<p>Returns list of categories available that Context might produce.</p>"},{"location":"singlepage/#medspacy.context.ConText.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"singlepage/#medspacy.context.ConText.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Returns list of ConTextRules available to context.</p>"},{"location":"singlepage/#medspacy.context.ConText.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"singlepage/#medspacy.context.ConText.__call__","title":"<code>__call__(doc, targets=None)</code>","text":"<p>Applies the ConText algorithm to a Doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <p>The spaCy Doc to process.</p> required <code>targets</code> <code>str</code> <p>The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects</p> <code>None</code> <p>Returns:</p> Type Description <code>Doc</code> <p>The processed spaCy Doc.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>def __call__(self, doc, targets: str = None) -&gt; Doc:\n    \"\"\"\n    Applies the ConText algorithm to a Doc.\n\n    Args:\n        doc: The spaCy Doc to process.\n        targets: The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects\n\n    Returns:\n        The processed spaCy Doc.\n    \"\"\"\n    if not targets and self.input_span_type == \"ents\":\n        targets = doc.ents\n    elif not targets and self.input_span_type == \"group\":\n        targets = doc.spans[self.span_group_name]\n    elif targets:\n        targets = getattr(doc._, targets)\n    # Store data in ConTextGraph object\n    # TODO: move some of this over to ConTextGraph\n    context_graph = ConTextGraph(\n        prune_on_modifier_overlap=self.prune_on_target_overlap\n    )\n\n    context_graph.targets = targets\n\n    context_graph.modifiers = []\n    matches = self.__matcher(doc)\n\n    for (match_id, start, end) in matches:\n        # Get the ConTextRule object defining this modifier\n        rule = self.__matcher.rule_map[self.nlp.vocab[match_id].text]\n        modifier = ConTextModifier(rule, start, end, doc, max_scope=self.max_scope)\n        context_graph.modifiers.append(modifier)\n\n    context_graph.update_scopes()\n    context_graph.apply_modifiers()\n\n    # Link targets to their modifiers\n    for target, modifier in context_graph.edges:\n        target._.modifiers += (modifier,)\n\n    # If attributes need to be modified\n    if self.context_attributes_mapping:\n        self.set_context_attributes(context_graph.edges)\n\n    doc._.context_graph = context_graph\n\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConText.__init__","title":"<code>__init__(nlp, name='medspacy_context', rules='default', language_code='en', phrase_matcher_attr='LOWER', allowed_types=None, excluded_types=None, terminating_types=None, max_scope=None, max_targets=None, prune_on_modifier_overlap=True, prune_on_target_overlap=False, span_attrs='default', input_span_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Creates a new ConText object.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A SpaCy Language object.</p> required <code>name</code> <code>str</code> <p>The name of the component.</p> <code>'medspacy_context'</code> <code>rules</code> <code>Optional[str]</code> <p>The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules directly through <code>ConText.add</code>.</p> <code>'default'</code> <code>language_code</code> <code>str</code> <p>Language code to use (ISO code) as a default for loading resources.  See documentation and also the /resources directory to see which resources might be available in each language. Default is \"en\" for English.</p> <code>'en'</code> <code>phrase_matcher_attr</code> <code>str</code> <p>The token attribute to use for PhraseMatcher for rules where <code>pattern</code> is None. Default is 'LOWER'.</p> <code>'LOWER'</code> <code>allowed_types</code> <code>Optional[Set[str]]</code> <p>A global list of types included by context. Rules will operate on only spans with these labels.</p> <code>None</code> <code>excluded_types</code> <code>Optional[Set[str]]</code> <p>A global list of types excluded by context. Rules will not operate on spans with these labels.</p> <code>None</code> <code>terminating_types</code> <code>Optional[Dict[str, Iterable[str]]]</code> <p>A global map of types to the types that can terminate them. This can be used to apply terminations to all rules of a particular type rather than adding to every rule individually in the ContextRule object.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>The number of tokens around a modifier in a target can be modified. Default value is None, Context will use the sentence boundaries. If a value greater than zero, applies the window globally. Both options will be overridden by a more specific value in a ContextRule.</p> <code>None</code> <code>max_targets</code> <code>Optional[int]</code> <p>The maximum number of targets a modifier can modify. Default value is None, context will modify all targets in its scope. If a value greater than zero, applies this value globally. Both options will be overridden by a more specific value in a ContextRule.</p> <code>None</code> <code>prune_on_modifier_overlap</code> <code>bool</code> <p>Whether to prune modifiers which are substrings of another modifier. If True, will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify afib. Default True.</p> <code>True</code> <code>prune_on_target_overlap</code> <code>bool</code> <p>Whether to remove any matched modifiers which overlap with target entities. If False, any overlapping modifiers will not modify the overlapping entity but will still modify any other targets in its scope. Default False.</p> <code>False</code> <code>span_attrs</code> <code>Union[Literal['default'], Dict[str, Dict[str, Any]], None]</code> <p>The optional span attributes to modify. Default option \"default\" uses attributes in <code>DEFAULT_ATTRIBUTES</code>. If a dictionary, format is mapping context modifier categories to a dictionary containing the attribute name and the value to set the attribute to when a  span is modified by a modifier of that category. If None, no attributes will be modified.</p> <code>'default'</code> <code>input_span_type</code> <code>Union[Literal['ents', 'group']]</code> <p>\"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans in doc.ents. \"group\" will modify attributes of spans in the span group specified by <code>span_group_name</code>.</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>The name of the span group used when <code>input_span_type</code> is \"group\". Default is \"medspacy_spans\".</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/context/context.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_context\",\n    rules: Optional[str] = \"default\",\n    language_code: str = 'en',\n    phrase_matcher_attr: str = \"LOWER\",\n    allowed_types: Optional[Set[str]] = None,\n    excluded_types: Optional[Set[str]] = None,\n    terminating_types: Optional[Dict[str, Iterable[str]]] = None,\n    max_scope: Optional[int] = None,\n    max_targets: Optional[int] = None,\n    prune_on_modifier_overlap: bool = True,\n    prune_on_target_overlap: bool = False,\n    span_attrs: Union[\n        Literal[\"default\"], Dict[str, Dict[str, Any]], None\n    ] = \"default\",\n    input_span_type: Union[Literal[\"ents\", \"group\"]] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Creates a new ConText object.\n\n    Args:\n        nlp: A SpaCy Language object.\n        name: The name of the component.\n        rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n            original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If\n            None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules\n            directly through `ConText.add`.\n        language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        allowed_types: A global list of types included by context. Rules will operate on only spans with these\n            labels.\n        excluded_types: A global list of types excluded by context. Rules will not operate on spans with these\n            labels.\n        terminating_types: A global map of types to the types that can terminate them. This can be used to apply\n            terminations to all rules of a particular type rather than adding to every rule individually in the\n            ContextRule object.\n        max_scope: The number of tokens around a modifier in a target can be modified. Default value is None,\n            Context will use the sentence boundaries. If a value greater than zero, applies the window globally.\n            Both options will be overridden by a more specific value in a ContextRule.\n        max_targets: The maximum number of targets a modifier can modify. Default value is None, context will modify\n            all targets in its scope. If a value greater than zero, applies this value globally. Both options will\n            be overridden by a more specific value in a ContextRule.\n        prune_on_modifier_overlap: Whether to prune modifiers which are substrings of another modifier. If True,\n            will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both\n            ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify\n            afib. Default True.\n        prune_on_target_overlap: Whether to remove any matched modifiers which overlap with target entities. If\n            False, any overlapping modifiers will not modify the overlapping entity but will still modify any other\n            targets in its scope. Default False.\n        span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n            `DEFAULT_ATTRIBUTES`. If a dictionary, format is mapping context modifier categories to a dictionary\n            containing the attribute name and the value to set the attribute to when a  span is modified by a\n            modifier of that category. If None, no attributes will be modified.\n        input_span_type: \"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans\n            in doc.ents. \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n            \"medspacy_spans\".\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self.prune_on_modifier_overlap = prune_on_modifier_overlap\n    self.prune_on_target_overlap = prune_on_target_overlap\n    self.input_span_type = input_span_type\n    self.span_group_name = span_group_name\n    self.context_attributes_mapping = None\n\n    self.DEFAULT_RULES_FILEPATH = path.join(\n        Path(__file__).resolve().parents[2], \"resources\", language_code.lower(), \"context_rules.json\"\n    )\n\n    self.__matcher = MedspacyMatcher(\n        nlp,\n        name=name,\n        phrase_matcher_attr=phrase_matcher_attr,\n        prune=prune_on_modifier_overlap,\n    )\n\n    if span_attrs == \"default\":\n        self.context_attributes_mapping = DEFAULT_ATTRIBUTES\n        self.register_default_attributes()\n    elif span_attrs:\n        for _, attr_dict in span_attrs.items():\n            for attr_name in attr_dict.keys():\n                if not Span.has_extension(attr_name):\n                    raise ValueError(\n                        f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                        f\"called for your pipeline's custom extensions.\"\n                    )\n        self.context_attributes_mapping = span_attrs\n\n    self.register_graph_attributes()\n\n    if max_scope is not None:\n        if not (isinstance(max_scope, int) and max_scope &gt; 0):\n            raise ValueError(\n                f\"If 'max_scope' must be a value greater than 0, not the current value: {max_scope}\"\n            )\n    self.max_scope = max_scope\n\n    self.allowed_types = allowed_types\n    self.excluded_types = excluded_types\n    self.max_targets = max_targets\n\n    self.terminating_types = dict()\n    if terminating_types:\n        self.terminating_types = {\n            k.upper(): v for (k, v) in terminating_types.items()\n        }\n\n    rule_path = None\n    if rules == \"default\":\n        rule_path = self.DEFAULT_RULES_FILEPATH\n    else:\n        rule_path = rules\n\n    if rule_path:\n        self.add(ConTextRule.from_json(rule_path))\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConText.add","title":"<code>add(rules)</code>","text":"<p>Adds ConTextRules to Context.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <p>A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.</p> required Source code in <code>medspacy/context/context.py</code> <pre><code>def add(self, rules):\n    \"\"\"\n    Adds ConTextRules to Context.\n\n    Args:\n        rules: A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.\n    \"\"\"\n    if isinstance(rules, ConTextRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, ConTextRule):\n            raise TypeError(f\"Rules must type ConTextRule, not {type(rule)}.\")\n\n        # If global attributes like allowed_types and max_scope are defined,\n        # check if the ConTextRule has them defined. If not, set to the global\n        for attr in (\n            \"allowed_types\",\n            \"excluded_types\",\n            \"max_scope\",\n            \"max_targets\",\n        ):\n            value = getattr(self, attr)\n            if value is None:  # No global value set\n                continue\n            if (\n                getattr(rule, attr) is None\n            ):  # If the direction itself has it defined, don't override\n                setattr(rule, attr, value)\n\n        # Check custom termination points\n        if rule.category.upper() in self.terminating_types:\n            for other_modifier in self.terminating_types[rule.category.upper()]:\n                rule.terminated_by.add(other_modifier.upper())\n\n    self.__matcher.add(rules)\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConText.register_default_attributes","title":"<code>register_default_attributes()</code>  <code>classmethod</code>","text":"<p>Registers the default values for the Span attributes defined in <code>DEFAULT_ATTRIBUTES</code>.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@classmethod\ndef register_default_attributes(cls):\n    \"\"\"\n    Registers the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n    \"\"\"\n    for attr_name in [\n        \"is_negated\",\n        \"is_uncertain\",\n        \"is_historical\",\n        \"is_hypothetical\",\n        \"is_family\",\n    ]:\n        try:\n            Span.set_extension(attr_name, default=False)\n        except ValueError:  # Extension already set\n            pass\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConText.register_graph_attributes","title":"<code>register_graph_attributes()</code>  <code>classmethod</code>","text":"<p>Registers spaCy attribute extensions: Span..modifiers and Doc..context_graph.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@classmethod\ndef register_graph_attributes(cls):\n    \"\"\"\n    Registers spaCy attribute extensions: Span._.modifiers and Doc._.context_graph.\n    \"\"\"\n    try:\n        Span.set_extension(\"modifiers\", default=(), force=True)\n        Doc.set_extension(\"context_graph\", default=None, force=True)\n    except ValueError:  # Extension already set\n        pass\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConText.set_context_attributes","title":"<code>set_context_attributes(edges)</code>","text":"<p>Adds Span-level attributes to targets with modifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <p>The edges of the ContextGraph to modify.</p> required Source code in <code>medspacy/context/context.py</code> <pre><code>def set_context_attributes(self, edges):\n    \"\"\"\n    Adds Span-level attributes to targets with modifiers.\n\n    Args:\n        edges: The edges of the ContextGraph to modify.\n    \"\"\"\n    for (target, modifier) in edges:\n        if modifier.category in self.context_attributes_mapping:\n            attr_dict = self.context_attributes_mapping[modifier.category]\n            for attr_name, attr_value in attr_dict.items():\n                setattr(target._, attr_name, attr_value)\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextGraph","title":"<code>ConTextGraph</code>","text":"<p>The ConTextGraph class defines the internal structure of the ConText algorithm. It stores a collection of modifiers, matched with ConTextRules, and targets from some other source such as the TargetMatcher or a spaCy NER model.</p> <p>Each modifier can have some number of associated targets that it modifies. This relationship is stored as edges of of the graph.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>class ConTextGraph:\n    \"\"\"\n    The ConTextGraph class defines the internal structure of the ConText algorithm. It stores a collection of modifiers,\n    matched with ConTextRules, and targets from some other source such as the TargetMatcher or a spaCy NER model.\n\n    Each modifier can have some number of associated targets that it modifies. This relationship is stored as edges of\n    of the graph.\n    \"\"\"\n\n    def __init__(\n        self,\n        targets: Optional[List[Span]] = None,\n        modifiers: Optional[List[ConTextModifier]] = None,\n        edges: Optional[List] = None,\n        prune_on_modifier_overlap: bool = False,\n    ):\n        \"\"\"\n        Creates a new ConTextGraph object.\n\n        Args:\n            targets: A spans that context might modify.\n            modifiers: A list of ConTextModifiers that might modify the targets.\n            edges: A list of edges between targets and modifiers representing the modification relationship.\n            prune_on_modifier_overlap: Whether to prune modifiers when one modifier completely covers another.\n        \"\"\"\n        self.targets = targets if targets is not None else []\n        self.modifiers = modifiers if modifiers is not None else []\n        self.edges = edges if edges is not None else []\n        self.prune_on_modifier_overlap = prune_on_modifier_overlap\n\n    def update_scopes(self):\n        \"\"\"\n        Update the scope of all ConTextModifier.\n\n        For each modifier in a list of ConTextModifiers, check against each other\n        modifier to see if one of the modifiers should update the other.\n        This allows neighboring similar modifiers to extend each other's\n        scope and allows \"terminate\" modifiers to end a modifier's scope.\n        \"\"\"\n        for i in range(len(self.modifiers) - 1):\n            modifier1 = self.modifiers[i]\n            for j in range(i + 1, len(self.modifiers)):\n                modifier2 = self.modifiers[j]\n                # TODO: Add modifier -&gt; modifier edges\n                modifier1.limit_scope(modifier2)\n                modifier2.limit_scope(modifier1)\n\n    def apply_modifiers(self):\n        \"\"\"\n        Checks each target/modifier pair. If modifier modifies target,\n        create an edge between them.\n        \"\"\"\n        if self.prune_on_modifier_overlap:\n            for i in range(len(self.modifiers) - 1, -1, -1):\n                modifier = self.modifiers[i]\n                for target in self.targets:\n                    if tuple_overlaps(\n                        (target.start, target.end), modifier.modifier_span\n                    ):\n                        self.modifiers.pop(i)\n                        break\n\n        edges = []\n        for target in self.targets:\n            for modifier in self.modifiers:\n                if modifier.modifies(target):\n                    modifier.modify(target)\n\n        # Now do a second pass and reduce the number of targets\n        # for any modifiers with a max_targets int\n        for modifier in self.modifiers:\n            modifier.reduce_targets()\n            for target in modifier._targets:\n                edges.append((target, modifier))\n\n        self.edges = edges\n\n    def __repr__(self):\n        return f\"&lt;ConTextGraph&gt; with {len(self.targets)} targets and {len(self.modifiers)} modifiers\"\n\n    def serialized_representation(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the serialized representation of the ConTextGraph\n        \"\"\"\n        return self.__dict__\n\n    @classmethod\n    def from_serialized_representation(cls, serialized_representation) -&gt; ConTextGraph:\n        \"\"\"\n        Creates the ConTextGraph from the serialized representation\n        \"\"\"\n        context_graph = ConTextGraph(**serialized_representation)\n\n        return context_graph\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextGraph.__init__","title":"<code>__init__(targets=None, modifiers=None, edges=None, prune_on_modifier_overlap=False)</code>","text":"<p>Creates a new ConTextGraph object.</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>Optional[List[Span]]</code> <p>A spans that context might modify.</p> <code>None</code> <code>modifiers</code> <code>Optional[List[ConTextModifier]]</code> <p>A list of ConTextModifiers that might modify the targets.</p> <code>None</code> <code>edges</code> <code>Optional[List]</code> <p>A list of edges between targets and modifiers representing the modification relationship.</p> <code>None</code> <code>prune_on_modifier_overlap</code> <code>bool</code> <p>Whether to prune modifiers when one modifier completely covers another.</p> <code>False</code> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def __init__(\n    self,\n    targets: Optional[List[Span]] = None,\n    modifiers: Optional[List[ConTextModifier]] = None,\n    edges: Optional[List] = None,\n    prune_on_modifier_overlap: bool = False,\n):\n    \"\"\"\n    Creates a new ConTextGraph object.\n\n    Args:\n        targets: A spans that context might modify.\n        modifiers: A list of ConTextModifiers that might modify the targets.\n        edges: A list of edges between targets and modifiers representing the modification relationship.\n        prune_on_modifier_overlap: Whether to prune modifiers when one modifier completely covers another.\n    \"\"\"\n    self.targets = targets if targets is not None else []\n    self.modifiers = modifiers if modifiers is not None else []\n    self.edges = edges if edges is not None else []\n    self.prune_on_modifier_overlap = prune_on_modifier_overlap\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextGraph.apply_modifiers","title":"<code>apply_modifiers()</code>","text":"<p>Checks each target/modifier pair. If modifier modifies target, create an edge between them.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def apply_modifiers(self):\n    \"\"\"\n    Checks each target/modifier pair. If modifier modifies target,\n    create an edge between them.\n    \"\"\"\n    if self.prune_on_modifier_overlap:\n        for i in range(len(self.modifiers) - 1, -1, -1):\n            modifier = self.modifiers[i]\n            for target in self.targets:\n                if tuple_overlaps(\n                    (target.start, target.end), modifier.modifier_span\n                ):\n                    self.modifiers.pop(i)\n                    break\n\n    edges = []\n    for target in self.targets:\n        for modifier in self.modifiers:\n            if modifier.modifies(target):\n                modifier.modify(target)\n\n    # Now do a second pass and reduce the number of targets\n    # for any modifiers with a max_targets int\n    for modifier in self.modifiers:\n        modifier.reduce_targets()\n        for target in modifier._targets:\n            edges.append((target, modifier))\n\n    self.edges = edges\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextGraph.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Creates the ConTextGraph from the serialized representation</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>@classmethod\ndef from_serialized_representation(cls, serialized_representation) -&gt; ConTextGraph:\n    \"\"\"\n    Creates the ConTextGraph from the serialized representation\n    \"\"\"\n    context_graph = ConTextGraph(**serialized_representation)\n\n    return context_graph\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextGraph.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Returns the serialized representation of the ConTextGraph</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def serialized_representation(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the serialized representation of the ConTextGraph\n    \"\"\"\n    return self.__dict__\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextGraph.update_scopes","title":"<code>update_scopes()</code>","text":"<p>Update the scope of all ConTextModifier.</p> <p>For each modifier in a list of ConTextModifiers, check against each other modifier to see if one of the modifiers should update the other. This allows neighboring similar modifiers to extend each other's scope and allows \"terminate\" modifiers to end a modifier's scope.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def update_scopes(self):\n    \"\"\"\n    Update the scope of all ConTextModifier.\n\n    For each modifier in a list of ConTextModifiers, check against each other\n    modifier to see if one of the modifiers should update the other.\n    This allows neighboring similar modifiers to extend each other's\n    scope and allows \"terminate\" modifiers to end a modifier's scope.\n    \"\"\"\n    for i in range(len(self.modifiers) - 1):\n        modifier1 = self.modifiers[i]\n        for j in range(i + 1, len(self.modifiers)):\n            modifier2 = self.modifiers[j]\n            # TODO: Add modifier -&gt; modifier edges\n            modifier1.limit_scope(modifier2)\n            modifier2.limit_scope(modifier1)\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier","title":"<code>ConTextModifier</code>","text":"<p>Represents a concept found by ConText in a document. An instance of this class is the result of ConTextRule matching text in a Doc.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>class ConTextModifier:\n    \"\"\"\n    Represents a concept found by ConText in a document. An instance of this class is the result of ConTextRule matching\n    text in a Doc.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_rule: ConTextRule,\n        start: int,\n        end: int,\n        doc: Doc,\n        scope_start: Optional[int] = None,\n        scope_end: Optional[int] = None,\n        max_scope: Optional[int] = None,\n    ):\n        \"\"\"\n        Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding\n        window. Spans such as entities or other members of span groups that occur within this window can be modified by\n        this ConTextModifier.\n\n        Args:\n            context_rule: The ConTextRule object which defines the modifier.\n            start: The start token index.\n            end: The end token index (non-inclusive).\n            doc: The spaCy Doc which contains this span. This is needed to initialize the modifier but is not\n                maintained.\n            scope_start: The start token index of the scope.\n            scope_end: The end index of the scope.\n            max_scope: Whether to use scope values rather than sentence boundaries for modifications.\n        \"\"\"\n        self._context_rule = context_rule\n        self._start = start\n        self._end = end\n\n        self._targets = []\n        self._num_targets = 0\n\n        self._max_scope = max_scope\n        self._scope_start = scope_start\n        self._scope_end = scope_end\n        if doc is not None and (self._scope_end is None or self._scope_start is None):\n            self.__set_scope(doc)\n\n    @property\n    def modifier_span(self) -&gt; Tuple[int, int]:\n        \"\"\"\n        The spaCy Span object, which is a view of self.doc, covered by this match.\n        \"\"\"\n        return self._start, self._end\n\n    @property\n    def rule(self) -&gt; ConTextRule:\n        \"\"\"\n        Returns the associated context rule.\n        \"\"\"\n        return self._context_rule\n\n    @property\n    def direction(self) -&gt; str:\n        \"\"\"\n        Returns the associated direction.\n        \"\"\"\n        return self.rule.direction\n\n    @property\n    def category(self) -&gt; str:\n        \"\"\"\n        Returns the associated category.\n        \"\"\"\n        return self.rule.category\n\n    @property\n    def scope_span(self) -&gt; Tuple[int, int]:\n        \"\"\"\n        Returns the associated scope.\n        \"\"\"\n        return self._scope_start, self._scope_end\n\n    @property\n    def allowed_types(self) -&gt; Set[str]:\n        \"\"\"\n        Returns the associated allowed types.\n        \"\"\"\n        return self.rule.allowed_types\n\n    @property\n    def excluded_types(self) -&gt; Set[str]:\n        \"\"\"\n        Returns the associated excluded types.\n        \"\"\"\n        return self.rule.excluded_types\n\n    @property\n    def num_targets(self) -&gt; int:\n        \"\"\"\n        Returns the associated number of targets.\n        \"\"\"\n        return self._num_targets\n\n    @property\n    def max_targets(self) -&gt; Union[int, None]:\n        \"\"\"\n        Returns the associated maximum number of targets.\n        \"\"\"\n        return self.rule.max_targets\n\n    @property\n    def max_scope(self) -&gt; Union[int, None]:\n        \"\"\"\n        Returns the associated maximum scope.\n        \"\"\"\n        return self.rule.max_scope\n\n    def __set_scope(self, doc: Doc):\n        \"\"\"\n        Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If\n        self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by\n        self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the\n        direction is \"backward\", it will be [self.start: sentence.start].\n\n        If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be\n        reduced to self.max_scope.\n\n        Args:\n            doc: The spaCy doc to use to set scope.\n        \"\"\"\n        # If ConText is set to use defined windows, do that instead of sentence splitting\n        if self._max_scope:\n            full_scope_span = doc[self._start : self._end]._.window(\n                n=self.rule.max_scope\n            )\n        # Otherwise, use the sentence\n        else:\n            full_scope_span = doc[self._start].sent\n            if full_scope_span is None:\n                raise ValueError(\n                    \"ConText failed because sentence boundaries have not been set. Add an upstream component such as the \"\n                    \"dependency parser, Sentencizer, or PyRuSH to detect sentence boundaries or initialize ConText with \"\n                    \"`max_scope` set to a value greater than 0.\"\n                )\n\n        if self.direction.lower() == \"forward\":\n            self._scope_start, self._scope_end = self._end, full_scope_span.end\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_end = self._end + self.max_scope\n\n        elif self.direction.lower() == \"backward\":\n            self._scope_start, self._scope_end = (\n                full_scope_span.start,\n                self._start,\n            )\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_start = self._start - self.max_scope\n\n        else:  # bidirectional\n            self._scope_start, self._scope_end = (\n                full_scope_span.start,\n                full_scope_span.end,\n            )\n\n            # Set the max scope on either side\n            # Backwards\n            if (\n                self.max_scope is not None\n                and (self._start - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_start = self._start - self.max_scope\n            # Forwards\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._end) &gt; self.max_scope\n            ):\n                self._scope_end = self._end + self.max_scope\n\n    def update_scope(self, span: Span):\n        \"\"\"\n        Changes the scope of self to be the given spaCy span.\n\n        Args:\n            span: a spaCy Span which contains the scope which a modifier should cover.\n        \"\"\"\n        self._scope_start = span.start\n        self._scope_end = span.end\n\n    def limit_scope(self, other: ConTextModifier) -&gt; bool:\n        \"\"\"\n        If self and other have the same category or if other has a directionality of 'terminate', use the span of other\n        to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of\n        modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not\n        'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of\n        CHF, but there is pneumonia'\n\n        Args:\n            other: The modifier to check against.\n\n        Returns:\n            Whether the other modifier modified the scope of self.\n        \"\"\"\n        if not tuple_overlaps(self.scope_span, other.scope_span):\n            return False\n        if self.direction.upper() == \"TERMINATE\":\n            return False\n        # Check if the other modifier is a type which can modify self\n        # or if they are the same category. If not, don't reduce scope.\n        if (\n            (other.direction.upper() != \"TERMINATE\")\n            and (other.category.upper() not in self.rule.terminated_by)\n            and (other.category.upper() != self.category.upper())\n        ):\n            return False\n\n        # If two modifiers have the same category but modify different target types,\n        # don't limit scope.\n        if self.category == other.category and (\n            (self.allowed_types != other.allowed_types)\n            or (self.excluded_types != other.excluded_types)\n        ):\n            return False\n\n        orig_scope = self.scope_span\n        if self.direction.lower() in (\"forward\", \"bidirectional\"):\n            if other &gt; self:\n                self._scope_end = min(self._scope_end, other.modifier_span[0])\n        if self.direction.lower() in (\"backward\", \"bidirectional\"):\n            if other &lt; self:\n                self._scope_start = max(self._scope_start, other.modifier_span[1])\n        return orig_scope != self.scope_span\n\n    def modifies(self, target: Span) -&gt; bool:\n        \"\"\"\n        Checks whether the target is within the modifier scope and if self is allowed to modify target.\n\n        Args:\n            target: a spaCy span representing a target concept.\n\n        Returns:\n            Whether the target is within `modifier_scope` and if self is allowed to modify the target.\n        \"\"\"\n        # If the target and modifier overlap, meaning at least one token\n        # one extracted as both a target and modifier, return False\n        # to avoid self-modifying concepts\n\n        if tuple_overlaps(\n            self.modifier_span, (target.start, target.end)\n        ):  # self.overlaps(target):\n            return False\n        if self.direction in (\"TERMINATE\", \"PSEUDO\"):\n            return False\n        if not self.allows(target.label_.upper()):\n            return False\n\n        if tuple_overlaps(self.scope_span, (target.start, target.end)):\n            if not self.on_modifies(target):\n                return False\n            else:\n                return True\n        return False\n\n    def allows(self, target_label: str) -&gt; bool:\n        \"\"\"\n        Returns whether if a modifier is able to modify a target type.\n\n        Args:\n            target_label: The target type to check.\n\n        Returns:\n            Whether the modifier is allowed to modify a target of the specified type. True if `target_label` in\n            `self.allowed_types` or if `target_label` not in `self.excluded_tupes`. False otherwise.\n        \"\"\"\n        if self.allowed_types is not None:\n            return target_label in self.allowed_types\n        if self.excluded_types is not None:\n            return target_label not in self.excluded_types\n        return True\n\n    def on_modifies(self, target: Span) -&gt; bool:\n        \"\"\"\n        If the ConTextRule used to define a ConTextModifier has an `on_modifies` callback function, evaluate and return\n        either True or False.\n\n        Args:\n            target: The spaCy span to evaluate.\n\n        Returns:\n            The result of the `on_modifies` callback for the rule. True if the callback is None.\n        \"\"\"\n        if self.rule.on_modifies is None:\n            return True\n        # Find the span in between the target and modifier\n        start = min(target.end, self._end)\n        end = max(target.start, self._end)\n        span_between = target.doc[start:end]\n        rslt = self.rule.on_modifies(\n            target, target.doc[self._start : self._end], span_between\n        )\n        if rslt not in (True, False):\n            raise ValueError(\n                \"The on_modifies function must return either True or False indicating \"\n                \"whether a modify modifies a target. Actual value: {0}\".format(rslt)\n            )\n        return rslt\n\n    def modify(self, target: Span):\n        \"\"\"\n        Add target to the list of self._targets and increment self._num_targets.\n\n        Args:\n            target: The spaCy span to add.\n        \"\"\"\n        self._targets.append(target)\n        self._num_targets += 1\n\n    def reduce_targets(self):\n        \"\"\"\n        Reduces the number of targets to the n-closest targets based on the value of `self.max_targets`. If\n        `self.max_targets` is None, no pruning is done.\n        \"\"\"\n        if self.max_targets is None or self.num_targets &lt;= self.max_targets:\n            return\n\n        target_dists = []\n        for target in self._targets:\n            dist = min(abs(self._start - target.end), abs(target.start - self._end))\n            target_dists.append((target, dist))\n        srtd_targets, _ = zip(*sorted(target_dists, key=lambda x: x[1]))\n        self._targets = srtd_targets[: self.max_targets]\n        self._num_targets = len(self._targets)\n\n    def __gt__(self, other: ConTextModifier):\n        return self._start &gt; other.modifier_span[0]\n\n    def __ge__(self, other):\n        return self._start &gt;= other.modifier_span[0]\n\n    def __lt__(self, other):\n        return self._end &lt; other.modifier_span[1]\n\n    def __le__(self, other):\n        return self._end &lt;= other.modifier_span[1]\n\n    def __len__(self):\n        return self._end - self._start\n\n    def __repr__(self):\n        return f\"&lt;ConTextModifier&gt; [{self._start}, {self._end}, {self.category}]\"\n\n    def serialized_representation(self):\n        \"\"\"\n        Serialized Representation of the modifier\n        \"\"\"\n        dict_repr = dict()\n        dict_repr[\"context_rule\"] = self.rule.to_dict()\n        dict_repr[\"start\"] = self._start\n        dict_repr[\"end\"] = self._end\n        dict_repr[\"max_scope\"] = self._max_scope\n        dict_repr[\"scope_start\"] = self._scope_start\n        dict_repr[\"scope_end\"] = self._scope_end\n\n        return dict_repr\n\n    @classmethod\n    def from_serialized_representation(\n        cls, serialized_representation\n    ) -&gt; ConTextModifier:\n        \"\"\"\n        Instantiates the class from the serialized representation\n        \"\"\"\n        rule = ConTextRule.from_dict(serialized_representation[\"context_rule\"])\n\n        serialized_representation[\"context_rule\"] = rule\n        serialized_representation[\"doc\"] = None\n\n        return ConTextModifier(**serialized_representation)\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.allowed_types","title":"<code>allowed_types</code>  <code>property</code>","text":"<p>Returns the associated allowed types.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.category","title":"<code>category</code>  <code>property</code>","text":"<p>Returns the associated category.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.direction","title":"<code>direction</code>  <code>property</code>","text":"<p>Returns the associated direction.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.excluded_types","title":"<code>excluded_types</code>  <code>property</code>","text":"<p>Returns the associated excluded types.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.max_scope","title":"<code>max_scope</code>  <code>property</code>","text":"<p>Returns the associated maximum scope.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.max_targets","title":"<code>max_targets</code>  <code>property</code>","text":"<p>Returns the associated maximum number of targets.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.modifier_span","title":"<code>modifier_span</code>  <code>property</code>","text":"<p>The spaCy Span object, which is a view of self.doc, covered by this match.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.num_targets","title":"<code>num_targets</code>  <code>property</code>","text":"<p>Returns the associated number of targets.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.rule","title":"<code>rule</code>  <code>property</code>","text":"<p>Returns the associated context rule.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.scope_span","title":"<code>scope_span</code>  <code>property</code>","text":"<p>Returns the associated scope.</p>"},{"location":"singlepage/#medspacy.context.ConTextModifier.__init__","title":"<code>__init__(context_rule, start, end, doc, scope_start=None, scope_end=None, max_scope=None)</code>","text":"<p>Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding window. Spans such as entities or other members of span groups that occur within this window can be modified by this ConTextModifier.</p> <p>Parameters:</p> Name Type Description Default <code>context_rule</code> <code>ConTextRule</code> <p>The ConTextRule object which defines the modifier.</p> required <code>start</code> <code>int</code> <p>The start token index.</p> required <code>end</code> <code>int</code> <p>The end token index (non-inclusive).</p> required <code>doc</code> <code>Doc</code> <p>The spaCy Doc which contains this span. This is needed to initialize the modifier but is not maintained.</p> required <code>scope_start</code> <code>Optional[int]</code> <p>The start token index of the scope.</p> <code>None</code> <code>scope_end</code> <code>Optional[int]</code> <p>The end index of the scope.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>Whether to use scope values rather than sentence boundaries for modifications.</p> <code>None</code> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def __init__(\n    self,\n    context_rule: ConTextRule,\n    start: int,\n    end: int,\n    doc: Doc,\n    scope_start: Optional[int] = None,\n    scope_end: Optional[int] = None,\n    max_scope: Optional[int] = None,\n):\n    \"\"\"\n    Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding\n    window. Spans such as entities or other members of span groups that occur within this window can be modified by\n    this ConTextModifier.\n\n    Args:\n        context_rule: The ConTextRule object which defines the modifier.\n        start: The start token index.\n        end: The end token index (non-inclusive).\n        doc: The spaCy Doc which contains this span. This is needed to initialize the modifier but is not\n            maintained.\n        scope_start: The start token index of the scope.\n        scope_end: The end index of the scope.\n        max_scope: Whether to use scope values rather than sentence boundaries for modifications.\n    \"\"\"\n    self._context_rule = context_rule\n    self._start = start\n    self._end = end\n\n    self._targets = []\n    self._num_targets = 0\n\n    self._max_scope = max_scope\n    self._scope_start = scope_start\n    self._scope_end = scope_end\n    if doc is not None and (self._scope_end is None or self._scope_start is None):\n        self.__set_scope(doc)\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.__set_scope","title":"<code>__set_scope(doc)</code>","text":"<p>Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the direction is \"backward\", it will be [self.start: sentence.start].</p> <p>If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be reduced to self.max_scope.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy doc to use to set scope.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def __set_scope(self, doc: Doc):\n    \"\"\"\n    Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If\n    self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by\n    self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the\n    direction is \"backward\", it will be [self.start: sentence.start].\n\n    If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be\n    reduced to self.max_scope.\n\n    Args:\n        doc: The spaCy doc to use to set scope.\n    \"\"\"\n    # If ConText is set to use defined windows, do that instead of sentence splitting\n    if self._max_scope:\n        full_scope_span = doc[self._start : self._end]._.window(\n            n=self.rule.max_scope\n        )\n    # Otherwise, use the sentence\n    else:\n        full_scope_span = doc[self._start].sent\n        if full_scope_span is None:\n            raise ValueError(\n                \"ConText failed because sentence boundaries have not been set. Add an upstream component such as the \"\n                \"dependency parser, Sentencizer, or PyRuSH to detect sentence boundaries or initialize ConText with \"\n                \"`max_scope` set to a value greater than 0.\"\n            )\n\n    if self.direction.lower() == \"forward\":\n        self._scope_start, self._scope_end = self._end, full_scope_span.end\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_end = self._end + self.max_scope\n\n    elif self.direction.lower() == \"backward\":\n        self._scope_start, self._scope_end = (\n            full_scope_span.start,\n            self._start,\n        )\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_start = self._start - self.max_scope\n\n    else:  # bidirectional\n        self._scope_start, self._scope_end = (\n            full_scope_span.start,\n            full_scope_span.end,\n        )\n\n        # Set the max scope on either side\n        # Backwards\n        if (\n            self.max_scope is not None\n            and (self._start - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_start = self._start - self.max_scope\n        # Forwards\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._end) &gt; self.max_scope\n        ):\n            self._scope_end = self._end + self.max_scope\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.allows","title":"<code>allows(target_label)</code>","text":"<p>Returns whether if a modifier is able to modify a target type.</p> <p>Parameters:</p> Name Type Description Default <code>target_label</code> <code>str</code> <p>The target type to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the modifier is allowed to modify a target of the specified type. True if <code>target_label</code> in</p> <code>bool</code> <p><code>self.allowed_types</code> or if <code>target_label</code> not in <code>self.excluded_tupes</code>. False otherwise.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def allows(self, target_label: str) -&gt; bool:\n    \"\"\"\n    Returns whether if a modifier is able to modify a target type.\n\n    Args:\n        target_label: The target type to check.\n\n    Returns:\n        Whether the modifier is allowed to modify a target of the specified type. True if `target_label` in\n        `self.allowed_types` or if `target_label` not in `self.excluded_tupes`. False otherwise.\n    \"\"\"\n    if self.allowed_types is not None:\n        return target_label in self.allowed_types\n    if self.excluded_types is not None:\n        return target_label not in self.excluded_types\n    return True\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Instantiates the class from the serialized representation</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>@classmethod\ndef from_serialized_representation(\n    cls, serialized_representation\n) -&gt; ConTextModifier:\n    \"\"\"\n    Instantiates the class from the serialized representation\n    \"\"\"\n    rule = ConTextRule.from_dict(serialized_representation[\"context_rule\"])\n\n    serialized_representation[\"context_rule\"] = rule\n    serialized_representation[\"doc\"] = None\n\n    return ConTextModifier(**serialized_representation)\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.limit_scope","title":"<code>limit_scope(other)</code>","text":"<p>If self and other have the same category or if other has a directionality of 'terminate', use the span of other to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not 'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of CHF, but there is pneumonia'</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ConTextModifier</code> <p>The modifier to check against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the other modifier modified the scope of self.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def limit_scope(self, other: ConTextModifier) -&gt; bool:\n    \"\"\"\n    If self and other have the same category or if other has a directionality of 'terminate', use the span of other\n    to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of\n    modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not\n    'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of\n    CHF, but there is pneumonia'\n\n    Args:\n        other: The modifier to check against.\n\n    Returns:\n        Whether the other modifier modified the scope of self.\n    \"\"\"\n    if not tuple_overlaps(self.scope_span, other.scope_span):\n        return False\n    if self.direction.upper() == \"TERMINATE\":\n        return False\n    # Check if the other modifier is a type which can modify self\n    # or if they are the same category. If not, don't reduce scope.\n    if (\n        (other.direction.upper() != \"TERMINATE\")\n        and (other.category.upper() not in self.rule.terminated_by)\n        and (other.category.upper() != self.category.upper())\n    ):\n        return False\n\n    # If two modifiers have the same category but modify different target types,\n    # don't limit scope.\n    if self.category == other.category and (\n        (self.allowed_types != other.allowed_types)\n        or (self.excluded_types != other.excluded_types)\n    ):\n        return False\n\n    orig_scope = self.scope_span\n    if self.direction.lower() in (\"forward\", \"bidirectional\"):\n        if other &gt; self:\n            self._scope_end = min(self._scope_end, other.modifier_span[0])\n    if self.direction.lower() in (\"backward\", \"bidirectional\"):\n        if other &lt; self:\n            self._scope_start = max(self._scope_start, other.modifier_span[1])\n    return orig_scope != self.scope_span\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.modifies","title":"<code>modifies(target)</code>","text":"<p>Checks whether the target is within the modifier scope and if self is allowed to modify target.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>a spaCy span representing a target concept.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the target is within <code>modifier_scope</code> and if self is allowed to modify the target.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def modifies(self, target: Span) -&gt; bool:\n    \"\"\"\n    Checks whether the target is within the modifier scope and if self is allowed to modify target.\n\n    Args:\n        target: a spaCy span representing a target concept.\n\n    Returns:\n        Whether the target is within `modifier_scope` and if self is allowed to modify the target.\n    \"\"\"\n    # If the target and modifier overlap, meaning at least one token\n    # one extracted as both a target and modifier, return False\n    # to avoid self-modifying concepts\n\n    if tuple_overlaps(\n        self.modifier_span, (target.start, target.end)\n    ):  # self.overlaps(target):\n        return False\n    if self.direction in (\"TERMINATE\", \"PSEUDO\"):\n        return False\n    if not self.allows(target.label_.upper()):\n        return False\n\n    if tuple_overlaps(self.scope_span, (target.start, target.end)):\n        if not self.on_modifies(target):\n            return False\n        else:\n            return True\n    return False\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.modify","title":"<code>modify(target)</code>","text":"<p>Add target to the list of self._targets and increment self._num_targets.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>The spaCy span to add.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def modify(self, target: Span):\n    \"\"\"\n    Add target to the list of self._targets and increment self._num_targets.\n\n    Args:\n        target: The spaCy span to add.\n    \"\"\"\n    self._targets.append(target)\n    self._num_targets += 1\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.on_modifies","title":"<code>on_modifies(target)</code>","text":"<p>If the ConTextRule used to define a ConTextModifier has an <code>on_modifies</code> callback function, evaluate and return either True or False.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>The spaCy span to evaluate.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>The result of the <code>on_modifies</code> callback for the rule. True if the callback is None.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def on_modifies(self, target: Span) -&gt; bool:\n    \"\"\"\n    If the ConTextRule used to define a ConTextModifier has an `on_modifies` callback function, evaluate and return\n    either True or False.\n\n    Args:\n        target: The spaCy span to evaluate.\n\n    Returns:\n        The result of the `on_modifies` callback for the rule. True if the callback is None.\n    \"\"\"\n    if self.rule.on_modifies is None:\n        return True\n    # Find the span in between the target and modifier\n    start = min(target.end, self._end)\n    end = max(target.start, self._end)\n    span_between = target.doc[start:end]\n    rslt = self.rule.on_modifies(\n        target, target.doc[self._start : self._end], span_between\n    )\n    if rslt not in (True, False):\n        raise ValueError(\n            \"The on_modifies function must return either True or False indicating \"\n            \"whether a modify modifies a target. Actual value: {0}\".format(rslt)\n        )\n    return rslt\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.reduce_targets","title":"<code>reduce_targets()</code>","text":"<p>Reduces the number of targets to the n-closest targets based on the value of <code>self.max_targets</code>. If <code>self.max_targets</code> is None, no pruning is done.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def reduce_targets(self):\n    \"\"\"\n    Reduces the number of targets to the n-closest targets based on the value of `self.max_targets`. If\n    `self.max_targets` is None, no pruning is done.\n    \"\"\"\n    if self.max_targets is None or self.num_targets &lt;= self.max_targets:\n        return\n\n    target_dists = []\n    for target in self._targets:\n        dist = min(abs(self._start - target.end), abs(target.start - self._end))\n        target_dists.append((target, dist))\n    srtd_targets, _ = zip(*sorted(target_dists, key=lambda x: x[1]))\n    self._targets = srtd_targets[: self.max_targets]\n    self._num_targets = len(self._targets)\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Serialized Representation of the modifier</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def serialized_representation(self):\n    \"\"\"\n    Serialized Representation of the modifier\n    \"\"\"\n    dict_repr = dict()\n    dict_repr[\"context_rule\"] = self.rule.to_dict()\n    dict_repr[\"start\"] = self._start\n    dict_repr[\"end\"] = self._end\n    dict_repr[\"max_scope\"] = self._max_scope\n    dict_repr[\"scope_start\"] = self._scope_start\n    dict_repr[\"scope_end\"] = self._scope_end\n\n    return dict_repr\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextModifier.update_scope","title":"<code>update_scope(span)</code>","text":"<p>Changes the scope of self to be the given spaCy span.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>a spaCy Span which contains the scope which a modifier should cover.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def update_scope(self, span: Span):\n    \"\"\"\n    Changes the scope of self to be the given spaCy span.\n\n    Args:\n        span: a spaCy Span which contains the scope which a modifier should cover.\n    \"\"\"\n    self._scope_start = span.start\n    self._scope_end = span.end\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextRule","title":"<code>ConTextRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>A ConTextRule defines a ConText modifier. ConTextRules are rules which define which spans are extracted as modifiers and how they behave, such as the phrase to be matched, the category/semantic class, the direction of the modifier in the text, and what types of target spans can be modified.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>class ConTextRule(BaseRule):\n    \"\"\"\n    A ConTextRule defines a ConText modifier. ConTextRules are rules which define which spans are extracted as modifiers\n    and how they behave, such as the phrase to be matched, the category/semantic class, the direction of the modifier in\n    the text, and what types of target spans can be modified.\n    \"\"\"\n\n    _ALLOWED_DIRECTIONS = (\n        \"FORWARD\",\n        \"BACKWARD\",\n        \"BIDIRECTIONAL\",\n        \"TERMINATE\",\n        \"PSEUDO\"\n    )\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"direction\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"allowed_types\",\n        \"excluded_types\",\n        \"max_targets\",\n        \"max_scope\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n        direction: str = \"BIDIRECTIONAL\",\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        on_modifies: Optional[Callable[[Span, Span, Span], bool]] = None,\n        allowed_types: Optional[Set[str]] = None,\n        excluded_types: Optional[Set[str]] = None,\n        max_scope: Optional[int] = None,\n        max_targets: Optional[int] = None,\n        terminated_by: Optional[Set[str]] = None,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Creates a ConTextRule object.\n\n        The primary arguments of `literal` `category`, and `direction` define the span of text to be matched, the\n        semantic category, and the direction within the sentence in which the modifier operates.\n        Other arguments specify additional custom logic such as:\n            - Additional control over what text can be matched as a modifier (pattern and on_match)\n            - Which types of targets can be modified (allowed_types, excluded_types)\n            - The scope size and number of targets that a modifier can modify (max_targets, max_scope)\n            - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,\n            terminated_by)\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            direction: The directionality or action of a modifier. This defines which part of a sentence a modifier will\n                include as its scope. Entities within the scope will be considered to be modified.\n                Valid values are:\n                - \"FORWARD\": Scope will begin after the end of a modifier and move to the right\n                - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left\n                - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier\n                - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:\n                    \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying\n                    \"pneumonia\"\n                - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating\n                    superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the\n                    phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a\n                    modifier.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            on_modifies: Callback function to run when building an edge between a target and a modifier. This allows\n                specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The\n                callable should take 3 arguments:\n                    target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')\n                    modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')\n                    span_between: The Span between the target and modifier in question.\n                Should return either True or False. If returns False, then the modifier will not modify the target.\n            allowed_types: A collection of target labels to allow a modifier to modify. If None, will apply to any type\n                not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used.\n                An error will be thrown if both are not None.\n            excluded_types: A collection of target labels which this modifier cannot modify. If None, will apply to all\n                target types unless allowed_types is not None.\n            max_scope: A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will\n                include the entire sentence in the direction of `direction` and the entire sentence for \"BIDIRECTIONAL\".\n                This is useful for requiring modifiers be very close to a concept in the text or for preventing long\n                modifier ranges caused by sentence splitting problems.\n            max_targets: The maximum number of targets which a modifier can modify. If None, will modify all targets in\n                its scope.\n            terminated_by: An optional collection of other modifier categories which will terminate the scope of this\n                modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has\n                terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the\n                positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\".\n                This helps prevent multiple conflicting modifiers from distributing too far across a sentence.\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category.upper(), pattern, on_match, metadata)\n        self.on_modifies = on_modifies\n\n        if allowed_types is not None and excluded_types is not None:\n            raise ValueError(\n                \"A ConTextRule was instantiated with non-null values for both allowed_types and excluded_types. \"\n                \"Only one of these can be non-null.\"\n            )\n        if allowed_types is not None:\n            self.allowed_types = {label.upper() for label in allowed_types}\n        else:\n            self.allowed_types = None\n        if excluded_types is not None:\n            self.excluded_types = {label.upper() for label in excluded_types}\n        else:\n            self.excluded_types = None\n\n        if max_targets is not None and max_targets &lt;= 0:\n            raise ValueError(\"max_targets must be &gt;= 0 or None.\")\n        self.max_targets = max_targets\n        if max_scope is not None and max_scope &lt;= 0:\n            raise ValueError(\"max_scope must be &gt;= 0 or None.\")\n        self.max_scope = max_scope\n        if terminated_by is None:\n            terminated_by = set()\n        else:\n            if isinstance(terminated_by, str):\n                raise ValueError(\n                    f\"terminated_by must be an iterable, such as a list or set, not {terminated_by}.\"\n                )\n            terminated_by = {string.upper() for string in terminated_by}\n\n        self.terminated_by = terminated_by\n\n        self.metadata = metadata\n\n        if direction.upper() not in self._ALLOWED_DIRECTIONS:\n            raise ValueError(\n                \"Direction {0} not recognized. Must be one of: {1}\".format(\n                    direction, self._ALLOWED_DIRECTIONS\n                )\n            )\n        self.direction = direction.upper()\n\n    @classmethod\n    def from_json(cls, filepath) -&gt; List[ConTextRule]:\n        \"\"\"\n        Reads in a lexicon of modifiers from a JSON file under the key `context_rules`.\n\n        Args:\n            filepath: The .json file containing modifier rules. Must contain `context_rules` key containing the rule\n                JSONs.\n\n        Returns:\n            A list of ConTextRules objects read from the JSON.\n        \"\"\"\n\n        with open(filepath) as file:\n            modifier_data = json.load(file)\n        context_rules = []\n        for data in modifier_data[\"context_rules\"]:\n            context_rules.append(ConTextRule.from_dict(data))\n        return context_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict) -&gt; ConTextRule:\n        \"\"\"\n        Reads a dictionary into a ConTextRule.\n\n        Args:\n            rule_dict: The dictionary to convert.\n\n        Returns:\n            The ConTextRule created from the dictionary.\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                \"JSON object contains invalid keys: {0}.\\n\"\n                \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n            )\n            raise ValueError(msg)\n        rule = ConTextRule(**rule_dict)\n        return rule\n\n    def to_dict(self):\n        \"\"\"\n        Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.\n\n        Returns:\n            The dictionary containing the ConTextRule info.\n        \"\"\"\n\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if isinstance(value, set):\n                value = list(value)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    @classmethod\n    def to_json(cls, context_rules: List[ConTextRule], filepath: str):\n        \"\"\"Writes ConTextItems to a json file.\n\n            Args:\n            context_rules: a list of ContextRules that will be written to a file.\n            filepath: the .json file to contain modifier rules\n        \"\"\"\n        import json\n\n        data = {\"context_rules\": [rule.to_dict() for rule in context_rules]}\n        with open(filepath, \"w\") as file:\n            json.dump(data, file, indent=4)\n\n    def __repr__(self):\n        return (\n            f\"ConTextRule(literal='{self.literal}', category='{self.category}', pattern={self.pattern}, \"\n            f\"direction='{self.direction}')\"\n        )\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextRule.__init__","title":"<code>__init__(literal, category, pattern=None, direction='BIDIRECTIONAL', on_match=None, on_modifies=None, allowed_types=None, excluded_types=None, max_scope=None, max_targets=None, terminated_by=None, metadata=None)</code>","text":"<p>Creates a ConTextRule object.</p> <p>The primary arguments of <code>literal</code> <code>category</code>, and <code>direction</code> define the span of text to be matched, the semantic category, and the direction within the sentence in which the modifier operates. Other arguments specify additional custom logic such as:     - Additional control over what text can be matched as a modifier (pattern and on_match)     - Which types of targets can be modified (allowed_types, excluded_types)     - The scope size and number of targets that a modifier can modify (max_targets, max_scope)     - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,     terminated_by)</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[str, List[Dict[str, str]]]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>direction</code> <code>str</code> <p>The directionality or action of a modifier. This defines which part of a sentence a modifier will include as its scope. Entities within the scope will be considered to be modified. Valid values are: - \"FORWARD\": Scope will begin after the end of a modifier and move to the right - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:     \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying     \"pneumonia\" - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating     superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the     phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a     modifier.</p> <code>'BIDIRECTIONAL'</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>on_modifies</code> <code>Optional[Callable[[Span, Span, Span], bool]]</code> <p>Callback function to run when building an edge between a target and a modifier. This allows specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The callable should take 3 arguments:     target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')     modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')     span_between: The Span between the target and modifier in question. Should return either True or False. If returns False, then the modifier will not modify the target.</p> <code>None</code> <code>allowed_types</code> <code>Optional[Set[str]]</code> <p>A collection of target labels to allow a modifier to modify. If None, will apply to any type not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used. An error will be thrown if both are not None.</p> <code>None</code> <code>excluded_types</code> <code>Optional[Set[str]]</code> <p>A collection of target labels which this modifier cannot modify. If None, will apply to all target types unless allowed_types is not None.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will include the entire sentence in the direction of <code>direction</code> and the entire sentence for \"BIDIRECTIONAL\". This is useful for requiring modifiers be very close to a concept in the text or for preventing long modifier ranges caused by sentence splitting problems.</p> <code>None</code> <code>max_targets</code> <code>Optional[int]</code> <p>The maximum number of targets which a modifier can modify. If None, will modify all targets in its scope.</p> <code>None</code> <code>terminated_by</code> <code>Optional[Set[str]]</code> <p>An optional collection of other modifier categories which will terminate the scope of this modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\". This helps prevent multiple conflicting modifiers from distributing too far across a sentence.</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n    direction: str = \"BIDIRECTIONAL\",\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    on_modifies: Optional[Callable[[Span, Span, Span], bool]] = None,\n    allowed_types: Optional[Set[str]] = None,\n    excluded_types: Optional[Set[str]] = None,\n    max_scope: Optional[int] = None,\n    max_targets: Optional[int] = None,\n    terminated_by: Optional[Set[str]] = None,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Creates a ConTextRule object.\n\n    The primary arguments of `literal` `category`, and `direction` define the span of text to be matched, the\n    semantic category, and the direction within the sentence in which the modifier operates.\n    Other arguments specify additional custom logic such as:\n        - Additional control over what text can be matched as a modifier (pattern and on_match)\n        - Which types of targets can be modified (allowed_types, excluded_types)\n        - The scope size and number of targets that a modifier can modify (max_targets, max_scope)\n        - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,\n        terminated_by)\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        direction: The directionality or action of a modifier. This defines which part of a sentence a modifier will\n            include as its scope. Entities within the scope will be considered to be modified.\n            Valid values are:\n            - \"FORWARD\": Scope will begin after the end of a modifier and move to the right\n            - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left\n            - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier\n            - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:\n                \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying\n                \"pneumonia\"\n            - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating\n                superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the\n                phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a\n                modifier.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        on_modifies: Callback function to run when building an edge between a target and a modifier. This allows\n            specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The\n            callable should take 3 arguments:\n                target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')\n                modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')\n                span_between: The Span between the target and modifier in question.\n            Should return either True or False. If returns False, then the modifier will not modify the target.\n        allowed_types: A collection of target labels to allow a modifier to modify. If None, will apply to any type\n            not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used.\n            An error will be thrown if both are not None.\n        excluded_types: A collection of target labels which this modifier cannot modify. If None, will apply to all\n            target types unless allowed_types is not None.\n        max_scope: A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will\n            include the entire sentence in the direction of `direction` and the entire sentence for \"BIDIRECTIONAL\".\n            This is useful for requiring modifiers be very close to a concept in the text or for preventing long\n            modifier ranges caused by sentence splitting problems.\n        max_targets: The maximum number of targets which a modifier can modify. If None, will modify all targets in\n            its scope.\n        terminated_by: An optional collection of other modifier categories which will terminate the scope of this\n            modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has\n            terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the\n            positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\".\n            This helps prevent multiple conflicting modifiers from distributing too far across a sentence.\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category.upper(), pattern, on_match, metadata)\n    self.on_modifies = on_modifies\n\n    if allowed_types is not None and excluded_types is not None:\n        raise ValueError(\n            \"A ConTextRule was instantiated with non-null values for both allowed_types and excluded_types. \"\n            \"Only one of these can be non-null.\"\n        )\n    if allowed_types is not None:\n        self.allowed_types = {label.upper() for label in allowed_types}\n    else:\n        self.allowed_types = None\n    if excluded_types is not None:\n        self.excluded_types = {label.upper() for label in excluded_types}\n    else:\n        self.excluded_types = None\n\n    if max_targets is not None and max_targets &lt;= 0:\n        raise ValueError(\"max_targets must be &gt;= 0 or None.\")\n    self.max_targets = max_targets\n    if max_scope is not None and max_scope &lt;= 0:\n        raise ValueError(\"max_scope must be &gt;= 0 or None.\")\n    self.max_scope = max_scope\n    if terminated_by is None:\n        terminated_by = set()\n    else:\n        if isinstance(terminated_by, str):\n            raise ValueError(\n                f\"terminated_by must be an iterable, such as a list or set, not {terminated_by}.\"\n            )\n        terminated_by = {string.upper() for string in terminated_by}\n\n    self.terminated_by = terminated_by\n\n    self.metadata = metadata\n\n    if direction.upper() not in self._ALLOWED_DIRECTIONS:\n        raise ValueError(\n            \"Direction {0} not recognized. Must be one of: {1}\".format(\n                direction, self._ALLOWED_DIRECTIONS\n            )\n        )\n    self.direction = direction.upper()\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a ConTextRule.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <p>The dictionary to convert.</p> required <p>Returns:</p> Type Description <code>ConTextRule</code> <p>The ConTextRule created from the dictionary.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict) -&gt; ConTextRule:\n    \"\"\"\n    Reads a dictionary into a ConTextRule.\n\n    Args:\n        rule_dict: The dictionary to convert.\n\n    Returns:\n        The ConTextRule created from the dictionary.\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            \"JSON object contains invalid keys: {0}.\\n\"\n            \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n        )\n        raise ValueError(msg)\n    rule = ConTextRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Reads in a lexicon of modifiers from a JSON file under the key <code>context_rules</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>The .json file containing modifier rules. Must contain <code>context_rules</code> key containing the rule JSONs.</p> required <p>Returns:</p> Type Description <code>List[ConTextRule]</code> <p>A list of ConTextRules objects read from the JSON.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath) -&gt; List[ConTextRule]:\n    \"\"\"\n    Reads in a lexicon of modifiers from a JSON file under the key `context_rules`.\n\n    Args:\n        filepath: The .json file containing modifier rules. Must contain `context_rules` key containing the rule\n            JSONs.\n\n    Returns:\n        A list of ConTextRules objects read from the JSON.\n    \"\"\"\n\n    with open(filepath) as file:\n        modifier_data = json.load(file)\n    context_rules = []\n    for data in modifier_data[\"context_rules\"]:\n        context_rules.append(ConTextRule.from_dict(data))\n    return context_rules\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.</p> <p>Returns:</p> Type Description <p>The dictionary containing the ConTextRule info.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.\n\n    Returns:\n        The dictionary containing the ConTextRule info.\n    \"\"\"\n\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if isinstance(value, set):\n            value = list(value)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"singlepage/#medspacy.context.ConTextRule.to_json","title":"<code>to_json(context_rules, filepath)</code>  <code>classmethod</code>","text":"<p>Writes ConTextItems to a json file.</p> <p>Args: context_rules: a list of ContextRules that will be written to a file. filepath: the .json file to contain modifier rules</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef to_json(cls, context_rules: List[ConTextRule], filepath: str):\n    \"\"\"Writes ConTextItems to a json file.\n\n        Args:\n        context_rules: a list of ContextRules that will be written to a file.\n        filepath: the .json file to contain modifier rules\n    \"\"\"\n    import json\n\n    data = {\"context_rules\": [rule.to_dict() for rule in context_rules]}\n    with open(filepath, \"w\") as file:\n        json.dump(data, file, indent=4)\n</code></pre>"},{"location":"singlepage/#medspacy.context.context","title":"<code>context</code>","text":"<p>The ConText definiton.</p>"},{"location":"singlepage/#medspacy.context.context.ConText","title":"<code>ConText</code>","text":"<p>The ConText for spaCy processing.</p> <p>This component matches modifiers in a Doc, defines their scope, and identifies edges between targets and modifiers. Sets two spaCy extensions:         - Span..modifiers: a list of ConTextModifier objects which modify a target Span         - Doc..context_graph: a ConText graph object which contains the targets,             modifiers, and edges between them.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@Language.factory(\"medspacy_context\")\nclass ConText:\n    \"\"\"\n    The ConText for spaCy processing.\n\n    This component matches modifiers in a Doc, defines their scope, and identifies edges between targets and modifiers.\n    Sets two spaCy extensions:\n            - Span._.modifiers: a list of ConTextModifier objects which modify a target Span\n            - Doc._.context_graph: a ConText graph object which contains the targets,\n                modifiers, and edges between them.\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_context\",\n        rules: Optional[str] = \"default\",\n        language_code: str = 'en',\n        phrase_matcher_attr: str = \"LOWER\",\n        allowed_types: Optional[Set[str]] = None,\n        excluded_types: Optional[Set[str]] = None,\n        terminating_types: Optional[Dict[str, Iterable[str]]] = None,\n        max_scope: Optional[int] = None,\n        max_targets: Optional[int] = None,\n        prune_on_modifier_overlap: bool = True,\n        prune_on_target_overlap: bool = False,\n        span_attrs: Union[\n            Literal[\"default\"], Dict[str, Dict[str, Any]], None\n        ] = \"default\",\n        input_span_type: Union[Literal[\"ents\", \"group\"]] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        \"\"\"\n        Creates a new ConText object.\n\n        Args:\n            nlp: A SpaCy Language object.\n            name: The name of the component.\n            rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n                original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If\n                None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules\n                directly through `ConText.add`.\n            language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n                and also the /resources directory to see which resources might be available in each language.\n                Default is \"en\" for English.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            allowed_types: A global list of types included by context. Rules will operate on only spans with these\n                labels.\n            excluded_types: A global list of types excluded by context. Rules will not operate on spans with these\n                labels.\n            terminating_types: A global map of types to the types that can terminate them. This can be used to apply\n                terminations to all rules of a particular type rather than adding to every rule individually in the\n                ContextRule object.\n            max_scope: The number of tokens around a modifier in a target can be modified. Default value is None,\n                Context will use the sentence boundaries. If a value greater than zero, applies the window globally.\n                Both options will be overridden by a more specific value in a ContextRule.\n            max_targets: The maximum number of targets a modifier can modify. Default value is None, context will modify\n                all targets in its scope. If a value greater than zero, applies this value globally. Both options will\n                be overridden by a more specific value in a ContextRule.\n            prune_on_modifier_overlap: Whether to prune modifiers which are substrings of another modifier. If True,\n                will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both\n                ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify\n                afib. Default True.\n            prune_on_target_overlap: Whether to remove any matched modifiers which overlap with target entities. If\n                False, any overlapping modifiers will not modify the overlapping entity but will still modify any other\n                targets in its scope. Default False.\n            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n                `DEFAULT_ATTRIBUTES`. If a dictionary, format is mapping context modifier categories to a dictionary\n                containing the attribute name and the value to set the attribute to when a  span is modified by a\n                modifier of that category. If None, no attributes will be modified.\n            input_span_type: \"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans\n                in doc.ents. \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n                \"medspacy_spans\".\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self.prune_on_modifier_overlap = prune_on_modifier_overlap\n        self.prune_on_target_overlap = prune_on_target_overlap\n        self.input_span_type = input_span_type\n        self.span_group_name = span_group_name\n        self.context_attributes_mapping = None\n\n        self.DEFAULT_RULES_FILEPATH = path.join(\n            Path(__file__).resolve().parents[2], \"resources\", language_code.lower(), \"context_rules.json\"\n        )\n\n        self.__matcher = MedspacyMatcher(\n            nlp,\n            name=name,\n            phrase_matcher_attr=phrase_matcher_attr,\n            prune=prune_on_modifier_overlap,\n        )\n\n        if span_attrs == \"default\":\n            self.context_attributes_mapping = DEFAULT_ATTRIBUTES\n            self.register_default_attributes()\n        elif span_attrs:\n            for _, attr_dict in span_attrs.items():\n                for attr_name in attr_dict.keys():\n                    if not Span.has_extension(attr_name):\n                        raise ValueError(\n                            f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                            f\"called for your pipeline's custom extensions.\"\n                        )\n            self.context_attributes_mapping = span_attrs\n\n        self.register_graph_attributes()\n\n        if max_scope is not None:\n            if not (isinstance(max_scope, int) and max_scope &gt; 0):\n                raise ValueError(\n                    f\"If 'max_scope' must be a value greater than 0, not the current value: {max_scope}\"\n                )\n        self.max_scope = max_scope\n\n        self.allowed_types = allowed_types\n        self.excluded_types = excluded_types\n        self.max_targets = max_targets\n\n        self.terminating_types = dict()\n        if terminating_types:\n            self.terminating_types = {\n                k.upper(): v for (k, v) in terminating_types.items()\n            }\n\n        rule_path = None\n        if rules == \"default\":\n            rule_path = self.DEFAULT_RULES_FILEPATH\n        else:\n            rule_path = rules\n\n        if rule_path:\n            self.add(ConTextRule.from_json(rule_path))\n\n    @property\n    def rules(self):\n        \"\"\"\n        Returns list of ConTextRules available to context.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def categories(self):\n        \"\"\"\n        Returns list of categories available that Context might produce.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules):\n        \"\"\"\n        Adds ConTextRules to Context.\n\n        Args:\n            rules: A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.\n        \"\"\"\n        if isinstance(rules, ConTextRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, ConTextRule):\n                raise TypeError(f\"Rules must type ConTextRule, not {type(rule)}.\")\n\n            # If global attributes like allowed_types and max_scope are defined,\n            # check if the ConTextRule has them defined. If not, set to the global\n            for attr in (\n                \"allowed_types\",\n                \"excluded_types\",\n                \"max_scope\",\n                \"max_targets\",\n            ):\n                value = getattr(self, attr)\n                if value is None:  # No global value set\n                    continue\n                if (\n                    getattr(rule, attr) is None\n                ):  # If the direction itself has it defined, don't override\n                    setattr(rule, attr, value)\n\n            # Check custom termination points\n            if rule.category.upper() in self.terminating_types:\n                for other_modifier in self.terminating_types[rule.category.upper()]:\n                    rule.terminated_by.add(other_modifier.upper())\n\n        self.__matcher.add(rules)\n\n    @classmethod\n    def register_graph_attributes(cls):\n        \"\"\"\n        Registers spaCy attribute extensions: Span._.modifiers and Doc._.context_graph.\n        \"\"\"\n        try:\n            Span.set_extension(\"modifiers\", default=(), force=True)\n            Doc.set_extension(\"context_graph\", default=None, force=True)\n        except ValueError:  # Extension already set\n            pass\n\n    @classmethod\n    def register_default_attributes(cls):\n        \"\"\"\n        Registers the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n        \"\"\"\n        for attr_name in [\n            \"is_negated\",\n            \"is_uncertain\",\n            \"is_historical\",\n            \"is_hypothetical\",\n            \"is_family\",\n        ]:\n            try:\n                Span.set_extension(attr_name, default=False)\n            except ValueError:  # Extension already set\n                pass\n\n    def set_context_attributes(self, edges):\n        \"\"\"\n        Adds Span-level attributes to targets with modifiers.\n\n        Args:\n            edges: The edges of the ContextGraph to modify.\n        \"\"\"\n        for (target, modifier) in edges:\n            if modifier.category in self.context_attributes_mapping:\n                attr_dict = self.context_attributes_mapping[modifier.category]\n                for attr_name, attr_value in attr_dict.items():\n                    setattr(target._, attr_name, attr_value)\n\n    def __call__(self, doc, targets: str = None) -&gt; Doc:\n        \"\"\"\n        Applies the ConText algorithm to a Doc.\n\n        Args:\n            doc: The spaCy Doc to process.\n            targets: The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects\n\n        Returns:\n            The processed spaCy Doc.\n        \"\"\"\n        if not targets and self.input_span_type == \"ents\":\n            targets = doc.ents\n        elif not targets and self.input_span_type == \"group\":\n            targets = doc.spans[self.span_group_name]\n        elif targets:\n            targets = getattr(doc._, targets)\n        # Store data in ConTextGraph object\n        # TODO: move some of this over to ConTextGraph\n        context_graph = ConTextGraph(\n            prune_on_modifier_overlap=self.prune_on_target_overlap\n        )\n\n        context_graph.targets = targets\n\n        context_graph.modifiers = []\n        matches = self.__matcher(doc)\n\n        for (match_id, start, end) in matches:\n            # Get the ConTextRule object defining this modifier\n            rule = self.__matcher.rule_map[self.nlp.vocab[match_id].text]\n            modifier = ConTextModifier(rule, start, end, doc, max_scope=self.max_scope)\n            context_graph.modifiers.append(modifier)\n\n        context_graph.update_scopes()\n        context_graph.apply_modifiers()\n\n        # Link targets to their modifiers\n        for target, modifier in context_graph.edges:\n            target._.modifiers += (modifier,)\n\n        # If attributes need to be modified\n        if self.context_attributes_mapping:\n            self.set_context_attributes(context_graph.edges)\n\n        doc._.context_graph = context_graph\n\n        return doc\n</code></pre>"},{"location":"singlepage/#medspacy.context.context.ConText.categories","title":"<code>categories</code>  <code>property</code>","text":"<p>Returns list of categories available that Context might produce.</p>"},{"location":"singlepage/#medspacy.context.context.ConText.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"singlepage/#medspacy.context.context.ConText.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Returns list of ConTextRules available to context.</p>"},{"location":"singlepage/#medspacy.context.context.ConText.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"singlepage/#medspacy.context.context.ConText.__call__","title":"<code>__call__(doc, targets=None)</code>","text":"<p>Applies the ConText algorithm to a Doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <p>The spaCy Doc to process.</p> required <code>targets</code> <code>str</code> <p>The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects</p> <code>None</code> <p>Returns:</p> Type Description <code>Doc</code> <p>The processed spaCy Doc.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>def __call__(self, doc, targets: str = None) -&gt; Doc:\n    \"\"\"\n    Applies the ConText algorithm to a Doc.\n\n    Args:\n        doc: The spaCy Doc to process.\n        targets: The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects\n\n    Returns:\n        The processed spaCy Doc.\n    \"\"\"\n    if not targets and self.input_span_type == \"ents\":\n        targets = doc.ents\n    elif not targets and self.input_span_type == \"group\":\n        targets = doc.spans[self.span_group_name]\n    elif targets:\n        targets = getattr(doc._, targets)\n    # Store data in ConTextGraph object\n    # TODO: move some of this over to ConTextGraph\n    context_graph = ConTextGraph(\n        prune_on_modifier_overlap=self.prune_on_target_overlap\n    )\n\n    context_graph.targets = targets\n\n    context_graph.modifiers = []\n    matches = self.__matcher(doc)\n\n    for (match_id, start, end) in matches:\n        # Get the ConTextRule object defining this modifier\n        rule = self.__matcher.rule_map[self.nlp.vocab[match_id].text]\n        modifier = ConTextModifier(rule, start, end, doc, max_scope=self.max_scope)\n        context_graph.modifiers.append(modifier)\n\n    context_graph.update_scopes()\n    context_graph.apply_modifiers()\n\n    # Link targets to their modifiers\n    for target, modifier in context_graph.edges:\n        target._.modifiers += (modifier,)\n\n    # If attributes need to be modified\n    if self.context_attributes_mapping:\n        self.set_context_attributes(context_graph.edges)\n\n    doc._.context_graph = context_graph\n\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.context.context.ConText.__init__","title":"<code>__init__(nlp, name='medspacy_context', rules='default', language_code='en', phrase_matcher_attr='LOWER', allowed_types=None, excluded_types=None, terminating_types=None, max_scope=None, max_targets=None, prune_on_modifier_overlap=True, prune_on_target_overlap=False, span_attrs='default', input_span_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Creates a new ConText object.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A SpaCy Language object.</p> required <code>name</code> <code>str</code> <p>The name of the component.</p> <code>'medspacy_context'</code> <code>rules</code> <code>Optional[str]</code> <p>The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules directly through <code>ConText.add</code>.</p> <code>'default'</code> <code>language_code</code> <code>str</code> <p>Language code to use (ISO code) as a default for loading resources.  See documentation and also the /resources directory to see which resources might be available in each language. Default is \"en\" for English.</p> <code>'en'</code> <code>phrase_matcher_attr</code> <code>str</code> <p>The token attribute to use for PhraseMatcher for rules where <code>pattern</code> is None. Default is 'LOWER'.</p> <code>'LOWER'</code> <code>allowed_types</code> <code>Optional[Set[str]]</code> <p>A global list of types included by context. Rules will operate on only spans with these labels.</p> <code>None</code> <code>excluded_types</code> <code>Optional[Set[str]]</code> <p>A global list of types excluded by context. Rules will not operate on spans with these labels.</p> <code>None</code> <code>terminating_types</code> <code>Optional[Dict[str, Iterable[str]]]</code> <p>A global map of types to the types that can terminate them. This can be used to apply terminations to all rules of a particular type rather than adding to every rule individually in the ContextRule object.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>The number of tokens around a modifier in a target can be modified. Default value is None, Context will use the sentence boundaries. If a value greater than zero, applies the window globally. Both options will be overridden by a more specific value in a ContextRule.</p> <code>None</code> <code>max_targets</code> <code>Optional[int]</code> <p>The maximum number of targets a modifier can modify. Default value is None, context will modify all targets in its scope. If a value greater than zero, applies this value globally. Both options will be overridden by a more specific value in a ContextRule.</p> <code>None</code> <code>prune_on_modifier_overlap</code> <code>bool</code> <p>Whether to prune modifiers which are substrings of another modifier. If True, will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify afib. Default True.</p> <code>True</code> <code>prune_on_target_overlap</code> <code>bool</code> <p>Whether to remove any matched modifiers which overlap with target entities. If False, any overlapping modifiers will not modify the overlapping entity but will still modify any other targets in its scope. Default False.</p> <code>False</code> <code>span_attrs</code> <code>Union[Literal['default'], Dict[str, Dict[str, Any]], None]</code> <p>The optional span attributes to modify. Default option \"default\" uses attributes in <code>DEFAULT_ATTRIBUTES</code>. If a dictionary, format is mapping context modifier categories to a dictionary containing the attribute name and the value to set the attribute to when a  span is modified by a modifier of that category. If None, no attributes will be modified.</p> <code>'default'</code> <code>input_span_type</code> <code>Union[Literal['ents', 'group']]</code> <p>\"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans in doc.ents. \"group\" will modify attributes of spans in the span group specified by <code>span_group_name</code>.</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>The name of the span group used when <code>input_span_type</code> is \"group\". Default is \"medspacy_spans\".</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/context/context.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_context\",\n    rules: Optional[str] = \"default\",\n    language_code: str = 'en',\n    phrase_matcher_attr: str = \"LOWER\",\n    allowed_types: Optional[Set[str]] = None,\n    excluded_types: Optional[Set[str]] = None,\n    terminating_types: Optional[Dict[str, Iterable[str]]] = None,\n    max_scope: Optional[int] = None,\n    max_targets: Optional[int] = None,\n    prune_on_modifier_overlap: bool = True,\n    prune_on_target_overlap: bool = False,\n    span_attrs: Union[\n        Literal[\"default\"], Dict[str, Dict[str, Any]], None\n    ] = \"default\",\n    input_span_type: Union[Literal[\"ents\", \"group\"]] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Creates a new ConText object.\n\n    Args:\n        nlp: A SpaCy Language object.\n        name: The name of the component.\n        rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n            original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If\n            None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules\n            directly through `ConText.add`.\n        language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        allowed_types: A global list of types included by context. Rules will operate on only spans with these\n            labels.\n        excluded_types: A global list of types excluded by context. Rules will not operate on spans with these\n            labels.\n        terminating_types: A global map of types to the types that can terminate them. This can be used to apply\n            terminations to all rules of a particular type rather than adding to every rule individually in the\n            ContextRule object.\n        max_scope: The number of tokens around a modifier in a target can be modified. Default value is None,\n            Context will use the sentence boundaries. If a value greater than zero, applies the window globally.\n            Both options will be overridden by a more specific value in a ContextRule.\n        max_targets: The maximum number of targets a modifier can modify. Default value is None, context will modify\n            all targets in its scope. If a value greater than zero, applies this value globally. Both options will\n            be overridden by a more specific value in a ContextRule.\n        prune_on_modifier_overlap: Whether to prune modifiers which are substrings of another modifier. If True,\n            will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both\n            ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify\n            afib. Default True.\n        prune_on_target_overlap: Whether to remove any matched modifiers which overlap with target entities. If\n            False, any overlapping modifiers will not modify the overlapping entity but will still modify any other\n            targets in its scope. Default False.\n        span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n            `DEFAULT_ATTRIBUTES`. If a dictionary, format is mapping context modifier categories to a dictionary\n            containing the attribute name and the value to set the attribute to when a  span is modified by a\n            modifier of that category. If None, no attributes will be modified.\n        input_span_type: \"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans\n            in doc.ents. \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n            \"medspacy_spans\".\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self.prune_on_modifier_overlap = prune_on_modifier_overlap\n    self.prune_on_target_overlap = prune_on_target_overlap\n    self.input_span_type = input_span_type\n    self.span_group_name = span_group_name\n    self.context_attributes_mapping = None\n\n    self.DEFAULT_RULES_FILEPATH = path.join(\n        Path(__file__).resolve().parents[2], \"resources\", language_code.lower(), \"context_rules.json\"\n    )\n\n    self.__matcher = MedspacyMatcher(\n        nlp,\n        name=name,\n        phrase_matcher_attr=phrase_matcher_attr,\n        prune=prune_on_modifier_overlap,\n    )\n\n    if span_attrs == \"default\":\n        self.context_attributes_mapping = DEFAULT_ATTRIBUTES\n        self.register_default_attributes()\n    elif span_attrs:\n        for _, attr_dict in span_attrs.items():\n            for attr_name in attr_dict.keys():\n                if not Span.has_extension(attr_name):\n                    raise ValueError(\n                        f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                        f\"called for your pipeline's custom extensions.\"\n                    )\n        self.context_attributes_mapping = span_attrs\n\n    self.register_graph_attributes()\n\n    if max_scope is not None:\n        if not (isinstance(max_scope, int) and max_scope &gt; 0):\n            raise ValueError(\n                f\"If 'max_scope' must be a value greater than 0, not the current value: {max_scope}\"\n            )\n    self.max_scope = max_scope\n\n    self.allowed_types = allowed_types\n    self.excluded_types = excluded_types\n    self.max_targets = max_targets\n\n    self.terminating_types = dict()\n    if terminating_types:\n        self.terminating_types = {\n            k.upper(): v for (k, v) in terminating_types.items()\n        }\n\n    rule_path = None\n    if rules == \"default\":\n        rule_path = self.DEFAULT_RULES_FILEPATH\n    else:\n        rule_path = rules\n\n    if rule_path:\n        self.add(ConTextRule.from_json(rule_path))\n</code></pre>"},{"location":"singlepage/#medspacy.context.context.ConText.add","title":"<code>add(rules)</code>","text":"<p>Adds ConTextRules to Context.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <p>A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.</p> required Source code in <code>medspacy/context/context.py</code> <pre><code>def add(self, rules):\n    \"\"\"\n    Adds ConTextRules to Context.\n\n    Args:\n        rules: A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.\n    \"\"\"\n    if isinstance(rules, ConTextRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, ConTextRule):\n            raise TypeError(f\"Rules must type ConTextRule, not {type(rule)}.\")\n\n        # If global attributes like allowed_types and max_scope are defined,\n        # check if the ConTextRule has them defined. If not, set to the global\n        for attr in (\n            \"allowed_types\",\n            \"excluded_types\",\n            \"max_scope\",\n            \"max_targets\",\n        ):\n            value = getattr(self, attr)\n            if value is None:  # No global value set\n                continue\n            if (\n                getattr(rule, attr) is None\n            ):  # If the direction itself has it defined, don't override\n                setattr(rule, attr, value)\n\n        # Check custom termination points\n        if rule.category.upper() in self.terminating_types:\n            for other_modifier in self.terminating_types[rule.category.upper()]:\n                rule.terminated_by.add(other_modifier.upper())\n\n    self.__matcher.add(rules)\n</code></pre>"},{"location":"singlepage/#medspacy.context.context.ConText.register_default_attributes","title":"<code>register_default_attributes()</code>  <code>classmethod</code>","text":"<p>Registers the default values for the Span attributes defined in <code>DEFAULT_ATTRIBUTES</code>.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@classmethod\ndef register_default_attributes(cls):\n    \"\"\"\n    Registers the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n    \"\"\"\n    for attr_name in [\n        \"is_negated\",\n        \"is_uncertain\",\n        \"is_historical\",\n        \"is_hypothetical\",\n        \"is_family\",\n    ]:\n        try:\n            Span.set_extension(attr_name, default=False)\n        except ValueError:  # Extension already set\n            pass\n</code></pre>"},{"location":"singlepage/#medspacy.context.context.ConText.register_graph_attributes","title":"<code>register_graph_attributes()</code>  <code>classmethod</code>","text":"<p>Registers spaCy attribute extensions: Span..modifiers and Doc..context_graph.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@classmethod\ndef register_graph_attributes(cls):\n    \"\"\"\n    Registers spaCy attribute extensions: Span._.modifiers and Doc._.context_graph.\n    \"\"\"\n    try:\n        Span.set_extension(\"modifiers\", default=(), force=True)\n        Doc.set_extension(\"context_graph\", default=None, force=True)\n    except ValueError:  # Extension already set\n        pass\n</code></pre>"},{"location":"singlepage/#medspacy.context.context.ConText.set_context_attributes","title":"<code>set_context_attributes(edges)</code>","text":"<p>Adds Span-level attributes to targets with modifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <p>The edges of the ContextGraph to modify.</p> required Source code in <code>medspacy/context/context.py</code> <pre><code>def set_context_attributes(self, edges):\n    \"\"\"\n    Adds Span-level attributes to targets with modifiers.\n\n    Args:\n        edges: The edges of the ContextGraph to modify.\n    \"\"\"\n    for (target, modifier) in edges:\n        if modifier.category in self.context_attributes_mapping:\n            attr_dict = self.context_attributes_mapping[modifier.category]\n            for attr_name, attr_value in attr_dict.items():\n                setattr(target._, attr_name, attr_value)\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_graph","title":"<code>context_graph</code>","text":""},{"location":"singlepage/#medspacy.context.context_graph.ConTextGraph","title":"<code>ConTextGraph</code>","text":"<p>The ConTextGraph class defines the internal structure of the ConText algorithm. It stores a collection of modifiers, matched with ConTextRules, and targets from some other source such as the TargetMatcher or a spaCy NER model.</p> <p>Each modifier can have some number of associated targets that it modifies. This relationship is stored as edges of of the graph.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>class ConTextGraph:\n    \"\"\"\n    The ConTextGraph class defines the internal structure of the ConText algorithm. It stores a collection of modifiers,\n    matched with ConTextRules, and targets from some other source such as the TargetMatcher or a spaCy NER model.\n\n    Each modifier can have some number of associated targets that it modifies. This relationship is stored as edges of\n    of the graph.\n    \"\"\"\n\n    def __init__(\n        self,\n        targets: Optional[List[Span]] = None,\n        modifiers: Optional[List[ConTextModifier]] = None,\n        edges: Optional[List] = None,\n        prune_on_modifier_overlap: bool = False,\n    ):\n        \"\"\"\n        Creates a new ConTextGraph object.\n\n        Args:\n            targets: A spans that context might modify.\n            modifiers: A list of ConTextModifiers that might modify the targets.\n            edges: A list of edges between targets and modifiers representing the modification relationship.\n            prune_on_modifier_overlap: Whether to prune modifiers when one modifier completely covers another.\n        \"\"\"\n        self.targets = targets if targets is not None else []\n        self.modifiers = modifiers if modifiers is not None else []\n        self.edges = edges if edges is not None else []\n        self.prune_on_modifier_overlap = prune_on_modifier_overlap\n\n    def update_scopes(self):\n        \"\"\"\n        Update the scope of all ConTextModifier.\n\n        For each modifier in a list of ConTextModifiers, check against each other\n        modifier to see if one of the modifiers should update the other.\n        This allows neighboring similar modifiers to extend each other's\n        scope and allows \"terminate\" modifiers to end a modifier's scope.\n        \"\"\"\n        for i in range(len(self.modifiers) - 1):\n            modifier1 = self.modifiers[i]\n            for j in range(i + 1, len(self.modifiers)):\n                modifier2 = self.modifiers[j]\n                # TODO: Add modifier -&gt; modifier edges\n                modifier1.limit_scope(modifier2)\n                modifier2.limit_scope(modifier1)\n\n    def apply_modifiers(self):\n        \"\"\"\n        Checks each target/modifier pair. If modifier modifies target,\n        create an edge between them.\n        \"\"\"\n        if self.prune_on_modifier_overlap:\n            for i in range(len(self.modifiers) - 1, -1, -1):\n                modifier = self.modifiers[i]\n                for target in self.targets:\n                    if tuple_overlaps(\n                        (target.start, target.end), modifier.modifier_span\n                    ):\n                        self.modifiers.pop(i)\n                        break\n\n        edges = []\n        for target in self.targets:\n            for modifier in self.modifiers:\n                if modifier.modifies(target):\n                    modifier.modify(target)\n\n        # Now do a second pass and reduce the number of targets\n        # for any modifiers with a max_targets int\n        for modifier in self.modifiers:\n            modifier.reduce_targets()\n            for target in modifier._targets:\n                edges.append((target, modifier))\n\n        self.edges = edges\n\n    def __repr__(self):\n        return f\"&lt;ConTextGraph&gt; with {len(self.targets)} targets and {len(self.modifiers)} modifiers\"\n\n    def serialized_representation(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the serialized representation of the ConTextGraph\n        \"\"\"\n        return self.__dict__\n\n    @classmethod\n    def from_serialized_representation(cls, serialized_representation) -&gt; ConTextGraph:\n        \"\"\"\n        Creates the ConTextGraph from the serialized representation\n        \"\"\"\n        context_graph = ConTextGraph(**serialized_representation)\n\n        return context_graph\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_graph.ConTextGraph.__init__","title":"<code>__init__(targets=None, modifiers=None, edges=None, prune_on_modifier_overlap=False)</code>","text":"<p>Creates a new ConTextGraph object.</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>Optional[List[Span]]</code> <p>A spans that context might modify.</p> <code>None</code> <code>modifiers</code> <code>Optional[List[ConTextModifier]]</code> <p>A list of ConTextModifiers that might modify the targets.</p> <code>None</code> <code>edges</code> <code>Optional[List]</code> <p>A list of edges between targets and modifiers representing the modification relationship.</p> <code>None</code> <code>prune_on_modifier_overlap</code> <code>bool</code> <p>Whether to prune modifiers when one modifier completely covers another.</p> <code>False</code> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def __init__(\n    self,\n    targets: Optional[List[Span]] = None,\n    modifiers: Optional[List[ConTextModifier]] = None,\n    edges: Optional[List] = None,\n    prune_on_modifier_overlap: bool = False,\n):\n    \"\"\"\n    Creates a new ConTextGraph object.\n\n    Args:\n        targets: A spans that context might modify.\n        modifiers: A list of ConTextModifiers that might modify the targets.\n        edges: A list of edges between targets and modifiers representing the modification relationship.\n        prune_on_modifier_overlap: Whether to prune modifiers when one modifier completely covers another.\n    \"\"\"\n    self.targets = targets if targets is not None else []\n    self.modifiers = modifiers if modifiers is not None else []\n    self.edges = edges if edges is not None else []\n    self.prune_on_modifier_overlap = prune_on_modifier_overlap\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_graph.ConTextGraph.apply_modifiers","title":"<code>apply_modifiers()</code>","text":"<p>Checks each target/modifier pair. If modifier modifies target, create an edge between them.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def apply_modifiers(self):\n    \"\"\"\n    Checks each target/modifier pair. If modifier modifies target,\n    create an edge between them.\n    \"\"\"\n    if self.prune_on_modifier_overlap:\n        for i in range(len(self.modifiers) - 1, -1, -1):\n            modifier = self.modifiers[i]\n            for target in self.targets:\n                if tuple_overlaps(\n                    (target.start, target.end), modifier.modifier_span\n                ):\n                    self.modifiers.pop(i)\n                    break\n\n    edges = []\n    for target in self.targets:\n        for modifier in self.modifiers:\n            if modifier.modifies(target):\n                modifier.modify(target)\n\n    # Now do a second pass and reduce the number of targets\n    # for any modifiers with a max_targets int\n    for modifier in self.modifiers:\n        modifier.reduce_targets()\n        for target in modifier._targets:\n            edges.append((target, modifier))\n\n    self.edges = edges\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_graph.ConTextGraph.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Creates the ConTextGraph from the serialized representation</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>@classmethod\ndef from_serialized_representation(cls, serialized_representation) -&gt; ConTextGraph:\n    \"\"\"\n    Creates the ConTextGraph from the serialized representation\n    \"\"\"\n    context_graph = ConTextGraph(**serialized_representation)\n\n    return context_graph\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_graph.ConTextGraph.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Returns the serialized representation of the ConTextGraph</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def serialized_representation(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the serialized representation of the ConTextGraph\n    \"\"\"\n    return self.__dict__\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_graph.ConTextGraph.update_scopes","title":"<code>update_scopes()</code>","text":"<p>Update the scope of all ConTextModifier.</p> <p>For each modifier in a list of ConTextModifiers, check against each other modifier to see if one of the modifiers should update the other. This allows neighboring similar modifiers to extend each other's scope and allows \"terminate\" modifiers to end a modifier's scope.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def update_scopes(self):\n    \"\"\"\n    Update the scope of all ConTextModifier.\n\n    For each modifier in a list of ConTextModifiers, check against each other\n    modifier to see if one of the modifiers should update the other.\n    This allows neighboring similar modifiers to extend each other's\n    scope and allows \"terminate\" modifiers to end a modifier's scope.\n    \"\"\"\n    for i in range(len(self.modifiers) - 1):\n        modifier1 = self.modifiers[i]\n        for j in range(i + 1, len(self.modifiers)):\n            modifier2 = self.modifiers[j]\n            # TODO: Add modifier -&gt; modifier edges\n            modifier1.limit_scope(modifier2)\n            modifier2.limit_scope(modifier1)\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier","title":"<code>context_modifier</code>","text":""},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier","title":"<code>ConTextModifier</code>","text":"<p>Represents a concept found by ConText in a document. An instance of this class is the result of ConTextRule matching text in a Doc.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>class ConTextModifier:\n    \"\"\"\n    Represents a concept found by ConText in a document. An instance of this class is the result of ConTextRule matching\n    text in a Doc.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_rule: ConTextRule,\n        start: int,\n        end: int,\n        doc: Doc,\n        scope_start: Optional[int] = None,\n        scope_end: Optional[int] = None,\n        max_scope: Optional[int] = None,\n    ):\n        \"\"\"\n        Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding\n        window. Spans such as entities or other members of span groups that occur within this window can be modified by\n        this ConTextModifier.\n\n        Args:\n            context_rule: The ConTextRule object which defines the modifier.\n            start: The start token index.\n            end: The end token index (non-inclusive).\n            doc: The spaCy Doc which contains this span. This is needed to initialize the modifier but is not\n                maintained.\n            scope_start: The start token index of the scope.\n            scope_end: The end index of the scope.\n            max_scope: Whether to use scope values rather than sentence boundaries for modifications.\n        \"\"\"\n        self._context_rule = context_rule\n        self._start = start\n        self._end = end\n\n        self._targets = []\n        self._num_targets = 0\n\n        self._max_scope = max_scope\n        self._scope_start = scope_start\n        self._scope_end = scope_end\n        if doc is not None and (self._scope_end is None or self._scope_start is None):\n            self.__set_scope(doc)\n\n    @property\n    def modifier_span(self) -&gt; Tuple[int, int]:\n        \"\"\"\n        The spaCy Span object, which is a view of self.doc, covered by this match.\n        \"\"\"\n        return self._start, self._end\n\n    @property\n    def rule(self) -&gt; ConTextRule:\n        \"\"\"\n        Returns the associated context rule.\n        \"\"\"\n        return self._context_rule\n\n    @property\n    def direction(self) -&gt; str:\n        \"\"\"\n        Returns the associated direction.\n        \"\"\"\n        return self.rule.direction\n\n    @property\n    def category(self) -&gt; str:\n        \"\"\"\n        Returns the associated category.\n        \"\"\"\n        return self.rule.category\n\n    @property\n    def scope_span(self) -&gt; Tuple[int, int]:\n        \"\"\"\n        Returns the associated scope.\n        \"\"\"\n        return self._scope_start, self._scope_end\n\n    @property\n    def allowed_types(self) -&gt; Set[str]:\n        \"\"\"\n        Returns the associated allowed types.\n        \"\"\"\n        return self.rule.allowed_types\n\n    @property\n    def excluded_types(self) -&gt; Set[str]:\n        \"\"\"\n        Returns the associated excluded types.\n        \"\"\"\n        return self.rule.excluded_types\n\n    @property\n    def num_targets(self) -&gt; int:\n        \"\"\"\n        Returns the associated number of targets.\n        \"\"\"\n        return self._num_targets\n\n    @property\n    def max_targets(self) -&gt; Union[int, None]:\n        \"\"\"\n        Returns the associated maximum number of targets.\n        \"\"\"\n        return self.rule.max_targets\n\n    @property\n    def max_scope(self) -&gt; Union[int, None]:\n        \"\"\"\n        Returns the associated maximum scope.\n        \"\"\"\n        return self.rule.max_scope\n\n    def __set_scope(self, doc: Doc):\n        \"\"\"\n        Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If\n        self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by\n        self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the\n        direction is \"backward\", it will be [self.start: sentence.start].\n\n        If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be\n        reduced to self.max_scope.\n\n        Args:\n            doc: The spaCy doc to use to set scope.\n        \"\"\"\n        # If ConText is set to use defined windows, do that instead of sentence splitting\n        if self._max_scope:\n            full_scope_span = doc[self._start : self._end]._.window(\n                n=self.rule.max_scope\n            )\n        # Otherwise, use the sentence\n        else:\n            full_scope_span = doc[self._start].sent\n            if full_scope_span is None:\n                raise ValueError(\n                    \"ConText failed because sentence boundaries have not been set. Add an upstream component such as the \"\n                    \"dependency parser, Sentencizer, or PyRuSH to detect sentence boundaries or initialize ConText with \"\n                    \"`max_scope` set to a value greater than 0.\"\n                )\n\n        if self.direction.lower() == \"forward\":\n            self._scope_start, self._scope_end = self._end, full_scope_span.end\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_end = self._end + self.max_scope\n\n        elif self.direction.lower() == \"backward\":\n            self._scope_start, self._scope_end = (\n                full_scope_span.start,\n                self._start,\n            )\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_start = self._start - self.max_scope\n\n        else:  # bidirectional\n            self._scope_start, self._scope_end = (\n                full_scope_span.start,\n                full_scope_span.end,\n            )\n\n            # Set the max scope on either side\n            # Backwards\n            if (\n                self.max_scope is not None\n                and (self._start - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_start = self._start - self.max_scope\n            # Forwards\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._end) &gt; self.max_scope\n            ):\n                self._scope_end = self._end + self.max_scope\n\n    def update_scope(self, span: Span):\n        \"\"\"\n        Changes the scope of self to be the given spaCy span.\n\n        Args:\n            span: a spaCy Span which contains the scope which a modifier should cover.\n        \"\"\"\n        self._scope_start = span.start\n        self._scope_end = span.end\n\n    def limit_scope(self, other: ConTextModifier) -&gt; bool:\n        \"\"\"\n        If self and other have the same category or if other has a directionality of 'terminate', use the span of other\n        to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of\n        modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not\n        'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of\n        CHF, but there is pneumonia'\n\n        Args:\n            other: The modifier to check against.\n\n        Returns:\n            Whether the other modifier modified the scope of self.\n        \"\"\"\n        if not tuple_overlaps(self.scope_span, other.scope_span):\n            return False\n        if self.direction.upper() == \"TERMINATE\":\n            return False\n        # Check if the other modifier is a type which can modify self\n        # or if they are the same category. If not, don't reduce scope.\n        if (\n            (other.direction.upper() != \"TERMINATE\")\n            and (other.category.upper() not in self.rule.terminated_by)\n            and (other.category.upper() != self.category.upper())\n        ):\n            return False\n\n        # If two modifiers have the same category but modify different target types,\n        # don't limit scope.\n        if self.category == other.category and (\n            (self.allowed_types != other.allowed_types)\n            or (self.excluded_types != other.excluded_types)\n        ):\n            return False\n\n        orig_scope = self.scope_span\n        if self.direction.lower() in (\"forward\", \"bidirectional\"):\n            if other &gt; self:\n                self._scope_end = min(self._scope_end, other.modifier_span[0])\n        if self.direction.lower() in (\"backward\", \"bidirectional\"):\n            if other &lt; self:\n                self._scope_start = max(self._scope_start, other.modifier_span[1])\n        return orig_scope != self.scope_span\n\n    def modifies(self, target: Span) -&gt; bool:\n        \"\"\"\n        Checks whether the target is within the modifier scope and if self is allowed to modify target.\n\n        Args:\n            target: a spaCy span representing a target concept.\n\n        Returns:\n            Whether the target is within `modifier_scope` and if self is allowed to modify the target.\n        \"\"\"\n        # If the target and modifier overlap, meaning at least one token\n        # one extracted as both a target and modifier, return False\n        # to avoid self-modifying concepts\n\n        if tuple_overlaps(\n            self.modifier_span, (target.start, target.end)\n        ):  # self.overlaps(target):\n            return False\n        if self.direction in (\"TERMINATE\", \"PSEUDO\"):\n            return False\n        if not self.allows(target.label_.upper()):\n            return False\n\n        if tuple_overlaps(self.scope_span, (target.start, target.end)):\n            if not self.on_modifies(target):\n                return False\n            else:\n                return True\n        return False\n\n    def allows(self, target_label: str) -&gt; bool:\n        \"\"\"\n        Returns whether if a modifier is able to modify a target type.\n\n        Args:\n            target_label: The target type to check.\n\n        Returns:\n            Whether the modifier is allowed to modify a target of the specified type. True if `target_label` in\n            `self.allowed_types` or if `target_label` not in `self.excluded_tupes`. False otherwise.\n        \"\"\"\n        if self.allowed_types is not None:\n            return target_label in self.allowed_types\n        if self.excluded_types is not None:\n            return target_label not in self.excluded_types\n        return True\n\n    def on_modifies(self, target: Span) -&gt; bool:\n        \"\"\"\n        If the ConTextRule used to define a ConTextModifier has an `on_modifies` callback function, evaluate and return\n        either True or False.\n\n        Args:\n            target: The spaCy span to evaluate.\n\n        Returns:\n            The result of the `on_modifies` callback for the rule. True if the callback is None.\n        \"\"\"\n        if self.rule.on_modifies is None:\n            return True\n        # Find the span in between the target and modifier\n        start = min(target.end, self._end)\n        end = max(target.start, self._end)\n        span_between = target.doc[start:end]\n        rslt = self.rule.on_modifies(\n            target, target.doc[self._start : self._end], span_between\n        )\n        if rslt not in (True, False):\n            raise ValueError(\n                \"The on_modifies function must return either True or False indicating \"\n                \"whether a modify modifies a target. Actual value: {0}\".format(rslt)\n            )\n        return rslt\n\n    def modify(self, target: Span):\n        \"\"\"\n        Add target to the list of self._targets and increment self._num_targets.\n\n        Args:\n            target: The spaCy span to add.\n        \"\"\"\n        self._targets.append(target)\n        self._num_targets += 1\n\n    def reduce_targets(self):\n        \"\"\"\n        Reduces the number of targets to the n-closest targets based on the value of `self.max_targets`. If\n        `self.max_targets` is None, no pruning is done.\n        \"\"\"\n        if self.max_targets is None or self.num_targets &lt;= self.max_targets:\n            return\n\n        target_dists = []\n        for target in self._targets:\n            dist = min(abs(self._start - target.end), abs(target.start - self._end))\n            target_dists.append((target, dist))\n        srtd_targets, _ = zip(*sorted(target_dists, key=lambda x: x[1]))\n        self._targets = srtd_targets[: self.max_targets]\n        self._num_targets = len(self._targets)\n\n    def __gt__(self, other: ConTextModifier):\n        return self._start &gt; other.modifier_span[0]\n\n    def __ge__(self, other):\n        return self._start &gt;= other.modifier_span[0]\n\n    def __lt__(self, other):\n        return self._end &lt; other.modifier_span[1]\n\n    def __le__(self, other):\n        return self._end &lt;= other.modifier_span[1]\n\n    def __len__(self):\n        return self._end - self._start\n\n    def __repr__(self):\n        return f\"&lt;ConTextModifier&gt; [{self._start}, {self._end}, {self.category}]\"\n\n    def serialized_representation(self):\n        \"\"\"\n        Serialized Representation of the modifier\n        \"\"\"\n        dict_repr = dict()\n        dict_repr[\"context_rule\"] = self.rule.to_dict()\n        dict_repr[\"start\"] = self._start\n        dict_repr[\"end\"] = self._end\n        dict_repr[\"max_scope\"] = self._max_scope\n        dict_repr[\"scope_start\"] = self._scope_start\n        dict_repr[\"scope_end\"] = self._scope_end\n\n        return dict_repr\n\n    @classmethod\n    def from_serialized_representation(\n        cls, serialized_representation\n    ) -&gt; ConTextModifier:\n        \"\"\"\n        Instantiates the class from the serialized representation\n        \"\"\"\n        rule = ConTextRule.from_dict(serialized_representation[\"context_rule\"])\n\n        serialized_representation[\"context_rule\"] = rule\n        serialized_representation[\"doc\"] = None\n\n        return ConTextModifier(**serialized_representation)\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.allowed_types","title":"<code>allowed_types</code>  <code>property</code>","text":"<p>Returns the associated allowed types.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.category","title":"<code>category</code>  <code>property</code>","text":"<p>Returns the associated category.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.direction","title":"<code>direction</code>  <code>property</code>","text":"<p>Returns the associated direction.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.excluded_types","title":"<code>excluded_types</code>  <code>property</code>","text":"<p>Returns the associated excluded types.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.max_scope","title":"<code>max_scope</code>  <code>property</code>","text":"<p>Returns the associated maximum scope.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.max_targets","title":"<code>max_targets</code>  <code>property</code>","text":"<p>Returns the associated maximum number of targets.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.modifier_span","title":"<code>modifier_span</code>  <code>property</code>","text":"<p>The spaCy Span object, which is a view of self.doc, covered by this match.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.num_targets","title":"<code>num_targets</code>  <code>property</code>","text":"<p>Returns the associated number of targets.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.rule","title":"<code>rule</code>  <code>property</code>","text":"<p>Returns the associated context rule.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.scope_span","title":"<code>scope_span</code>  <code>property</code>","text":"<p>Returns the associated scope.</p>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.__init__","title":"<code>__init__(context_rule, start, end, doc, scope_start=None, scope_end=None, max_scope=None)</code>","text":"<p>Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding window. Spans such as entities or other members of span groups that occur within this window can be modified by this ConTextModifier.</p> <p>Parameters:</p> Name Type Description Default <code>context_rule</code> <code>ConTextRule</code> <p>The ConTextRule object which defines the modifier.</p> required <code>start</code> <code>int</code> <p>The start token index.</p> required <code>end</code> <code>int</code> <p>The end token index (non-inclusive).</p> required <code>doc</code> <code>Doc</code> <p>The spaCy Doc which contains this span. This is needed to initialize the modifier but is not maintained.</p> required <code>scope_start</code> <code>Optional[int]</code> <p>The start token index of the scope.</p> <code>None</code> <code>scope_end</code> <code>Optional[int]</code> <p>The end index of the scope.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>Whether to use scope values rather than sentence boundaries for modifications.</p> <code>None</code> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def __init__(\n    self,\n    context_rule: ConTextRule,\n    start: int,\n    end: int,\n    doc: Doc,\n    scope_start: Optional[int] = None,\n    scope_end: Optional[int] = None,\n    max_scope: Optional[int] = None,\n):\n    \"\"\"\n    Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding\n    window. Spans such as entities or other members of span groups that occur within this window can be modified by\n    this ConTextModifier.\n\n    Args:\n        context_rule: The ConTextRule object which defines the modifier.\n        start: The start token index.\n        end: The end token index (non-inclusive).\n        doc: The spaCy Doc which contains this span. This is needed to initialize the modifier but is not\n            maintained.\n        scope_start: The start token index of the scope.\n        scope_end: The end index of the scope.\n        max_scope: Whether to use scope values rather than sentence boundaries for modifications.\n    \"\"\"\n    self._context_rule = context_rule\n    self._start = start\n    self._end = end\n\n    self._targets = []\n    self._num_targets = 0\n\n    self._max_scope = max_scope\n    self._scope_start = scope_start\n    self._scope_end = scope_end\n    if doc is not None and (self._scope_end is None or self._scope_start is None):\n        self.__set_scope(doc)\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.__set_scope","title":"<code>__set_scope(doc)</code>","text":"<p>Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the direction is \"backward\", it will be [self.start: sentence.start].</p> <p>If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be reduced to self.max_scope.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy doc to use to set scope.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def __set_scope(self, doc: Doc):\n    \"\"\"\n    Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If\n    self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by\n    self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the\n    direction is \"backward\", it will be [self.start: sentence.start].\n\n    If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be\n    reduced to self.max_scope.\n\n    Args:\n        doc: The spaCy doc to use to set scope.\n    \"\"\"\n    # If ConText is set to use defined windows, do that instead of sentence splitting\n    if self._max_scope:\n        full_scope_span = doc[self._start : self._end]._.window(\n            n=self.rule.max_scope\n        )\n    # Otherwise, use the sentence\n    else:\n        full_scope_span = doc[self._start].sent\n        if full_scope_span is None:\n            raise ValueError(\n                \"ConText failed because sentence boundaries have not been set. Add an upstream component such as the \"\n                \"dependency parser, Sentencizer, or PyRuSH to detect sentence boundaries or initialize ConText with \"\n                \"`max_scope` set to a value greater than 0.\"\n            )\n\n    if self.direction.lower() == \"forward\":\n        self._scope_start, self._scope_end = self._end, full_scope_span.end\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_end = self._end + self.max_scope\n\n    elif self.direction.lower() == \"backward\":\n        self._scope_start, self._scope_end = (\n            full_scope_span.start,\n            self._start,\n        )\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_start = self._start - self.max_scope\n\n    else:  # bidirectional\n        self._scope_start, self._scope_end = (\n            full_scope_span.start,\n            full_scope_span.end,\n        )\n\n        # Set the max scope on either side\n        # Backwards\n        if (\n            self.max_scope is not None\n            and (self._start - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_start = self._start - self.max_scope\n        # Forwards\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._end) &gt; self.max_scope\n        ):\n            self._scope_end = self._end + self.max_scope\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.allows","title":"<code>allows(target_label)</code>","text":"<p>Returns whether if a modifier is able to modify a target type.</p> <p>Parameters:</p> Name Type Description Default <code>target_label</code> <code>str</code> <p>The target type to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the modifier is allowed to modify a target of the specified type. True if <code>target_label</code> in</p> <code>bool</code> <p><code>self.allowed_types</code> or if <code>target_label</code> not in <code>self.excluded_tupes</code>. False otherwise.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def allows(self, target_label: str) -&gt; bool:\n    \"\"\"\n    Returns whether if a modifier is able to modify a target type.\n\n    Args:\n        target_label: The target type to check.\n\n    Returns:\n        Whether the modifier is allowed to modify a target of the specified type. True if `target_label` in\n        `self.allowed_types` or if `target_label` not in `self.excluded_tupes`. False otherwise.\n    \"\"\"\n    if self.allowed_types is not None:\n        return target_label in self.allowed_types\n    if self.excluded_types is not None:\n        return target_label not in self.excluded_types\n    return True\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Instantiates the class from the serialized representation</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>@classmethod\ndef from_serialized_representation(\n    cls, serialized_representation\n) -&gt; ConTextModifier:\n    \"\"\"\n    Instantiates the class from the serialized representation\n    \"\"\"\n    rule = ConTextRule.from_dict(serialized_representation[\"context_rule\"])\n\n    serialized_representation[\"context_rule\"] = rule\n    serialized_representation[\"doc\"] = None\n\n    return ConTextModifier(**serialized_representation)\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.limit_scope","title":"<code>limit_scope(other)</code>","text":"<p>If self and other have the same category or if other has a directionality of 'terminate', use the span of other to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not 'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of CHF, but there is pneumonia'</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ConTextModifier</code> <p>The modifier to check against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the other modifier modified the scope of self.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def limit_scope(self, other: ConTextModifier) -&gt; bool:\n    \"\"\"\n    If self and other have the same category or if other has a directionality of 'terminate', use the span of other\n    to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of\n    modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not\n    'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of\n    CHF, but there is pneumonia'\n\n    Args:\n        other: The modifier to check against.\n\n    Returns:\n        Whether the other modifier modified the scope of self.\n    \"\"\"\n    if not tuple_overlaps(self.scope_span, other.scope_span):\n        return False\n    if self.direction.upper() == \"TERMINATE\":\n        return False\n    # Check if the other modifier is a type which can modify self\n    # or if they are the same category. If not, don't reduce scope.\n    if (\n        (other.direction.upper() != \"TERMINATE\")\n        and (other.category.upper() not in self.rule.terminated_by)\n        and (other.category.upper() != self.category.upper())\n    ):\n        return False\n\n    # If two modifiers have the same category but modify different target types,\n    # don't limit scope.\n    if self.category == other.category and (\n        (self.allowed_types != other.allowed_types)\n        or (self.excluded_types != other.excluded_types)\n    ):\n        return False\n\n    orig_scope = self.scope_span\n    if self.direction.lower() in (\"forward\", \"bidirectional\"):\n        if other &gt; self:\n            self._scope_end = min(self._scope_end, other.modifier_span[0])\n    if self.direction.lower() in (\"backward\", \"bidirectional\"):\n        if other &lt; self:\n            self._scope_start = max(self._scope_start, other.modifier_span[1])\n    return orig_scope != self.scope_span\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.modifies","title":"<code>modifies(target)</code>","text":"<p>Checks whether the target is within the modifier scope and if self is allowed to modify target.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>a spaCy span representing a target concept.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the target is within <code>modifier_scope</code> and if self is allowed to modify the target.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def modifies(self, target: Span) -&gt; bool:\n    \"\"\"\n    Checks whether the target is within the modifier scope and if self is allowed to modify target.\n\n    Args:\n        target: a spaCy span representing a target concept.\n\n    Returns:\n        Whether the target is within `modifier_scope` and if self is allowed to modify the target.\n    \"\"\"\n    # If the target and modifier overlap, meaning at least one token\n    # one extracted as both a target and modifier, return False\n    # to avoid self-modifying concepts\n\n    if tuple_overlaps(\n        self.modifier_span, (target.start, target.end)\n    ):  # self.overlaps(target):\n        return False\n    if self.direction in (\"TERMINATE\", \"PSEUDO\"):\n        return False\n    if not self.allows(target.label_.upper()):\n        return False\n\n    if tuple_overlaps(self.scope_span, (target.start, target.end)):\n        if not self.on_modifies(target):\n            return False\n        else:\n            return True\n    return False\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.modify","title":"<code>modify(target)</code>","text":"<p>Add target to the list of self._targets and increment self._num_targets.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>The spaCy span to add.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def modify(self, target: Span):\n    \"\"\"\n    Add target to the list of self._targets and increment self._num_targets.\n\n    Args:\n        target: The spaCy span to add.\n    \"\"\"\n    self._targets.append(target)\n    self._num_targets += 1\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.on_modifies","title":"<code>on_modifies(target)</code>","text":"<p>If the ConTextRule used to define a ConTextModifier has an <code>on_modifies</code> callback function, evaluate and return either True or False.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>The spaCy span to evaluate.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>The result of the <code>on_modifies</code> callback for the rule. True if the callback is None.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def on_modifies(self, target: Span) -&gt; bool:\n    \"\"\"\n    If the ConTextRule used to define a ConTextModifier has an `on_modifies` callback function, evaluate and return\n    either True or False.\n\n    Args:\n        target: The spaCy span to evaluate.\n\n    Returns:\n        The result of the `on_modifies` callback for the rule. True if the callback is None.\n    \"\"\"\n    if self.rule.on_modifies is None:\n        return True\n    # Find the span in between the target and modifier\n    start = min(target.end, self._end)\n    end = max(target.start, self._end)\n    span_between = target.doc[start:end]\n    rslt = self.rule.on_modifies(\n        target, target.doc[self._start : self._end], span_between\n    )\n    if rslt not in (True, False):\n        raise ValueError(\n            \"The on_modifies function must return either True or False indicating \"\n            \"whether a modify modifies a target. Actual value: {0}\".format(rslt)\n        )\n    return rslt\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.reduce_targets","title":"<code>reduce_targets()</code>","text":"<p>Reduces the number of targets to the n-closest targets based on the value of <code>self.max_targets</code>. If <code>self.max_targets</code> is None, no pruning is done.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def reduce_targets(self):\n    \"\"\"\n    Reduces the number of targets to the n-closest targets based on the value of `self.max_targets`. If\n    `self.max_targets` is None, no pruning is done.\n    \"\"\"\n    if self.max_targets is None or self.num_targets &lt;= self.max_targets:\n        return\n\n    target_dists = []\n    for target in self._targets:\n        dist = min(abs(self._start - target.end), abs(target.start - self._end))\n        target_dists.append((target, dist))\n    srtd_targets, _ = zip(*sorted(target_dists, key=lambda x: x[1]))\n    self._targets = srtd_targets[: self.max_targets]\n    self._num_targets = len(self._targets)\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Serialized Representation of the modifier</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def serialized_representation(self):\n    \"\"\"\n    Serialized Representation of the modifier\n    \"\"\"\n    dict_repr = dict()\n    dict_repr[\"context_rule\"] = self.rule.to_dict()\n    dict_repr[\"start\"] = self._start\n    dict_repr[\"end\"] = self._end\n    dict_repr[\"max_scope\"] = self._max_scope\n    dict_repr[\"scope_start\"] = self._scope_start\n    dict_repr[\"scope_end\"] = self._scope_end\n\n    return dict_repr\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_modifier.ConTextModifier.update_scope","title":"<code>update_scope(span)</code>","text":"<p>Changes the scope of self to be the given spaCy span.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>a spaCy Span which contains the scope which a modifier should cover.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def update_scope(self, span: Span):\n    \"\"\"\n    Changes the scope of self to be the given spaCy span.\n\n    Args:\n        span: a spaCy Span which contains the scope which a modifier should cover.\n    \"\"\"\n    self._scope_start = span.start\n    self._scope_end = span.end\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_rule","title":"<code>context_rule</code>","text":""},{"location":"singlepage/#medspacy.context.context_rule.ConTextRule","title":"<code>ConTextRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>A ConTextRule defines a ConText modifier. ConTextRules are rules which define which spans are extracted as modifiers and how they behave, such as the phrase to be matched, the category/semantic class, the direction of the modifier in the text, and what types of target spans can be modified.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>class ConTextRule(BaseRule):\n    \"\"\"\n    A ConTextRule defines a ConText modifier. ConTextRules are rules which define which spans are extracted as modifiers\n    and how they behave, such as the phrase to be matched, the category/semantic class, the direction of the modifier in\n    the text, and what types of target spans can be modified.\n    \"\"\"\n\n    _ALLOWED_DIRECTIONS = (\n        \"FORWARD\",\n        \"BACKWARD\",\n        \"BIDIRECTIONAL\",\n        \"TERMINATE\",\n        \"PSEUDO\"\n    )\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"direction\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"allowed_types\",\n        \"excluded_types\",\n        \"max_targets\",\n        \"max_scope\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n        direction: str = \"BIDIRECTIONAL\",\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        on_modifies: Optional[Callable[[Span, Span, Span], bool]] = None,\n        allowed_types: Optional[Set[str]] = None,\n        excluded_types: Optional[Set[str]] = None,\n        max_scope: Optional[int] = None,\n        max_targets: Optional[int] = None,\n        terminated_by: Optional[Set[str]] = None,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Creates a ConTextRule object.\n\n        The primary arguments of `literal` `category`, and `direction` define the span of text to be matched, the\n        semantic category, and the direction within the sentence in which the modifier operates.\n        Other arguments specify additional custom logic such as:\n            - Additional control over what text can be matched as a modifier (pattern and on_match)\n            - Which types of targets can be modified (allowed_types, excluded_types)\n            - The scope size and number of targets that a modifier can modify (max_targets, max_scope)\n            - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,\n            terminated_by)\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            direction: The directionality or action of a modifier. This defines which part of a sentence a modifier will\n                include as its scope. Entities within the scope will be considered to be modified.\n                Valid values are:\n                - \"FORWARD\": Scope will begin after the end of a modifier and move to the right\n                - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left\n                - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier\n                - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:\n                    \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying\n                    \"pneumonia\"\n                - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating\n                    superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the\n                    phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a\n                    modifier.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            on_modifies: Callback function to run when building an edge between a target and a modifier. This allows\n                specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The\n                callable should take 3 arguments:\n                    target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')\n                    modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')\n                    span_between: The Span between the target and modifier in question.\n                Should return either True or False. If returns False, then the modifier will not modify the target.\n            allowed_types: A collection of target labels to allow a modifier to modify. If None, will apply to any type\n                not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used.\n                An error will be thrown if both are not None.\n            excluded_types: A collection of target labels which this modifier cannot modify. If None, will apply to all\n                target types unless allowed_types is not None.\n            max_scope: A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will\n                include the entire sentence in the direction of `direction` and the entire sentence for \"BIDIRECTIONAL\".\n                This is useful for requiring modifiers be very close to a concept in the text or for preventing long\n                modifier ranges caused by sentence splitting problems.\n            max_targets: The maximum number of targets which a modifier can modify. If None, will modify all targets in\n                its scope.\n            terminated_by: An optional collection of other modifier categories which will terminate the scope of this\n                modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has\n                terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the\n                positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\".\n                This helps prevent multiple conflicting modifiers from distributing too far across a sentence.\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category.upper(), pattern, on_match, metadata)\n        self.on_modifies = on_modifies\n\n        if allowed_types is not None and excluded_types is not None:\n            raise ValueError(\n                \"A ConTextRule was instantiated with non-null values for both allowed_types and excluded_types. \"\n                \"Only one of these can be non-null.\"\n            )\n        if allowed_types is not None:\n            self.allowed_types = {label.upper() for label in allowed_types}\n        else:\n            self.allowed_types = None\n        if excluded_types is not None:\n            self.excluded_types = {label.upper() for label in excluded_types}\n        else:\n            self.excluded_types = None\n\n        if max_targets is not None and max_targets &lt;= 0:\n            raise ValueError(\"max_targets must be &gt;= 0 or None.\")\n        self.max_targets = max_targets\n        if max_scope is not None and max_scope &lt;= 0:\n            raise ValueError(\"max_scope must be &gt;= 0 or None.\")\n        self.max_scope = max_scope\n        if terminated_by is None:\n            terminated_by = set()\n        else:\n            if isinstance(terminated_by, str):\n                raise ValueError(\n                    f\"terminated_by must be an iterable, such as a list or set, not {terminated_by}.\"\n                )\n            terminated_by = {string.upper() for string in terminated_by}\n\n        self.terminated_by = terminated_by\n\n        self.metadata = metadata\n\n        if direction.upper() not in self._ALLOWED_DIRECTIONS:\n            raise ValueError(\n                \"Direction {0} not recognized. Must be one of: {1}\".format(\n                    direction, self._ALLOWED_DIRECTIONS\n                )\n            )\n        self.direction = direction.upper()\n\n    @classmethod\n    def from_json(cls, filepath) -&gt; List[ConTextRule]:\n        \"\"\"\n        Reads in a lexicon of modifiers from a JSON file under the key `context_rules`.\n\n        Args:\n            filepath: The .json file containing modifier rules. Must contain `context_rules` key containing the rule\n                JSONs.\n\n        Returns:\n            A list of ConTextRules objects read from the JSON.\n        \"\"\"\n\n        with open(filepath) as file:\n            modifier_data = json.load(file)\n        context_rules = []\n        for data in modifier_data[\"context_rules\"]:\n            context_rules.append(ConTextRule.from_dict(data))\n        return context_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict) -&gt; ConTextRule:\n        \"\"\"\n        Reads a dictionary into a ConTextRule.\n\n        Args:\n            rule_dict: The dictionary to convert.\n\n        Returns:\n            The ConTextRule created from the dictionary.\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                \"JSON object contains invalid keys: {0}.\\n\"\n                \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n            )\n            raise ValueError(msg)\n        rule = ConTextRule(**rule_dict)\n        return rule\n\n    def to_dict(self):\n        \"\"\"\n        Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.\n\n        Returns:\n            The dictionary containing the ConTextRule info.\n        \"\"\"\n\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if isinstance(value, set):\n                value = list(value)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    @classmethod\n    def to_json(cls, context_rules: List[ConTextRule], filepath: str):\n        \"\"\"Writes ConTextItems to a json file.\n\n            Args:\n            context_rules: a list of ContextRules that will be written to a file.\n            filepath: the .json file to contain modifier rules\n        \"\"\"\n        import json\n\n        data = {\"context_rules\": [rule.to_dict() for rule in context_rules]}\n        with open(filepath, \"w\") as file:\n            json.dump(data, file, indent=4)\n\n    def __repr__(self):\n        return (\n            f\"ConTextRule(literal='{self.literal}', category='{self.category}', pattern={self.pattern}, \"\n            f\"direction='{self.direction}')\"\n        )\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_rule.ConTextRule.__init__","title":"<code>__init__(literal, category, pattern=None, direction='BIDIRECTIONAL', on_match=None, on_modifies=None, allowed_types=None, excluded_types=None, max_scope=None, max_targets=None, terminated_by=None, metadata=None)</code>","text":"<p>Creates a ConTextRule object.</p> <p>The primary arguments of <code>literal</code> <code>category</code>, and <code>direction</code> define the span of text to be matched, the semantic category, and the direction within the sentence in which the modifier operates. Other arguments specify additional custom logic such as:     - Additional control over what text can be matched as a modifier (pattern and on_match)     - Which types of targets can be modified (allowed_types, excluded_types)     - The scope size and number of targets that a modifier can modify (max_targets, max_scope)     - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,     terminated_by)</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[str, List[Dict[str, str]]]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>direction</code> <code>str</code> <p>The directionality or action of a modifier. This defines which part of a sentence a modifier will include as its scope. Entities within the scope will be considered to be modified. Valid values are: - \"FORWARD\": Scope will begin after the end of a modifier and move to the right - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:     \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying     \"pneumonia\" - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating     superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the     phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a     modifier.</p> <code>'BIDIRECTIONAL'</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>on_modifies</code> <code>Optional[Callable[[Span, Span, Span], bool]]</code> <p>Callback function to run when building an edge between a target and a modifier. This allows specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The callable should take 3 arguments:     target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')     modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')     span_between: The Span between the target and modifier in question. Should return either True or False. If returns False, then the modifier will not modify the target.</p> <code>None</code> <code>allowed_types</code> <code>Optional[Set[str]]</code> <p>A collection of target labels to allow a modifier to modify. If None, will apply to any type not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used. An error will be thrown if both are not None.</p> <code>None</code> <code>excluded_types</code> <code>Optional[Set[str]]</code> <p>A collection of target labels which this modifier cannot modify. If None, will apply to all target types unless allowed_types is not None.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will include the entire sentence in the direction of <code>direction</code> and the entire sentence for \"BIDIRECTIONAL\". This is useful for requiring modifiers be very close to a concept in the text or for preventing long modifier ranges caused by sentence splitting problems.</p> <code>None</code> <code>max_targets</code> <code>Optional[int]</code> <p>The maximum number of targets which a modifier can modify. If None, will modify all targets in its scope.</p> <code>None</code> <code>terminated_by</code> <code>Optional[Set[str]]</code> <p>An optional collection of other modifier categories which will terminate the scope of this modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\". This helps prevent multiple conflicting modifiers from distributing too far across a sentence.</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n    direction: str = \"BIDIRECTIONAL\",\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    on_modifies: Optional[Callable[[Span, Span, Span], bool]] = None,\n    allowed_types: Optional[Set[str]] = None,\n    excluded_types: Optional[Set[str]] = None,\n    max_scope: Optional[int] = None,\n    max_targets: Optional[int] = None,\n    terminated_by: Optional[Set[str]] = None,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Creates a ConTextRule object.\n\n    The primary arguments of `literal` `category`, and `direction` define the span of text to be matched, the\n    semantic category, and the direction within the sentence in which the modifier operates.\n    Other arguments specify additional custom logic such as:\n        - Additional control over what text can be matched as a modifier (pattern and on_match)\n        - Which types of targets can be modified (allowed_types, excluded_types)\n        - The scope size and number of targets that a modifier can modify (max_targets, max_scope)\n        - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,\n        terminated_by)\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        direction: The directionality or action of a modifier. This defines which part of a sentence a modifier will\n            include as its scope. Entities within the scope will be considered to be modified.\n            Valid values are:\n            - \"FORWARD\": Scope will begin after the end of a modifier and move to the right\n            - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left\n            - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier\n            - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:\n                \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying\n                \"pneumonia\"\n            - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating\n                superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the\n                phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a\n                modifier.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        on_modifies: Callback function to run when building an edge between a target and a modifier. This allows\n            specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The\n            callable should take 3 arguments:\n                target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')\n                modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')\n                span_between: The Span between the target and modifier in question.\n            Should return either True or False. If returns False, then the modifier will not modify the target.\n        allowed_types: A collection of target labels to allow a modifier to modify. If None, will apply to any type\n            not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used.\n            An error will be thrown if both are not None.\n        excluded_types: A collection of target labels which this modifier cannot modify. If None, will apply to all\n            target types unless allowed_types is not None.\n        max_scope: A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will\n            include the entire sentence in the direction of `direction` and the entire sentence for \"BIDIRECTIONAL\".\n            This is useful for requiring modifiers be very close to a concept in the text or for preventing long\n            modifier ranges caused by sentence splitting problems.\n        max_targets: The maximum number of targets which a modifier can modify. If None, will modify all targets in\n            its scope.\n        terminated_by: An optional collection of other modifier categories which will terminate the scope of this\n            modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has\n            terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the\n            positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\".\n            This helps prevent multiple conflicting modifiers from distributing too far across a sentence.\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category.upper(), pattern, on_match, metadata)\n    self.on_modifies = on_modifies\n\n    if allowed_types is not None and excluded_types is not None:\n        raise ValueError(\n            \"A ConTextRule was instantiated with non-null values for both allowed_types and excluded_types. \"\n            \"Only one of these can be non-null.\"\n        )\n    if allowed_types is not None:\n        self.allowed_types = {label.upper() for label in allowed_types}\n    else:\n        self.allowed_types = None\n    if excluded_types is not None:\n        self.excluded_types = {label.upper() for label in excluded_types}\n    else:\n        self.excluded_types = None\n\n    if max_targets is not None and max_targets &lt;= 0:\n        raise ValueError(\"max_targets must be &gt;= 0 or None.\")\n    self.max_targets = max_targets\n    if max_scope is not None and max_scope &lt;= 0:\n        raise ValueError(\"max_scope must be &gt;= 0 or None.\")\n    self.max_scope = max_scope\n    if terminated_by is None:\n        terminated_by = set()\n    else:\n        if isinstance(terminated_by, str):\n            raise ValueError(\n                f\"terminated_by must be an iterable, such as a list or set, not {terminated_by}.\"\n            )\n        terminated_by = {string.upper() for string in terminated_by}\n\n    self.terminated_by = terminated_by\n\n    self.metadata = metadata\n\n    if direction.upper() not in self._ALLOWED_DIRECTIONS:\n        raise ValueError(\n            \"Direction {0} not recognized. Must be one of: {1}\".format(\n                direction, self._ALLOWED_DIRECTIONS\n            )\n        )\n    self.direction = direction.upper()\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_rule.ConTextRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a ConTextRule.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <p>The dictionary to convert.</p> required <p>Returns:</p> Type Description <code>ConTextRule</code> <p>The ConTextRule created from the dictionary.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict) -&gt; ConTextRule:\n    \"\"\"\n    Reads a dictionary into a ConTextRule.\n\n    Args:\n        rule_dict: The dictionary to convert.\n\n    Returns:\n        The ConTextRule created from the dictionary.\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            \"JSON object contains invalid keys: {0}.\\n\"\n            \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n        )\n        raise ValueError(msg)\n    rule = ConTextRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_rule.ConTextRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Reads in a lexicon of modifiers from a JSON file under the key <code>context_rules</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>The .json file containing modifier rules. Must contain <code>context_rules</code> key containing the rule JSONs.</p> required <p>Returns:</p> Type Description <code>List[ConTextRule]</code> <p>A list of ConTextRules objects read from the JSON.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath) -&gt; List[ConTextRule]:\n    \"\"\"\n    Reads in a lexicon of modifiers from a JSON file under the key `context_rules`.\n\n    Args:\n        filepath: The .json file containing modifier rules. Must contain `context_rules` key containing the rule\n            JSONs.\n\n    Returns:\n        A list of ConTextRules objects read from the JSON.\n    \"\"\"\n\n    with open(filepath) as file:\n        modifier_data = json.load(file)\n    context_rules = []\n    for data in modifier_data[\"context_rules\"]:\n        context_rules.append(ConTextRule.from_dict(data))\n    return context_rules\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_rule.ConTextRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.</p> <p>Returns:</p> Type Description <p>The dictionary containing the ConTextRule info.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.\n\n    Returns:\n        The dictionary containing the ConTextRule info.\n    \"\"\"\n\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if isinstance(value, set):\n            value = list(value)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"singlepage/#medspacy.context.context_rule.ConTextRule.to_json","title":"<code>to_json(context_rules, filepath)</code>  <code>classmethod</code>","text":"<p>Writes ConTextItems to a json file.</p> <p>Args: context_rules: a list of ContextRules that will be written to a file. filepath: the .json file to contain modifier rules</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef to_json(cls, context_rules: List[ConTextRule], filepath: str):\n    \"\"\"Writes ConTextItems to a json file.\n\n        Args:\n        context_rules: a list of ContextRules that will be written to a file.\n        filepath: the .json file to contain modifier rules\n    \"\"\"\n    import json\n\n    data = {\"context_rules\": [rule.to_dict() for rule in context_rules]}\n    with open(filepath, \"w\") as file:\n        json.dump(data, file, indent=4)\n</code></pre>"},{"location":"singlepage/#medspacy.context.util","title":"<code>util</code>","text":"<p>This module will contain helper functions and classes for common clinical processing tasks which will be used in medspaCy's context implementation.</p>"},{"location":"singlepage/#medspacy.context.util.is_modified_by","title":"<code>is_modified_by(span, modifier_label)</code>","text":"<p>Check whether a span has a modifier of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to examine.</p> required <code>modifier_label</code> <code>str</code> <p>The type of modifier to check for.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether there is a modifier of <code>modifier_label</code> that modifies <code>span</code>.</p> Source code in <code>medspacy/context/util.py</code> <pre><code>def is_modified_by(span: Span, modifier_label: str) -&gt; bool:\n    \"\"\"\n    Check whether a span has a modifier of a specific type.\n\n    Args:\n        span: The span to examine.\n        modifier_label: The type of modifier to check for.\n\n    Returns:\n        Whether there is a modifier of `modifier_label` that modifies `span`.\n    \"\"\"\n    for modifier in span._.modifiers:\n        if modifier.category.upper() == modifier_label.upper():\n            return True\n    return False\n</code></pre>"},{"location":"singlepage/#medspacy.custom_tokenizer","title":"<code>custom_tokenizer</code>","text":""},{"location":"singlepage/#medspacy.custom_tokenizer.create_medspacy_tokenizer","title":"<code>create_medspacy_tokenizer(nlp)</code>","text":"<p>Generates a custom tokenizer to augment the default spacy tokenizer  for situations commonly seen in clinical text.  This includes:      * Punctuation infixes.          For example, this allows the following examples to be more aggresively tokenized as :              \"Patient complains of c/o\" -&gt; [..., 'c', '/', 'o']              \"chf+cp\" -&gt; ['chf', '+', 'cp'] @param nlp: Spacy language model</p> Source code in <code>medspacy/custom_tokenizer.py</code> <pre><code>def create_medspacy_tokenizer(nlp):\n    \"\"\"Generates a custom tokenizer to augment the default spacy tokenizer\n     for situations commonly seen in clinical text.\n     This includes:\n         * Punctuation infixes.\n             For example, this allows the following examples to be more aggresively tokenized as :\n                 \"Patient complains of c/o\" -&gt; [..., 'c', '/', 'o']\n                 \"chf+cp\" -&gt; ['chf', '+', 'cp']\n    @param nlp: Spacy language model\n    \"\"\"\n\n    # augment the defaults\n    # this is not quite correct.  We do not want to break on uppercase and we do not\n    # want to break on all punctuation (periods)\n    # infixes = nlp.Defaults.infixes + (r'''[^a-z0-9]''',)\n    # escape all the punctuation we want to allow to allow to break up tokens\n\n    # get all python punctuation\n    punctuation_chars = string.punctuation\n    # remove periods so that we do not break up '1.5 mg' into '1 . 5 mg'\n    punctuation_chars = punctuation_chars.replace(\".\", \"\")\n\n    infixes = nlp.Defaults.infixes + [\n        r\"\"\"[{}]\"\"\".format(re.escape(punctuation_chars)),\n    ]\n    prefixes = nlp.Defaults.prefixes\n    suffixes = nlp.Defaults.suffixes\n\n    # compile\n    infix_re = compile_infix_regex(infixes)\n    prefix_re = compile_prefix_regex(prefixes)\n    suffix_re = compile_suffix_regex(suffixes)\n\n    # Default exceptions could be extended later\n    tokenizer_exceptions = nlp.Defaults.tokenizer_exceptions.copy()\n\n    # now create this\n    tokenizer = Tokenizer(\n        nlp.vocab,\n        tokenizer_exceptions,\n        prefix_search=prefix_re.search,\n        suffix_search=suffix_re.search,\n        infix_finditer=infix_re.finditer,\n        token_match=nlp.tokenizer.token_match,\n    )\n\n    return tokenizer\n</code></pre>"},{"location":"singlepage/#medspacy.io","title":"<code>io</code>","text":""},{"location":"singlepage/#medspacy.io.DbConnect","title":"<code>DbConnect</code>","text":"<p>DbConnect is a wrapper for either a pyodbc or sqlite3 connection. It can then be passed into the DbReader and DbWriter classes to retrieve/store document data.</p> Source code in <code>medspacy/io/db_connect.py</code> <pre><code>class DbConnect:\n    \"\"\"DbConnect is a wrapper for either a pyodbc or sqlite3 connection. It can then be\n    passed into the DbReader and DbWriter classes to retrieve/store document data.\n    \"\"\"\n\n    def __init__(\n        self, driver=None, server=None, db=None, user=None, pwd=None, conn=None\n    ):\n        \"\"\"Create a new DbConnect object. You can pass in either information for a pyodbc connection string\n        or directly pass in a sqlite or pyodbc connection object.\n\n        If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.\n\n        Args:\n            driver\n            server\n            db:\n            user\n            pwd\n            conn\n        \"\"\"\n        if conn is None:\n            if not all([driver, server, db, user, pwd]):\n                raise ValueError(\n                    \"If you are not passing in a connection object, \"\n                    \"you must pass in all other arguments to create a DB connection.\"\n                )\n            import pyodbc\n\n            self.conn = pyodbc.connect(\n                \"DRIVER={0};SERVER={1};DATABASE={2};USER={3};PWD={4}\".format(\n                    driver, server, db, user, pwd\n                )\n            )\n        else:\n            self.conn = conn\n        self.cursor = self.conn.cursor()\n        # according this thread, bulk insert for sqlserver need to set fast_executemany=True.\n        # https://stackoverflow.com/questions/29638136/how-to-speed-up-bulk-insert-to-ms-sql-server-using-pyodbc\n        if hasattr(self.cursor, 'fast_executemany'):\n            self.cursor.fast_executemany = True\n\n        import sqlite3\n\n        if isinstance(self.conn, sqlite3.Connection):\n            self.db_lib = \"sqlite3\"\n            self.database_exception = sqlite3.DatabaseError\n        else:\n            import pyodbc\n            if isinstance(self.conn, pyodbc.Connection):\n                self.db_lib = \"pyodbc\"\n                self.database_exception = pyodbc.DatabaseError\n            else:\n                raise ValueError(\n                    \"conn must be either a sqlite3 or pyodbc Connection object, not {0}\".format(\n                        type(self.conn)\n                    )\n                )\n\n        print(\"Opened connection to {0}.{1}\".format(server, db))\n\n    def create_table(self, query, table_name, drop_existing):\n        if drop_existing:\n            try:\n                self.cursor.execute(\"drop table if exists {0}\".format(table_name))\n            # except pyodbc.DatabaseError:\n            except self.database_exception as e:\n                pass\n            else:\n                self.conn.commit()\n        try:\n            self.cursor.execute(query)\n        except self.database_exception as e:\n            self.conn.rollback()\n            self.conn.close()\n            raise e\n        else:\n            self.conn.commit()\n            print(\"Created table {0} with query: {1}\".format(table_name, query))\n\n    def write(self, query, data):\n        try:\n            self.cursor.executemany(query, data)\n        except self.database_exception as e:\n            self.conn.rollback()\n            self.conn.close()\n            raise e\n        else:\n            self.conn.commit()\n            # print(\"Wrote {0} rows with query: {1}\".format(len(data), query))\n\n    def read(self, query):\n        self.cursor.execute(query)\n        result = self.cursor.fetchall()\n        # print(\"Read {0} rows with query: {1}\".format(len(result), query))\n        return result\n\n    def close(self):\n        self.conn.commit()\n        self.conn.close()\n        print(\"Connection closed.\")\n</code></pre>"},{"location":"singlepage/#medspacy.io.DbConnect.__init__","title":"<code>__init__(driver=None, server=None, db=None, user=None, pwd=None, conn=None)</code>","text":"<p>Create a new DbConnect object. You can pass in either information for a pyodbc connection string or directly pass in a sqlite or pyodbc connection object.</p> <p>If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>None</code> Source code in <code>medspacy/io/db_connect.py</code> <pre><code>def __init__(\n    self, driver=None, server=None, db=None, user=None, pwd=None, conn=None\n):\n    \"\"\"Create a new DbConnect object. You can pass in either information for a pyodbc connection string\n    or directly pass in a sqlite or pyodbc connection object.\n\n    If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.\n\n    Args:\n        driver\n        server\n        db:\n        user\n        pwd\n        conn\n    \"\"\"\n    if conn is None:\n        if not all([driver, server, db, user, pwd]):\n            raise ValueError(\n                \"If you are not passing in a connection object, \"\n                \"you must pass in all other arguments to create a DB connection.\"\n            )\n        import pyodbc\n\n        self.conn = pyodbc.connect(\n            \"DRIVER={0};SERVER={1};DATABASE={2};USER={3};PWD={4}\".format(\n                driver, server, db, user, pwd\n            )\n        )\n    else:\n        self.conn = conn\n    self.cursor = self.conn.cursor()\n    # according this thread, bulk insert for sqlserver need to set fast_executemany=True.\n    # https://stackoverflow.com/questions/29638136/how-to-speed-up-bulk-insert-to-ms-sql-server-using-pyodbc\n    if hasattr(self.cursor, 'fast_executemany'):\n        self.cursor.fast_executemany = True\n\n    import sqlite3\n\n    if isinstance(self.conn, sqlite3.Connection):\n        self.db_lib = \"sqlite3\"\n        self.database_exception = sqlite3.DatabaseError\n    else:\n        import pyodbc\n        if isinstance(self.conn, pyodbc.Connection):\n            self.db_lib = \"pyodbc\"\n            self.database_exception = pyodbc.DatabaseError\n        else:\n            raise ValueError(\n                \"conn must be either a sqlite3 or pyodbc Connection object, not {0}\".format(\n                    type(self.conn)\n                )\n            )\n\n    print(\"Opened connection to {0}.{1}\".format(server, db))\n</code></pre>"},{"location":"singlepage/#medspacy.io.DbWriter","title":"<code>DbWriter</code>","text":"<p>DbWriter is a utility class for writing structured data back to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>class DbWriter:\n    \"\"\"DbWriter is a utility class for writing structured data back to a database.\"\"\"\n\n    def __init__(\n            self,\n            db_conn,\n            destination_table,\n            cols=None,\n            col_types=None,\n            doc_dtype=\"ents\",\n            create_table=False,\n            drop_existing=False,\n            write_batch_size=100,\n    ):\n        \"\"\"Create a new DbWriter object.\n\n        Args:\n            db_conn: A medspacy.io.DbConnect object\n            destination_table: The name of the table to write to\n            cols (opt): The names of the columns of the destination table. These should align with attributes extracted\n                by DocConsumer and stored in doc._.data. A set of default values can be accessed by:\n                &gt;&gt;&gt; DbWriter.get_default_cols()\n            col_types (opt): The sql data types of the table columns. They should correspond 1:1 with cols.\n                A set of default values can be accesed by:\n                &gt;&gt;&gt; DbWriter.get_default_col_types()\n            doc_dtype: The type of data from DocConsumer to write from a doc.\n                Either (\"ents\", \"section\", \"context\", or \"doc\")\n            create_table (bool): Whether to create a table\n\n        \"\"\"\n        self.db = db_conn\n        self.destination_table = destination_table\n        self._create_table = create_table\n        self.drop_existing = drop_existing\n        if cols is None and col_types is None:\n            cols = DEFAULT_COLS[doc_dtype]\n            col_types = [DEFAULT_COL_TYPES[doc_dtype][col] for col in cols]\n        elif cols is None and col_types is not None:\n            raise ValueError(\"cols must be specified if col_types is not None.\")\n        self.cols = cols\n        self.col_types = col_types\n        _validate_dtypes((doc_dtype,))\n        self.doc_dtype = doc_dtype\n        self.batch_size = write_batch_size\n\n        self.insert_query = \"\"\n        if create_table:\n            self.create_table()\n        self.make_insert_query()\n\n    @classmethod\n    def get_default_col_types(cls, dtypes=None):\n\n        if dtypes is None:\n            dtypes = tuple(DEFAULT_COL_TYPES.keys())\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n\n        _validate_dtypes(dtypes)\n        dtype_col_types = {\n            dtype: col_types\n            for (dtype, col_types) in DEFAULT_COL_TYPES.items()\n            if dtype in dtypes\n        }\n        return dtype_col_types\n\n    @classmethod\n    def get_default_cols(cls, dtypes=None):\n        if dtypes is None:\n            dtypes = tuple(DEFAULT_COL_TYPES.keys())\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n        _validate_dtypes(dtypes)\n\n        dtype_cols = {\n            dtype: cols\n            for (dtype, cols) in DEFAULT_COL_TYPES.items()\n            if dtype in dtypes\n        }\n        return dtype_cols\n\n    def create_table(self):\n        query = \"CREATE TABLE {0} (\".format(self.destination_table)\n        for i, col in enumerate(self.cols):\n            query += \"{0} {1}\".format(col, self.col_types[i])\n            if i &lt; len(self.cols) - 1:\n                query += \", \"\n            else:\n                query += \")\"\n        self.db.create_table(query, self.destination_table, self.drop_existing)\n\n    def make_insert_query(self):\n        col_list = \", \".join([col for col in self.cols])\n        q_list = \", \".join([\"?\" for col in self.cols])\n        self.insert_query = \"INSERT INTO {0} ({1}) VALUES ({2})\".format(\n            self.destination_table, col_list, q_list\n        )\n\n    def write(self, docs: Union[Doc, List[Doc]]):\n        \"\"\"Write a list of docs or doc to a database.\"\"\"\n        if isinstance(docs, Doc):\n            self.write_doc(docs)\n        else:\n            self.write_docs(docs)\n\n    def write_doc(self, doc):\n        \"\"\"Write a doc to a database.\"\"\"\n        data = doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True)\n        self.write_data(data)\n\n    def write_docs(self, docs, batch_size=800):\n        \"\"\"write a list of docs to database through bulk insert\"\"\"\n        data = []\n        for doc in docs:\n            data.extend(doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True))\n            if len(data) &gt;= batch_size:\n                self.write_data(data)\n                data = []\n        if len(data) &gt; 0:\n            self.write_data(data)\n        pass\n\n    def write_data(self, data):\n        self.db.write(self.insert_query, data)\n\n    def close(self):\n        self.db.close()\n</code></pre>"},{"location":"singlepage/#medspacy.io.DbWriter.__init__","title":"<code>__init__(db_conn, destination_table, cols=None, col_types=None, doc_dtype='ents', create_table=False, drop_existing=False, write_batch_size=100)</code>","text":"<p>Create a new DbWriter object.</p> <p>Parameters:</p> Name Type Description Default <code>db_conn</code> <p>A medspacy.io.DbConnect object</p> required <code>destination_table</code> <p>The name of the table to write to</p> required <code>cols</code> <code>opt</code> <p>The names of the columns of the destination table. These should align with attributes extracted by DocConsumer and stored in doc._.data. A set of default values can be accessed by:</p> <p>DbWriter.get_default_cols()</p> <code>None</code> <code>col_types</code> <code>opt</code> <p>The sql data types of the table columns. They should correspond 1:1 with cols. A set of default values can be accesed by:</p> <p>DbWriter.get_default_col_types()</p> <code>None</code> <code>doc_dtype</code> <p>The type of data from DocConsumer to write from a doc. Either (\"ents\", \"section\", \"context\", or \"doc\")</p> <code>'ents'</code> <code>create_table</code> <code>bool</code> <p>Whether to create a table</p> <code>False</code> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def __init__(\n        self,\n        db_conn,\n        destination_table,\n        cols=None,\n        col_types=None,\n        doc_dtype=\"ents\",\n        create_table=False,\n        drop_existing=False,\n        write_batch_size=100,\n):\n    \"\"\"Create a new DbWriter object.\n\n    Args:\n        db_conn: A medspacy.io.DbConnect object\n        destination_table: The name of the table to write to\n        cols (opt): The names of the columns of the destination table. These should align with attributes extracted\n            by DocConsumer and stored in doc._.data. A set of default values can be accessed by:\n            &gt;&gt;&gt; DbWriter.get_default_cols()\n        col_types (opt): The sql data types of the table columns. They should correspond 1:1 with cols.\n            A set of default values can be accesed by:\n            &gt;&gt;&gt; DbWriter.get_default_col_types()\n        doc_dtype: The type of data from DocConsumer to write from a doc.\n            Either (\"ents\", \"section\", \"context\", or \"doc\")\n        create_table (bool): Whether to create a table\n\n    \"\"\"\n    self.db = db_conn\n    self.destination_table = destination_table\n    self._create_table = create_table\n    self.drop_existing = drop_existing\n    if cols is None and col_types is None:\n        cols = DEFAULT_COLS[doc_dtype]\n        col_types = [DEFAULT_COL_TYPES[doc_dtype][col] for col in cols]\n    elif cols is None and col_types is not None:\n        raise ValueError(\"cols must be specified if col_types is not None.\")\n    self.cols = cols\n    self.col_types = col_types\n    _validate_dtypes((doc_dtype,))\n    self.doc_dtype = doc_dtype\n    self.batch_size = write_batch_size\n\n    self.insert_query = \"\"\n    if create_table:\n        self.create_table()\n    self.make_insert_query()\n</code></pre>"},{"location":"singlepage/#medspacy.io.DbWriter.write","title":"<code>write(docs)</code>","text":"<p>Write a list of docs or doc to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write(self, docs: Union[Doc, List[Doc]]):\n    \"\"\"Write a list of docs or doc to a database.\"\"\"\n    if isinstance(docs, Doc):\n        self.write_doc(docs)\n    else:\n        self.write_docs(docs)\n</code></pre>"},{"location":"singlepage/#medspacy.io.DbWriter.write_doc","title":"<code>write_doc(doc)</code>","text":"<p>Write a doc to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write_doc(self, doc):\n    \"\"\"Write a doc to a database.\"\"\"\n    data = doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True)\n    self.write_data(data)\n</code></pre>"},{"location":"singlepage/#medspacy.io.DbWriter.write_docs","title":"<code>write_docs(docs, batch_size=800)</code>","text":"<p>write a list of docs to database through bulk insert</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write_docs(self, docs, batch_size=800):\n    \"\"\"write a list of docs to database through bulk insert\"\"\"\n    data = []\n    for doc in docs:\n        data.extend(doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True))\n        if len(data) &gt;= batch_size:\n            self.write_data(data)\n            data = []\n    if len(data) &gt; 0:\n        self.write_data(data)\n    pass\n</code></pre>"},{"location":"singlepage/#medspacy.io.DocConsumer","title":"<code>DocConsumer</code>","text":"<p>A DocConsumer object will consume a spacy doc and output rows based on a configuration provided by the user.</p> <p>This component extracts structured information from a Doc. Information is stored in doc._.data, which is a     nested dictionary. The outer keys represent the data type of can one or more of:         - \"ents\": data about the spans in doc.ents such as the text, label,             context attributes, section information, or custom attributes         - \"group\": data about spans in a span group with the name <code>span_group_attrs</code> section text and category         - \"context\": data about entity-modifier pairs extracted by ConText         - \"doc\": a single doc-level representation. By default only doc.text is extracted, but other attributes may             be specified</p> <pre><code>Once processed, a doc's data can be accessed either by:\n    - doc._.data\n    - doc._.get_data(dtype=...)\n    - doc._.ent_data\n    - doc._.to_dataframe(dtype=...)\n</code></pre> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>@Language.factory(\"medspacy_doc_consumer\")\nclass DocConsumer:\n    \"\"\"\n    A DocConsumer object will consume a spacy doc and output rows based on a configuration provided by the user.\n\n    This component extracts structured information from a Doc. Information is stored in doc._.data, which is a\n        nested dictionary. The outer keys represent the data type of can one or more of:\n            - \"ents\": data about the spans in doc.ents such as the text, label,\n                context attributes, section information, or custom attributes\n            - \"group\": data about spans in a span group with the name `span_group_attrs` section text and category\n            - \"context\": data about entity-modifier pairs extracted by ConText\n            - \"doc\": a single doc-level representation. By default only doc.text is extracted, but other attributes may\n                be specified\n\n        Once processed, a doc's data can be accessed either by:\n            - doc._.data\n            - doc._.get_data(dtype=...)\n            - doc._.ent_data\n            - doc._.to_dataframe(dtype=...)\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp,\n        name: str = \"medspacy_doc_consumer\",\n        dtypes: Tuple = (\"ents\",),\n        dtype_attrs: Dict = None,\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        \"\"\"\n        Creates a new DocConsumer.\n\n        Args:\n            nlp: A spaCy model\n            dtypes: Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are:\n                \"ents\", \"group\", \"section\", \"context\", \"doc\".\n            dtype_attrs: An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will\n                set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either\n                native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time.\n                Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()\n            span_group_name: the name of the span group used when dtypes contains \"group\". At this time, only one span\n                group is supported.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self._span_group_name = span_group_name\n        if not isinstance(dtypes, tuple):\n            if dtypes == \"all\":\n                dtypes = tuple(ALLOWED_DATA_TYPES)\n            else:\n                raise ValueError(\n                    \"dtypes must be either 'all' or a tuple, not {0}\".format(dtypes)\n                )\n        for dtype in dtypes:\n            if dtype not in ALLOWED_DATA_TYPES:\n                raise ValueError(\n                    \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                        ALLOWED_DATA_TYPES, dtype\n                    )\n                )\n            if dtype == \"section\":\n                self.validate_section_attrs(dtype_attrs)\n        self.dtypes = dtypes\n        self.dtype_attrs = dtype_attrs\n\n        if self.dtype_attrs is None:\n            self._set_default_attrs()\n\n    @classmethod\n    def get_default_attrs(cls, dtypes: Optional[Tuple] = None):\n        \"\"\"\n        Gets the default attributes available to each type specified.\n\n        Args:\n            dtypes: Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be\n                returned.\n\n        Returns:\n            The attributes the doc consumer will output for each of the specified types in `dtypes`.\n        \"\"\"\n        if dtypes is None:\n            dtypes = ALLOWED_DATA_TYPES\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n            for dtype in dtypes:\n                if dtype not in ALLOWED_DATA_TYPES:\n                    raise ValueError(\"Invalid dtype,\", dtype)\n        dtype_attrs = {\n            dtype: list(attrs)\n            for (dtype, attrs) in DEFAULT_ATTRS.items()\n            if dtype in dtypes\n        }\n        return dtype_attrs\n\n    def _set_default_attrs(self):\n        \"\"\"\n        Gets the default attributes.\n        \"\"\"\n        self.dtype_attrs = self.get_default_attrs(self.dtypes)\n\n    def validate_section_attrs(self, attrs):\n        \"\"\"\n        Validate that section attributes are either not specified or are valid attribute names.\n        \"\"\"\n        if attrs is None:\n            return True\n        if \"section\" not in attrs:\n            return True\n        diff = set(attrs[\"section\"]).difference(ALLOWED_SECTION_ATTRS)\n        if diff:\n            raise ValueError(\"Invalid section dtype_attrs specified: {0}\".format(diff))\n        return True\n\n    def __call__(self, doc):\n        \"\"\"\n        Call the doc consumer on a doc and assign the data.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed Doc.\n        \"\"\"\n        data = dict()\n        for dtype, attrs in self.dtype_attrs.items():\n            data.setdefault(dtype, OrderedDict())\n            for attr in attrs:\n                data[dtype][attr] = list()\n        if \"ents\" in self.dtypes:\n            for ent in doc.ents:\n                for attr in self.dtype_attrs[\"ents\"]:\n                    try:\n                        val = getattr(ent, attr)\n                    except AttributeError:\n                        val = getattr(ent._, attr)\n                    data[\"ents\"][attr].append(val)\n        if \"group\" in self.dtypes:\n            for span in doc.spans[self._span_group_name]:\n                for attr in self.dtype_attrs[\"group\"]:\n                    try:\n                        val = getattr(span, attr)\n                    except AttributeError:\n                        val = getattr(span._, attr)\n                    data[\"group\"][attr].append(val)\n        if \"context\" in self.dtypes:\n            for (ent, modifier) in doc._.context_graph.edges:\n                self.add_context_edge_attributes(ent, modifier, data[\"context\"], doc)\n        if \"section\" in self.dtypes:\n            for section in doc._.sections:\n                self.add_section_attributes(section, data[\"section\"], doc)\n        if \"doc\" in self.dtypes:\n            for attr in self.dtype_attrs[\"doc\"]:\n                try:\n                    val = getattr(doc, attr)\n                except AttributeError:\n                    val = getattr(doc._, attr)\n                data[\"doc\"][attr].append(val)\n\n        doc._.data = data\n        return doc\n\n    def add_context_edge_attributes(\n        self, ent: Span, modifier: ConTextModifier, context_data, doc\n    ):\n        span_tup = modifier.modifier_span\n        span = doc[span_tup[0] : span_tup[1]]\n        scope_tup = modifier.scope_span\n        scope = doc[scope_tup[0] : scope_tup[1]]\n        for attr in self.dtype_attrs[\"context\"]:\n            if attr == \"ent_text\":\n                context_data[\"ent_text\"].append(ent.text)\n            elif attr == \"ent_label_\":\n                context_data[\"ent_label_\"].append(ent.label_)\n            elif attr == \"ent_start_char\":\n                context_data[\"ent_start_char\"].append(ent.start_char)\n            elif attr == \"ent_end_char\":\n                context_data[\"ent_end_char\"].append(ent.end_char)\n            elif attr == \"modifier_text\":\n                context_data[\"modifier_text\"].append(span.text)\n            elif attr == \"modifier_category\":\n                context_data[\"modifier_category\"].append(modifier.category)\n            elif attr == \"modifier_direction\":\n               context_data[\"modifier_direction\"].append(modifier.direction)\n            elif attr == \"modifier_start_char\":\n                context_data[\"modifier_start_char\"].append(span.start_char)\n            elif attr == \"modifier_end_char\":\n                context_data[\"modifier_end_char\"].append(span.end_char)\n            elif attr == \"modifier_scope_start_char\":\n                context_data[\"modifier_scope_start_char\"].append(scope.start_char)\n            elif attr == \"modifier_scope_end_char\":\n                context_data[\"modifier_scope_end_char\"].append(scope.end_char)\n            else:\n            # if specified attribute is not one of these standard values, check the entity to see if it's an entity value\n                try:\n                    val = getattr(ent, attr)\n                except AttributeError:\n                    try:\n                        val = getattr(ent._, attr)\n                    except AttributeError:\n                        raise ValueError(f\"Attributes for dtype 'context' must be either \"\n                                         f\"a registered custom Span attribute (i.e., Span._.attr) or one of these pre-defined values: \"\n                                          f\"{ALLOWED_CONTEXT_ATTRS}. \\nYou passed in '{attr}'\")\n                context_data[f\"{attr}\"].append(val)\n\n    def add_section_attributes(self, section, section_data, doc):\n        # Allow for null sections\n        section_title_tup = section.title_span\n        section_body_tup = section.body_span\n        section_title = doc[section_title_tup[0] : section_title_tup[1]]\n        section_body = doc[section_body_tup[0] : section_body_tup[1]]\n        if \"section_category\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_category\"].append(section.category)\n        if section.category is not None:\n            if \"section_title_text\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_text\"].append(section_title.text)\n            if \"section_title_start_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_start_char\"].append(\n                    section_title.start_char\n                )\n            if \"section_title_end_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_end_char\"].append(section_title.end_char)\n        else:\n            if \"section_title_text\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_text\"].append(None)\n            if \"section_title_start_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_start_char\"].append(0)\n            if \"section_title_end_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_end_char\"].append(0)\n        if \"section_body\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body\"].append(section_body.text)\n        if \"section_body_start_char\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body_start_char\"].append(section_body.start_char)\n        if \"section_body_end_char\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body_end_char\"].append(section_body.end_char)\n        if \"section_parent\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_parent\"].append(section.parent)\n</code></pre>"},{"location":"singlepage/#medspacy.io.DocConsumer.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the doc consumer on a doc and assign the data.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <p>The processed Doc.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def __call__(self, doc):\n    \"\"\"\n    Call the doc consumer on a doc and assign the data.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed Doc.\n    \"\"\"\n    data = dict()\n    for dtype, attrs in self.dtype_attrs.items():\n        data.setdefault(dtype, OrderedDict())\n        for attr in attrs:\n            data[dtype][attr] = list()\n    if \"ents\" in self.dtypes:\n        for ent in doc.ents:\n            for attr in self.dtype_attrs[\"ents\"]:\n                try:\n                    val = getattr(ent, attr)\n                except AttributeError:\n                    val = getattr(ent._, attr)\n                data[\"ents\"][attr].append(val)\n    if \"group\" in self.dtypes:\n        for span in doc.spans[self._span_group_name]:\n            for attr in self.dtype_attrs[\"group\"]:\n                try:\n                    val = getattr(span, attr)\n                except AttributeError:\n                    val = getattr(span._, attr)\n                data[\"group\"][attr].append(val)\n    if \"context\" in self.dtypes:\n        for (ent, modifier) in doc._.context_graph.edges:\n            self.add_context_edge_attributes(ent, modifier, data[\"context\"], doc)\n    if \"section\" in self.dtypes:\n        for section in doc._.sections:\n            self.add_section_attributes(section, data[\"section\"], doc)\n    if \"doc\" in self.dtypes:\n        for attr in self.dtype_attrs[\"doc\"]:\n            try:\n                val = getattr(doc, attr)\n            except AttributeError:\n                val = getattr(doc._, attr)\n            data[\"doc\"][attr].append(val)\n\n    doc._.data = data\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.io.DocConsumer.__init__","title":"<code>__init__(nlp, name='medspacy_doc_consumer', dtypes=('ents',), dtype_attrs=None, span_group_name='medspacy_spans')</code>","text":"<p>Creates a new DocConsumer.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <p>A spaCy model</p> required <code>dtypes</code> <code>Tuple</code> <p>Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are: \"ents\", \"group\", \"section\", \"context\", \"doc\".</p> <code>('ents',)</code> <code>dtype_attrs</code> <code>Dict</code> <p>An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time. Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()</p> <code>None</code> <code>span_group_name</code> <code>str</code> <p>the name of the span group used when dtypes contains \"group\". At this time, only one span group is supported.</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def __init__(\n    self,\n    nlp,\n    name: str = \"medspacy_doc_consumer\",\n    dtypes: Tuple = (\"ents\",),\n    dtype_attrs: Dict = None,\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Creates a new DocConsumer.\n\n    Args:\n        nlp: A spaCy model\n        dtypes: Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are:\n            \"ents\", \"group\", \"section\", \"context\", \"doc\".\n        dtype_attrs: An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will\n            set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either\n            native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time.\n            Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()\n        span_group_name: the name of the span group used when dtypes contains \"group\". At this time, only one span\n            group is supported.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self._span_group_name = span_group_name\n    if not isinstance(dtypes, tuple):\n        if dtypes == \"all\":\n            dtypes = tuple(ALLOWED_DATA_TYPES)\n        else:\n            raise ValueError(\n                \"dtypes must be either 'all' or a tuple, not {0}\".format(dtypes)\n            )\n    for dtype in dtypes:\n        if dtype not in ALLOWED_DATA_TYPES:\n            raise ValueError(\n                \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                    ALLOWED_DATA_TYPES, dtype\n                )\n            )\n        if dtype == \"section\":\n            self.validate_section_attrs(dtype_attrs)\n    self.dtypes = dtypes\n    self.dtype_attrs = dtype_attrs\n\n    if self.dtype_attrs is None:\n        self._set_default_attrs()\n</code></pre>"},{"location":"singlepage/#medspacy.io.DocConsumer._set_default_attrs","title":"<code>_set_default_attrs()</code>","text":"<p>Gets the default attributes.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def _set_default_attrs(self):\n    \"\"\"\n    Gets the default attributes.\n    \"\"\"\n    self.dtype_attrs = self.get_default_attrs(self.dtypes)\n</code></pre>"},{"location":"singlepage/#medspacy.io.DocConsumer.get_default_attrs","title":"<code>get_default_attrs(dtypes=None)</code>  <code>classmethod</code>","text":"<p>Gets the default attributes available to each type specified.</p> <p>Parameters:</p> Name Type Description Default <code>dtypes</code> <code>Optional[Tuple]</code> <p>Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <p>The attributes the doc consumer will output for each of the specified types in <code>dtypes</code>.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>@classmethod\ndef get_default_attrs(cls, dtypes: Optional[Tuple] = None):\n    \"\"\"\n    Gets the default attributes available to each type specified.\n\n    Args:\n        dtypes: Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be\n            returned.\n\n    Returns:\n        The attributes the doc consumer will output for each of the specified types in `dtypes`.\n    \"\"\"\n    if dtypes is None:\n        dtypes = ALLOWED_DATA_TYPES\n    else:\n        if isinstance(dtypes, str):\n            dtypes = (dtypes,)\n        for dtype in dtypes:\n            if dtype not in ALLOWED_DATA_TYPES:\n                raise ValueError(\"Invalid dtype,\", dtype)\n    dtype_attrs = {\n        dtype: list(attrs)\n        for (dtype, attrs) in DEFAULT_ATTRS.items()\n        if dtype in dtypes\n    }\n    return dtype_attrs\n</code></pre>"},{"location":"singlepage/#medspacy.io.DocConsumer.validate_section_attrs","title":"<code>validate_section_attrs(attrs)</code>","text":"<p>Validate that section attributes are either not specified or are valid attribute names.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def validate_section_attrs(self, attrs):\n    \"\"\"\n    Validate that section attributes are either not specified or are valid attribute names.\n    \"\"\"\n    if attrs is None:\n        return True\n    if \"section\" not in attrs:\n        return True\n    diff = set(attrs[\"section\"]).difference(ALLOWED_SECTION_ATTRS)\n    if diff:\n        raise ValueError(\"Invalid section dtype_attrs specified: {0}\".format(diff))\n    return True\n</code></pre>"},{"location":"singlepage/#medspacy.io.Pipeline","title":"<code>Pipeline</code>","text":"<p>The Pipeline class executes a batch process of reading texts, processing them with a spaCy model, and writing the results back to a database.</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>@Language.factory(\"medspacy_pipeline\")\nclass Pipeline:\n    \"\"\"The Pipeline class executes a batch process of reading texts, processing them with a spaCy model, and writing\n    the results back to a database.\n    \"\"\"\n\n    def __init__(self, nlp, reader, writer, name=\"medspacy_pipeline\", dtype=\"ent\"):\n        \"\"\"Create a new Pipeline object.\n        Args:\n            reader: A DbReader object\n            writer: A Dbwriter object\n            nlp: A spaCy model\n            dtype: The DocConsumer data type to write to a database.\n                Default \"ent\n                Valid options are (\"ent\", \"section\", \"context\", \"doc\")\n        \"\"\"\n\n        self.reader = reader\n        self.writer = writer\n        self.name = name\n        self.nlp = nlp\n        self.dtype = dtype\n        if dtype not in ALLOWED_DATA_TYPES:\n            raise ValueError(\n                \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                    ALLOWED_DATA_TYPES, dtype\n                )\n            )\n\n    def process(self):\n        \"\"\"Run a pipeline by reading a set of texts from a source table, processing them with nlp,\n        and writing doc._.data back to the destination table.\n        \"\"\"\n        query_result = self.reader.read()\n        data = None\n        while query_result:\n            if len(query_result) &gt; 0:\n                query_zip = list(zip(*query_result))\n                ids = query_zip[0]\n                texts = query_zip[1]\n\n                docs = self.nlp.pipe(texts)\n\n                for i, doc in enumerate(docs):\n                    text_id = ids[i]\n                    # Get the data as rows of tuples\n                    doc_data = doc._.get_data(self.dtype, as_rows=True)\n                    # Add the identifier column\n                    doc_data = [(text_id,) + row_data for row_data in doc_data]\n                    # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n                    # doc_data = pd.DataFrame(data=doc._.get_data(self.dtype))\n                    # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n\n                    if data is None:\n                        data = doc_data.copy()\n                    else:\n                        data += doc_data.copy()\n                    if len(data) &gt;= self.writer.batch_size:\n                        self.writer.write_data(data)\n                        data = None\n            query_result = self.reader.read()\n\n        if data is not None:\n            self.writer.write_data(data)\n            data = None\n\n        self.reader.close()\n        if self.writer.db.conn != self.reader.db.conn:\n            self.writer.close()\n</code></pre>"},{"location":"singlepage/#medspacy.io.Pipeline.__init__","title":"<code>__init__(nlp, reader, writer, name='medspacy_pipeline', dtype='ent')</code>","text":"<p>Create a new Pipeline object. Args:     reader: A DbReader object     writer: A Dbwriter object     nlp: A spaCy model     dtype: The DocConsumer data type to write to a database.         Default \"ent         Valid options are (\"ent\", \"section\", \"context\", \"doc\")</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>def __init__(self, nlp, reader, writer, name=\"medspacy_pipeline\", dtype=\"ent\"):\n    \"\"\"Create a new Pipeline object.\n    Args:\n        reader: A DbReader object\n        writer: A Dbwriter object\n        nlp: A spaCy model\n        dtype: The DocConsumer data type to write to a database.\n            Default \"ent\n            Valid options are (\"ent\", \"section\", \"context\", \"doc\")\n    \"\"\"\n\n    self.reader = reader\n    self.writer = writer\n    self.name = name\n    self.nlp = nlp\n    self.dtype = dtype\n    if dtype not in ALLOWED_DATA_TYPES:\n        raise ValueError(\n            \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                ALLOWED_DATA_TYPES, dtype\n            )\n        )\n</code></pre>"},{"location":"singlepage/#medspacy.io.Pipeline.process","title":"<code>process()</code>","text":"<p>Run a pipeline by reading a set of texts from a source table, processing them with nlp, and writing doc._.data back to the destination table.</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>def process(self):\n    \"\"\"Run a pipeline by reading a set of texts from a source table, processing them with nlp,\n    and writing doc._.data back to the destination table.\n    \"\"\"\n    query_result = self.reader.read()\n    data = None\n    while query_result:\n        if len(query_result) &gt; 0:\n            query_zip = list(zip(*query_result))\n            ids = query_zip[0]\n            texts = query_zip[1]\n\n            docs = self.nlp.pipe(texts)\n\n            for i, doc in enumerate(docs):\n                text_id = ids[i]\n                # Get the data as rows of tuples\n                doc_data = doc._.get_data(self.dtype, as_rows=True)\n                # Add the identifier column\n                doc_data = [(text_id,) + row_data for row_data in doc_data]\n                # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n                # doc_data = pd.DataFrame(data=doc._.get_data(self.dtype))\n                # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n\n                if data is None:\n                    data = doc_data.copy()\n                else:\n                    data += doc_data.copy()\n                if len(data) &gt;= self.writer.batch_size:\n                    self.writer.write_data(data)\n                    data = None\n        query_result = self.reader.read()\n\n    if data is not None:\n        self.writer.write_data(data)\n        data = None\n\n    self.reader.close()\n    if self.writer.db.conn != self.reader.db.conn:\n        self.writer.close()\n</code></pre>"},{"location":"singlepage/#medspacy.io.db_connect","title":"<code>db_connect</code>","text":""},{"location":"singlepage/#medspacy.io.db_connect.DbConnect","title":"<code>DbConnect</code>","text":"<p>DbConnect is a wrapper for either a pyodbc or sqlite3 connection. It can then be passed into the DbReader and DbWriter classes to retrieve/store document data.</p> Source code in <code>medspacy/io/db_connect.py</code> <pre><code>class DbConnect:\n    \"\"\"DbConnect is a wrapper for either a pyodbc or sqlite3 connection. It can then be\n    passed into the DbReader and DbWriter classes to retrieve/store document data.\n    \"\"\"\n\n    def __init__(\n        self, driver=None, server=None, db=None, user=None, pwd=None, conn=None\n    ):\n        \"\"\"Create a new DbConnect object. You can pass in either information for a pyodbc connection string\n        or directly pass in a sqlite or pyodbc connection object.\n\n        If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.\n\n        Args:\n            driver\n            server\n            db:\n            user\n            pwd\n            conn\n        \"\"\"\n        if conn is None:\n            if not all([driver, server, db, user, pwd]):\n                raise ValueError(\n                    \"If you are not passing in a connection object, \"\n                    \"you must pass in all other arguments to create a DB connection.\"\n                )\n            import pyodbc\n\n            self.conn = pyodbc.connect(\n                \"DRIVER={0};SERVER={1};DATABASE={2};USER={3};PWD={4}\".format(\n                    driver, server, db, user, pwd\n                )\n            )\n        else:\n            self.conn = conn\n        self.cursor = self.conn.cursor()\n        # according this thread, bulk insert for sqlserver need to set fast_executemany=True.\n        # https://stackoverflow.com/questions/29638136/how-to-speed-up-bulk-insert-to-ms-sql-server-using-pyodbc\n        if hasattr(self.cursor, 'fast_executemany'):\n            self.cursor.fast_executemany = True\n\n        import sqlite3\n\n        if isinstance(self.conn, sqlite3.Connection):\n            self.db_lib = \"sqlite3\"\n            self.database_exception = sqlite3.DatabaseError\n        else:\n            import pyodbc\n            if isinstance(self.conn, pyodbc.Connection):\n                self.db_lib = \"pyodbc\"\n                self.database_exception = pyodbc.DatabaseError\n            else:\n                raise ValueError(\n                    \"conn must be either a sqlite3 or pyodbc Connection object, not {0}\".format(\n                        type(self.conn)\n                    )\n                )\n\n        print(\"Opened connection to {0}.{1}\".format(server, db))\n\n    def create_table(self, query, table_name, drop_existing):\n        if drop_existing:\n            try:\n                self.cursor.execute(\"drop table if exists {0}\".format(table_name))\n            # except pyodbc.DatabaseError:\n            except self.database_exception as e:\n                pass\n            else:\n                self.conn.commit()\n        try:\n            self.cursor.execute(query)\n        except self.database_exception as e:\n            self.conn.rollback()\n            self.conn.close()\n            raise e\n        else:\n            self.conn.commit()\n            print(\"Created table {0} with query: {1}\".format(table_name, query))\n\n    def write(self, query, data):\n        try:\n            self.cursor.executemany(query, data)\n        except self.database_exception as e:\n            self.conn.rollback()\n            self.conn.close()\n            raise e\n        else:\n            self.conn.commit()\n            # print(\"Wrote {0} rows with query: {1}\".format(len(data), query))\n\n    def read(self, query):\n        self.cursor.execute(query)\n        result = self.cursor.fetchall()\n        # print(\"Read {0} rows with query: {1}\".format(len(result), query))\n        return result\n\n    def close(self):\n        self.conn.commit()\n        self.conn.close()\n        print(\"Connection closed.\")\n</code></pre>"},{"location":"singlepage/#medspacy.io.db_connect.DbConnect.__init__","title":"<code>__init__(driver=None, server=None, db=None, user=None, pwd=None, conn=None)</code>","text":"<p>Create a new DbConnect object. You can pass in either information for a pyodbc connection string or directly pass in a sqlite or pyodbc connection object.</p> <p>If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>None</code> Source code in <code>medspacy/io/db_connect.py</code> <pre><code>def __init__(\n    self, driver=None, server=None, db=None, user=None, pwd=None, conn=None\n):\n    \"\"\"Create a new DbConnect object. You can pass in either information for a pyodbc connection string\n    or directly pass in a sqlite or pyodbc connection object.\n\n    If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.\n\n    Args:\n        driver\n        server\n        db:\n        user\n        pwd\n        conn\n    \"\"\"\n    if conn is None:\n        if not all([driver, server, db, user, pwd]):\n            raise ValueError(\n                \"If you are not passing in a connection object, \"\n                \"you must pass in all other arguments to create a DB connection.\"\n            )\n        import pyodbc\n\n        self.conn = pyodbc.connect(\n            \"DRIVER={0};SERVER={1};DATABASE={2};USER={3};PWD={4}\".format(\n                driver, server, db, user, pwd\n            )\n        )\n    else:\n        self.conn = conn\n    self.cursor = self.conn.cursor()\n    # according this thread, bulk insert for sqlserver need to set fast_executemany=True.\n    # https://stackoverflow.com/questions/29638136/how-to-speed-up-bulk-insert-to-ms-sql-server-using-pyodbc\n    if hasattr(self.cursor, 'fast_executemany'):\n        self.cursor.fast_executemany = True\n\n    import sqlite3\n\n    if isinstance(self.conn, sqlite3.Connection):\n        self.db_lib = \"sqlite3\"\n        self.database_exception = sqlite3.DatabaseError\n    else:\n        import pyodbc\n        if isinstance(self.conn, pyodbc.Connection):\n            self.db_lib = \"pyodbc\"\n            self.database_exception = pyodbc.DatabaseError\n        else:\n            raise ValueError(\n                \"conn must be either a sqlite3 or pyodbc Connection object, not {0}\".format(\n                    type(self.conn)\n                )\n            )\n\n    print(\"Opened connection to {0}.{1}\".format(server, db))\n</code></pre>"},{"location":"singlepage/#medspacy.io.db_writer","title":"<code>db_writer</code>","text":""},{"location":"singlepage/#medspacy.io.db_writer.DbWriter","title":"<code>DbWriter</code>","text":"<p>DbWriter is a utility class for writing structured data back to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>class DbWriter:\n    \"\"\"DbWriter is a utility class for writing structured data back to a database.\"\"\"\n\n    def __init__(\n            self,\n            db_conn,\n            destination_table,\n            cols=None,\n            col_types=None,\n            doc_dtype=\"ents\",\n            create_table=False,\n            drop_existing=False,\n            write_batch_size=100,\n    ):\n        \"\"\"Create a new DbWriter object.\n\n        Args:\n            db_conn: A medspacy.io.DbConnect object\n            destination_table: The name of the table to write to\n            cols (opt): The names of the columns of the destination table. These should align with attributes extracted\n                by DocConsumer and stored in doc._.data. A set of default values can be accessed by:\n                &gt;&gt;&gt; DbWriter.get_default_cols()\n            col_types (opt): The sql data types of the table columns. They should correspond 1:1 with cols.\n                A set of default values can be accesed by:\n                &gt;&gt;&gt; DbWriter.get_default_col_types()\n            doc_dtype: The type of data from DocConsumer to write from a doc.\n                Either (\"ents\", \"section\", \"context\", or \"doc\")\n            create_table (bool): Whether to create a table\n\n        \"\"\"\n        self.db = db_conn\n        self.destination_table = destination_table\n        self._create_table = create_table\n        self.drop_existing = drop_existing\n        if cols is None and col_types is None:\n            cols = DEFAULT_COLS[doc_dtype]\n            col_types = [DEFAULT_COL_TYPES[doc_dtype][col] for col in cols]\n        elif cols is None and col_types is not None:\n            raise ValueError(\"cols must be specified if col_types is not None.\")\n        self.cols = cols\n        self.col_types = col_types\n        _validate_dtypes((doc_dtype,))\n        self.doc_dtype = doc_dtype\n        self.batch_size = write_batch_size\n\n        self.insert_query = \"\"\n        if create_table:\n            self.create_table()\n        self.make_insert_query()\n\n    @classmethod\n    def get_default_col_types(cls, dtypes=None):\n\n        if dtypes is None:\n            dtypes = tuple(DEFAULT_COL_TYPES.keys())\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n\n        _validate_dtypes(dtypes)\n        dtype_col_types = {\n            dtype: col_types\n            for (dtype, col_types) in DEFAULT_COL_TYPES.items()\n            if dtype in dtypes\n        }\n        return dtype_col_types\n\n    @classmethod\n    def get_default_cols(cls, dtypes=None):\n        if dtypes is None:\n            dtypes = tuple(DEFAULT_COL_TYPES.keys())\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n        _validate_dtypes(dtypes)\n\n        dtype_cols = {\n            dtype: cols\n            for (dtype, cols) in DEFAULT_COL_TYPES.items()\n            if dtype in dtypes\n        }\n        return dtype_cols\n\n    def create_table(self):\n        query = \"CREATE TABLE {0} (\".format(self.destination_table)\n        for i, col in enumerate(self.cols):\n            query += \"{0} {1}\".format(col, self.col_types[i])\n            if i &lt; len(self.cols) - 1:\n                query += \", \"\n            else:\n                query += \")\"\n        self.db.create_table(query, self.destination_table, self.drop_existing)\n\n    def make_insert_query(self):\n        col_list = \", \".join([col for col in self.cols])\n        q_list = \", \".join([\"?\" for col in self.cols])\n        self.insert_query = \"INSERT INTO {0} ({1}) VALUES ({2})\".format(\n            self.destination_table, col_list, q_list\n        )\n\n    def write(self, docs: Union[Doc, List[Doc]]):\n        \"\"\"Write a list of docs or doc to a database.\"\"\"\n        if isinstance(docs, Doc):\n            self.write_doc(docs)\n        else:\n            self.write_docs(docs)\n\n    def write_doc(self, doc):\n        \"\"\"Write a doc to a database.\"\"\"\n        data = doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True)\n        self.write_data(data)\n\n    def write_docs(self, docs, batch_size=800):\n        \"\"\"write a list of docs to database through bulk insert\"\"\"\n        data = []\n        for doc in docs:\n            data.extend(doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True))\n            if len(data) &gt;= batch_size:\n                self.write_data(data)\n                data = []\n        if len(data) &gt; 0:\n            self.write_data(data)\n        pass\n\n    def write_data(self, data):\n        self.db.write(self.insert_query, data)\n\n    def close(self):\n        self.db.close()\n</code></pre>"},{"location":"singlepage/#medspacy.io.db_writer.DbWriter.__init__","title":"<code>__init__(db_conn, destination_table, cols=None, col_types=None, doc_dtype='ents', create_table=False, drop_existing=False, write_batch_size=100)</code>","text":"<p>Create a new DbWriter object.</p> <p>Parameters:</p> Name Type Description Default <code>db_conn</code> <p>A medspacy.io.DbConnect object</p> required <code>destination_table</code> <p>The name of the table to write to</p> required <code>cols</code> <code>opt</code> <p>The names of the columns of the destination table. These should align with attributes extracted by DocConsumer and stored in doc._.data. A set of default values can be accessed by:</p> <p>DbWriter.get_default_cols()</p> <code>None</code> <code>col_types</code> <code>opt</code> <p>The sql data types of the table columns. They should correspond 1:1 with cols. A set of default values can be accesed by:</p> <p>DbWriter.get_default_col_types()</p> <code>None</code> <code>doc_dtype</code> <p>The type of data from DocConsumer to write from a doc. Either (\"ents\", \"section\", \"context\", or \"doc\")</p> <code>'ents'</code> <code>create_table</code> <code>bool</code> <p>Whether to create a table</p> <code>False</code> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def __init__(\n        self,\n        db_conn,\n        destination_table,\n        cols=None,\n        col_types=None,\n        doc_dtype=\"ents\",\n        create_table=False,\n        drop_existing=False,\n        write_batch_size=100,\n):\n    \"\"\"Create a new DbWriter object.\n\n    Args:\n        db_conn: A medspacy.io.DbConnect object\n        destination_table: The name of the table to write to\n        cols (opt): The names of the columns of the destination table. These should align with attributes extracted\n            by DocConsumer and stored in doc._.data. A set of default values can be accessed by:\n            &gt;&gt;&gt; DbWriter.get_default_cols()\n        col_types (opt): The sql data types of the table columns. They should correspond 1:1 with cols.\n            A set of default values can be accesed by:\n            &gt;&gt;&gt; DbWriter.get_default_col_types()\n        doc_dtype: The type of data from DocConsumer to write from a doc.\n            Either (\"ents\", \"section\", \"context\", or \"doc\")\n        create_table (bool): Whether to create a table\n\n    \"\"\"\n    self.db = db_conn\n    self.destination_table = destination_table\n    self._create_table = create_table\n    self.drop_existing = drop_existing\n    if cols is None and col_types is None:\n        cols = DEFAULT_COLS[doc_dtype]\n        col_types = [DEFAULT_COL_TYPES[doc_dtype][col] for col in cols]\n    elif cols is None and col_types is not None:\n        raise ValueError(\"cols must be specified if col_types is not None.\")\n    self.cols = cols\n    self.col_types = col_types\n    _validate_dtypes((doc_dtype,))\n    self.doc_dtype = doc_dtype\n    self.batch_size = write_batch_size\n\n    self.insert_query = \"\"\n    if create_table:\n        self.create_table()\n    self.make_insert_query()\n</code></pre>"},{"location":"singlepage/#medspacy.io.db_writer.DbWriter.write","title":"<code>write(docs)</code>","text":"<p>Write a list of docs or doc to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write(self, docs: Union[Doc, List[Doc]]):\n    \"\"\"Write a list of docs or doc to a database.\"\"\"\n    if isinstance(docs, Doc):\n        self.write_doc(docs)\n    else:\n        self.write_docs(docs)\n</code></pre>"},{"location":"singlepage/#medspacy.io.db_writer.DbWriter.write_doc","title":"<code>write_doc(doc)</code>","text":"<p>Write a doc to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write_doc(self, doc):\n    \"\"\"Write a doc to a database.\"\"\"\n    data = doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True)\n    self.write_data(data)\n</code></pre>"},{"location":"singlepage/#medspacy.io.db_writer.DbWriter.write_docs","title":"<code>write_docs(docs, batch_size=800)</code>","text":"<p>write a list of docs to database through bulk insert</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write_docs(self, docs, batch_size=800):\n    \"\"\"write a list of docs to database through bulk insert\"\"\"\n    data = []\n    for doc in docs:\n        data.extend(doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True))\n        if len(data) &gt;= batch_size:\n            self.write_data(data)\n            data = []\n    if len(data) &gt; 0:\n        self.write_data(data)\n    pass\n</code></pre>"},{"location":"singlepage/#medspacy.io.doc_consumer","title":"<code>doc_consumer</code>","text":""},{"location":"singlepage/#medspacy.io.doc_consumer.DocConsumer","title":"<code>DocConsumer</code>","text":"<p>A DocConsumer object will consume a spacy doc and output rows based on a configuration provided by the user.</p> <p>This component extracts structured information from a Doc. Information is stored in doc._.data, which is a     nested dictionary. The outer keys represent the data type of can one or more of:         - \"ents\": data about the spans in doc.ents such as the text, label,             context attributes, section information, or custom attributes         - \"group\": data about spans in a span group with the name <code>span_group_attrs</code> section text and category         - \"context\": data about entity-modifier pairs extracted by ConText         - \"doc\": a single doc-level representation. By default only doc.text is extracted, but other attributes may             be specified</p> <pre><code>Once processed, a doc's data can be accessed either by:\n    - doc._.data\n    - doc._.get_data(dtype=...)\n    - doc._.ent_data\n    - doc._.to_dataframe(dtype=...)\n</code></pre> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>@Language.factory(\"medspacy_doc_consumer\")\nclass DocConsumer:\n    \"\"\"\n    A DocConsumer object will consume a spacy doc and output rows based on a configuration provided by the user.\n\n    This component extracts structured information from a Doc. Information is stored in doc._.data, which is a\n        nested dictionary. The outer keys represent the data type of can one or more of:\n            - \"ents\": data about the spans in doc.ents such as the text, label,\n                context attributes, section information, or custom attributes\n            - \"group\": data about spans in a span group with the name `span_group_attrs` section text and category\n            - \"context\": data about entity-modifier pairs extracted by ConText\n            - \"doc\": a single doc-level representation. By default only doc.text is extracted, but other attributes may\n                be specified\n\n        Once processed, a doc's data can be accessed either by:\n            - doc._.data\n            - doc._.get_data(dtype=...)\n            - doc._.ent_data\n            - doc._.to_dataframe(dtype=...)\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp,\n        name: str = \"medspacy_doc_consumer\",\n        dtypes: Tuple = (\"ents\",),\n        dtype_attrs: Dict = None,\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        \"\"\"\n        Creates a new DocConsumer.\n\n        Args:\n            nlp: A spaCy model\n            dtypes: Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are:\n                \"ents\", \"group\", \"section\", \"context\", \"doc\".\n            dtype_attrs: An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will\n                set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either\n                native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time.\n                Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()\n            span_group_name: the name of the span group used when dtypes contains \"group\". At this time, only one span\n                group is supported.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self._span_group_name = span_group_name\n        if not isinstance(dtypes, tuple):\n            if dtypes == \"all\":\n                dtypes = tuple(ALLOWED_DATA_TYPES)\n            else:\n                raise ValueError(\n                    \"dtypes must be either 'all' or a tuple, not {0}\".format(dtypes)\n                )\n        for dtype in dtypes:\n            if dtype not in ALLOWED_DATA_TYPES:\n                raise ValueError(\n                    \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                        ALLOWED_DATA_TYPES, dtype\n                    )\n                )\n            if dtype == \"section\":\n                self.validate_section_attrs(dtype_attrs)\n        self.dtypes = dtypes\n        self.dtype_attrs = dtype_attrs\n\n        if self.dtype_attrs is None:\n            self._set_default_attrs()\n\n    @classmethod\n    def get_default_attrs(cls, dtypes: Optional[Tuple] = None):\n        \"\"\"\n        Gets the default attributes available to each type specified.\n\n        Args:\n            dtypes: Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be\n                returned.\n\n        Returns:\n            The attributes the doc consumer will output for each of the specified types in `dtypes`.\n        \"\"\"\n        if dtypes is None:\n            dtypes = ALLOWED_DATA_TYPES\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n            for dtype in dtypes:\n                if dtype not in ALLOWED_DATA_TYPES:\n                    raise ValueError(\"Invalid dtype,\", dtype)\n        dtype_attrs = {\n            dtype: list(attrs)\n            for (dtype, attrs) in DEFAULT_ATTRS.items()\n            if dtype in dtypes\n        }\n        return dtype_attrs\n\n    def _set_default_attrs(self):\n        \"\"\"\n        Gets the default attributes.\n        \"\"\"\n        self.dtype_attrs = self.get_default_attrs(self.dtypes)\n\n    def validate_section_attrs(self, attrs):\n        \"\"\"\n        Validate that section attributes are either not specified or are valid attribute names.\n        \"\"\"\n        if attrs is None:\n            return True\n        if \"section\" not in attrs:\n            return True\n        diff = set(attrs[\"section\"]).difference(ALLOWED_SECTION_ATTRS)\n        if diff:\n            raise ValueError(\"Invalid section dtype_attrs specified: {0}\".format(diff))\n        return True\n\n    def __call__(self, doc):\n        \"\"\"\n        Call the doc consumer on a doc and assign the data.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed Doc.\n        \"\"\"\n        data = dict()\n        for dtype, attrs in self.dtype_attrs.items():\n            data.setdefault(dtype, OrderedDict())\n            for attr in attrs:\n                data[dtype][attr] = list()\n        if \"ents\" in self.dtypes:\n            for ent in doc.ents:\n                for attr in self.dtype_attrs[\"ents\"]:\n                    try:\n                        val = getattr(ent, attr)\n                    except AttributeError:\n                        val = getattr(ent._, attr)\n                    data[\"ents\"][attr].append(val)\n        if \"group\" in self.dtypes:\n            for span in doc.spans[self._span_group_name]:\n                for attr in self.dtype_attrs[\"group\"]:\n                    try:\n                        val = getattr(span, attr)\n                    except AttributeError:\n                        val = getattr(span._, attr)\n                    data[\"group\"][attr].append(val)\n        if \"context\" in self.dtypes:\n            for (ent, modifier) in doc._.context_graph.edges:\n                self.add_context_edge_attributes(ent, modifier, data[\"context\"], doc)\n        if \"section\" in self.dtypes:\n            for section in doc._.sections:\n                self.add_section_attributes(section, data[\"section\"], doc)\n        if \"doc\" in self.dtypes:\n            for attr in self.dtype_attrs[\"doc\"]:\n                try:\n                    val = getattr(doc, attr)\n                except AttributeError:\n                    val = getattr(doc._, attr)\n                data[\"doc\"][attr].append(val)\n\n        doc._.data = data\n        return doc\n\n    def add_context_edge_attributes(\n        self, ent: Span, modifier: ConTextModifier, context_data, doc\n    ):\n        span_tup = modifier.modifier_span\n        span = doc[span_tup[0] : span_tup[1]]\n        scope_tup = modifier.scope_span\n        scope = doc[scope_tup[0] : scope_tup[1]]\n        for attr in self.dtype_attrs[\"context\"]:\n            if attr == \"ent_text\":\n                context_data[\"ent_text\"].append(ent.text)\n            elif attr == \"ent_label_\":\n                context_data[\"ent_label_\"].append(ent.label_)\n            elif attr == \"ent_start_char\":\n                context_data[\"ent_start_char\"].append(ent.start_char)\n            elif attr == \"ent_end_char\":\n                context_data[\"ent_end_char\"].append(ent.end_char)\n            elif attr == \"modifier_text\":\n                context_data[\"modifier_text\"].append(span.text)\n            elif attr == \"modifier_category\":\n                context_data[\"modifier_category\"].append(modifier.category)\n            elif attr == \"modifier_direction\":\n               context_data[\"modifier_direction\"].append(modifier.direction)\n            elif attr == \"modifier_start_char\":\n                context_data[\"modifier_start_char\"].append(span.start_char)\n            elif attr == \"modifier_end_char\":\n                context_data[\"modifier_end_char\"].append(span.end_char)\n            elif attr == \"modifier_scope_start_char\":\n                context_data[\"modifier_scope_start_char\"].append(scope.start_char)\n            elif attr == \"modifier_scope_end_char\":\n                context_data[\"modifier_scope_end_char\"].append(scope.end_char)\n            else:\n            # if specified attribute is not one of these standard values, check the entity to see if it's an entity value\n                try:\n                    val = getattr(ent, attr)\n                except AttributeError:\n                    try:\n                        val = getattr(ent._, attr)\n                    except AttributeError:\n                        raise ValueError(f\"Attributes for dtype 'context' must be either \"\n                                         f\"a registered custom Span attribute (i.e., Span._.attr) or one of these pre-defined values: \"\n                                          f\"{ALLOWED_CONTEXT_ATTRS}. \\nYou passed in '{attr}'\")\n                context_data[f\"{attr}\"].append(val)\n\n    def add_section_attributes(self, section, section_data, doc):\n        # Allow for null sections\n        section_title_tup = section.title_span\n        section_body_tup = section.body_span\n        section_title = doc[section_title_tup[0] : section_title_tup[1]]\n        section_body = doc[section_body_tup[0] : section_body_tup[1]]\n        if \"section_category\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_category\"].append(section.category)\n        if section.category is not None:\n            if \"section_title_text\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_text\"].append(section_title.text)\n            if \"section_title_start_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_start_char\"].append(\n                    section_title.start_char\n                )\n            if \"section_title_end_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_end_char\"].append(section_title.end_char)\n        else:\n            if \"section_title_text\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_text\"].append(None)\n            if \"section_title_start_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_start_char\"].append(0)\n            if \"section_title_end_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_end_char\"].append(0)\n        if \"section_body\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body\"].append(section_body.text)\n        if \"section_body_start_char\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body_start_char\"].append(section_body.start_char)\n        if \"section_body_end_char\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body_end_char\"].append(section_body.end_char)\n        if \"section_parent\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_parent\"].append(section.parent)\n</code></pre>"},{"location":"singlepage/#medspacy.io.doc_consumer.DocConsumer.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the doc consumer on a doc and assign the data.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <p>The processed Doc.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def __call__(self, doc):\n    \"\"\"\n    Call the doc consumer on a doc and assign the data.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed Doc.\n    \"\"\"\n    data = dict()\n    for dtype, attrs in self.dtype_attrs.items():\n        data.setdefault(dtype, OrderedDict())\n        for attr in attrs:\n            data[dtype][attr] = list()\n    if \"ents\" in self.dtypes:\n        for ent in doc.ents:\n            for attr in self.dtype_attrs[\"ents\"]:\n                try:\n                    val = getattr(ent, attr)\n                except AttributeError:\n                    val = getattr(ent._, attr)\n                data[\"ents\"][attr].append(val)\n    if \"group\" in self.dtypes:\n        for span in doc.spans[self._span_group_name]:\n            for attr in self.dtype_attrs[\"group\"]:\n                try:\n                    val = getattr(span, attr)\n                except AttributeError:\n                    val = getattr(span._, attr)\n                data[\"group\"][attr].append(val)\n    if \"context\" in self.dtypes:\n        for (ent, modifier) in doc._.context_graph.edges:\n            self.add_context_edge_attributes(ent, modifier, data[\"context\"], doc)\n    if \"section\" in self.dtypes:\n        for section in doc._.sections:\n            self.add_section_attributes(section, data[\"section\"], doc)\n    if \"doc\" in self.dtypes:\n        for attr in self.dtype_attrs[\"doc\"]:\n            try:\n                val = getattr(doc, attr)\n            except AttributeError:\n                val = getattr(doc._, attr)\n            data[\"doc\"][attr].append(val)\n\n    doc._.data = data\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.io.doc_consumer.DocConsumer.__init__","title":"<code>__init__(nlp, name='medspacy_doc_consumer', dtypes=('ents',), dtype_attrs=None, span_group_name='medspacy_spans')</code>","text":"<p>Creates a new DocConsumer.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <p>A spaCy model</p> required <code>dtypes</code> <code>Tuple</code> <p>Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are: \"ents\", \"group\", \"section\", \"context\", \"doc\".</p> <code>('ents',)</code> <code>dtype_attrs</code> <code>Dict</code> <p>An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time. Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()</p> <code>None</code> <code>span_group_name</code> <code>str</code> <p>the name of the span group used when dtypes contains \"group\". At this time, only one span group is supported.</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def __init__(\n    self,\n    nlp,\n    name: str = \"medspacy_doc_consumer\",\n    dtypes: Tuple = (\"ents\",),\n    dtype_attrs: Dict = None,\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Creates a new DocConsumer.\n\n    Args:\n        nlp: A spaCy model\n        dtypes: Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are:\n            \"ents\", \"group\", \"section\", \"context\", \"doc\".\n        dtype_attrs: An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will\n            set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either\n            native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time.\n            Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()\n        span_group_name: the name of the span group used when dtypes contains \"group\". At this time, only one span\n            group is supported.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self._span_group_name = span_group_name\n    if not isinstance(dtypes, tuple):\n        if dtypes == \"all\":\n            dtypes = tuple(ALLOWED_DATA_TYPES)\n        else:\n            raise ValueError(\n                \"dtypes must be either 'all' or a tuple, not {0}\".format(dtypes)\n            )\n    for dtype in dtypes:\n        if dtype not in ALLOWED_DATA_TYPES:\n            raise ValueError(\n                \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                    ALLOWED_DATA_TYPES, dtype\n                )\n            )\n        if dtype == \"section\":\n            self.validate_section_attrs(dtype_attrs)\n    self.dtypes = dtypes\n    self.dtype_attrs = dtype_attrs\n\n    if self.dtype_attrs is None:\n        self._set_default_attrs()\n</code></pre>"},{"location":"singlepage/#medspacy.io.doc_consumer.DocConsumer._set_default_attrs","title":"<code>_set_default_attrs()</code>","text":"<p>Gets the default attributes.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def _set_default_attrs(self):\n    \"\"\"\n    Gets the default attributes.\n    \"\"\"\n    self.dtype_attrs = self.get_default_attrs(self.dtypes)\n</code></pre>"},{"location":"singlepage/#medspacy.io.doc_consumer.DocConsumer.get_default_attrs","title":"<code>get_default_attrs(dtypes=None)</code>  <code>classmethod</code>","text":"<p>Gets the default attributes available to each type specified.</p> <p>Parameters:</p> Name Type Description Default <code>dtypes</code> <code>Optional[Tuple]</code> <p>Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <p>The attributes the doc consumer will output for each of the specified types in <code>dtypes</code>.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>@classmethod\ndef get_default_attrs(cls, dtypes: Optional[Tuple] = None):\n    \"\"\"\n    Gets the default attributes available to each type specified.\n\n    Args:\n        dtypes: Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be\n            returned.\n\n    Returns:\n        The attributes the doc consumer will output for each of the specified types in `dtypes`.\n    \"\"\"\n    if dtypes is None:\n        dtypes = ALLOWED_DATA_TYPES\n    else:\n        if isinstance(dtypes, str):\n            dtypes = (dtypes,)\n        for dtype in dtypes:\n            if dtype not in ALLOWED_DATA_TYPES:\n                raise ValueError(\"Invalid dtype,\", dtype)\n    dtype_attrs = {\n        dtype: list(attrs)\n        for (dtype, attrs) in DEFAULT_ATTRS.items()\n        if dtype in dtypes\n    }\n    return dtype_attrs\n</code></pre>"},{"location":"singlepage/#medspacy.io.doc_consumer.DocConsumer.validate_section_attrs","title":"<code>validate_section_attrs(attrs)</code>","text":"<p>Validate that section attributes are either not specified or are valid attribute names.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def validate_section_attrs(self, attrs):\n    \"\"\"\n    Validate that section attributes are either not specified or are valid attribute names.\n    \"\"\"\n    if attrs is None:\n        return True\n    if \"section\" not in attrs:\n        return True\n    diff = set(attrs[\"section\"]).difference(ALLOWED_SECTION_ATTRS)\n    if diff:\n        raise ValueError(\"Invalid section dtype_attrs specified: {0}\".format(diff))\n    return True\n</code></pre>"},{"location":"singlepage/#medspacy.io.pipeline","title":"<code>pipeline</code>","text":""},{"location":"singlepage/#medspacy.io.pipeline.Pipeline","title":"<code>Pipeline</code>","text":"<p>The Pipeline class executes a batch process of reading texts, processing them with a spaCy model, and writing the results back to a database.</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>@Language.factory(\"medspacy_pipeline\")\nclass Pipeline:\n    \"\"\"The Pipeline class executes a batch process of reading texts, processing them with a spaCy model, and writing\n    the results back to a database.\n    \"\"\"\n\n    def __init__(self, nlp, reader, writer, name=\"medspacy_pipeline\", dtype=\"ent\"):\n        \"\"\"Create a new Pipeline object.\n        Args:\n            reader: A DbReader object\n            writer: A Dbwriter object\n            nlp: A spaCy model\n            dtype: The DocConsumer data type to write to a database.\n                Default \"ent\n                Valid options are (\"ent\", \"section\", \"context\", \"doc\")\n        \"\"\"\n\n        self.reader = reader\n        self.writer = writer\n        self.name = name\n        self.nlp = nlp\n        self.dtype = dtype\n        if dtype not in ALLOWED_DATA_TYPES:\n            raise ValueError(\n                \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                    ALLOWED_DATA_TYPES, dtype\n                )\n            )\n\n    def process(self):\n        \"\"\"Run a pipeline by reading a set of texts from a source table, processing them with nlp,\n        and writing doc._.data back to the destination table.\n        \"\"\"\n        query_result = self.reader.read()\n        data = None\n        while query_result:\n            if len(query_result) &gt; 0:\n                query_zip = list(zip(*query_result))\n                ids = query_zip[0]\n                texts = query_zip[1]\n\n                docs = self.nlp.pipe(texts)\n\n                for i, doc in enumerate(docs):\n                    text_id = ids[i]\n                    # Get the data as rows of tuples\n                    doc_data = doc._.get_data(self.dtype, as_rows=True)\n                    # Add the identifier column\n                    doc_data = [(text_id,) + row_data for row_data in doc_data]\n                    # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n                    # doc_data = pd.DataFrame(data=doc._.get_data(self.dtype))\n                    # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n\n                    if data is None:\n                        data = doc_data.copy()\n                    else:\n                        data += doc_data.copy()\n                    if len(data) &gt;= self.writer.batch_size:\n                        self.writer.write_data(data)\n                        data = None\n            query_result = self.reader.read()\n\n        if data is not None:\n            self.writer.write_data(data)\n            data = None\n\n        self.reader.close()\n        if self.writer.db.conn != self.reader.db.conn:\n            self.writer.close()\n</code></pre>"},{"location":"singlepage/#medspacy.io.pipeline.Pipeline.__init__","title":"<code>__init__(nlp, reader, writer, name='medspacy_pipeline', dtype='ent')</code>","text":"<p>Create a new Pipeline object. Args:     reader: A DbReader object     writer: A Dbwriter object     nlp: A spaCy model     dtype: The DocConsumer data type to write to a database.         Default \"ent         Valid options are (\"ent\", \"section\", \"context\", \"doc\")</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>def __init__(self, nlp, reader, writer, name=\"medspacy_pipeline\", dtype=\"ent\"):\n    \"\"\"Create a new Pipeline object.\n    Args:\n        reader: A DbReader object\n        writer: A Dbwriter object\n        nlp: A spaCy model\n        dtype: The DocConsumer data type to write to a database.\n            Default \"ent\n            Valid options are (\"ent\", \"section\", \"context\", \"doc\")\n    \"\"\"\n\n    self.reader = reader\n    self.writer = writer\n    self.name = name\n    self.nlp = nlp\n    self.dtype = dtype\n    if dtype not in ALLOWED_DATA_TYPES:\n        raise ValueError(\n            \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                ALLOWED_DATA_TYPES, dtype\n            )\n        )\n</code></pre>"},{"location":"singlepage/#medspacy.io.pipeline.Pipeline.process","title":"<code>process()</code>","text":"<p>Run a pipeline by reading a set of texts from a source table, processing them with nlp, and writing doc._.data back to the destination table.</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>def process(self):\n    \"\"\"Run a pipeline by reading a set of texts from a source table, processing them with nlp,\n    and writing doc._.data back to the destination table.\n    \"\"\"\n    query_result = self.reader.read()\n    data = None\n    while query_result:\n        if len(query_result) &gt; 0:\n            query_zip = list(zip(*query_result))\n            ids = query_zip[0]\n            texts = query_zip[1]\n\n            docs = self.nlp.pipe(texts)\n\n            for i, doc in enumerate(docs):\n                text_id = ids[i]\n                # Get the data as rows of tuples\n                doc_data = doc._.get_data(self.dtype, as_rows=True)\n                # Add the identifier column\n                doc_data = [(text_id,) + row_data for row_data in doc_data]\n                # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n                # doc_data = pd.DataFrame(data=doc._.get_data(self.dtype))\n                # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n\n                if data is None:\n                    data = doc_data.copy()\n                else:\n                    data += doc_data.copy()\n                if len(data) &gt;= self.writer.batch_size:\n                    self.writer.write_data(data)\n                    data = None\n        query_result = self.reader.read()\n\n    if data is not None:\n        self.writer.write_data(data)\n        data = None\n\n    self.reader.close()\n    if self.writer.db.conn != self.reader.db.conn:\n        self.writer.close()\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess","title":"<code>postprocess</code>","text":""},{"location":"singlepage/#medspacy.postprocess.PostprocessingPattern","title":"<code>PostprocessingPattern</code>","text":"<p>PostprocessingPatterns are callable functions and equality values wrapped together that will create triggers in the later Postprocessor as part of PostprocessingRules.</p> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>class PostprocessingPattern:\n    \"\"\"\n    PostprocessingPatterns are callable functions and equality values wrapped together that will create triggers\n    in the later Postprocessor as part of PostprocessingRules.\n    \"\"\"\n\n    def __init__(self, condition: Callable, success_value: Any = True, **kwargs):\n        \"\"\"\n        A PostprocessingPattern defines a single condition to check against an entity.\n\n        Args:\n            condition: A function to call on an entity. If the result of the function call equals success_value, then\n                the pattern passes.\n            success_value: The value which should be returned by condition(ent) in order for the pattern to pass. Must\n                have == defined for condition(ent) == success_value.\n            kwargs: Optional keyword arguments to call with condition(ent, **kwargs).\n        \"\"\"\n        self.condition = condition\n        self.success_value = success_value\n        self.kwargs = kwargs\n\n    def __call__(self, ent: Span) -&gt; bool:\n        \"\"\"\n        Call the PostprocessingPattern on the span specified.\n\n        Args:\n            ent: the span to process.\n\n        Returns:\n            Whether calling `condition` on the entity specified is `success_value`.\n        \"\"\"\n        if self.kwargs:\n            result = self.condition(ent, **self.kwargs)\n        else:\n            result = self.condition(ent)\n        return result == self.success_value\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.PostprocessingPattern.__call__","title":"<code>__call__(ent)</code>","text":"<p>Call the PostprocessingPattern on the span specified.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>the span to process.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether calling <code>condition</code> on the entity specified is <code>success_value</code>.</p> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>def __call__(self, ent: Span) -&gt; bool:\n    \"\"\"\n    Call the PostprocessingPattern on the span specified.\n\n    Args:\n        ent: the span to process.\n\n    Returns:\n        Whether calling `condition` on the entity specified is `success_value`.\n    \"\"\"\n    if self.kwargs:\n        result = self.condition(ent, **self.kwargs)\n    else:\n        result = self.condition(ent)\n    return result == self.success_value\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.PostprocessingPattern.__init__","title":"<code>__init__(condition, success_value=True, **kwargs)</code>","text":"<p>A PostprocessingPattern defines a single condition to check against an entity.</p> <p>Parameters:</p> Name Type Description Default <code>condition</code> <code>Callable</code> <p>A function to call on an entity. If the result of the function call equals success_value, then the pattern passes.</p> required <code>success_value</code> <code>Any</code> <p>The value which should be returned by condition(ent) in order for the pattern to pass. Must have == defined for condition(ent) == success_value.</p> <code>True</code> <code>kwargs</code> <p>Optional keyword arguments to call with condition(ent, **kwargs).</p> <code>{}</code> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>def __init__(self, condition: Callable, success_value: Any = True, **kwargs):\n    \"\"\"\n    A PostprocessingPattern defines a single condition to check against an entity.\n\n    Args:\n        condition: A function to call on an entity. If the result of the function call equals success_value, then\n            the pattern passes.\n        success_value: The value which should be returned by condition(ent) in order for the pattern to pass. Must\n            have == defined for condition(ent) == success_value.\n        kwargs: Optional keyword arguments to call with condition(ent, **kwargs).\n    \"\"\"\n    self.condition = condition\n    self.success_value = success_value\n    self.kwargs = kwargs\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.PostprocessingRule","title":"<code>PostprocessingRule</code>","text":"Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>class PostprocessingRule:\n    def __init__(\n        self,\n        patterns: Iterable[PostprocessingPattern],\n        action: Callable,\n        name: str = None,\n        description: str = None,\n        span_group_name: str = \"medspacy_spans\",\n        **kwargs,\n    ):\n        \"\"\"\n        A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.\n\n        patterns: A list of PostprocessingPatterns, each of which check a condition of an entity.\n        action: A function to call with the entity as an argument. This function should take the following arguments:\n            ent: The spacy span\n            i: The index of ent\n            input_span_type: \"ents\" or \"group\". Describes where to look for spans.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\".\n            kwargs: Any additional keyword arguments for action.\n        name: Optional name of direction.\n        description: Optional description of the direction.\n        kwargs: Optional keyword arguments to send to `action`.\n\n        \"\"\"\n        self.patterns = patterns\n        self.action = action\n        self.name = name\n        self.description = description\n        self.input_span_type = None\n        self.span_group_name = span_group_name\n        self.kwargs = kwargs\n\n    def __call__(self, ent, i, debug=False):\n        \"\"\"\n        Iterate through all the rules in self.rules.\n        If any pattern does not pass (ie., return True), then returns False.\n        If they all pass, execute self.action and return True.\n        \"\"\"\n        for pattern in self.patterns:\n            # If this is a tuple, at least one has to pass\n            if isinstance(pattern, tuple):\n                passed = False\n                for subpattern in pattern:\n                    rslt = subpattern(ent)\n                    if rslt is True:\n                        passed = True\n                        break\n                if passed is False:\n                    return False\n            # Otherwise just check a single value\n            else:\n                rslt = pattern(ent)\n                if rslt is False:\n                    return False\n\n        # Every pattern passed - do the action\n        if debug:\n            print(\"Passed:\", self, \"on ent:\", ent, ent.sent)\n\n        try:\n            if self.kwargs:\n                self.action(\n                    ent, i, self.input_span_type, self.span_group_name, **self.kwargs\n                )\n            else:\n                self.action(ent, i, self.input_span_type, self.span_group_name)\n        except TypeError:\n            _raise_action_error(\n                self.action,\n                (ent, i, self.input_span_type, self.span_group_name, self.kwargs),\n            )\n\n    def __repr__(self):\n        return f\"PostprocessingRule: {self.name} - {self.description}\"\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.PostprocessingRule.__call__","title":"<code>__call__(ent, i, debug=False)</code>","text":"<p>Iterate through all the rules in self.rules. If any pattern does not pass (ie., return True), then returns False. If they all pass, execute self.action and return True.</p> Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>def __call__(self, ent, i, debug=False):\n    \"\"\"\n    Iterate through all the rules in self.rules.\n    If any pattern does not pass (ie., return True), then returns False.\n    If they all pass, execute self.action and return True.\n    \"\"\"\n    for pattern in self.patterns:\n        # If this is a tuple, at least one has to pass\n        if isinstance(pattern, tuple):\n            passed = False\n            for subpattern in pattern:\n                rslt = subpattern(ent)\n                if rslt is True:\n                    passed = True\n                    break\n            if passed is False:\n                return False\n        # Otherwise just check a single value\n        else:\n            rslt = pattern(ent)\n            if rslt is False:\n                return False\n\n    # Every pattern passed - do the action\n    if debug:\n        print(\"Passed:\", self, \"on ent:\", ent, ent.sent)\n\n    try:\n        if self.kwargs:\n            self.action(\n                ent, i, self.input_span_type, self.span_group_name, **self.kwargs\n            )\n        else:\n            self.action(ent, i, self.input_span_type, self.span_group_name)\n    except TypeError:\n        _raise_action_error(\n            self.action,\n            (ent, i, self.input_span_type, self.span_group_name, self.kwargs),\n        )\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.PostprocessingRule.__init__","title":"<code>__init__(patterns, action, name=None, description=None, span_group_name='medspacy_spans', **kwargs)</code>","text":"<p>A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.</p> <p>patterns: A list of PostprocessingPatterns, each of which check a condition of an entity. action: A function to call with the entity as an argument. This function should take the following arguments:     ent: The spacy span     i: The index of ent     input_span_type: \"ents\" or \"group\". Describes where to look for spans.     span_group_name: The name of the span group used when <code>input_span_type</code> is \"group\".     kwargs: Any additional keyword arguments for action. name: Optional name of direction. description: Optional description of the direction. kwargs: Optional keyword arguments to send to <code>action</code>.</p> Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>def __init__(\n    self,\n    patterns: Iterable[PostprocessingPattern],\n    action: Callable,\n    name: str = None,\n    description: str = None,\n    span_group_name: str = \"medspacy_spans\",\n    **kwargs,\n):\n    \"\"\"\n    A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.\n\n    patterns: A list of PostprocessingPatterns, each of which check a condition of an entity.\n    action: A function to call with the entity as an argument. This function should take the following arguments:\n        ent: The spacy span\n        i: The index of ent\n        input_span_type: \"ents\" or \"group\". Describes where to look for spans.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\".\n        kwargs: Any additional keyword arguments for action.\n    name: Optional name of direction.\n    description: Optional description of the direction.\n    kwargs: Optional keyword arguments to send to `action`.\n\n    \"\"\"\n    self.patterns = patterns\n    self.action = action\n    self.name = name\n    self.description = description\n    self.input_span_type = None\n    self.span_group_name = span_group_name\n    self.kwargs = kwargs\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.Postprocessor","title":"<code>Postprocessor</code>","text":"Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>@Language.factory(\"medspacy_postprocessor\")\nclass Postprocessor:\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_postprocessor\",\n        rules: Iterable[PostprocessingRule] = None,\n        debug: bool = False,\n        input_span_type: Literal[\"ents\", \"group\"] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        self.nlp = nlp\n        self.name = name\n        self._rules = []\n        self.debug = debug\n        self._input_span_type = input_span_type\n        self._span_group_name = span_group_name\n\n        if rules:\n            self.add(rules)\n\n    @property\n    def rules(self) -&gt; List[PostprocessingRule]:\n        \"\"\"\n        Gets the rules.\n\n        Returns:\n            The list of PostprocessingRules available to the Postprocessor.\n        \"\"\"\n        return self._rules\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_span_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_span_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules: Union[PostprocessingRule, Iterable[PostprocessingRule]]):\n        \"\"\"\n        Adds PostprocessingRules to the Postprocessor.\n\n        Args:\n            rules: A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.\n        \"\"\"\n        if isinstance(rules, PostprocessingRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, PostprocessingRule):\n                raise TypeError(\n                    f\"Rules must be type PostprocessingRule, not {type(rule)}.\"\n                )\n            if rule.input_span_type is None:\n                rule.input_span_type = self.input_span_type\n        self._rules += rules\n\n    def __call__(self, doc: Doc):\n        \"\"\"\n        Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed Doc.\n        \"\"\"\n        # Iterate through the entities in reversed order\n        if self._input_span_type == \"ents\":\n            spans = doc.ents\n        else:\n            spans = doc.spans[self._span_group_name]\n\n        for i in range(len(spans) - 1, -1, -1):\n            ent = spans[i]\n            if self.debug:\n                print(ent)\n\n            # let's keep track of whether the rule makes a change to spans\n            span_count_before_rule = None\n            if self._input_span_type == \"ents\":\n                span_count_before_rule = len(doc.ents)\n            else:\n                span_count_before_rule = len(doc.spans[self.span_group_name])\n\n            for rule in self.rules:\n                rule(ent, i, debug=self.debug)\n                # Check if the entity was removed based on span counts before and after rule execution\n                # if it was, skip to the next entity\n                try:\n                    if self._input_span_type == \"ents\":\n                        if len(doc.ents) != span_count_before_rule:\n                            break\n                    else:\n                        if len(doc.spans[self.span_group_name]) != span_count_before_rule:\n                            break\n                except IndexError:\n                    break\n            # if self.debug:\n            #     print()\n        return doc\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.Postprocessor.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"singlepage/#medspacy.postprocess.Postprocessor.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets the rules.</p> <p>Returns:</p> Type Description <code>List[PostprocessingRule]</code> <p>The list of PostprocessingRules available to the Postprocessor.</p>"},{"location":"singlepage/#medspacy.postprocess.Postprocessor.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_span_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"singlepage/#medspacy.postprocess.Postprocessor.__call__","title":"<code>__call__(doc)</code>","text":"<p>Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <p>The processed Doc.</p> Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>def __call__(self, doc: Doc):\n    \"\"\"\n    Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed Doc.\n    \"\"\"\n    # Iterate through the entities in reversed order\n    if self._input_span_type == \"ents\":\n        spans = doc.ents\n    else:\n        spans = doc.spans[self._span_group_name]\n\n    for i in range(len(spans) - 1, -1, -1):\n        ent = spans[i]\n        if self.debug:\n            print(ent)\n\n        # let's keep track of whether the rule makes a change to spans\n        span_count_before_rule = None\n        if self._input_span_type == \"ents\":\n            span_count_before_rule = len(doc.ents)\n        else:\n            span_count_before_rule = len(doc.spans[self.span_group_name])\n\n        for rule in self.rules:\n            rule(ent, i, debug=self.debug)\n            # Check if the entity was removed based on span counts before and after rule execution\n            # if it was, skip to the next entity\n            try:\n                if self._input_span_type == \"ents\":\n                    if len(doc.ents) != span_count_before_rule:\n                        break\n                else:\n                    if len(doc.spans[self.span_group_name]) != span_count_before_rule:\n                        break\n            except IndexError:\n                break\n        # if self.debug:\n        #     print()\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.Postprocessor.add","title":"<code>add(rules)</code>","text":"<p>Adds PostprocessingRules to the Postprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[PostprocessingRule, Iterable[PostprocessingRule]]</code> <p>A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.</p> required Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>def add(self, rules: Union[PostprocessingRule, Iterable[PostprocessingRule]]):\n    \"\"\"\n    Adds PostprocessingRules to the Postprocessor.\n\n    Args:\n        rules: A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.\n    \"\"\"\n    if isinstance(rules, PostprocessingRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, PostprocessingRule):\n            raise TypeError(\n                f\"Rules must be type PostprocessingRule, not {type(rule)}.\"\n            )\n        if rule.input_span_type is None:\n            rule.input_span_type = self.input_span_type\n    self._rules += rules\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions","title":"<code>postprocessing_functions</code>","text":"<p>This module contains some simple functions that can be used as action or condition functions for postprocessing rules.</p>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.ent_contains","title":"<code>ent_contains(ent, target, regex=True)</code>","text":"<p>Check if an entity occurs in the same sentence as another span of text. Case-insensitive.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>A string or a collection of strings that will be searched inside <code>ent</code>.</p> required <code>regex</code> <code>bool</code> <p>If the <code>target</code> specified is a regex pattern. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the target is contained in the ent.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def ent_contains(\n    ent: Span, target: Union[str, Iterable[str]], regex: bool = True\n) -&gt; bool:\n    \"\"\"\n    Check if an entity occurs in the same sentence as another span of text. Case-insensitive.\n\n    Args:\n        ent: The span to check.\n        target: A string or a collection of strings that will be searched inside `ent`.\n        regex: If the `target` specified is a regex pattern. Default is True.\n\n    Returns:\n        Whether the target is contained in the ent.\n    \"\"\"\n    return span_contains(ent, target, regex)\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.is_family","title":"<code>is_family(span)</code>","text":"<p>Returns whether a span is marked as family.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_family set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_family(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as family.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_family set to True.\n    \"\"\"\n    return span._.is_family\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.is_followed_by","title":"<code>is_followed_by(ent, target, window=1)</code>","text":"<p>Checks if an entity is followed by a target word within a certain window. If any phrases in target are more than one token long, this may not capture it if window is smaller than the number of tokens. Case-insensitive.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>A string or a collection of strings that will be searched for in the text following <code>ent</code>.</p> required <code>window</code> <code>int</code> <p>The number of tokens to search for <code>target</code> following <code>ent</code>. Default is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the entity specified is followed by a target.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_followed_by(\n    ent: Span, target: Union[str, Iterable[str]], window: int = 1\n) -&gt; bool:\n    \"\"\"\n    Checks if an entity is followed by a target word within a certain window. If any phrases in target are more than one\n    token long, this may not capture it if window is smaller than the number of tokens. Case-insensitive.\n\n    Args:\n        ent: The span to check.\n        target: A string or a collection of strings that will be searched for in the text following `ent`.\n        window: The number of tokens to search for `target` following `ent`. Default is 1.\n\n    Returns:\n        Whether the entity specified is followed by a target.\n    \"\"\"\n    following_span = ent.doc[ent.end : ent.end + window]\n    following_string = \" \".join([token.text.lower() for token in following_span])\n    if isinstance(target, str):\n        return target.lower() in following_string\n    for string in target:\n        if string.lower() in following_string:\n            return True\n    return False\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.is_historical","title":"<code>is_historical(span)</code>","text":"<p>Returns whether a span is marked as historical.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_historical set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_historical(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as historical.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_historical set to True.\n    \"\"\"\n    return span._.is_historical\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.is_hypothetical","title":"<code>is_hypothetical(span)</code>","text":"<p>Returns whether a span is marked as hypothetical.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_hypothetical set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_hypothetical(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as hypothetical.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_hypothetical set to True.\n    \"\"\"\n    return span._.is_hypothetical\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.is_modified_by_category","title":"<code>is_modified_by_category(span, category)</code>","text":"<p>Returns whether a span is modified by a ConTextModifier of that type.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <code>category</code> <code>str</code> <p>The category to check whether a ConTextModifier of that type modifies the span.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has the specified modifier type.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_modified_by_category(span: Span, category: str) -&gt; bool:\n    \"\"\"\n    Returns whether a span is modified by a ConTextModifier of that type.\n\n    Args:\n        span: The span to check.\n        category: The category to check whether a ConTextModifier of that type modifies the span.\n\n    Returns:\n        Whether the specified span has the specified modifier type.\n    \"\"\"\n    for modifier in span._.modifiers:\n        if modifier.category.upper() == category.upper():\n            return True\n    return False\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.is_modified_by_text","title":"<code>is_modified_by_text(span, target, regex=True)</code>","text":"<p>Returns whether a span is modified by a ConTextModifier with the specified text.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>The category to check whether a ConTextModifier with this text modifies the span.</p> required <code>regex</code> <code>bool</code> <p>If the <code>target</code> specified is a regex pattern. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has the specified modifier type.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_modified_by_text(\n    span: Span, target: Union[str, Iterable[str]], regex: bool = True\n) -&gt; bool:\n    \"\"\"\n    Returns whether a span is modified by a ConTextModifier with the specified text.\n\n    Args:\n        span: The span to check.\n        target: The category to check whether a ConTextModifier with this text modifies the span.\n        regex: If the `target` specified is a regex pattern. Default is True.\n\n    Returns:\n        Whether the specified span has the specified modifier type.\n    \"\"\"\n    for modifier in span._.modifiers:\n        if span_contains(modifier.span, target, regex):\n            return True\n    return False\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.is_negated","title":"<code>is_negated(span)</code>","text":"<p>Returns whether a span is marked as negated.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_negated set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_negated(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as negated.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_negated set to True.\n    \"\"\"\n    return span._.is_negated\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.is_preceded_by","title":"<code>is_preceded_by(ent, target, window=1)</code>","text":"<p>Checks if an entity is preceded by a target word within a certain window. If any phrases in target are more than one token long, this may not capture it if window is smaller than the number of tokens. Case-insensitive.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>A string or a collection of strings that will be searched for in the text preceding <code>ent</code>.</p> required <code>window</code> <code>int</code> <p>The number of tokens to search for <code>target</code> preceding <code>ent</code>. Default is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the entity specified is preceded by a target.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_preceded_by(\n    ent: Span, target: Union[str, Iterable[str]], window: int = 1\n) -&gt; bool:\n    \"\"\"\n    Checks if an entity is preceded by a target word within a certain window. If any phrases in target are more than one\n    token long, this may not capture it if window is smaller than the number of tokens. Case-insensitive.\n\n    Args:\n        ent: The span to check.\n        target: A string or a collection of strings that will be searched for in the text preceding `ent`.\n        window: The number of tokens to search for `target` preceding `ent`. Default is 1.\n\n    Returns:\n        Whether the entity specified is preceded by a target.\n    \"\"\"\n    preceding_span = ent.doc[ent.start - window : ent.start]\n    preceding_string = \" \".join([token.text.lower() for token in preceding_span])\n    if isinstance(target, str):\n        return target.lower() in preceding_string\n    for string in target:\n        if string.lower() in preceding_string:\n            return True\n    return False\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.is_uncertain","title":"<code>is_uncertain(span)</code>","text":"<p>Returns whether a span is marked as uncertain.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_uncertain set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_uncertain(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as uncertain.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_uncertain set to True.\n    \"\"\"\n    return span._.is_uncertain\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.remove_ent","title":"<code>remove_ent(ent, i, input_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Remove an entity at position [i] from doc.ents.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The entity to remove.</p> required <code>i</code> <code>int</code> <p>The index of <code>ent</code> in its source list.</p> required <code>input_type</code> <code>Literal['ents', 'group']</code> <p>The source of the entity, either \"ents\" or \"group\".</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>If <code>input_type</code> is \"group\", the name of the span group.</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def remove_ent(\n    ent: Span,\n    i: int,\n    input_type: Literal[\"ents\", \"group\"] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Remove an entity at position [i] from doc.ents.\n\n    Args:\n        ent: The entity to remove.\n        i: The index of `ent` in its source list.\n        input_type: The source of the entity, either \"ents\" or \"group\".\n        span_group_name: If `input_type` is \"group\", the name of the span group.\n    \"\"\"\n    doc = ent.doc\n    if input_type == \"ents\":\n        doc.ents = doc.ents[:i] + doc.ents[i + 1 :]\n    elif input_type == \"group\":\n        t = list(doc.spans[span_group_name])\n        doc.spans[span_group_name] = t[:i] + t[i + 1 :]\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.sentence_contains","title":"<code>sentence_contains(ent, target, regex=True)</code>","text":"<p>Check if an entity occurs in the same sentence as another span of text.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>A string or a collection of strings that will be searched for in the text of the sentence containing <code>ent</code>.</p> required <code>regex</code> <p>If the <code>target</code> specified is a regex pattern. Default is True.</p> <code>True</code> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def sentence_contains(ent: Span, target: Union[str, Iterable[str]], regex=True) -&gt; bool:\n    \"\"\"\n    Check if an entity occurs in the same sentence as another span of text.\n\n    Args:\n        ent: The span to check.\n        target: A string or a collection of strings that will be searched for in the text of the sentence containing\n            `ent`.\n        regex: If the `target` specified is a regex pattern. Default is True.\n    \"\"\"\n    return span_contains(ent.sent, target, regex)\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.set_family","title":"<code>set_family(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_family to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_family(ent, i, value=True):\n    \"Set the value of ent._.is_family to value.\"\n    ent._.is_hypothetical = value\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.set_historical","title":"<code>set_historical(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_historical to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_historical(ent, i, value=True):\n    \"\"\"Set the value of ent._.is_historical to value.\"\"\"\n    ent._.is_historical = value\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.set_hypothetical","title":"<code>set_hypothetical(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_hypothetical to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_hypothetical(ent, i, value=True):\n    \"\"\"Set the value of ent._.is_hypothetical to value.\"\"\"\n    ent._.is_hypothetical = value\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.set_label","title":"<code>set_label(ent, i, input_type='ents', span_group_name='medspacy_spans', **kwargs)</code>","text":"<p>Creates a copy of the entity with a new label.</p> <p>WARNING: This is not fully safe, as spaCy does not allow modifying the label of a span. Instead, this creates a new copy and attempts to copy existing attributes, but this is not totally reliable.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <p>The entity to MODIFY.</p> required <code>i</code> <p>The index of <code>ent</code> in its source list.</p> required <code>input_type</code> <code>Literal['ents', 'group']</code> <p>The source of the entity, either \"ents\" or \"group\".</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>If <code>input_type</code> is \"group\", the name of the span group.</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_label(\n    ent,\n    i,\n    input_type: Literal[\"ents\", \"group\"] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n    **kwargs\n):\n    \"\"\"\n    Creates a copy of the entity with a new label.\n\n    WARNING: This is not fully safe, as spaCy does not allow modifying the label of a span. Instead, this creates a new\n    copy and attempts to copy existing attributes, but this is not totally reliable.\n\n    Args:\n        ent: The entity to MODIFY.\n        i: The index of `ent` in its source list.\n        input_type: The source of the entity, either \"ents\" or \"group\".\n        span_group_name: If `input_type` is \"group\", the name of the span group.\n    \"\"\"\n    from spacy.tokens import Span\n\n    new_ent = Span(ent.doc, ent.start, ent.end, label=kwargs[\"label\"])\n    # Copy any additional attributes\n    # NOTE: This may not be complete and should be used with caution\n    for (attr, values) in ent._.__dict__[\"_extensions\"].items():\n        setattr(new_ent._, attr, values[0])\n    if input_type == \"ents\":\n        if len(ent.doc.ents) == 1:\n            ent.doc.ents = (new_ent,)\n        else:\n            ent.doc.ents = ent.doc.ents[:i] + (new_ent,) + ent.doc.ents[i + 1 :]\n    else:\n        if len(ent.doc.spans[span_group_name] == 1):\n            ent.doc.spans[span_group_name] = (new_ent,)\n        else:\n            ent.doc.spans[span_group_name] = (\n                ent.doc.spans[span_group_name][:i]\n                + (new_ent,)\n                + ent.doc.spans[span_group_name][i + 1 :]\n            )\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.set_negated","title":"<code>set_negated(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_negated to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_negated(ent, i, value=True):\n    \"\"\"Set the value of ent._.is_negated to value.\"\"\"\n    ent._.is_negated = value\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_functions.set_uncertain","title":"<code>set_uncertain(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_uncertain to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_uncertain(ent, i, value=True):\n    \"\"\"Set the value of ent._.is_uncertain to value.\"\"\"\n    ent._.is_uncertain = value\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_pattern","title":"<code>postprocessing_pattern</code>","text":""},{"location":"singlepage/#medspacy.postprocess.postprocessing_pattern.PostprocessingPattern","title":"<code>PostprocessingPattern</code>","text":"<p>PostprocessingPatterns are callable functions and equality values wrapped together that will create triggers in the later Postprocessor as part of PostprocessingRules.</p> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>class PostprocessingPattern:\n    \"\"\"\n    PostprocessingPatterns are callable functions and equality values wrapped together that will create triggers\n    in the later Postprocessor as part of PostprocessingRules.\n    \"\"\"\n\n    def __init__(self, condition: Callable, success_value: Any = True, **kwargs):\n        \"\"\"\n        A PostprocessingPattern defines a single condition to check against an entity.\n\n        Args:\n            condition: A function to call on an entity. If the result of the function call equals success_value, then\n                the pattern passes.\n            success_value: The value which should be returned by condition(ent) in order for the pattern to pass. Must\n                have == defined for condition(ent) == success_value.\n            kwargs: Optional keyword arguments to call with condition(ent, **kwargs).\n        \"\"\"\n        self.condition = condition\n        self.success_value = success_value\n        self.kwargs = kwargs\n\n    def __call__(self, ent: Span) -&gt; bool:\n        \"\"\"\n        Call the PostprocessingPattern on the span specified.\n\n        Args:\n            ent: the span to process.\n\n        Returns:\n            Whether calling `condition` on the entity specified is `success_value`.\n        \"\"\"\n        if self.kwargs:\n            result = self.condition(ent, **self.kwargs)\n        else:\n            result = self.condition(ent)\n        return result == self.success_value\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_pattern.PostprocessingPattern.__call__","title":"<code>__call__(ent)</code>","text":"<p>Call the PostprocessingPattern on the span specified.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>the span to process.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether calling <code>condition</code> on the entity specified is <code>success_value</code>.</p> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>def __call__(self, ent: Span) -&gt; bool:\n    \"\"\"\n    Call the PostprocessingPattern on the span specified.\n\n    Args:\n        ent: the span to process.\n\n    Returns:\n        Whether calling `condition` on the entity specified is `success_value`.\n    \"\"\"\n    if self.kwargs:\n        result = self.condition(ent, **self.kwargs)\n    else:\n        result = self.condition(ent)\n    return result == self.success_value\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_pattern.PostprocessingPattern.__init__","title":"<code>__init__(condition, success_value=True, **kwargs)</code>","text":"<p>A PostprocessingPattern defines a single condition to check against an entity.</p> <p>Parameters:</p> Name Type Description Default <code>condition</code> <code>Callable</code> <p>A function to call on an entity. If the result of the function call equals success_value, then the pattern passes.</p> required <code>success_value</code> <code>Any</code> <p>The value which should be returned by condition(ent) in order for the pattern to pass. Must have == defined for condition(ent) == success_value.</p> <code>True</code> <code>kwargs</code> <p>Optional keyword arguments to call with condition(ent, **kwargs).</p> <code>{}</code> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>def __init__(self, condition: Callable, success_value: Any = True, **kwargs):\n    \"\"\"\n    A PostprocessingPattern defines a single condition to check against an entity.\n\n    Args:\n        condition: A function to call on an entity. If the result of the function call equals success_value, then\n            the pattern passes.\n        success_value: The value which should be returned by condition(ent) in order for the pattern to pass. Must\n            have == defined for condition(ent) == success_value.\n        kwargs: Optional keyword arguments to call with condition(ent, **kwargs).\n    \"\"\"\n    self.condition = condition\n    self.success_value = success_value\n    self.kwargs = kwargs\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_rule","title":"<code>postprocessing_rule</code>","text":""},{"location":"singlepage/#medspacy.postprocess.postprocessing_rule.PostprocessingRule","title":"<code>PostprocessingRule</code>","text":"Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>class PostprocessingRule:\n    def __init__(\n        self,\n        patterns: Iterable[PostprocessingPattern],\n        action: Callable,\n        name: str = None,\n        description: str = None,\n        span_group_name: str = \"medspacy_spans\",\n        **kwargs,\n    ):\n        \"\"\"\n        A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.\n\n        patterns: A list of PostprocessingPatterns, each of which check a condition of an entity.\n        action: A function to call with the entity as an argument. This function should take the following arguments:\n            ent: The spacy span\n            i: The index of ent\n            input_span_type: \"ents\" or \"group\". Describes where to look for spans.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\".\n            kwargs: Any additional keyword arguments for action.\n        name: Optional name of direction.\n        description: Optional description of the direction.\n        kwargs: Optional keyword arguments to send to `action`.\n\n        \"\"\"\n        self.patterns = patterns\n        self.action = action\n        self.name = name\n        self.description = description\n        self.input_span_type = None\n        self.span_group_name = span_group_name\n        self.kwargs = kwargs\n\n    def __call__(self, ent, i, debug=False):\n        \"\"\"\n        Iterate through all the rules in self.rules.\n        If any pattern does not pass (ie., return True), then returns False.\n        If they all pass, execute self.action and return True.\n        \"\"\"\n        for pattern in self.patterns:\n            # If this is a tuple, at least one has to pass\n            if isinstance(pattern, tuple):\n                passed = False\n                for subpattern in pattern:\n                    rslt = subpattern(ent)\n                    if rslt is True:\n                        passed = True\n                        break\n                if passed is False:\n                    return False\n            # Otherwise just check a single value\n            else:\n                rslt = pattern(ent)\n                if rslt is False:\n                    return False\n\n        # Every pattern passed - do the action\n        if debug:\n            print(\"Passed:\", self, \"on ent:\", ent, ent.sent)\n\n        try:\n            if self.kwargs:\n                self.action(\n                    ent, i, self.input_span_type, self.span_group_name, **self.kwargs\n                )\n            else:\n                self.action(ent, i, self.input_span_type, self.span_group_name)\n        except TypeError:\n            _raise_action_error(\n                self.action,\n                (ent, i, self.input_span_type, self.span_group_name, self.kwargs),\n            )\n\n    def __repr__(self):\n        return f\"PostprocessingRule: {self.name} - {self.description}\"\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_rule.PostprocessingRule.__call__","title":"<code>__call__(ent, i, debug=False)</code>","text":"<p>Iterate through all the rules in self.rules. If any pattern does not pass (ie., return True), then returns False. If they all pass, execute self.action and return True.</p> Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>def __call__(self, ent, i, debug=False):\n    \"\"\"\n    Iterate through all the rules in self.rules.\n    If any pattern does not pass (ie., return True), then returns False.\n    If they all pass, execute self.action and return True.\n    \"\"\"\n    for pattern in self.patterns:\n        # If this is a tuple, at least one has to pass\n        if isinstance(pattern, tuple):\n            passed = False\n            for subpattern in pattern:\n                rslt = subpattern(ent)\n                if rslt is True:\n                    passed = True\n                    break\n            if passed is False:\n                return False\n        # Otherwise just check a single value\n        else:\n            rslt = pattern(ent)\n            if rslt is False:\n                return False\n\n    # Every pattern passed - do the action\n    if debug:\n        print(\"Passed:\", self, \"on ent:\", ent, ent.sent)\n\n    try:\n        if self.kwargs:\n            self.action(\n                ent, i, self.input_span_type, self.span_group_name, **self.kwargs\n            )\n        else:\n            self.action(ent, i, self.input_span_type, self.span_group_name)\n    except TypeError:\n        _raise_action_error(\n            self.action,\n            (ent, i, self.input_span_type, self.span_group_name, self.kwargs),\n        )\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessing_rule.PostprocessingRule.__init__","title":"<code>__init__(patterns, action, name=None, description=None, span_group_name='medspacy_spans', **kwargs)</code>","text":"<p>A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.</p> <p>patterns: A list of PostprocessingPatterns, each of which check a condition of an entity. action: A function to call with the entity as an argument. This function should take the following arguments:     ent: The spacy span     i: The index of ent     input_span_type: \"ents\" or \"group\". Describes where to look for spans.     span_group_name: The name of the span group used when <code>input_span_type</code> is \"group\".     kwargs: Any additional keyword arguments for action. name: Optional name of direction. description: Optional description of the direction. kwargs: Optional keyword arguments to send to <code>action</code>.</p> Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>def __init__(\n    self,\n    patterns: Iterable[PostprocessingPattern],\n    action: Callable,\n    name: str = None,\n    description: str = None,\n    span_group_name: str = \"medspacy_spans\",\n    **kwargs,\n):\n    \"\"\"\n    A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.\n\n    patterns: A list of PostprocessingPatterns, each of which check a condition of an entity.\n    action: A function to call with the entity as an argument. This function should take the following arguments:\n        ent: The spacy span\n        i: The index of ent\n        input_span_type: \"ents\" or \"group\". Describes where to look for spans.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\".\n        kwargs: Any additional keyword arguments for action.\n    name: Optional name of direction.\n    description: Optional description of the direction.\n    kwargs: Optional keyword arguments to send to `action`.\n\n    \"\"\"\n    self.patterns = patterns\n    self.action = action\n    self.name = name\n    self.description = description\n    self.input_span_type = None\n    self.span_group_name = span_group_name\n    self.kwargs = kwargs\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessor","title":"<code>postprocessor</code>","text":""},{"location":"singlepage/#medspacy.postprocess.postprocessor.Postprocessor","title":"<code>Postprocessor</code>","text":"Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>@Language.factory(\"medspacy_postprocessor\")\nclass Postprocessor:\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_postprocessor\",\n        rules: Iterable[PostprocessingRule] = None,\n        debug: bool = False,\n        input_span_type: Literal[\"ents\", \"group\"] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        self.nlp = nlp\n        self.name = name\n        self._rules = []\n        self.debug = debug\n        self._input_span_type = input_span_type\n        self._span_group_name = span_group_name\n\n        if rules:\n            self.add(rules)\n\n    @property\n    def rules(self) -&gt; List[PostprocessingRule]:\n        \"\"\"\n        Gets the rules.\n\n        Returns:\n            The list of PostprocessingRules available to the Postprocessor.\n        \"\"\"\n        return self._rules\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_span_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_span_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules: Union[PostprocessingRule, Iterable[PostprocessingRule]]):\n        \"\"\"\n        Adds PostprocessingRules to the Postprocessor.\n\n        Args:\n            rules: A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.\n        \"\"\"\n        if isinstance(rules, PostprocessingRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, PostprocessingRule):\n                raise TypeError(\n                    f\"Rules must be type PostprocessingRule, not {type(rule)}.\"\n                )\n            if rule.input_span_type is None:\n                rule.input_span_type = self.input_span_type\n        self._rules += rules\n\n    def __call__(self, doc: Doc):\n        \"\"\"\n        Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed Doc.\n        \"\"\"\n        # Iterate through the entities in reversed order\n        if self._input_span_type == \"ents\":\n            spans = doc.ents\n        else:\n            spans = doc.spans[self._span_group_name]\n\n        for i in range(len(spans) - 1, -1, -1):\n            ent = spans[i]\n            if self.debug:\n                print(ent)\n\n            # let's keep track of whether the rule makes a change to spans\n            span_count_before_rule = None\n            if self._input_span_type == \"ents\":\n                span_count_before_rule = len(doc.ents)\n            else:\n                span_count_before_rule = len(doc.spans[self.span_group_name])\n\n            for rule in self.rules:\n                rule(ent, i, debug=self.debug)\n                # Check if the entity was removed based on span counts before and after rule execution\n                # if it was, skip to the next entity\n                try:\n                    if self._input_span_type == \"ents\":\n                        if len(doc.ents) != span_count_before_rule:\n                            break\n                    else:\n                        if len(doc.spans[self.span_group_name]) != span_count_before_rule:\n                            break\n                except IndexError:\n                    break\n            # if self.debug:\n            #     print()\n        return doc\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessor.Postprocessor.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"singlepage/#medspacy.postprocess.postprocessor.Postprocessor.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets the rules.</p> <p>Returns:</p> Type Description <code>List[PostprocessingRule]</code> <p>The list of PostprocessingRules available to the Postprocessor.</p>"},{"location":"singlepage/#medspacy.postprocess.postprocessor.Postprocessor.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_span_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"singlepage/#medspacy.postprocess.postprocessor.Postprocessor.__call__","title":"<code>__call__(doc)</code>","text":"<p>Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <p>The processed Doc.</p> Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>def __call__(self, doc: Doc):\n    \"\"\"\n    Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed Doc.\n    \"\"\"\n    # Iterate through the entities in reversed order\n    if self._input_span_type == \"ents\":\n        spans = doc.ents\n    else:\n        spans = doc.spans[self._span_group_name]\n\n    for i in range(len(spans) - 1, -1, -1):\n        ent = spans[i]\n        if self.debug:\n            print(ent)\n\n        # let's keep track of whether the rule makes a change to spans\n        span_count_before_rule = None\n        if self._input_span_type == \"ents\":\n            span_count_before_rule = len(doc.ents)\n        else:\n            span_count_before_rule = len(doc.spans[self.span_group_name])\n\n        for rule in self.rules:\n            rule(ent, i, debug=self.debug)\n            # Check if the entity was removed based on span counts before and after rule execution\n            # if it was, skip to the next entity\n            try:\n                if self._input_span_type == \"ents\":\n                    if len(doc.ents) != span_count_before_rule:\n                        break\n                else:\n                    if len(doc.spans[self.span_group_name]) != span_count_before_rule:\n                        break\n            except IndexError:\n                break\n        # if self.debug:\n        #     print()\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.postprocess.postprocessor.Postprocessor.add","title":"<code>add(rules)</code>","text":"<p>Adds PostprocessingRules to the Postprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[PostprocessingRule, Iterable[PostprocessingRule]]</code> <p>A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.</p> required Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>def add(self, rules: Union[PostprocessingRule, Iterable[PostprocessingRule]]):\n    \"\"\"\n    Adds PostprocessingRules to the Postprocessor.\n\n    Args:\n        rules: A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.\n    \"\"\"\n    if isinstance(rules, PostprocessingRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, PostprocessingRule):\n            raise TypeError(\n                f\"Rules must be type PostprocessingRule, not {type(rule)}.\"\n            )\n        if rule.input_span_type is None:\n            rule.input_span_type = self.input_span_type\n    self._rules += rules\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess","title":"<code>preprocess</code>","text":""},{"location":"singlepage/#medspacy.preprocess.PreprocessingRule","title":"<code>PreprocessingRule</code>","text":"<p>This is a rule for handling preprocessing in the medspaCy Preprocessor. This class does not inherit from BaseRule, as it cannot be used in a spaCy pipeline. The Preprocessor and PreprocessingRules are designed to preprocess text before entering a spaCy pipeline to allow for destructive preprocessing, such as stripping or replacing text.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>class PreprocessingRule:\n    \"\"\"\n    This is a rule for handling preprocessing in the medspaCy Preprocessor. This class does not inherit from BaseRule,\n    as it cannot be used in a spaCy pipeline. The Preprocessor and PreprocessingRules are designed to preprocess text\n    before entering a spaCy pipeline to allow for destructive preprocessing, such as stripping or replacing text.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\"pattern\", \"repl\", \"desc\", \"pattern\", \"flags\"}\n\n    def __init__(\n        self,\n        pattern: str,\n        repl: Union[str, Callable[[re.Match], Any]] = \"\",\n        flags: re.RegexFlag = re.IGNORECASE,\n        callback: Optional[Callable[[str, re.Match], str]] = None,\n        desc: Optional[str] = None,\n    ):\n        \"\"\"\n        Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally\n        replaced from the text underneath a doc.\n\n        Args:\n            pattern: The text pattern to match and replace in a doc. Must be a string, which will be compiled as\n                a regular expression. The patterns will lead to re.Match objects.\n            repl: The text to replace a matched string with. By default, repl is an empty string. If repl is a function,\n                sends function to re.sub and it will be called on each Match object. More info here\n                https://docs.python.org/3/library/re.html#re.sub\n            flags: A regex compilation flag. Default is re.IGNORECASE.\n            callback: An optional callable which takes the raw text and a Match and returns the new copy of the text,\n                rather than just replacing strings for the matched text. This can allow larger text manipulation, such\n                as stripping out an entire section based on a header.\n            desc: An optional description.\n        \"\"\"\n        self.pattern = re.compile(pattern, flags=flags)\n        self.repl = repl\n        self.callback = callback\n        self.desc = desc\n\n    @classmethod\n    def from_dict(cls, d: Dict) -&gt; PreprocessingRule:\n        \"\"\"\n        Creates a PreprocessingRule from a dictionary.\n\n        Args:\n            d: The dict to read.\n\n        Returns:\n            A PreprocessingRule from the dictionary.\n        \"\"\"\n        return PreprocessingRule(\n            d[\"pattern\"],\n            repl=d[\"repl\"],\n            flags=d[\"flags\"],\n            callback=d[\"callback\"],\n            desc=d.get(\"desc\", None),\n        )\n\n    def to_dict(self):\n        \"\"\"\n        Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.\n\n        Returns:\n            A dictionary containing the PreprocessingRule's data.\n        \"\"\"\n        d = {\n            \"pattern\": self.pattern.pattern,\n            \"repl\": self.repl,\n            \"callback\": self.callback,\n            \"desc\": self.desc,\n            \"flags\": self.pattern.flags,\n        }\n        return d\n\n    @classmethod\n    def from_json(cls, filepath):\n        \"\"\"\n        Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".\n\n        Args:\n            filepath: The filepath of the JSON to read.\n\n        Returns:\n            A list of PreprocessingRules from the JSON file.\n        \"\"\"\n        import json\n\n        with open(filepath) as f:\n            data = json.load(f)\n        return [\n            PreprocessingRule.from_dict(rule) for rule in data[\"preprocessing_rules\"]\n        ]\n\n    def __call__(self, text):\n        \"\"\"\n        Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string\n        using the direction sub method. If callback is not None, then callback function will be executed using\n        the resulting match as an argument.\n        \"\"\"\n        # If the direction just has a repl attribute,\n        # Just return a simple re.sub\n        if self.callback is None:\n            return self.pattern.sub(self.repl, text)\n\n        match = self.pattern.search(text)\n        if match is None:\n            return text\n        return self.callback(text, match)\n\n    def __repr__(self):\n        return (\n            f\"PreprocessingRule(pattern={self.pattern.pattern}, flags={self.pattern.flags}, repl={self.repl}, \"\n            f\"callback={self.callback}, desc={self.desc})\"\n        )\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.PreprocessingRule.__call__","title":"<code>__call__(text)</code>","text":"<p>Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string using the direction sub method. If callback is not None, then callback function will be executed using the resulting match as an argument.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def __call__(self, text):\n    \"\"\"\n    Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string\n    using the direction sub method. If callback is not None, then callback function will be executed using\n    the resulting match as an argument.\n    \"\"\"\n    # If the direction just has a repl attribute,\n    # Just return a simple re.sub\n    if self.callback is None:\n        return self.pattern.sub(self.repl, text)\n\n    match = self.pattern.search(text)\n    if match is None:\n        return text\n    return self.callback(text, match)\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.PreprocessingRule.__init__","title":"<code>__init__(pattern, repl='', flags=re.IGNORECASE, callback=None, desc=None)</code>","text":"<p>Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally replaced from the text underneath a doc.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>The text pattern to match and replace in a doc. Must be a string, which will be compiled as a regular expression. The patterns will lead to re.Match objects.</p> required <code>repl</code> <code>Union[str, Callable[[Match], Any]]</code> <p>The text to replace a matched string with. By default, repl is an empty string. If repl is a function, sends function to re.sub and it will be called on each Match object. More info here https://docs.python.org/3/library/re.html#re.sub</p> <code>''</code> <code>flags</code> <code>RegexFlag</code> <p>A regex compilation flag. Default is re.IGNORECASE.</p> <code>IGNORECASE</code> <code>callback</code> <code>Optional[Callable[[str, Match], str]]</code> <p>An optional callable which takes the raw text and a Match and returns the new copy of the text, rather than just replacing strings for the matched text. This can allow larger text manipulation, such as stripping out an entire section based on a header.</p> <code>None</code> <code>desc</code> <code>Optional[str]</code> <p>An optional description.</p> <code>None</code> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def __init__(\n    self,\n    pattern: str,\n    repl: Union[str, Callable[[re.Match], Any]] = \"\",\n    flags: re.RegexFlag = re.IGNORECASE,\n    callback: Optional[Callable[[str, re.Match], str]] = None,\n    desc: Optional[str] = None,\n):\n    \"\"\"\n    Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally\n    replaced from the text underneath a doc.\n\n    Args:\n        pattern: The text pattern to match and replace in a doc. Must be a string, which will be compiled as\n            a regular expression. The patterns will lead to re.Match objects.\n        repl: The text to replace a matched string with. By default, repl is an empty string. If repl is a function,\n            sends function to re.sub and it will be called on each Match object. More info here\n            https://docs.python.org/3/library/re.html#re.sub\n        flags: A regex compilation flag. Default is re.IGNORECASE.\n        callback: An optional callable which takes the raw text and a Match and returns the new copy of the text,\n            rather than just replacing strings for the matched text. This can allow larger text manipulation, such\n            as stripping out an entire section based on a header.\n        desc: An optional description.\n    \"\"\"\n    self.pattern = re.compile(pattern, flags=flags)\n    self.repl = repl\n    self.callback = callback\n    self.desc = desc\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.PreprocessingRule.from_dict","title":"<code>from_dict(d)</code>  <code>classmethod</code>","text":"<p>Creates a PreprocessingRule from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Dict</code> <p>The dict to read.</p> required <p>Returns:</p> Type Description <code>PreprocessingRule</code> <p>A PreprocessingRule from the dictionary.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, d: Dict) -&gt; PreprocessingRule:\n    \"\"\"\n    Creates a PreprocessingRule from a dictionary.\n\n    Args:\n        d: The dict to read.\n\n    Returns:\n        A PreprocessingRule from the dictionary.\n    \"\"\"\n    return PreprocessingRule(\n        d[\"pattern\"],\n        repl=d[\"repl\"],\n        flags=d[\"flags\"],\n        callback=d[\"callback\"],\n        desc=d.get(\"desc\", None),\n    )\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.PreprocessingRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>The filepath of the JSON to read.</p> required <p>Returns:</p> Type Description <p>A list of PreprocessingRules from the JSON file.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath):\n    \"\"\"\n    Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".\n\n    Args:\n        filepath: The filepath of the JSON to read.\n\n    Returns:\n        A list of PreprocessingRules from the JSON file.\n    \"\"\"\n    import json\n\n    with open(filepath) as f:\n        data = json.load(f)\n    return [\n        PreprocessingRule.from_dict(rule) for rule in data[\"preprocessing_rules\"]\n    ]\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.PreprocessingRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.</p> <p>Returns:</p> Type Description <p>A dictionary containing the PreprocessingRule's data.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.\n\n    Returns:\n        A dictionary containing the PreprocessingRule's data.\n    \"\"\"\n    d = {\n        \"pattern\": self.pattern.pattern,\n        \"repl\": self.repl,\n        \"callback\": self.callback,\n        \"desc\": self.desc,\n        \"flags\": self.pattern.flags,\n    }\n    return d\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.Preprocessor","title":"<code>Preprocessor</code>","text":"<p>This is the medspacy Preprocessor class. It is designed as a wrapper for destructive preprocessing rules such as stripping or replacing text in a document before the text enters a spaCy pipeline.</p> <p>This is NOT a spaCy component and cannot be added to a spaCy pipeline. Please use the preprocessor before calling <code>nlp(\"your text here\")</code>. SpaCy only allows for non-destructive processing on the text, but that is not always advisable for every project, so this enables destructive preprocessing when required.</p> Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>class Preprocessor:\n    \"\"\"\n    This is the medspacy Preprocessor class. It is designed as a wrapper for destructive preprocessing rules such as\n    stripping or replacing text in a document before the text enters a spaCy pipeline.\n\n    This is NOT a spaCy component and cannot be added to a spaCy pipeline. Please use the preprocessor before\n    calling `nlp(\"your text here\")`. SpaCy only allows for non-destructive processing on the text, but that is not\n    always advisable for every project, so this enables destructive preprocessing when required.\n    \"\"\"\n\n    def __init__(self, tokenizer):\n        \"\"\"\n\n        Args:\n            tokenizer:\n        \"\"\"\n        self.tokenizer = tokenizer\n        self._rules = []\n\n    def add(self, rules: Union[PreprocessingRule, Iterable[PreprocessingRule]]):\n        \"\"\"\n        Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.\n\n        Args:\n            rules: A single PreprocessingRule or a collection of PreprocessingRules to add.\n        \"\"\"\n        if isinstance(rules, PreprocessingRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, PreprocessingRule):\n                raise TypeError(\n                    f\"Each rule must be an instance of PreprocessingRule, not {type(rule)}.\"\n                )\n        self._rules += rules\n\n    def __call__(self, text, tokenize=True) -&gt; Union[str, Doc]:\n        \"\"\"\n\n        Args:\n            text:\n            tokenize:\n\n        Returns:\n\n        \"\"\"\n        for rule in self._rules:\n            text = rule(text)\n\n        if not tokenize:\n            return text\n\n        return self.tokenizer(text)\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.Preprocessor.__call__","title":"<code>__call__(text, tokenize=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>text</code> required <code>tokenize</code> <code>True</code> <p>Returns:</p> Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def __call__(self, text, tokenize=True) -&gt; Union[str, Doc]:\n    \"\"\"\n\n    Args:\n        text:\n        tokenize:\n\n    Returns:\n\n    \"\"\"\n    for rule in self._rules:\n        text = rule(text)\n\n    if not tokenize:\n        return text\n\n    return self.tokenizer(text)\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.Preprocessor.__init__","title":"<code>__init__(tokenizer)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>tokenizer</code> required Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def __init__(self, tokenizer):\n    \"\"\"\n\n    Args:\n        tokenizer:\n    \"\"\"\n    self.tokenizer = tokenizer\n    self._rules = []\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.Preprocessor.add","title":"<code>add(rules)</code>","text":"<p>Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[PreprocessingRule, Iterable[PreprocessingRule]]</code> <p>A single PreprocessingRule or a collection of PreprocessingRules to add.</p> required Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def add(self, rules: Union[PreprocessingRule, Iterable[PreprocessingRule]]):\n    \"\"\"\n    Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.\n\n    Args:\n        rules: A single PreprocessingRule or a collection of PreprocessingRules to add.\n    \"\"\"\n    if isinstance(rules, PreprocessingRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, PreprocessingRule):\n            raise TypeError(\n                f\"Each rule must be an instance of PreprocessingRule, not {type(rule)}.\"\n            )\n    self._rules += rules\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessing_rule","title":"<code>preprocessing_rule</code>","text":""},{"location":"singlepage/#medspacy.preprocess.preprocessing_rule.PreprocessingRule","title":"<code>PreprocessingRule</code>","text":"<p>This is a rule for handling preprocessing in the medspaCy Preprocessor. This class does not inherit from BaseRule, as it cannot be used in a spaCy pipeline. The Preprocessor and PreprocessingRules are designed to preprocess text before entering a spaCy pipeline to allow for destructive preprocessing, such as stripping or replacing text.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>class PreprocessingRule:\n    \"\"\"\n    This is a rule for handling preprocessing in the medspaCy Preprocessor. This class does not inherit from BaseRule,\n    as it cannot be used in a spaCy pipeline. The Preprocessor and PreprocessingRules are designed to preprocess text\n    before entering a spaCy pipeline to allow for destructive preprocessing, such as stripping or replacing text.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\"pattern\", \"repl\", \"desc\", \"pattern\", \"flags\"}\n\n    def __init__(\n        self,\n        pattern: str,\n        repl: Union[str, Callable[[re.Match], Any]] = \"\",\n        flags: re.RegexFlag = re.IGNORECASE,\n        callback: Optional[Callable[[str, re.Match], str]] = None,\n        desc: Optional[str] = None,\n    ):\n        \"\"\"\n        Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally\n        replaced from the text underneath a doc.\n\n        Args:\n            pattern: The text pattern to match and replace in a doc. Must be a string, which will be compiled as\n                a regular expression. The patterns will lead to re.Match objects.\n            repl: The text to replace a matched string with. By default, repl is an empty string. If repl is a function,\n                sends function to re.sub and it will be called on each Match object. More info here\n                https://docs.python.org/3/library/re.html#re.sub\n            flags: A regex compilation flag. Default is re.IGNORECASE.\n            callback: An optional callable which takes the raw text and a Match and returns the new copy of the text,\n                rather than just replacing strings for the matched text. This can allow larger text manipulation, such\n                as stripping out an entire section based on a header.\n            desc: An optional description.\n        \"\"\"\n        self.pattern = re.compile(pattern, flags=flags)\n        self.repl = repl\n        self.callback = callback\n        self.desc = desc\n\n    @classmethod\n    def from_dict(cls, d: Dict) -&gt; PreprocessingRule:\n        \"\"\"\n        Creates a PreprocessingRule from a dictionary.\n\n        Args:\n            d: The dict to read.\n\n        Returns:\n            A PreprocessingRule from the dictionary.\n        \"\"\"\n        return PreprocessingRule(\n            d[\"pattern\"],\n            repl=d[\"repl\"],\n            flags=d[\"flags\"],\n            callback=d[\"callback\"],\n            desc=d.get(\"desc\", None),\n        )\n\n    def to_dict(self):\n        \"\"\"\n        Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.\n\n        Returns:\n            A dictionary containing the PreprocessingRule's data.\n        \"\"\"\n        d = {\n            \"pattern\": self.pattern.pattern,\n            \"repl\": self.repl,\n            \"callback\": self.callback,\n            \"desc\": self.desc,\n            \"flags\": self.pattern.flags,\n        }\n        return d\n\n    @classmethod\n    def from_json(cls, filepath):\n        \"\"\"\n        Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".\n\n        Args:\n            filepath: The filepath of the JSON to read.\n\n        Returns:\n            A list of PreprocessingRules from the JSON file.\n        \"\"\"\n        import json\n\n        with open(filepath) as f:\n            data = json.load(f)\n        return [\n            PreprocessingRule.from_dict(rule) for rule in data[\"preprocessing_rules\"]\n        ]\n\n    def __call__(self, text):\n        \"\"\"\n        Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string\n        using the direction sub method. If callback is not None, then callback function will be executed using\n        the resulting match as an argument.\n        \"\"\"\n        # If the direction just has a repl attribute,\n        # Just return a simple re.sub\n        if self.callback is None:\n            return self.pattern.sub(self.repl, text)\n\n        match = self.pattern.search(text)\n        if match is None:\n            return text\n        return self.callback(text, match)\n\n    def __repr__(self):\n        return (\n            f\"PreprocessingRule(pattern={self.pattern.pattern}, flags={self.pattern.flags}, repl={self.repl}, \"\n            f\"callback={self.callback}, desc={self.desc})\"\n        )\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.__call__","title":"<code>__call__(text)</code>","text":"<p>Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string using the direction sub method. If callback is not None, then callback function will be executed using the resulting match as an argument.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def __call__(self, text):\n    \"\"\"\n    Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string\n    using the direction sub method. If callback is not None, then callback function will be executed using\n    the resulting match as an argument.\n    \"\"\"\n    # If the direction just has a repl attribute,\n    # Just return a simple re.sub\n    if self.callback is None:\n        return self.pattern.sub(self.repl, text)\n\n    match = self.pattern.search(text)\n    if match is None:\n        return text\n    return self.callback(text, match)\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.__init__","title":"<code>__init__(pattern, repl='', flags=re.IGNORECASE, callback=None, desc=None)</code>","text":"<p>Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally replaced from the text underneath a doc.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>The text pattern to match and replace in a doc. Must be a string, which will be compiled as a regular expression. The patterns will lead to re.Match objects.</p> required <code>repl</code> <code>Union[str, Callable[[Match], Any]]</code> <p>The text to replace a matched string with. By default, repl is an empty string. If repl is a function, sends function to re.sub and it will be called on each Match object. More info here https://docs.python.org/3/library/re.html#re.sub</p> <code>''</code> <code>flags</code> <code>RegexFlag</code> <p>A regex compilation flag. Default is re.IGNORECASE.</p> <code>IGNORECASE</code> <code>callback</code> <code>Optional[Callable[[str, Match], str]]</code> <p>An optional callable which takes the raw text and a Match and returns the new copy of the text, rather than just replacing strings for the matched text. This can allow larger text manipulation, such as stripping out an entire section based on a header.</p> <code>None</code> <code>desc</code> <code>Optional[str]</code> <p>An optional description.</p> <code>None</code> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def __init__(\n    self,\n    pattern: str,\n    repl: Union[str, Callable[[re.Match], Any]] = \"\",\n    flags: re.RegexFlag = re.IGNORECASE,\n    callback: Optional[Callable[[str, re.Match], str]] = None,\n    desc: Optional[str] = None,\n):\n    \"\"\"\n    Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally\n    replaced from the text underneath a doc.\n\n    Args:\n        pattern: The text pattern to match and replace in a doc. Must be a string, which will be compiled as\n            a regular expression. The patterns will lead to re.Match objects.\n        repl: The text to replace a matched string with. By default, repl is an empty string. If repl is a function,\n            sends function to re.sub and it will be called on each Match object. More info here\n            https://docs.python.org/3/library/re.html#re.sub\n        flags: A regex compilation flag. Default is re.IGNORECASE.\n        callback: An optional callable which takes the raw text and a Match and returns the new copy of the text,\n            rather than just replacing strings for the matched text. This can allow larger text manipulation, such\n            as stripping out an entire section based on a header.\n        desc: An optional description.\n    \"\"\"\n    self.pattern = re.compile(pattern, flags=flags)\n    self.repl = repl\n    self.callback = callback\n    self.desc = desc\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.from_dict","title":"<code>from_dict(d)</code>  <code>classmethod</code>","text":"<p>Creates a PreprocessingRule from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Dict</code> <p>The dict to read.</p> required <p>Returns:</p> Type Description <code>PreprocessingRule</code> <p>A PreprocessingRule from the dictionary.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, d: Dict) -&gt; PreprocessingRule:\n    \"\"\"\n    Creates a PreprocessingRule from a dictionary.\n\n    Args:\n        d: The dict to read.\n\n    Returns:\n        A PreprocessingRule from the dictionary.\n    \"\"\"\n    return PreprocessingRule(\n        d[\"pattern\"],\n        repl=d[\"repl\"],\n        flags=d[\"flags\"],\n        callback=d[\"callback\"],\n        desc=d.get(\"desc\", None),\n    )\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>The filepath of the JSON to read.</p> required <p>Returns:</p> Type Description <p>A list of PreprocessingRules from the JSON file.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath):\n    \"\"\"\n    Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".\n\n    Args:\n        filepath: The filepath of the JSON to read.\n\n    Returns:\n        A list of PreprocessingRules from the JSON file.\n    \"\"\"\n    import json\n\n    with open(filepath) as f:\n        data = json.load(f)\n    return [\n        PreprocessingRule.from_dict(rule) for rule in data[\"preprocessing_rules\"]\n    ]\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.</p> <p>Returns:</p> Type Description <p>A dictionary containing the PreprocessingRule's data.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.\n\n    Returns:\n        A dictionary containing the PreprocessingRule's data.\n    \"\"\"\n    d = {\n        \"pattern\": self.pattern.pattern,\n        \"repl\": self.repl,\n        \"callback\": self.callback,\n        \"desc\": self.desc,\n        \"flags\": self.pattern.flags,\n    }\n    return d\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessor","title":"<code>preprocessor</code>","text":""},{"location":"singlepage/#medspacy.preprocess.preprocessor.Preprocessor","title":"<code>Preprocessor</code>","text":"<p>This is the medspacy Preprocessor class. It is designed as a wrapper for destructive preprocessing rules such as stripping or replacing text in a document before the text enters a spaCy pipeline.</p> <p>This is NOT a spaCy component and cannot be added to a spaCy pipeline. Please use the preprocessor before calling <code>nlp(\"your text here\")</code>. SpaCy only allows for non-destructive processing on the text, but that is not always advisable for every project, so this enables destructive preprocessing when required.</p> Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>class Preprocessor:\n    \"\"\"\n    This is the medspacy Preprocessor class. It is designed as a wrapper for destructive preprocessing rules such as\n    stripping or replacing text in a document before the text enters a spaCy pipeline.\n\n    This is NOT a spaCy component and cannot be added to a spaCy pipeline. Please use the preprocessor before\n    calling `nlp(\"your text here\")`. SpaCy only allows for non-destructive processing on the text, but that is not\n    always advisable for every project, so this enables destructive preprocessing when required.\n    \"\"\"\n\n    def __init__(self, tokenizer):\n        \"\"\"\n\n        Args:\n            tokenizer:\n        \"\"\"\n        self.tokenizer = tokenizer\n        self._rules = []\n\n    def add(self, rules: Union[PreprocessingRule, Iterable[PreprocessingRule]]):\n        \"\"\"\n        Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.\n\n        Args:\n            rules: A single PreprocessingRule or a collection of PreprocessingRules to add.\n        \"\"\"\n        if isinstance(rules, PreprocessingRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, PreprocessingRule):\n                raise TypeError(\n                    f\"Each rule must be an instance of PreprocessingRule, not {type(rule)}.\"\n                )\n        self._rules += rules\n\n    def __call__(self, text, tokenize=True) -&gt; Union[str, Doc]:\n        \"\"\"\n\n        Args:\n            text:\n            tokenize:\n\n        Returns:\n\n        \"\"\"\n        for rule in self._rules:\n            text = rule(text)\n\n        if not tokenize:\n            return text\n\n        return self.tokenizer(text)\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessor.Preprocessor.__call__","title":"<code>__call__(text, tokenize=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>text</code> required <code>tokenize</code> <code>True</code> <p>Returns:</p> Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def __call__(self, text, tokenize=True) -&gt; Union[str, Doc]:\n    \"\"\"\n\n    Args:\n        text:\n        tokenize:\n\n    Returns:\n\n    \"\"\"\n    for rule in self._rules:\n        text = rule(text)\n\n    if not tokenize:\n        return text\n\n    return self.tokenizer(text)\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessor.Preprocessor.__init__","title":"<code>__init__(tokenizer)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>tokenizer</code> required Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def __init__(self, tokenizer):\n    \"\"\"\n\n    Args:\n        tokenizer:\n    \"\"\"\n    self.tokenizer = tokenizer\n    self._rules = []\n</code></pre>"},{"location":"singlepage/#medspacy.preprocess.preprocessor.Preprocessor.add","title":"<code>add(rules)</code>","text":"<p>Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[PreprocessingRule, Iterable[PreprocessingRule]]</code> <p>A single PreprocessingRule or a collection of PreprocessingRules to add.</p> required Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def add(self, rules: Union[PreprocessingRule, Iterable[PreprocessingRule]]):\n    \"\"\"\n    Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.\n\n    Args:\n        rules: A single PreprocessingRule or a collection of PreprocessingRules to add.\n    \"\"\"\n    if isinstance(rules, PreprocessingRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, PreprocessingRule):\n            raise TypeError(\n                f\"Each rule must be an instance of PreprocessingRule, not {type(rule)}.\"\n            )\n    self._rules += rules\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection","title":"<code>section_detection</code>","text":""},{"location":"singlepage/#medspacy.section_detection.Section","title":"<code>Section</code>","text":"<p>               Bases: <code>object</code></p> <p>Section is the object that stores the result of processing by the Sectionizer class. A Section contains information describing the section's category, title span, body span, parent, and the rule that created it.</p> <p>Section <code>category</code> is equivalent to <code>label_</code> in a basic spaCy entity. It is a normalized name for the section type determined on initialization, either created manually or through the Sectionizer pipeline component.</p> <p>Section title, defined with <code>title_start</code>, <code>title_end</code>, and <code>title_span</code> represents the section title or header matched with the rule. In the text \"Past medical history: stroke and high blood pressure\", \"Past medical history:\" would be the title.</p> <p>Section body is defined with <code>body_start</code>, <code>body_end</code>, and <code>body_span</code>. It represents the text between the end of the current section's title and the start of the title for the next Section or when scope is set in the rule or by the Sectionizer. In the text \"Past medical history: stroke and high blood pressure\", \"stroke and high blood pressure\" would be the body.</p> <p>Parent is a string that represents the conceptual \"parent\" section in a section-&gt;subsection-&gt;subsubsection hierarchy. Candidates are determined by category in the rule and matched at runtime.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>class Section(object):\n    \"\"\"\n    Section is the object that stores the result of processing by the Sectionizer class. A Section contains information\n    describing the section's category, title span, body span, parent, and the rule that created it.\n\n    Section `category` is equivalent to `label_` in a basic spaCy entity. It is a normalized name for the section type\n    determined on initialization, either created manually or through the Sectionizer pipeline component.\n\n    Section title, defined with `title_start`, `title_end`, and `title_span` represents the section title or header\n    matched with the rule. In the text \"Past medical history: stroke and high blood pressure\", \"Past medical history:\"\n    would be the title.\n\n    Section body is defined with `body_start`, `body_end`, and `body_span`. It represents the text between the end of\n    the current section's title and the start of the title for the next Section or when scope is set in the rule or by\n    the Sectionizer. In the text \"Past medical history: stroke and high blood pressure\", \"stroke and high blood\n    pressure\" would be the body.\n\n    Parent is a string that represents the conceptual \"parent\" section in a section-&gt;subsection-&gt;subsubsection\n    hierarchy. Candidates are determined by category in the rule and matched at runtime.\n    \"\"\"\n\n    def __init__(\n        self,\n        category: Union[str, None],\n        title_start: int,\n        title_end: int,\n        body_start: int,\n        body_end: int,\n        parent: Optional[str] = None,\n        rule: Optional[SectionRule] = None,\n    ):\n        \"\"\"\n        Create a new Section object.\n\n        Args:\n            category: A normalized name for the section. Equivalent to `label_` for basic spaCy entities.\n            title_start: Index of the first token of the section title.\n            title_end: Index of the last token of the section title.\n            body_start: Index of the first token of the section body.\n            body_end: Index of the last token of the section body.\n            parent: The category of the parent section.\n            rule: The SectionRule that generated the section.\n        \"\"\"\n        self.category = category\n        self.title_start = title_start\n        self.title_end = title_end\n        self.body_start = body_start\n        self.body_end = body_end\n        self.parent = parent\n        self.rule = rule\n\n    def __repr__(self):\n        return (\n            f\"Section(category={self.category} at {self.title_start} : {self.title_end} in the doc with a body at \"\n            f\"{self.body_start} : {self.body_end} based on the rule {self.rule}\"\n        )\n\n    @property\n    def title_span(self):\n        \"\"\"\n        Gets the span of the section title.\n\n        Returns:\n            A tuple (int,int) containing the start and end indexes of the section title.\n        \"\"\"\n        return self.title_start, self.title_end\n\n    @property\n    def body_span(self):\n        \"\"\"\n        Gets the span of the section body.\n\n        Returns:\n            A tuple (int,int) containing the start and end indexes of the section body.\n        \"\"\"\n        return self.body_start, self.body_end\n\n    @property\n    def section_span(self):\n        \"\"\"\n        Gets the span of the entire section, from title start to body end.\n\n        Returns:\n            A tuple (int,int) containing the start index of the section title and the end index of the section body.\n        \"\"\"\n        return self.title_start, self.body_end\n\n    def serialized_representation(self):\n        \"\"\"\n        Serialize the Section.\n\n        Returns:\n            A json-serialized representation of the section.\n        \"\"\"\n        rule = self.rule\n\n        return {\n            \"category\": self.category,\n            \"title_start\": self.title_start,\n            \"title_end\": self.title_end,\n            \"body_start\": self.body_start,\n            \"body_end\": self.body_end,\n            \"parent\": self.parent,\n            \"rule\": rule.to_dict() if rule is not None else None,\n        }\n\n    @classmethod\n    def from_serialized_representation(cls, serialized_representation: Dict[str, str]):\n        \"\"\"\n        Load the section from a json-serialized form.\n\n        Args:\n            serialized_representation: The dictionary form of the section object to load.\n\n        Returns:\n            A Section object containing the data from the dictionary provided.\n        \"\"\"\n        rule = SectionRule.from_dict(serialized_representation[\"rule\"])\n        section = Section(\n            **{k: v for k, v in serialized_representation.items() if k not in [\"rule\"]}\n        )\n        section.rule = rule\n\n        return section\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Section.body_span","title":"<code>body_span</code>  <code>property</code>","text":"<p>Gets the span of the section body.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start and end indexes of the section body.</p>"},{"location":"singlepage/#medspacy.section_detection.Section.section_span","title":"<code>section_span</code>  <code>property</code>","text":"<p>Gets the span of the entire section, from title start to body end.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start index of the section title and the end index of the section body.</p>"},{"location":"singlepage/#medspacy.section_detection.Section.title_span","title":"<code>title_span</code>  <code>property</code>","text":"<p>Gets the span of the section title.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start and end indexes of the section title.</p>"},{"location":"singlepage/#medspacy.section_detection.Section.__init__","title":"<code>__init__(category, title_start, title_end, body_start, body_end, parent=None, rule=None)</code>","text":"<p>Create a new Section object.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>Union[str, None]</code> <p>A normalized name for the section. Equivalent to <code>label_</code> for basic spaCy entities.</p> required <code>title_start</code> <code>int</code> <p>Index of the first token of the section title.</p> required <code>title_end</code> <code>int</code> <p>Index of the last token of the section title.</p> required <code>body_start</code> <code>int</code> <p>Index of the first token of the section body.</p> required <code>body_end</code> <code>int</code> <p>Index of the last token of the section body.</p> required <code>parent</code> <code>Optional[str]</code> <p>The category of the parent section.</p> <code>None</code> <code>rule</code> <code>Optional[SectionRule]</code> <p>The SectionRule that generated the section.</p> <code>None</code> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>def __init__(\n    self,\n    category: Union[str, None],\n    title_start: int,\n    title_end: int,\n    body_start: int,\n    body_end: int,\n    parent: Optional[str] = None,\n    rule: Optional[SectionRule] = None,\n):\n    \"\"\"\n    Create a new Section object.\n\n    Args:\n        category: A normalized name for the section. Equivalent to `label_` for basic spaCy entities.\n        title_start: Index of the first token of the section title.\n        title_end: Index of the last token of the section title.\n        body_start: Index of the first token of the section body.\n        body_end: Index of the last token of the section body.\n        parent: The category of the parent section.\n        rule: The SectionRule that generated the section.\n    \"\"\"\n    self.category = category\n    self.title_start = title_start\n    self.title_end = title_end\n    self.body_start = body_start\n    self.body_end = body_end\n    self.parent = parent\n    self.rule = rule\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Section.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Load the section from a json-serialized form.</p> <p>Parameters:</p> Name Type Description Default <code>serialized_representation</code> <code>Dict[str, str]</code> <p>The dictionary form of the section object to load.</p> required <p>Returns:</p> Type Description <p>A Section object containing the data from the dictionary provided.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>@classmethod\ndef from_serialized_representation(cls, serialized_representation: Dict[str, str]):\n    \"\"\"\n    Load the section from a json-serialized form.\n\n    Args:\n        serialized_representation: The dictionary form of the section object to load.\n\n    Returns:\n        A Section object containing the data from the dictionary provided.\n    \"\"\"\n    rule = SectionRule.from_dict(serialized_representation[\"rule\"])\n    section = Section(\n        **{k: v for k, v in serialized_representation.items() if k not in [\"rule\"]}\n    )\n    section.rule = rule\n\n    return section\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Section.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Serialize the Section.</p> <p>Returns:</p> Type Description <p>A json-serialized representation of the section.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>def serialized_representation(self):\n    \"\"\"\n    Serialize the Section.\n\n    Returns:\n        A json-serialized representation of the section.\n    \"\"\"\n    rule = self.rule\n\n    return {\n        \"category\": self.category,\n        \"title_start\": self.title_start,\n        \"title_end\": self.title_end,\n        \"body_start\": self.body_start,\n        \"body_end\": self.body_end,\n        \"parent\": self.parent,\n        \"rule\": rule.to_dict() if rule is not None else None,\n    }\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.SectionRule","title":"<code>SectionRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>SectionRule defines rules for extracting entities from text using the Sectionizer.</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>class SectionRule(BaseRule):\n    \"\"\"\n    SectionRule defines rules for extracting entities from text using the Sectionizer.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"parents\",\n        \"parent_required\",\n        \"max_scope\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        max_scope: Optional[int] = None,\n        parents: Optional[List[str]] = None,\n        parent_required: bool = False,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Class for defining rules for extracting entities from text using TargetMatcher.\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            max_scope: A number of tokens to explicitly limit the size of a section body. If None, the scope will\n                include the entire doc up until either the next section header or the end of the doc. This variable can\n                also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the\n                rule scope will take precedence. If not None, this will be the number of tokens following the matched\n                section header\n                    Example:\n                        In the text \"Past Medical History: Pt has hx of pneumonia\",\n                        SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but\n                        SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section\n                            to be \"Past Medical History: Pt has\"\n                This can be useful for limiting certain sections which are known to be short or allowing others to be\n                longer than the regular global max_scope.\n            parents: A list of candidate parents for determining subsections\n            parent_required: Whether a parent is required for the section to exist in the final output. If true and no\n                parent is identified, the section will be removed.\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category, pattern, on_match, metadata)\n        self.max_scope = max_scope\n        self.parents = parents\n        if parent_required:\n            if not parents:\n                raise ValueError(\n                    f\"Jsonl file incorrectly formatted for pattern name {category}. \"\n                    f\"If parents are required, then at least one parent must be specified.\"\n                )\n        self.parent_required = parent_required\n\n    @classmethod\n    def from_json(cls, filepath) -&gt; List[SectionRule]:\n        \"\"\"\n        Read in a lexicon of modifiers from a JSON file.\n\n        Args:\n            filepath: the .json file containing modifier rules\n\n        Returns:\n            section_rules: a list of SectionRule objects\n        \"\"\"\n        import json\n\n        with open(filepath) as file:\n            section_data = json.load(file)\n        section_rules = []\n        for data in section_data[\"section_rules\"]:\n            section_rules.append(SectionRule.from_dict(data))\n        return section_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict):\n        \"\"\"\n        Reads a dictionary into a SectionRule list. Used when reading from a json file.\n\n        Args:\n            rule_dict: the dictionary to convert\n\n        Returns:\n            item: the SectionRule created from the dictionary\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                f\"JSON object contains invalid keys: {invalid_keys}. \"\n                f\"Must be one of: {cls._ALLOWED_KEYS}\"\n            )\n            raise ValueError(msg)\n        rule = SectionRule(**rule_dict)\n        return rule\n\n    def to_dict(self):\n        \"\"\"\n        Converts TargetRules to a python dictionary. Used when writing section rules to a json file.\n\n        Returns:\n            rule_dict: the dictionary containing the TargetRule info.\n        \"\"\"\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    def __repr__(self):\n        return f\"\"\"SectionRule(literal=\"{self.literal}\", category=\"{self.category}\", pattern={self.pattern}, on_match={self.on_match}, parents={self.parents}, parent_required={self.parent_required})\"\"\"\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.SectionRule.__init__","title":"<code>__init__(literal, category, pattern=None, on_match=None, max_scope=None, parents=None, parent_required=False, metadata=None)</code>","text":"<p>Class for defining rules for extracting entities from text using TargetMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[List[Dict[str, str]], str]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>A number of tokens to explicitly limit the size of a section body. If None, the scope will include the entire doc up until either the next section header or the end of the doc. This variable can also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the rule scope will take precedence. If not None, this will be the number of tokens following the matched section header     Example:         In the text \"Past Medical History: Pt has hx of pneumonia\",         SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but         SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section             to be \"Past Medical History: Pt has\" This can be useful for limiting certain sections which are known to be short or allowing others to be longer than the regular global max_scope.</p> <code>None</code> <code>parents</code> <code>Optional[List[str]]</code> <p>A list of candidate parents for determining subsections</p> <code>None</code> <code>parent_required</code> <code>bool</code> <p>Whether a parent is required for the section to exist in the final output. If true and no parent is identified, the section will be removed.</p> <code>False</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    max_scope: Optional[int] = None,\n    parents: Optional[List[str]] = None,\n    parent_required: bool = False,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Class for defining rules for extracting entities from text using TargetMatcher.\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        max_scope: A number of tokens to explicitly limit the size of a section body. If None, the scope will\n            include the entire doc up until either the next section header or the end of the doc. This variable can\n            also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the\n            rule scope will take precedence. If not None, this will be the number of tokens following the matched\n            section header\n                Example:\n                    In the text \"Past Medical History: Pt has hx of pneumonia\",\n                    SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but\n                    SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section\n                        to be \"Past Medical History: Pt has\"\n            This can be useful for limiting certain sections which are known to be short or allowing others to be\n            longer than the regular global max_scope.\n        parents: A list of candidate parents for determining subsections\n        parent_required: Whether a parent is required for the section to exist in the final output. If true and no\n            parent is identified, the section will be removed.\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category, pattern, on_match, metadata)\n    self.max_scope = max_scope\n    self.parents = parents\n    if parent_required:\n        if not parents:\n            raise ValueError(\n                f\"Jsonl file incorrectly formatted for pattern name {category}. \"\n                f\"If parents are required, then at least one parent must be specified.\"\n            )\n    self.parent_required = parent_required\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.SectionRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a SectionRule list. Used when reading from a json file.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <p>the dictionary to convert</p> required <p>Returns:</p> Name Type Description <code>item</code> <p>the SectionRule created from the dictionary</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict):\n    \"\"\"\n    Reads a dictionary into a SectionRule list. Used when reading from a json file.\n\n    Args:\n        rule_dict: the dictionary to convert\n\n    Returns:\n        item: the SectionRule created from the dictionary\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            f\"JSON object contains invalid keys: {invalid_keys}. \"\n            f\"Must be one of: {cls._ALLOWED_KEYS}\"\n        )\n        raise ValueError(msg)\n    rule = SectionRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.SectionRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read in a lexicon of modifiers from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>the .json file containing modifier rules</p> required <p>Returns:</p> Name Type Description <code>section_rules</code> <code>List[SectionRule]</code> <p>a list of SectionRule objects</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath) -&gt; List[SectionRule]:\n    \"\"\"\n    Read in a lexicon of modifiers from a JSON file.\n\n    Args:\n        filepath: the .json file containing modifier rules\n\n    Returns:\n        section_rules: a list of SectionRule objects\n    \"\"\"\n    import json\n\n    with open(filepath) as file:\n        section_data = json.load(file)\n    section_rules = []\n    for data in section_data[\"section_rules\"]:\n        section_rules.append(SectionRule.from_dict(data))\n    return section_rules\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.SectionRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts TargetRules to a python dictionary. Used when writing section rules to a json file.</p> <p>Returns:</p> Name Type Description <code>rule_dict</code> <p>the dictionary containing the TargetRule info.</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Converts TargetRules to a python dictionary. Used when writing section rules to a json file.\n\n    Returns:\n        rule_dict: the dictionary containing the TargetRule info.\n    \"\"\"\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer","title":"<code>Sectionizer</code>","text":"<p>The Sectionizer will search for spans in the text which match section header rules, such as 'Past Medical History:'. Sections will be represented in custom attributes as:     category: A normalized title of the section. Example: 'past_medical_history'     section_title: The Span of the doc which was matched as a section header.         Example: 'Past Medical History:'     section_span: The entire section of the note, starting with section_header and up until the end         of the section, which will be either the start of the next section header of some pre-specified         scope. Example: 'Past Medical History: Type II DM'</p> <p>Section attributes will be registered for each Doc, Span, and Token in the following attributes:     Doc..sections: A list of namedtuples of type Section with 4 elements:         - section_title         - section_header         - section_parent         - section_span.     A Doc will also have attributes corresponding to lists of each         (ie., Doc..section_titles, Doc..section_headers, Doc..section_parents, Doc..section_list)     (Span|Token)..section_title     (Span|Token)..section_header     (Span|Token)..section_parent     (Span|Token)._.section_span</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>@Language.factory(\"medspacy_sectionizer\")\nclass Sectionizer:\n    \"\"\"\n    The Sectionizer will search for spans in the text which match section header rules, such as 'Past Medical History:'.\n    Sections will be represented in custom attributes as:\n        category: A normalized title of the section. Example: 'past_medical_history'\n        section_title: The Span of the doc which was matched as a section header.\n            Example: 'Past Medical History:'\n        section_span: The entire section of the note, starting with section_header and up until the end\n            of the section, which will be either the start of the next section header of some pre-specified\n            scope. Example: 'Past Medical History: Type II DM'\n\n    Section attributes will be registered for each Doc, Span, and Token in the following attributes:\n        Doc._.sections: A list of namedtuples of type Section with 4 elements:\n            - section_title\n            - section_header\n            - section_parent\n            - section_span.\n        A Doc will also have attributes corresponding to lists of each\n            (ie., Doc._.section_titles, Doc._.section_headers, Doc._.section_parents, Doc._.section_list)\n        (Span|Token)._.section_title\n        (Span|Token)._.section_header\n        (Span|Token)._.section_parent\n        (Span|Token)._.section_span\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_sectionizer\",\n        rules: Optional[str] = \"default\",\n        language_code: str = 'en',\n        max_section_length: Optional[int] = None,\n        phrase_matcher_attr: str = \"LOWER\",\n        require_start_line: bool = False,\n        require_end_line: bool = False,\n        newline_pattern: str = r\"[\\n\\r]+[\\s]*$\",\n        input_span_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n        span_attrs: Union[\n            Literal[\"default\"], Dict[str, Dict[str, Any]], None\n        ] = \"default\",\n        apply_sentence_boundary: bool = False,\n    ):\n        \"\"\"\n        Create a new Sectionizer component.\n\n        Args:\n            nlp: A SpaCy Language object.\n            name: The name of the component.\n            rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n                SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n                are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n                `Sectionizer.add`.\n            language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n                and also the /resources directory to see which resources might be available in each language.\n                Default is \"en\" for English.\n            max_section_length: Optional argument specifying the maximum number of tokens following a section header\n                which can be included in a section body. This can be useful if you think your section rules are\n                incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n                the scope of a section will be until either the next section header or the end of the document.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            require_start_line: Optionally require a section header to start on a new line. Default False.\n            require_end_line: Optionally require a section header to end with a new line. Default False.\n            newline_pattern: Regular expression to match the new line either preceding or following a header\n                if either require_start_line or require_end_line are True. Default is r\"[\\n\\r]+[\\s]*$\"\n            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n                `DEFAULT_ATTRIBUTES`. If a dictionary of custom attributes, format is a dictionary mapping section\n                categories to a dictionary containing the attribute name and the value to set the attribute to when a\n                span is contained in a section of that category. Custom attributes must be assigned with\n                `Span.set_extension` before creating the Sectionizer. If None, sectionizer will not modify span\n                attributes.\n            input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans\n                contained in a section if `span_attrs` is not None. \"ents\" will modify attributes of spans in doc.ents.\n                \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n                \"medspacy_spans\".\n            apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures\n                the section header is considered its own sentence.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self.max_section_length = max_section_length\n        self.require_start_line = require_start_line\n        self.require_end_line = require_end_line\n        self.newline_pattern = re.compile(newline_pattern)\n        self.assertion_attributes_mapping = None\n        self._parent_sections = {}\n        self._parent_required = {}\n        self._input_span_type = input_span_type\n        self._span_group_name = span_group_name\n        self._apply_sentence_boundary = apply_sentence_boundary\n\n        self.__matcher = MedspacyMatcher(\n            nlp, name=name, phrase_matcher_attr=phrase_matcher_attr\n        )\n\n        self.DEFAULT_RULES_FILEPATH = path.join(\n            Path(__file__).resolve().parents[2],\n            \"resources\",\n            language_code.lower(),\n            \"section_patterns.json\",\n        )\n\n        rule_path = None\n        if rules == \"default\":\n            rule_path = self.DEFAULT_RULES_FILEPATH\n        else:\n            rule_path = rules\n\n        if rule_path:\n            self.add(SectionRule.from_json(rule_path))\n\n        if span_attrs == \"default\":\n            self.assertion_attributes_mapping = DEFAULT_ATTRS\n            self.register_default_attributes()\n        elif span_attrs:\n            for _, attr_dict in span_attrs.items():\n                for attr_name in attr_dict.keys():\n                    if not Span.has_extension(attr_name):\n                        raise ValueError(\n                            f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                            f\"called for your pipeline's custom extensions.\"\n                        )\n            self.assertion_attributes_mapping = span_attrs\n\n    @property\n    def rules(self) -&gt; List[SectionRule]:\n        \"\"\"\n        Gets list of rules associated with the Sectionizer.\n\n        Returns:\n            The list of SectionRules associated with the Sectionizer.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def section_categories(self) -&gt; Set[str]:\n        \"\"\"\n        Gets a list of categories used in the Sectionizer.\n\n        Returns:\n                The list of all section categories available to the Sectionizer.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    @classmethod\n    def register_default_attributes(cls):\n        \"\"\"\n        Register the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n        \"\"\"\n        for attr_name in [\n            \"is_negated\",\n            \"is_uncertain\",\n            \"is_historical\",\n            \"is_hypothetical\",\n            \"is_family\",\n        ]:\n            try:\n                Span.set_extension(attr_name, default=False)\n            except ValueError:  # Extension already set\n                pass\n\n    def add(self, rules):\n        \"\"\"\n        Adds SectionRules to the Sectionizer.\n\n        Args:\n            rules: A single SectionRule or a collection of SectionRules to add to the Sectionizer.\n        \"\"\"\n        if isinstance(rules, SectionRule):\n            rules = [rules]\n\n        for rule in rules:\n            if not isinstance(rule, SectionRule):\n                raise TypeError(\"Rules must be type SectionRule, not\", type(rule))\n\n        self.__matcher.add(rules)\n\n        for rule in rules:\n            name = rule.category\n            parents = rule.parents\n            parent_required = rule.parent_required\n            if parents:\n                if name in self._parent_sections.keys():\n                    warnings.warn(\n                        f\"Duplicate section title {name}. Merging parents. \"\n                        f\"If this is not intended, please specify distinct titles.\",\n                        RuntimeWarning,\n                    )\n                    self._parent_sections[name].update(parents)\n                else:\n                    self._parent_sections[name] = set(parents)\n\n            if (\n                name in self._parent_required.keys()\n                and self._parent_required[name] != parent_required\n            ):\n                warnings.warn(\n                    f\"Duplicate section title {name} has different parent_required option. \"\n                    f\"Setting parent_required to False.\",\n                    RuntimeWarning,\n                )\n                self._parent_required[name] = False\n            else:\n                self._parent_required[name] = parent_required\n\n    def set_parent_sections(\n        self, sections: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int, int]]:\n        \"\"\"\n        Determine the legal parent-child section relationships from the list\n        of in-order sections of a document and the possible parents of each\n        section as specified during direction creation.\n\n        Args:\n            sections: a list of spacy match tuples found in the doc\n\n        Returns:\n            A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input\n            and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a\n            smaller list than the input due to pruning with `parent_required`.\n        \"\"\"\n        sections_final = []\n        removed_sections = 0\n        for i, (match_id, start, end) in enumerate(sections):\n            name = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]].category\n            required = self._parent_required[name]\n            i_a = i - removed_sections  # adjusted index for removed values\n            if required and i_a == 0:\n                removed_sections += 1\n                continue\n            elif i_a == 0 or name not in self._parent_sections.keys():\n                sections_final.append((match_id, start, end, None))\n            else:\n                parents = self._parent_sections[name]\n                identified_parent = None\n                for parent in parents:\n                    # go backwards through the section \"tree\" until you hit a root or the start of the list\n                    candidate = self.__matcher.rule_map[\n                        self.nlp.vocab.strings[sections_final[i_a - 1][0]]\n                    ].category\n                    candidates_parent_idx = sections_final[i_a - 1][3]\n                    if candidates_parent_idx is not None:\n                        candidates_parent = self.__matcher.rule_map[\n                            self.nlp.vocab.strings[\n                                sections_final[candidates_parent_idx][0]\n                            ]\n                        ].category\n                    else:\n                        candidates_parent = None\n                    candidate_i = i_a - 1\n                    while candidate:\n                        if candidate == parent:\n                            identified_parent = candidate_i\n                            candidate = None\n                        else:\n                            # if you are at the end of the list... no parent\n                            if candidate_i &lt; 1:\n                                candidate = None\n                                continue\n                            # if the current candidate has no parent... no parent exists\n                            if not candidates_parent:\n                                candidate = None\n                                continue\n                            # otherwise get the previous item in the list\n                            temp = self.__matcher.rule_map[\n                                self.nlp.vocab.strings[\n                                    sections_final[candidate_i - 1][0]\n                                ]\n                            ].category\n                            temp_parent_idx = sections_final[candidate_i - 1][3]\n                            if temp_parent_idx is not None:\n                                temp_parent = self.__matcher.rule_map[\n                                    self.nlp.vocab.strings[\n                                        sections_final[temp_parent_idx][0]\n                                    ]\n                                ].category\n                            else:\n                                temp_parent = None\n                            # if the previous item is the parent of the current item\n                            # OR if the previous item is a sibling of the current item\n                            # continue to search\n                            if (\n                                temp == candidates_parent\n                                or temp_parent == candidates_parent\n                            ):\n                                candidate = temp\n                                candidates_parent = temp_parent\n                                candidate_i -= 1\n                            # otherwise, there is no further tree traversal\n                            else:\n                                candidate = None\n\n                # if a parent is required, then add\n                if identified_parent is not None or not required:\n                    # if the parent is identified, add section\n                    # if the parent is not required, add section\n                    # if parent is not identified and required, do not add the section\n                    sections_final.append((match_id, start, end, identified_parent))\n                else:\n                    removed_sections += 1\n        return sections_final\n\n    def set_assertion_attributes(self, spans: Iterable[Span]):\n        \"\"\"\n        Add Span-level attributes to entities based on which section they occur in.\n\n        Args:\n            spans: the spans to modify.\n        \"\"\"\n        for span in spans:\n            if (\n                span._.section\n                and span._.section.category in self.assertion_attributes_mapping\n            ):\n                attr_dict = self.assertion_attributes_mapping[span._.section.category]\n                for (attr_name, attr_value) in attr_dict.items():\n                    setattr(span._, attr_name, attr_value)\n\n    def __call__(self, doc: Doc) -&gt; Doc:\n        \"\"\"\n        Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any\n        section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections\n        the entities spans in.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed spaCy Doc.\n        \"\"\"\n        matches = self.__matcher(doc)\n        if self.require_start_line:\n            matches = self.filter_start_lines(doc, matches)\n        if self.require_end_line:\n            matches = self.filter_end_lines(doc, matches)\n        if self._parent_sections:\n            matches = self.set_parent_sections(matches)\n\n        # If this has already been processed by the sectionizer, reset the sections\n        doc._.sections = []\n        # if there were no matches, return the doc as one section\n        if len(matches) == 0:\n            doc._.sections.append(Section(None, 0, 0, 0, len(doc)))\n            return doc\n\n        section_list = []\n        # if the first match does not begin at token 0, handle the first section\n        first_match = matches[0]\n        if first_match[1] != 0:\n            section_list.append(Section(None, 0, 0, 0, first_match[1]))\n\n        # handle section spans\n        for i, match in enumerate(matches):\n            parent = None\n            if len(match) == 4:\n                (match_id, start, end, parent_idx) = match\n                if parent_idx is not None:\n                    parent = section_list[parent_idx]\n            else:\n                # IDEs will warn here about match shape disagreeing w/ type hinting, but this if is only used if\n                # parent sections were never set, so parent_idx does not exist\n                (match_id, start, end) = match\n\n            # Make section header its own sentence\n            if self._apply_sentence_boundary:\n                # Section headers should be considered the start of a sentence\n                doc[start].sent_start = True\n                # Text following the header should also be considered a new sentence\n                if end &lt; len(doc):\n                    doc[end].sent_start = True\n\n            rule = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]]\n            category = rule.category\n            # If this is the last match, it should include the rest of the doc\n            if i == len(matches) - 1:\n                # If there is no scope limitation, go until the end of the doc\n                if self.max_section_length is None and rule.max_scope is None:\n                    section_list.append(\n                        Section(category, start, end, end, len(doc), parent, rule)\n                    )\n                else:\n                    # If the rule has a max_scope, use that as a precedence\n                    if rule.max_scope is not None:\n                        scope_end = min(end + rule.max_scope, doc[-1].i + 1)\n                    else:\n                        scope_end = min(end + self.max_section_length, doc[-1].i + 1)\n\n                    section_list.append(\n                        Section(category, start, end, end, scope_end, parent, rule)\n                    )\n            # Otherwise, go until the next section header\n            else:\n                next_match = matches[i + 1]\n                if len(match) == 4:\n                    _, next_start, _, _ = next_match\n                else:\n                    _, next_start, _ = next_match\n                if self.max_section_length is None and rule.max_scope is None:\n                    section_list.append(\n                        Section(category, start, end, end, next_start, parent, rule)\n                    )\n                else:\n                    if rule.max_scope is not None:\n                        scope_end = min(end + rule.max_scope, next_start)\n                    else:\n                        scope_end = min(end + self.max_section_length, next_start)\n                    section_list.append(\n                        Section(category, start, end, end, scope_end, parent, rule)\n                    )\n\n        for section in section_list:\n            doc._.sections.append(section)\n            start, end = section.section_span\n            for token in doc[start:end]:\n                token._.section = section\n\n        # If it is specified to add assertion attributes,\n        # iterate through the entities in doc and add them\n        if self.assertion_attributes_mapping:\n            if self._input_span_type.lower() == \"ents\":\n                self.set_assertion_attributes(doc.ents)\n            elif self._input_span_type.lower() == \"group\":\n                self.set_assertion_attributes(doc.spans[self._span_group_name])\n\n        return doc\n\n    def filter_start_lines(\n        self, doc: Doc, matches: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Filter a list of matches to only contain spans where the start token is the beginning of a new line.\n\n        Returns:\n            A list of match tuples (match_id, start, end) that meet the filter criteria.\n        \"\"\"\n        return [\n            m for m in matches if util.is_start_line(m[1], doc, self.newline_pattern)\n        ]\n\n    def filter_end_lines(\n        self, doc: Doc, matches: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Filter a list of matches to only contain spans where the start token is followed by a new line.\n\n        Returns:\n            A list of match tuples (match_id, start, end) that meet the filter criteria.\n        \"\"\"\n        return [\n            m for m in matches if util.is_end_line(m[2] - 1, doc, self.newline_pattern)\n        ]\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets list of rules associated with the Sectionizer.</p> <p>Returns:</p> Type Description <code>List[SectionRule]</code> <p>The list of SectionRules associated with the Sectionizer.</p>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.section_categories","title":"<code>section_categories</code>  <code>property</code>","text":"<p>Gets a list of categories used in the Sectionizer.</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>The list of all section categories available to the Sectionizer.</p>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections the entities spans in.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <code>Doc</code> <p>The processed spaCy Doc.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; Doc:\n    \"\"\"\n    Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any\n    section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections\n    the entities spans in.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed spaCy Doc.\n    \"\"\"\n    matches = self.__matcher(doc)\n    if self.require_start_line:\n        matches = self.filter_start_lines(doc, matches)\n    if self.require_end_line:\n        matches = self.filter_end_lines(doc, matches)\n    if self._parent_sections:\n        matches = self.set_parent_sections(matches)\n\n    # If this has already been processed by the sectionizer, reset the sections\n    doc._.sections = []\n    # if there were no matches, return the doc as one section\n    if len(matches) == 0:\n        doc._.sections.append(Section(None, 0, 0, 0, len(doc)))\n        return doc\n\n    section_list = []\n    # if the first match does not begin at token 0, handle the first section\n    first_match = matches[0]\n    if first_match[1] != 0:\n        section_list.append(Section(None, 0, 0, 0, first_match[1]))\n\n    # handle section spans\n    for i, match in enumerate(matches):\n        parent = None\n        if len(match) == 4:\n            (match_id, start, end, parent_idx) = match\n            if parent_idx is not None:\n                parent = section_list[parent_idx]\n        else:\n            # IDEs will warn here about match shape disagreeing w/ type hinting, but this if is only used if\n            # parent sections were never set, so parent_idx does not exist\n            (match_id, start, end) = match\n\n        # Make section header its own sentence\n        if self._apply_sentence_boundary:\n            # Section headers should be considered the start of a sentence\n            doc[start].sent_start = True\n            # Text following the header should also be considered a new sentence\n            if end &lt; len(doc):\n                doc[end].sent_start = True\n\n        rule = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]]\n        category = rule.category\n        # If this is the last match, it should include the rest of the doc\n        if i == len(matches) - 1:\n            # If there is no scope limitation, go until the end of the doc\n            if self.max_section_length is None and rule.max_scope is None:\n                section_list.append(\n                    Section(category, start, end, end, len(doc), parent, rule)\n                )\n            else:\n                # If the rule has a max_scope, use that as a precedence\n                if rule.max_scope is not None:\n                    scope_end = min(end + rule.max_scope, doc[-1].i + 1)\n                else:\n                    scope_end = min(end + self.max_section_length, doc[-1].i + 1)\n\n                section_list.append(\n                    Section(category, start, end, end, scope_end, parent, rule)\n                )\n        # Otherwise, go until the next section header\n        else:\n            next_match = matches[i + 1]\n            if len(match) == 4:\n                _, next_start, _, _ = next_match\n            else:\n                _, next_start, _ = next_match\n            if self.max_section_length is None and rule.max_scope is None:\n                section_list.append(\n                    Section(category, start, end, end, next_start, parent, rule)\n                )\n            else:\n                if rule.max_scope is not None:\n                    scope_end = min(end + rule.max_scope, next_start)\n                else:\n                    scope_end = min(end + self.max_section_length, next_start)\n                section_list.append(\n                    Section(category, start, end, end, scope_end, parent, rule)\n                )\n\n    for section in section_list:\n        doc._.sections.append(section)\n        start, end = section.section_span\n        for token in doc[start:end]:\n            token._.section = section\n\n    # If it is specified to add assertion attributes,\n    # iterate through the entities in doc and add them\n    if self.assertion_attributes_mapping:\n        if self._input_span_type.lower() == \"ents\":\n            self.set_assertion_attributes(doc.ents)\n        elif self._input_span_type.lower() == \"group\":\n            self.set_assertion_attributes(doc.spans[self._span_group_name])\n\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.__init__","title":"<code>__init__(nlp, name='medspacy_sectionizer', rules='default', language_code='en', max_section_length=None, phrase_matcher_attr='LOWER', require_start_line=False, require_end_line=False, newline_pattern='[\\\\n\\\\r]+[\\\\s]*$', input_span_type='ents', span_group_name='medspacy_spans', span_attrs='default', apply_sentence_boundary=False)</code>","text":"<pre><code>   Create a new Sectionizer component.\n\n   Args:\n       nlp: A SpaCy Language object.\n       name: The name of the component.\n       rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n           SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n           are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n           `Sectionizer.add`.\n       language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n           and also the /resources directory to see which resources might be available in each language.\n           Default is \"en\" for English.\n       max_section_length: Optional argument specifying the maximum number of tokens following a section header\n           which can be included in a section body. This can be useful if you think your section rules are\n           incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n           the scope of a section will be until either the next section header or the end of the document.\n       phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n           is 'LOWER'.\n       require_start_line: Optionally require a section header to start on a new line. Default False.\n       require_end_line: Optionally require a section header to end with a new line. Default False.\n       newline_pattern: Regular expression to match the new line either preceding or following a header\n           if either require_start_line or require_end_line are True. Default is r\"[\n</code></pre> <p>]+[\\s]*$\"            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in                <code>DEFAULT_ATTRIBUTES</code>. If a dictionary of custom attributes, format is a dictionary mapping section                categories to a dictionary containing the attribute name and the value to set the attribute to when a                span is contained in a section of that category. Custom attributes must be assigned with                <code>Span.set_extension</code> before creating the Sectionizer. If None, sectionizer will not modify span                attributes.            input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans                contained in a section if <code>span_attrs</code> is not None. \"ents\" will modify attributes of spans in doc.ents.                \"group\" will modify attributes of spans in the span group specified by <code>span_group_name</code>.            span_group_name: The name of the span group used when <code>input_span_type</code> is \"group\". Default is                \"medspacy_spans\".            apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures                the section header is considered its own sentence.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_sectionizer\",\n    rules: Optional[str] = \"default\",\n    language_code: str = 'en',\n    max_section_length: Optional[int] = None,\n    phrase_matcher_attr: str = \"LOWER\",\n    require_start_line: bool = False,\n    require_end_line: bool = False,\n    newline_pattern: str = r\"[\\n\\r]+[\\s]*$\",\n    input_span_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n    span_attrs: Union[\n        Literal[\"default\"], Dict[str, Dict[str, Any]], None\n    ] = \"default\",\n    apply_sentence_boundary: bool = False,\n):\n    \"\"\"\n    Create a new Sectionizer component.\n\n    Args:\n        nlp: A SpaCy Language object.\n        name: The name of the component.\n        rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n            SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n            are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n            `Sectionizer.add`.\n        language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        max_section_length: Optional argument specifying the maximum number of tokens following a section header\n            which can be included in a section body. This can be useful if you think your section rules are\n            incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n            the scope of a section will be until either the next section header or the end of the document.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        require_start_line: Optionally require a section header to start on a new line. Default False.\n        require_end_line: Optionally require a section header to end with a new line. Default False.\n        newline_pattern: Regular expression to match the new line either preceding or following a header\n            if either require_start_line or require_end_line are True. Default is r\"[\\n\\r]+[\\s]*$\"\n        span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n            `DEFAULT_ATTRIBUTES`. If a dictionary of custom attributes, format is a dictionary mapping section\n            categories to a dictionary containing the attribute name and the value to set the attribute to when a\n            span is contained in a section of that category. Custom attributes must be assigned with\n            `Span.set_extension` before creating the Sectionizer. If None, sectionizer will not modify span\n            attributes.\n        input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans\n            contained in a section if `span_attrs` is not None. \"ents\" will modify attributes of spans in doc.ents.\n            \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n            \"medspacy_spans\".\n        apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures\n            the section header is considered its own sentence.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self.max_section_length = max_section_length\n    self.require_start_line = require_start_line\n    self.require_end_line = require_end_line\n    self.newline_pattern = re.compile(newline_pattern)\n    self.assertion_attributes_mapping = None\n    self._parent_sections = {}\n    self._parent_required = {}\n    self._input_span_type = input_span_type\n    self._span_group_name = span_group_name\n    self._apply_sentence_boundary = apply_sentence_boundary\n\n    self.__matcher = MedspacyMatcher(\n        nlp, name=name, phrase_matcher_attr=phrase_matcher_attr\n    )\n\n    self.DEFAULT_RULES_FILEPATH = path.join(\n        Path(__file__).resolve().parents[2],\n        \"resources\",\n        language_code.lower(),\n        \"section_patterns.json\",\n    )\n\n    rule_path = None\n    if rules == \"default\":\n        rule_path = self.DEFAULT_RULES_FILEPATH\n    else:\n        rule_path = rules\n\n    if rule_path:\n        self.add(SectionRule.from_json(rule_path))\n\n    if span_attrs == \"default\":\n        self.assertion_attributes_mapping = DEFAULT_ATTRS\n        self.register_default_attributes()\n    elif span_attrs:\n        for _, attr_dict in span_attrs.items():\n            for attr_name in attr_dict.keys():\n                if not Span.has_extension(attr_name):\n                    raise ValueError(\n                        f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                        f\"called for your pipeline's custom extensions.\"\n                    )\n        self.assertion_attributes_mapping = span_attrs\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.add","title":"<code>add(rules)</code>","text":"<p>Adds SectionRules to the Sectionizer.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <p>A single SectionRule or a collection of SectionRules to add to the Sectionizer.</p> required Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def add(self, rules):\n    \"\"\"\n    Adds SectionRules to the Sectionizer.\n\n    Args:\n        rules: A single SectionRule or a collection of SectionRules to add to the Sectionizer.\n    \"\"\"\n    if isinstance(rules, SectionRule):\n        rules = [rules]\n\n    for rule in rules:\n        if not isinstance(rule, SectionRule):\n            raise TypeError(\"Rules must be type SectionRule, not\", type(rule))\n\n    self.__matcher.add(rules)\n\n    for rule in rules:\n        name = rule.category\n        parents = rule.parents\n        parent_required = rule.parent_required\n        if parents:\n            if name in self._parent_sections.keys():\n                warnings.warn(\n                    f\"Duplicate section title {name}. Merging parents. \"\n                    f\"If this is not intended, please specify distinct titles.\",\n                    RuntimeWarning,\n                )\n                self._parent_sections[name].update(parents)\n            else:\n                self._parent_sections[name] = set(parents)\n\n        if (\n            name in self._parent_required.keys()\n            and self._parent_required[name] != parent_required\n        ):\n            warnings.warn(\n                f\"Duplicate section title {name} has different parent_required option. \"\n                f\"Setting parent_required to False.\",\n                RuntimeWarning,\n            )\n            self._parent_required[name] = False\n        else:\n            self._parent_required[name] = parent_required\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.filter_end_lines","title":"<code>filter_end_lines(doc, matches)</code>","text":"<p>Filter a list of matches to only contain spans where the start token is followed by a new line.</p> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples (match_id, start, end) that meet the filter criteria.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def filter_end_lines(\n    self, doc: Doc, matches: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Filter a list of matches to only contain spans where the start token is followed by a new line.\n\n    Returns:\n        A list of match tuples (match_id, start, end) that meet the filter criteria.\n    \"\"\"\n    return [\n        m for m in matches if util.is_end_line(m[2] - 1, doc, self.newline_pattern)\n    ]\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.filter_start_lines","title":"<code>filter_start_lines(doc, matches)</code>","text":"<p>Filter a list of matches to only contain spans where the start token is the beginning of a new line.</p> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples (match_id, start, end) that meet the filter criteria.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def filter_start_lines(\n    self, doc: Doc, matches: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Filter a list of matches to only contain spans where the start token is the beginning of a new line.\n\n    Returns:\n        A list of match tuples (match_id, start, end) that meet the filter criteria.\n    \"\"\"\n    return [\n        m for m in matches if util.is_start_line(m[1], doc, self.newline_pattern)\n    ]\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.register_default_attributes","title":"<code>register_default_attributes()</code>  <code>classmethod</code>","text":"<p>Register the default values for the Span attributes defined in <code>DEFAULT_ATTRIBUTES</code>.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>@classmethod\ndef register_default_attributes(cls):\n    \"\"\"\n    Register the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n    \"\"\"\n    for attr_name in [\n        \"is_negated\",\n        \"is_uncertain\",\n        \"is_historical\",\n        \"is_hypothetical\",\n        \"is_family\",\n    ]:\n        try:\n            Span.set_extension(attr_name, default=False)\n        except ValueError:  # Extension already set\n            pass\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.set_assertion_attributes","title":"<code>set_assertion_attributes(spans)</code>","text":"<p>Add Span-level attributes to entities based on which section they occur in.</p> <p>Parameters:</p> Name Type Description Default <code>spans</code> <code>Iterable[Span]</code> <p>the spans to modify.</p> required Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def set_assertion_attributes(self, spans: Iterable[Span]):\n    \"\"\"\n    Add Span-level attributes to entities based on which section they occur in.\n\n    Args:\n        spans: the spans to modify.\n    \"\"\"\n    for span in spans:\n        if (\n            span._.section\n            and span._.section.category in self.assertion_attributes_mapping\n        ):\n            attr_dict = self.assertion_attributes_mapping[span._.section.category]\n            for (attr_name, attr_value) in attr_dict.items():\n                setattr(span._, attr_name, attr_value)\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.Sectionizer.set_parent_sections","title":"<code>set_parent_sections(sections)</code>","text":"<p>Determine the legal parent-child section relationships from the list of in-order sections of a document and the possible parents of each section as specified during direction creation.</p> <p>Parameters:</p> Name Type Description Default <code>sections</code> <code>List[Tuple[int, int, int]]</code> <p>a list of spacy match tuples found in the doc</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int, int, int]]</code> <p>A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input</p> <code>List[Tuple[int, int, int, int]]</code> <p>and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a</p> <code>List[Tuple[int, int, int, int]]</code> <p>smaller list than the input due to pruning with <code>parent_required</code>.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def set_parent_sections(\n    self, sections: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int, int]]:\n    \"\"\"\n    Determine the legal parent-child section relationships from the list\n    of in-order sections of a document and the possible parents of each\n    section as specified during direction creation.\n\n    Args:\n        sections: a list of spacy match tuples found in the doc\n\n    Returns:\n        A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input\n        and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a\n        smaller list than the input due to pruning with `parent_required`.\n    \"\"\"\n    sections_final = []\n    removed_sections = 0\n    for i, (match_id, start, end) in enumerate(sections):\n        name = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]].category\n        required = self._parent_required[name]\n        i_a = i - removed_sections  # adjusted index for removed values\n        if required and i_a == 0:\n            removed_sections += 1\n            continue\n        elif i_a == 0 or name not in self._parent_sections.keys():\n            sections_final.append((match_id, start, end, None))\n        else:\n            parents = self._parent_sections[name]\n            identified_parent = None\n            for parent in parents:\n                # go backwards through the section \"tree\" until you hit a root or the start of the list\n                candidate = self.__matcher.rule_map[\n                    self.nlp.vocab.strings[sections_final[i_a - 1][0]]\n                ].category\n                candidates_parent_idx = sections_final[i_a - 1][3]\n                if candidates_parent_idx is not None:\n                    candidates_parent = self.__matcher.rule_map[\n                        self.nlp.vocab.strings[\n                            sections_final[candidates_parent_idx][0]\n                        ]\n                    ].category\n                else:\n                    candidates_parent = None\n                candidate_i = i_a - 1\n                while candidate:\n                    if candidate == parent:\n                        identified_parent = candidate_i\n                        candidate = None\n                    else:\n                        # if you are at the end of the list... no parent\n                        if candidate_i &lt; 1:\n                            candidate = None\n                            continue\n                        # if the current candidate has no parent... no parent exists\n                        if not candidates_parent:\n                            candidate = None\n                            continue\n                        # otherwise get the previous item in the list\n                        temp = self.__matcher.rule_map[\n                            self.nlp.vocab.strings[\n                                sections_final[candidate_i - 1][0]\n                            ]\n                        ].category\n                        temp_parent_idx = sections_final[candidate_i - 1][3]\n                        if temp_parent_idx is not None:\n                            temp_parent = self.__matcher.rule_map[\n                                self.nlp.vocab.strings[\n                                    sections_final[temp_parent_idx][0]\n                                ]\n                            ].category\n                        else:\n                            temp_parent = None\n                        # if the previous item is the parent of the current item\n                        # OR if the previous item is a sibling of the current item\n                        # continue to search\n                        if (\n                            temp == candidates_parent\n                            or temp_parent == candidates_parent\n                        ):\n                            candidate = temp\n                            candidates_parent = temp_parent\n                            candidate_i -= 1\n                        # otherwise, there is no further tree traversal\n                        else:\n                            candidate = None\n\n            # if a parent is required, then add\n            if identified_parent is not None or not required:\n                # if the parent is identified, add section\n                # if the parent is not required, add section\n                # if parent is not identified and required, do not add the section\n                sections_final.append((match_id, start, end, identified_parent))\n            else:\n                removed_sections += 1\n    return sections_final\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.section","title":"<code>section</code>","text":""},{"location":"singlepage/#medspacy.section_detection.section.Section","title":"<code>Section</code>","text":"<p>               Bases: <code>object</code></p> <p>Section is the object that stores the result of processing by the Sectionizer class. A Section contains information describing the section's category, title span, body span, parent, and the rule that created it.</p> <p>Section <code>category</code> is equivalent to <code>label_</code> in a basic spaCy entity. It is a normalized name for the section type determined on initialization, either created manually or through the Sectionizer pipeline component.</p> <p>Section title, defined with <code>title_start</code>, <code>title_end</code>, and <code>title_span</code> represents the section title or header matched with the rule. In the text \"Past medical history: stroke and high blood pressure\", \"Past medical history:\" would be the title.</p> <p>Section body is defined with <code>body_start</code>, <code>body_end</code>, and <code>body_span</code>. It represents the text between the end of the current section's title and the start of the title for the next Section or when scope is set in the rule or by the Sectionizer. In the text \"Past medical history: stroke and high blood pressure\", \"stroke and high blood pressure\" would be the body.</p> <p>Parent is a string that represents the conceptual \"parent\" section in a section-&gt;subsection-&gt;subsubsection hierarchy. Candidates are determined by category in the rule and matched at runtime.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>class Section(object):\n    \"\"\"\n    Section is the object that stores the result of processing by the Sectionizer class. A Section contains information\n    describing the section's category, title span, body span, parent, and the rule that created it.\n\n    Section `category` is equivalent to `label_` in a basic spaCy entity. It is a normalized name for the section type\n    determined on initialization, either created manually or through the Sectionizer pipeline component.\n\n    Section title, defined with `title_start`, `title_end`, and `title_span` represents the section title or header\n    matched with the rule. In the text \"Past medical history: stroke and high blood pressure\", \"Past medical history:\"\n    would be the title.\n\n    Section body is defined with `body_start`, `body_end`, and `body_span`. It represents the text between the end of\n    the current section's title and the start of the title for the next Section or when scope is set in the rule or by\n    the Sectionizer. In the text \"Past medical history: stroke and high blood pressure\", \"stroke and high blood\n    pressure\" would be the body.\n\n    Parent is a string that represents the conceptual \"parent\" section in a section-&gt;subsection-&gt;subsubsection\n    hierarchy. Candidates are determined by category in the rule and matched at runtime.\n    \"\"\"\n\n    def __init__(\n        self,\n        category: Union[str, None],\n        title_start: int,\n        title_end: int,\n        body_start: int,\n        body_end: int,\n        parent: Optional[str] = None,\n        rule: Optional[SectionRule] = None,\n    ):\n        \"\"\"\n        Create a new Section object.\n\n        Args:\n            category: A normalized name for the section. Equivalent to `label_` for basic spaCy entities.\n            title_start: Index of the first token of the section title.\n            title_end: Index of the last token of the section title.\n            body_start: Index of the first token of the section body.\n            body_end: Index of the last token of the section body.\n            parent: The category of the parent section.\n            rule: The SectionRule that generated the section.\n        \"\"\"\n        self.category = category\n        self.title_start = title_start\n        self.title_end = title_end\n        self.body_start = body_start\n        self.body_end = body_end\n        self.parent = parent\n        self.rule = rule\n\n    def __repr__(self):\n        return (\n            f\"Section(category={self.category} at {self.title_start} : {self.title_end} in the doc with a body at \"\n            f\"{self.body_start} : {self.body_end} based on the rule {self.rule}\"\n        )\n\n    @property\n    def title_span(self):\n        \"\"\"\n        Gets the span of the section title.\n\n        Returns:\n            A tuple (int,int) containing the start and end indexes of the section title.\n        \"\"\"\n        return self.title_start, self.title_end\n\n    @property\n    def body_span(self):\n        \"\"\"\n        Gets the span of the section body.\n\n        Returns:\n            A tuple (int,int) containing the start and end indexes of the section body.\n        \"\"\"\n        return self.body_start, self.body_end\n\n    @property\n    def section_span(self):\n        \"\"\"\n        Gets the span of the entire section, from title start to body end.\n\n        Returns:\n            A tuple (int,int) containing the start index of the section title and the end index of the section body.\n        \"\"\"\n        return self.title_start, self.body_end\n\n    def serialized_representation(self):\n        \"\"\"\n        Serialize the Section.\n\n        Returns:\n            A json-serialized representation of the section.\n        \"\"\"\n        rule = self.rule\n\n        return {\n            \"category\": self.category,\n            \"title_start\": self.title_start,\n            \"title_end\": self.title_end,\n            \"body_start\": self.body_start,\n            \"body_end\": self.body_end,\n            \"parent\": self.parent,\n            \"rule\": rule.to_dict() if rule is not None else None,\n        }\n\n    @classmethod\n    def from_serialized_representation(cls, serialized_representation: Dict[str, str]):\n        \"\"\"\n        Load the section from a json-serialized form.\n\n        Args:\n            serialized_representation: The dictionary form of the section object to load.\n\n        Returns:\n            A Section object containing the data from the dictionary provided.\n        \"\"\"\n        rule = SectionRule.from_dict(serialized_representation[\"rule\"])\n        section = Section(\n            **{k: v for k, v in serialized_representation.items() if k not in [\"rule\"]}\n        )\n        section.rule = rule\n\n        return section\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.section.Section.body_span","title":"<code>body_span</code>  <code>property</code>","text":"<p>Gets the span of the section body.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start and end indexes of the section body.</p>"},{"location":"singlepage/#medspacy.section_detection.section.Section.section_span","title":"<code>section_span</code>  <code>property</code>","text":"<p>Gets the span of the entire section, from title start to body end.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start index of the section title and the end index of the section body.</p>"},{"location":"singlepage/#medspacy.section_detection.section.Section.title_span","title":"<code>title_span</code>  <code>property</code>","text":"<p>Gets the span of the section title.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start and end indexes of the section title.</p>"},{"location":"singlepage/#medspacy.section_detection.section.Section.__init__","title":"<code>__init__(category, title_start, title_end, body_start, body_end, parent=None, rule=None)</code>","text":"<p>Create a new Section object.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>Union[str, None]</code> <p>A normalized name for the section. Equivalent to <code>label_</code> for basic spaCy entities.</p> required <code>title_start</code> <code>int</code> <p>Index of the first token of the section title.</p> required <code>title_end</code> <code>int</code> <p>Index of the last token of the section title.</p> required <code>body_start</code> <code>int</code> <p>Index of the first token of the section body.</p> required <code>body_end</code> <code>int</code> <p>Index of the last token of the section body.</p> required <code>parent</code> <code>Optional[str]</code> <p>The category of the parent section.</p> <code>None</code> <code>rule</code> <code>Optional[SectionRule]</code> <p>The SectionRule that generated the section.</p> <code>None</code> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>def __init__(\n    self,\n    category: Union[str, None],\n    title_start: int,\n    title_end: int,\n    body_start: int,\n    body_end: int,\n    parent: Optional[str] = None,\n    rule: Optional[SectionRule] = None,\n):\n    \"\"\"\n    Create a new Section object.\n\n    Args:\n        category: A normalized name for the section. Equivalent to `label_` for basic spaCy entities.\n        title_start: Index of the first token of the section title.\n        title_end: Index of the last token of the section title.\n        body_start: Index of the first token of the section body.\n        body_end: Index of the last token of the section body.\n        parent: The category of the parent section.\n        rule: The SectionRule that generated the section.\n    \"\"\"\n    self.category = category\n    self.title_start = title_start\n    self.title_end = title_end\n    self.body_start = body_start\n    self.body_end = body_end\n    self.parent = parent\n    self.rule = rule\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.section.Section.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Load the section from a json-serialized form.</p> <p>Parameters:</p> Name Type Description Default <code>serialized_representation</code> <code>Dict[str, str]</code> <p>The dictionary form of the section object to load.</p> required <p>Returns:</p> Type Description <p>A Section object containing the data from the dictionary provided.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>@classmethod\ndef from_serialized_representation(cls, serialized_representation: Dict[str, str]):\n    \"\"\"\n    Load the section from a json-serialized form.\n\n    Args:\n        serialized_representation: The dictionary form of the section object to load.\n\n    Returns:\n        A Section object containing the data from the dictionary provided.\n    \"\"\"\n    rule = SectionRule.from_dict(serialized_representation[\"rule\"])\n    section = Section(\n        **{k: v for k, v in serialized_representation.items() if k not in [\"rule\"]}\n    )\n    section.rule = rule\n\n    return section\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.section.Section.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Serialize the Section.</p> <p>Returns:</p> Type Description <p>A json-serialized representation of the section.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>def serialized_representation(self):\n    \"\"\"\n    Serialize the Section.\n\n    Returns:\n        A json-serialized representation of the section.\n    \"\"\"\n    rule = self.rule\n\n    return {\n        \"category\": self.category,\n        \"title_start\": self.title_start,\n        \"title_end\": self.title_end,\n        \"body_start\": self.body_start,\n        \"body_end\": self.body_end,\n        \"parent\": self.parent,\n        \"rule\": rule.to_dict() if rule is not None else None,\n    }\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.section_rule","title":"<code>section_rule</code>","text":""},{"location":"singlepage/#medspacy.section_detection.section_rule.SectionRule","title":"<code>SectionRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>SectionRule defines rules for extracting entities from text using the Sectionizer.</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>class SectionRule(BaseRule):\n    \"\"\"\n    SectionRule defines rules for extracting entities from text using the Sectionizer.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"parents\",\n        \"parent_required\",\n        \"max_scope\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        max_scope: Optional[int] = None,\n        parents: Optional[List[str]] = None,\n        parent_required: bool = False,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Class for defining rules for extracting entities from text using TargetMatcher.\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            max_scope: A number of tokens to explicitly limit the size of a section body. If None, the scope will\n                include the entire doc up until either the next section header or the end of the doc. This variable can\n                also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the\n                rule scope will take precedence. If not None, this will be the number of tokens following the matched\n                section header\n                    Example:\n                        In the text \"Past Medical History: Pt has hx of pneumonia\",\n                        SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but\n                        SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section\n                            to be \"Past Medical History: Pt has\"\n                This can be useful for limiting certain sections which are known to be short or allowing others to be\n                longer than the regular global max_scope.\n            parents: A list of candidate parents for determining subsections\n            parent_required: Whether a parent is required for the section to exist in the final output. If true and no\n                parent is identified, the section will be removed.\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category, pattern, on_match, metadata)\n        self.max_scope = max_scope\n        self.parents = parents\n        if parent_required:\n            if not parents:\n                raise ValueError(\n                    f\"Jsonl file incorrectly formatted for pattern name {category}. \"\n                    f\"If parents are required, then at least one parent must be specified.\"\n                )\n        self.parent_required = parent_required\n\n    @classmethod\n    def from_json(cls, filepath) -&gt; List[SectionRule]:\n        \"\"\"\n        Read in a lexicon of modifiers from a JSON file.\n\n        Args:\n            filepath: the .json file containing modifier rules\n\n        Returns:\n            section_rules: a list of SectionRule objects\n        \"\"\"\n        import json\n\n        with open(filepath) as file:\n            section_data = json.load(file)\n        section_rules = []\n        for data in section_data[\"section_rules\"]:\n            section_rules.append(SectionRule.from_dict(data))\n        return section_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict):\n        \"\"\"\n        Reads a dictionary into a SectionRule list. Used when reading from a json file.\n\n        Args:\n            rule_dict: the dictionary to convert\n\n        Returns:\n            item: the SectionRule created from the dictionary\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                f\"JSON object contains invalid keys: {invalid_keys}. \"\n                f\"Must be one of: {cls._ALLOWED_KEYS}\"\n            )\n            raise ValueError(msg)\n        rule = SectionRule(**rule_dict)\n        return rule\n\n    def to_dict(self):\n        \"\"\"\n        Converts TargetRules to a python dictionary. Used when writing section rules to a json file.\n\n        Returns:\n            rule_dict: the dictionary containing the TargetRule info.\n        \"\"\"\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    def __repr__(self):\n        return f\"\"\"SectionRule(literal=\"{self.literal}\", category=\"{self.category}\", pattern={self.pattern}, on_match={self.on_match}, parents={self.parents}, parent_required={self.parent_required})\"\"\"\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.section_rule.SectionRule.__init__","title":"<code>__init__(literal, category, pattern=None, on_match=None, max_scope=None, parents=None, parent_required=False, metadata=None)</code>","text":"<p>Class for defining rules for extracting entities from text using TargetMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[List[Dict[str, str]], str]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>A number of tokens to explicitly limit the size of a section body. If None, the scope will include the entire doc up until either the next section header or the end of the doc. This variable can also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the rule scope will take precedence. If not None, this will be the number of tokens following the matched section header     Example:         In the text \"Past Medical History: Pt has hx of pneumonia\",         SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but         SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section             to be \"Past Medical History: Pt has\" This can be useful for limiting certain sections which are known to be short or allowing others to be longer than the regular global max_scope.</p> <code>None</code> <code>parents</code> <code>Optional[List[str]]</code> <p>A list of candidate parents for determining subsections</p> <code>None</code> <code>parent_required</code> <code>bool</code> <p>Whether a parent is required for the section to exist in the final output. If true and no parent is identified, the section will be removed.</p> <code>False</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    max_scope: Optional[int] = None,\n    parents: Optional[List[str]] = None,\n    parent_required: bool = False,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Class for defining rules for extracting entities from text using TargetMatcher.\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        max_scope: A number of tokens to explicitly limit the size of a section body. If None, the scope will\n            include the entire doc up until either the next section header or the end of the doc. This variable can\n            also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the\n            rule scope will take precedence. If not None, this will be the number of tokens following the matched\n            section header\n                Example:\n                    In the text \"Past Medical History: Pt has hx of pneumonia\",\n                    SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but\n                    SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section\n                        to be \"Past Medical History: Pt has\"\n            This can be useful for limiting certain sections which are known to be short or allowing others to be\n            longer than the regular global max_scope.\n        parents: A list of candidate parents for determining subsections\n        parent_required: Whether a parent is required for the section to exist in the final output. If true and no\n            parent is identified, the section will be removed.\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category, pattern, on_match, metadata)\n    self.max_scope = max_scope\n    self.parents = parents\n    if parent_required:\n        if not parents:\n            raise ValueError(\n                f\"Jsonl file incorrectly formatted for pattern name {category}. \"\n                f\"If parents are required, then at least one parent must be specified.\"\n            )\n    self.parent_required = parent_required\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.section_rule.SectionRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a SectionRule list. Used when reading from a json file.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <p>the dictionary to convert</p> required <p>Returns:</p> Name Type Description <code>item</code> <p>the SectionRule created from the dictionary</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict):\n    \"\"\"\n    Reads a dictionary into a SectionRule list. Used when reading from a json file.\n\n    Args:\n        rule_dict: the dictionary to convert\n\n    Returns:\n        item: the SectionRule created from the dictionary\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            f\"JSON object contains invalid keys: {invalid_keys}. \"\n            f\"Must be one of: {cls._ALLOWED_KEYS}\"\n        )\n        raise ValueError(msg)\n    rule = SectionRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.section_rule.SectionRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read in a lexicon of modifiers from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>the .json file containing modifier rules</p> required <p>Returns:</p> Name Type Description <code>section_rules</code> <code>List[SectionRule]</code> <p>a list of SectionRule objects</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath) -&gt; List[SectionRule]:\n    \"\"\"\n    Read in a lexicon of modifiers from a JSON file.\n\n    Args:\n        filepath: the .json file containing modifier rules\n\n    Returns:\n        section_rules: a list of SectionRule objects\n    \"\"\"\n    import json\n\n    with open(filepath) as file:\n        section_data = json.load(file)\n    section_rules = []\n    for data in section_data[\"section_rules\"]:\n        section_rules.append(SectionRule.from_dict(data))\n    return section_rules\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.section_rule.SectionRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts TargetRules to a python dictionary. Used when writing section rules to a json file.</p> <p>Returns:</p> Name Type Description <code>rule_dict</code> <p>the dictionary containing the TargetRule info.</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Converts TargetRules to a python dictionary. Used when writing section rules to a json file.\n\n    Returns:\n        rule_dict: the dictionary containing the TargetRule info.\n    \"\"\"\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.sectionizer","title":"<code>sectionizer</code>","text":""},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer","title":"<code>Sectionizer</code>","text":"<p>The Sectionizer will search for spans in the text which match section header rules, such as 'Past Medical History:'. Sections will be represented in custom attributes as:     category: A normalized title of the section. Example: 'past_medical_history'     section_title: The Span of the doc which was matched as a section header.         Example: 'Past Medical History:'     section_span: The entire section of the note, starting with section_header and up until the end         of the section, which will be either the start of the next section header of some pre-specified         scope. Example: 'Past Medical History: Type II DM'</p> <p>Section attributes will be registered for each Doc, Span, and Token in the following attributes:     Doc..sections: A list of namedtuples of type Section with 4 elements:         - section_title         - section_header         - section_parent         - section_span.     A Doc will also have attributes corresponding to lists of each         (ie., Doc..section_titles, Doc..section_headers, Doc..section_parents, Doc..section_list)     (Span|Token)..section_title     (Span|Token)..section_header     (Span|Token)..section_parent     (Span|Token)._.section_span</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>@Language.factory(\"medspacy_sectionizer\")\nclass Sectionizer:\n    \"\"\"\n    The Sectionizer will search for spans in the text which match section header rules, such as 'Past Medical History:'.\n    Sections will be represented in custom attributes as:\n        category: A normalized title of the section. Example: 'past_medical_history'\n        section_title: The Span of the doc which was matched as a section header.\n            Example: 'Past Medical History:'\n        section_span: The entire section of the note, starting with section_header and up until the end\n            of the section, which will be either the start of the next section header of some pre-specified\n            scope. Example: 'Past Medical History: Type II DM'\n\n    Section attributes will be registered for each Doc, Span, and Token in the following attributes:\n        Doc._.sections: A list of namedtuples of type Section with 4 elements:\n            - section_title\n            - section_header\n            - section_parent\n            - section_span.\n        A Doc will also have attributes corresponding to lists of each\n            (ie., Doc._.section_titles, Doc._.section_headers, Doc._.section_parents, Doc._.section_list)\n        (Span|Token)._.section_title\n        (Span|Token)._.section_header\n        (Span|Token)._.section_parent\n        (Span|Token)._.section_span\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_sectionizer\",\n        rules: Optional[str] = \"default\",\n        language_code: str = 'en',\n        max_section_length: Optional[int] = None,\n        phrase_matcher_attr: str = \"LOWER\",\n        require_start_line: bool = False,\n        require_end_line: bool = False,\n        newline_pattern: str = r\"[\\n\\r]+[\\s]*$\",\n        input_span_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n        span_attrs: Union[\n            Literal[\"default\"], Dict[str, Dict[str, Any]], None\n        ] = \"default\",\n        apply_sentence_boundary: bool = False,\n    ):\n        \"\"\"\n        Create a new Sectionizer component.\n\n        Args:\n            nlp: A SpaCy Language object.\n            name: The name of the component.\n            rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n                SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n                are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n                `Sectionizer.add`.\n            language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n                and also the /resources directory to see which resources might be available in each language.\n                Default is \"en\" for English.\n            max_section_length: Optional argument specifying the maximum number of tokens following a section header\n                which can be included in a section body. This can be useful if you think your section rules are\n                incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n                the scope of a section will be until either the next section header or the end of the document.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            require_start_line: Optionally require a section header to start on a new line. Default False.\n            require_end_line: Optionally require a section header to end with a new line. Default False.\n            newline_pattern: Regular expression to match the new line either preceding or following a header\n                if either require_start_line or require_end_line are True. Default is r\"[\\n\\r]+[\\s]*$\"\n            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n                `DEFAULT_ATTRIBUTES`. If a dictionary of custom attributes, format is a dictionary mapping section\n                categories to a dictionary containing the attribute name and the value to set the attribute to when a\n                span is contained in a section of that category. Custom attributes must be assigned with\n                `Span.set_extension` before creating the Sectionizer. If None, sectionizer will not modify span\n                attributes.\n            input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans\n                contained in a section if `span_attrs` is not None. \"ents\" will modify attributes of spans in doc.ents.\n                \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n                \"medspacy_spans\".\n            apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures\n                the section header is considered its own sentence.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self.max_section_length = max_section_length\n        self.require_start_line = require_start_line\n        self.require_end_line = require_end_line\n        self.newline_pattern = re.compile(newline_pattern)\n        self.assertion_attributes_mapping = None\n        self._parent_sections = {}\n        self._parent_required = {}\n        self._input_span_type = input_span_type\n        self._span_group_name = span_group_name\n        self._apply_sentence_boundary = apply_sentence_boundary\n\n        self.__matcher = MedspacyMatcher(\n            nlp, name=name, phrase_matcher_attr=phrase_matcher_attr\n        )\n\n        self.DEFAULT_RULES_FILEPATH = path.join(\n            Path(__file__).resolve().parents[2],\n            \"resources\",\n            language_code.lower(),\n            \"section_patterns.json\",\n        )\n\n        rule_path = None\n        if rules == \"default\":\n            rule_path = self.DEFAULT_RULES_FILEPATH\n        else:\n            rule_path = rules\n\n        if rule_path:\n            self.add(SectionRule.from_json(rule_path))\n\n        if span_attrs == \"default\":\n            self.assertion_attributes_mapping = DEFAULT_ATTRS\n            self.register_default_attributes()\n        elif span_attrs:\n            for _, attr_dict in span_attrs.items():\n                for attr_name in attr_dict.keys():\n                    if not Span.has_extension(attr_name):\n                        raise ValueError(\n                            f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                            f\"called for your pipeline's custom extensions.\"\n                        )\n            self.assertion_attributes_mapping = span_attrs\n\n    @property\n    def rules(self) -&gt; List[SectionRule]:\n        \"\"\"\n        Gets list of rules associated with the Sectionizer.\n\n        Returns:\n            The list of SectionRules associated with the Sectionizer.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def section_categories(self) -&gt; Set[str]:\n        \"\"\"\n        Gets a list of categories used in the Sectionizer.\n\n        Returns:\n                The list of all section categories available to the Sectionizer.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    @classmethod\n    def register_default_attributes(cls):\n        \"\"\"\n        Register the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n        \"\"\"\n        for attr_name in [\n            \"is_negated\",\n            \"is_uncertain\",\n            \"is_historical\",\n            \"is_hypothetical\",\n            \"is_family\",\n        ]:\n            try:\n                Span.set_extension(attr_name, default=False)\n            except ValueError:  # Extension already set\n                pass\n\n    def add(self, rules):\n        \"\"\"\n        Adds SectionRules to the Sectionizer.\n\n        Args:\n            rules: A single SectionRule or a collection of SectionRules to add to the Sectionizer.\n        \"\"\"\n        if isinstance(rules, SectionRule):\n            rules = [rules]\n\n        for rule in rules:\n            if not isinstance(rule, SectionRule):\n                raise TypeError(\"Rules must be type SectionRule, not\", type(rule))\n\n        self.__matcher.add(rules)\n\n        for rule in rules:\n            name = rule.category\n            parents = rule.parents\n            parent_required = rule.parent_required\n            if parents:\n                if name in self._parent_sections.keys():\n                    warnings.warn(\n                        f\"Duplicate section title {name}. Merging parents. \"\n                        f\"If this is not intended, please specify distinct titles.\",\n                        RuntimeWarning,\n                    )\n                    self._parent_sections[name].update(parents)\n                else:\n                    self._parent_sections[name] = set(parents)\n\n            if (\n                name in self._parent_required.keys()\n                and self._parent_required[name] != parent_required\n            ):\n                warnings.warn(\n                    f\"Duplicate section title {name} has different parent_required option. \"\n                    f\"Setting parent_required to False.\",\n                    RuntimeWarning,\n                )\n                self._parent_required[name] = False\n            else:\n                self._parent_required[name] = parent_required\n\n    def set_parent_sections(\n        self, sections: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int, int]]:\n        \"\"\"\n        Determine the legal parent-child section relationships from the list\n        of in-order sections of a document and the possible parents of each\n        section as specified during direction creation.\n\n        Args:\n            sections: a list of spacy match tuples found in the doc\n\n        Returns:\n            A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input\n            and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a\n            smaller list than the input due to pruning with `parent_required`.\n        \"\"\"\n        sections_final = []\n        removed_sections = 0\n        for i, (match_id, start, end) in enumerate(sections):\n            name = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]].category\n            required = self._parent_required[name]\n            i_a = i - removed_sections  # adjusted index for removed values\n            if required and i_a == 0:\n                removed_sections += 1\n                continue\n            elif i_a == 0 or name not in self._parent_sections.keys():\n                sections_final.append((match_id, start, end, None))\n            else:\n                parents = self._parent_sections[name]\n                identified_parent = None\n                for parent in parents:\n                    # go backwards through the section \"tree\" until you hit a root or the start of the list\n                    candidate = self.__matcher.rule_map[\n                        self.nlp.vocab.strings[sections_final[i_a - 1][0]]\n                    ].category\n                    candidates_parent_idx = sections_final[i_a - 1][3]\n                    if candidates_parent_idx is not None:\n                        candidates_parent = self.__matcher.rule_map[\n                            self.nlp.vocab.strings[\n                                sections_final[candidates_parent_idx][0]\n                            ]\n                        ].category\n                    else:\n                        candidates_parent = None\n                    candidate_i = i_a - 1\n                    while candidate:\n                        if candidate == parent:\n                            identified_parent = candidate_i\n                            candidate = None\n                        else:\n                            # if you are at the end of the list... no parent\n                            if candidate_i &lt; 1:\n                                candidate = None\n                                continue\n                            # if the current candidate has no parent... no parent exists\n                            if not candidates_parent:\n                                candidate = None\n                                continue\n                            # otherwise get the previous item in the list\n                            temp = self.__matcher.rule_map[\n                                self.nlp.vocab.strings[\n                                    sections_final[candidate_i - 1][0]\n                                ]\n                            ].category\n                            temp_parent_idx = sections_final[candidate_i - 1][3]\n                            if temp_parent_idx is not None:\n                                temp_parent = self.__matcher.rule_map[\n                                    self.nlp.vocab.strings[\n                                        sections_final[temp_parent_idx][0]\n                                    ]\n                                ].category\n                            else:\n                                temp_parent = None\n                            # if the previous item is the parent of the current item\n                            # OR if the previous item is a sibling of the current item\n                            # continue to search\n                            if (\n                                temp == candidates_parent\n                                or temp_parent == candidates_parent\n                            ):\n                                candidate = temp\n                                candidates_parent = temp_parent\n                                candidate_i -= 1\n                            # otherwise, there is no further tree traversal\n                            else:\n                                candidate = None\n\n                # if a parent is required, then add\n                if identified_parent is not None or not required:\n                    # if the parent is identified, add section\n                    # if the parent is not required, add section\n                    # if parent is not identified and required, do not add the section\n                    sections_final.append((match_id, start, end, identified_parent))\n                else:\n                    removed_sections += 1\n        return sections_final\n\n    def set_assertion_attributes(self, spans: Iterable[Span]):\n        \"\"\"\n        Add Span-level attributes to entities based on which section they occur in.\n\n        Args:\n            spans: the spans to modify.\n        \"\"\"\n        for span in spans:\n            if (\n                span._.section\n                and span._.section.category in self.assertion_attributes_mapping\n            ):\n                attr_dict = self.assertion_attributes_mapping[span._.section.category]\n                for (attr_name, attr_value) in attr_dict.items():\n                    setattr(span._, attr_name, attr_value)\n\n    def __call__(self, doc: Doc) -&gt; Doc:\n        \"\"\"\n        Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any\n        section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections\n        the entities spans in.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed spaCy Doc.\n        \"\"\"\n        matches = self.__matcher(doc)\n        if self.require_start_line:\n            matches = self.filter_start_lines(doc, matches)\n        if self.require_end_line:\n            matches = self.filter_end_lines(doc, matches)\n        if self._parent_sections:\n            matches = self.set_parent_sections(matches)\n\n        # If this has already been processed by the sectionizer, reset the sections\n        doc._.sections = []\n        # if there were no matches, return the doc as one section\n        if len(matches) == 0:\n            doc._.sections.append(Section(None, 0, 0, 0, len(doc)))\n            return doc\n\n        section_list = []\n        # if the first match does not begin at token 0, handle the first section\n        first_match = matches[0]\n        if first_match[1] != 0:\n            section_list.append(Section(None, 0, 0, 0, first_match[1]))\n\n        # handle section spans\n        for i, match in enumerate(matches):\n            parent = None\n            if len(match) == 4:\n                (match_id, start, end, parent_idx) = match\n                if parent_idx is not None:\n                    parent = section_list[parent_idx]\n            else:\n                # IDEs will warn here about match shape disagreeing w/ type hinting, but this if is only used if\n                # parent sections were never set, so parent_idx does not exist\n                (match_id, start, end) = match\n\n            # Make section header its own sentence\n            if self._apply_sentence_boundary:\n                # Section headers should be considered the start of a sentence\n                doc[start].sent_start = True\n                # Text following the header should also be considered a new sentence\n                if end &lt; len(doc):\n                    doc[end].sent_start = True\n\n            rule = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]]\n            category = rule.category\n            # If this is the last match, it should include the rest of the doc\n            if i == len(matches) - 1:\n                # If there is no scope limitation, go until the end of the doc\n                if self.max_section_length is None and rule.max_scope is None:\n                    section_list.append(\n                        Section(category, start, end, end, len(doc), parent, rule)\n                    )\n                else:\n                    # If the rule has a max_scope, use that as a precedence\n                    if rule.max_scope is not None:\n                        scope_end = min(end + rule.max_scope, doc[-1].i + 1)\n                    else:\n                        scope_end = min(end + self.max_section_length, doc[-1].i + 1)\n\n                    section_list.append(\n                        Section(category, start, end, end, scope_end, parent, rule)\n                    )\n            # Otherwise, go until the next section header\n            else:\n                next_match = matches[i + 1]\n                if len(match) == 4:\n                    _, next_start, _, _ = next_match\n                else:\n                    _, next_start, _ = next_match\n                if self.max_section_length is None and rule.max_scope is None:\n                    section_list.append(\n                        Section(category, start, end, end, next_start, parent, rule)\n                    )\n                else:\n                    if rule.max_scope is not None:\n                        scope_end = min(end + rule.max_scope, next_start)\n                    else:\n                        scope_end = min(end + self.max_section_length, next_start)\n                    section_list.append(\n                        Section(category, start, end, end, scope_end, parent, rule)\n                    )\n\n        for section in section_list:\n            doc._.sections.append(section)\n            start, end = section.section_span\n            for token in doc[start:end]:\n                token._.section = section\n\n        # If it is specified to add assertion attributes,\n        # iterate through the entities in doc and add them\n        if self.assertion_attributes_mapping:\n            if self._input_span_type.lower() == \"ents\":\n                self.set_assertion_attributes(doc.ents)\n            elif self._input_span_type.lower() == \"group\":\n                self.set_assertion_attributes(doc.spans[self._span_group_name])\n\n        return doc\n\n    def filter_start_lines(\n        self, doc: Doc, matches: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Filter a list of matches to only contain spans where the start token is the beginning of a new line.\n\n        Returns:\n            A list of match tuples (match_id, start, end) that meet the filter criteria.\n        \"\"\"\n        return [\n            m for m in matches if util.is_start_line(m[1], doc, self.newline_pattern)\n        ]\n\n    def filter_end_lines(\n        self, doc: Doc, matches: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Filter a list of matches to only contain spans where the start token is followed by a new line.\n\n        Returns:\n            A list of match tuples (match_id, start, end) that meet the filter criteria.\n        \"\"\"\n        return [\n            m for m in matches if util.is_end_line(m[2] - 1, doc, self.newline_pattern)\n        ]\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets list of rules associated with the Sectionizer.</p> <p>Returns:</p> Type Description <code>List[SectionRule]</code> <p>The list of SectionRules associated with the Sectionizer.</p>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.section_categories","title":"<code>section_categories</code>  <code>property</code>","text":"<p>Gets a list of categories used in the Sectionizer.</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>The list of all section categories available to the Sectionizer.</p>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections the entities spans in.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <code>Doc</code> <p>The processed spaCy Doc.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; Doc:\n    \"\"\"\n    Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any\n    section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections\n    the entities spans in.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed spaCy Doc.\n    \"\"\"\n    matches = self.__matcher(doc)\n    if self.require_start_line:\n        matches = self.filter_start_lines(doc, matches)\n    if self.require_end_line:\n        matches = self.filter_end_lines(doc, matches)\n    if self._parent_sections:\n        matches = self.set_parent_sections(matches)\n\n    # If this has already been processed by the sectionizer, reset the sections\n    doc._.sections = []\n    # if there were no matches, return the doc as one section\n    if len(matches) == 0:\n        doc._.sections.append(Section(None, 0, 0, 0, len(doc)))\n        return doc\n\n    section_list = []\n    # if the first match does not begin at token 0, handle the first section\n    first_match = matches[0]\n    if first_match[1] != 0:\n        section_list.append(Section(None, 0, 0, 0, first_match[1]))\n\n    # handle section spans\n    for i, match in enumerate(matches):\n        parent = None\n        if len(match) == 4:\n            (match_id, start, end, parent_idx) = match\n            if parent_idx is not None:\n                parent = section_list[parent_idx]\n        else:\n            # IDEs will warn here about match shape disagreeing w/ type hinting, but this if is only used if\n            # parent sections were never set, so parent_idx does not exist\n            (match_id, start, end) = match\n\n        # Make section header its own sentence\n        if self._apply_sentence_boundary:\n            # Section headers should be considered the start of a sentence\n            doc[start].sent_start = True\n            # Text following the header should also be considered a new sentence\n            if end &lt; len(doc):\n                doc[end].sent_start = True\n\n        rule = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]]\n        category = rule.category\n        # If this is the last match, it should include the rest of the doc\n        if i == len(matches) - 1:\n            # If there is no scope limitation, go until the end of the doc\n            if self.max_section_length is None and rule.max_scope is None:\n                section_list.append(\n                    Section(category, start, end, end, len(doc), parent, rule)\n                )\n            else:\n                # If the rule has a max_scope, use that as a precedence\n                if rule.max_scope is not None:\n                    scope_end = min(end + rule.max_scope, doc[-1].i + 1)\n                else:\n                    scope_end = min(end + self.max_section_length, doc[-1].i + 1)\n\n                section_list.append(\n                    Section(category, start, end, end, scope_end, parent, rule)\n                )\n        # Otherwise, go until the next section header\n        else:\n            next_match = matches[i + 1]\n            if len(match) == 4:\n                _, next_start, _, _ = next_match\n            else:\n                _, next_start, _ = next_match\n            if self.max_section_length is None and rule.max_scope is None:\n                section_list.append(\n                    Section(category, start, end, end, next_start, parent, rule)\n                )\n            else:\n                if rule.max_scope is not None:\n                    scope_end = min(end + rule.max_scope, next_start)\n                else:\n                    scope_end = min(end + self.max_section_length, next_start)\n                section_list.append(\n                    Section(category, start, end, end, scope_end, parent, rule)\n                )\n\n    for section in section_list:\n        doc._.sections.append(section)\n        start, end = section.section_span\n        for token in doc[start:end]:\n            token._.section = section\n\n    # If it is specified to add assertion attributes,\n    # iterate through the entities in doc and add them\n    if self.assertion_attributes_mapping:\n        if self._input_span_type.lower() == \"ents\":\n            self.set_assertion_attributes(doc.ents)\n        elif self._input_span_type.lower() == \"group\":\n            self.set_assertion_attributes(doc.spans[self._span_group_name])\n\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.__init__","title":"<code>__init__(nlp, name='medspacy_sectionizer', rules='default', language_code='en', max_section_length=None, phrase_matcher_attr='LOWER', require_start_line=False, require_end_line=False, newline_pattern='[\\\\n\\\\r]+[\\\\s]*$', input_span_type='ents', span_group_name='medspacy_spans', span_attrs='default', apply_sentence_boundary=False)</code>","text":"<pre><code>   Create a new Sectionizer component.\n\n   Args:\n       nlp: A SpaCy Language object.\n       name: The name of the component.\n       rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n           SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n           are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n           `Sectionizer.add`.\n       language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n           and also the /resources directory to see which resources might be available in each language.\n           Default is \"en\" for English.\n       max_section_length: Optional argument specifying the maximum number of tokens following a section header\n           which can be included in a section body. This can be useful if you think your section rules are\n           incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n           the scope of a section will be until either the next section header or the end of the document.\n       phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n           is 'LOWER'.\n       require_start_line: Optionally require a section header to start on a new line. Default False.\n       require_end_line: Optionally require a section header to end with a new line. Default False.\n       newline_pattern: Regular expression to match the new line either preceding or following a header\n           if either require_start_line or require_end_line are True. Default is r\"[\n</code></pre> <p>]+[\\s]*$\"            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in                <code>DEFAULT_ATTRIBUTES</code>. If a dictionary of custom attributes, format is a dictionary mapping section                categories to a dictionary containing the attribute name and the value to set the attribute to when a                span is contained in a section of that category. Custom attributes must be assigned with                <code>Span.set_extension</code> before creating the Sectionizer. If None, sectionizer will not modify span                attributes.            input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans                contained in a section if <code>span_attrs</code> is not None. \"ents\" will modify attributes of spans in doc.ents.                \"group\" will modify attributes of spans in the span group specified by <code>span_group_name</code>.            span_group_name: The name of the span group used when <code>input_span_type</code> is \"group\". Default is                \"medspacy_spans\".            apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures                the section header is considered its own sentence.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_sectionizer\",\n    rules: Optional[str] = \"default\",\n    language_code: str = 'en',\n    max_section_length: Optional[int] = None,\n    phrase_matcher_attr: str = \"LOWER\",\n    require_start_line: bool = False,\n    require_end_line: bool = False,\n    newline_pattern: str = r\"[\\n\\r]+[\\s]*$\",\n    input_span_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n    span_attrs: Union[\n        Literal[\"default\"], Dict[str, Dict[str, Any]], None\n    ] = \"default\",\n    apply_sentence_boundary: bool = False,\n):\n    \"\"\"\n    Create a new Sectionizer component.\n\n    Args:\n        nlp: A SpaCy Language object.\n        name: The name of the component.\n        rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n            SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n            are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n            `Sectionizer.add`.\n        language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        max_section_length: Optional argument specifying the maximum number of tokens following a section header\n            which can be included in a section body. This can be useful if you think your section rules are\n            incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n            the scope of a section will be until either the next section header or the end of the document.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        require_start_line: Optionally require a section header to start on a new line. Default False.\n        require_end_line: Optionally require a section header to end with a new line. Default False.\n        newline_pattern: Regular expression to match the new line either preceding or following a header\n            if either require_start_line or require_end_line are True. Default is r\"[\\n\\r]+[\\s]*$\"\n        span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n            `DEFAULT_ATTRIBUTES`. If a dictionary of custom attributes, format is a dictionary mapping section\n            categories to a dictionary containing the attribute name and the value to set the attribute to when a\n            span is contained in a section of that category. Custom attributes must be assigned with\n            `Span.set_extension` before creating the Sectionizer. If None, sectionizer will not modify span\n            attributes.\n        input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans\n            contained in a section if `span_attrs` is not None. \"ents\" will modify attributes of spans in doc.ents.\n            \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n            \"medspacy_spans\".\n        apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures\n            the section header is considered its own sentence.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self.max_section_length = max_section_length\n    self.require_start_line = require_start_line\n    self.require_end_line = require_end_line\n    self.newline_pattern = re.compile(newline_pattern)\n    self.assertion_attributes_mapping = None\n    self._parent_sections = {}\n    self._parent_required = {}\n    self._input_span_type = input_span_type\n    self._span_group_name = span_group_name\n    self._apply_sentence_boundary = apply_sentence_boundary\n\n    self.__matcher = MedspacyMatcher(\n        nlp, name=name, phrase_matcher_attr=phrase_matcher_attr\n    )\n\n    self.DEFAULT_RULES_FILEPATH = path.join(\n        Path(__file__).resolve().parents[2],\n        \"resources\",\n        language_code.lower(),\n        \"section_patterns.json\",\n    )\n\n    rule_path = None\n    if rules == \"default\":\n        rule_path = self.DEFAULT_RULES_FILEPATH\n    else:\n        rule_path = rules\n\n    if rule_path:\n        self.add(SectionRule.from_json(rule_path))\n\n    if span_attrs == \"default\":\n        self.assertion_attributes_mapping = DEFAULT_ATTRS\n        self.register_default_attributes()\n    elif span_attrs:\n        for _, attr_dict in span_attrs.items():\n            for attr_name in attr_dict.keys():\n                if not Span.has_extension(attr_name):\n                    raise ValueError(\n                        f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                        f\"called for your pipeline's custom extensions.\"\n                    )\n        self.assertion_attributes_mapping = span_attrs\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.add","title":"<code>add(rules)</code>","text":"<p>Adds SectionRules to the Sectionizer.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <p>A single SectionRule or a collection of SectionRules to add to the Sectionizer.</p> required Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def add(self, rules):\n    \"\"\"\n    Adds SectionRules to the Sectionizer.\n\n    Args:\n        rules: A single SectionRule or a collection of SectionRules to add to the Sectionizer.\n    \"\"\"\n    if isinstance(rules, SectionRule):\n        rules = [rules]\n\n    for rule in rules:\n        if not isinstance(rule, SectionRule):\n            raise TypeError(\"Rules must be type SectionRule, not\", type(rule))\n\n    self.__matcher.add(rules)\n\n    for rule in rules:\n        name = rule.category\n        parents = rule.parents\n        parent_required = rule.parent_required\n        if parents:\n            if name in self._parent_sections.keys():\n                warnings.warn(\n                    f\"Duplicate section title {name}. Merging parents. \"\n                    f\"If this is not intended, please specify distinct titles.\",\n                    RuntimeWarning,\n                )\n                self._parent_sections[name].update(parents)\n            else:\n                self._parent_sections[name] = set(parents)\n\n        if (\n            name in self._parent_required.keys()\n            and self._parent_required[name] != parent_required\n        ):\n            warnings.warn(\n                f\"Duplicate section title {name} has different parent_required option. \"\n                f\"Setting parent_required to False.\",\n                RuntimeWarning,\n            )\n            self._parent_required[name] = False\n        else:\n            self._parent_required[name] = parent_required\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.filter_end_lines","title":"<code>filter_end_lines(doc, matches)</code>","text":"<p>Filter a list of matches to only contain spans where the start token is followed by a new line.</p> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples (match_id, start, end) that meet the filter criteria.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def filter_end_lines(\n    self, doc: Doc, matches: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Filter a list of matches to only contain spans where the start token is followed by a new line.\n\n    Returns:\n        A list of match tuples (match_id, start, end) that meet the filter criteria.\n    \"\"\"\n    return [\n        m for m in matches if util.is_end_line(m[2] - 1, doc, self.newline_pattern)\n    ]\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.filter_start_lines","title":"<code>filter_start_lines(doc, matches)</code>","text":"<p>Filter a list of matches to only contain spans where the start token is the beginning of a new line.</p> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples (match_id, start, end) that meet the filter criteria.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def filter_start_lines(\n    self, doc: Doc, matches: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Filter a list of matches to only contain spans where the start token is the beginning of a new line.\n\n    Returns:\n        A list of match tuples (match_id, start, end) that meet the filter criteria.\n    \"\"\"\n    return [\n        m for m in matches if util.is_start_line(m[1], doc, self.newline_pattern)\n    ]\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.register_default_attributes","title":"<code>register_default_attributes()</code>  <code>classmethod</code>","text":"<p>Register the default values for the Span attributes defined in <code>DEFAULT_ATTRIBUTES</code>.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>@classmethod\ndef register_default_attributes(cls):\n    \"\"\"\n    Register the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n    \"\"\"\n    for attr_name in [\n        \"is_negated\",\n        \"is_uncertain\",\n        \"is_historical\",\n        \"is_hypothetical\",\n        \"is_family\",\n    ]:\n        try:\n            Span.set_extension(attr_name, default=False)\n        except ValueError:  # Extension already set\n            pass\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.set_assertion_attributes","title":"<code>set_assertion_attributes(spans)</code>","text":"<p>Add Span-level attributes to entities based on which section they occur in.</p> <p>Parameters:</p> Name Type Description Default <code>spans</code> <code>Iterable[Span]</code> <p>the spans to modify.</p> required Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def set_assertion_attributes(self, spans: Iterable[Span]):\n    \"\"\"\n    Add Span-level attributes to entities based on which section they occur in.\n\n    Args:\n        spans: the spans to modify.\n    \"\"\"\n    for span in spans:\n        if (\n            span._.section\n            and span._.section.category in self.assertion_attributes_mapping\n        ):\n            attr_dict = self.assertion_attributes_mapping[span._.section.category]\n            for (attr_name, attr_value) in attr_dict.items():\n                setattr(span._, attr_name, attr_value)\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.sectionizer.Sectionizer.set_parent_sections","title":"<code>set_parent_sections(sections)</code>","text":"<p>Determine the legal parent-child section relationships from the list of in-order sections of a document and the possible parents of each section as specified during direction creation.</p> <p>Parameters:</p> Name Type Description Default <code>sections</code> <code>List[Tuple[int, int, int]]</code> <p>a list of spacy match tuples found in the doc</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int, int, int]]</code> <p>A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input</p> <code>List[Tuple[int, int, int, int]]</code> <p>and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a</p> <code>List[Tuple[int, int, int, int]]</code> <p>smaller list than the input due to pruning with <code>parent_required</code>.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def set_parent_sections(\n    self, sections: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int, int]]:\n    \"\"\"\n    Determine the legal parent-child section relationships from the list\n    of in-order sections of a document and the possible parents of each\n    section as specified during direction creation.\n\n    Args:\n        sections: a list of spacy match tuples found in the doc\n\n    Returns:\n        A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input\n        and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a\n        smaller list than the input due to pruning with `parent_required`.\n    \"\"\"\n    sections_final = []\n    removed_sections = 0\n    for i, (match_id, start, end) in enumerate(sections):\n        name = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]].category\n        required = self._parent_required[name]\n        i_a = i - removed_sections  # adjusted index for removed values\n        if required and i_a == 0:\n            removed_sections += 1\n            continue\n        elif i_a == 0 or name not in self._parent_sections.keys():\n            sections_final.append((match_id, start, end, None))\n        else:\n            parents = self._parent_sections[name]\n            identified_parent = None\n            for parent in parents:\n                # go backwards through the section \"tree\" until you hit a root or the start of the list\n                candidate = self.__matcher.rule_map[\n                    self.nlp.vocab.strings[sections_final[i_a - 1][0]]\n                ].category\n                candidates_parent_idx = sections_final[i_a - 1][3]\n                if candidates_parent_idx is not None:\n                    candidates_parent = self.__matcher.rule_map[\n                        self.nlp.vocab.strings[\n                            sections_final[candidates_parent_idx][0]\n                        ]\n                    ].category\n                else:\n                    candidates_parent = None\n                candidate_i = i_a - 1\n                while candidate:\n                    if candidate == parent:\n                        identified_parent = candidate_i\n                        candidate = None\n                    else:\n                        # if you are at the end of the list... no parent\n                        if candidate_i &lt; 1:\n                            candidate = None\n                            continue\n                        # if the current candidate has no parent... no parent exists\n                        if not candidates_parent:\n                            candidate = None\n                            continue\n                        # otherwise get the previous item in the list\n                        temp = self.__matcher.rule_map[\n                            self.nlp.vocab.strings[\n                                sections_final[candidate_i - 1][0]\n                            ]\n                        ].category\n                        temp_parent_idx = sections_final[candidate_i - 1][3]\n                        if temp_parent_idx is not None:\n                            temp_parent = self.__matcher.rule_map[\n                                self.nlp.vocab.strings[\n                                    sections_final[temp_parent_idx][0]\n                                ]\n                            ].category\n                        else:\n                            temp_parent = None\n                        # if the previous item is the parent of the current item\n                        # OR if the previous item is a sibling of the current item\n                        # continue to search\n                        if (\n                            temp == candidates_parent\n                            or temp_parent == candidates_parent\n                        ):\n                            candidate = temp\n                            candidates_parent = temp_parent\n                            candidate_i -= 1\n                        # otherwise, there is no further tree traversal\n                        else:\n                            candidate = None\n\n            # if a parent is required, then add\n            if identified_parent is not None or not required:\n                # if the parent is identified, add section\n                # if the parent is not required, add section\n                # if parent is not identified and required, do not add the section\n                sections_final.append((match_id, start, end, identified_parent))\n            else:\n                removed_sections += 1\n    return sections_final\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.util","title":"<code>util</code>","text":"<p>This module will contain helper functions and classes for common clinical processing tasks which will be used in medspaCy's sectionizer.</p>"},{"location":"singlepage/#medspacy.section_detection.util.is_end_line","title":"<code>is_end_line(idx, doc, pattern)</code>","text":"<p>Check whether the token at idx occurs at the end of the line.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The token index to check.</p> required <code>doc</code> <code>Doc</code> <p>The doc to check in.</p> required <code>pattern</code> <code>Pattern</code> <p>The newline pattern to check with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the token occurs at the end of a line.</p> Source code in <code>medspacy/section_detection/util.py</code> <pre><code>def is_end_line(idx: int, doc: Doc, pattern: re.Pattern) -&gt; bool:\n    \"\"\"\n    Check whether the token at idx occurs at the end of the line.\n\n    Args:\n        idx: The token index to check.\n        doc: The doc to check in.\n        pattern: The newline pattern to check with.\n\n    Returns:\n        Whether the token occurs at the end of a line.\n    \"\"\"\n    # If it's the end of the doc, return True\n    if idx == len(doc) - 1:\n        return True\n\n    # Check if either the token has trailing newlines,\n    # or if the next token is a newline\n    text = doc[idx].text_with_ws\n    if pattern.search(text) is not None:\n        return True\n    following_text = doc[idx + 1].text_with_ws\n    return pattern.search(following_text) is not None\n</code></pre>"},{"location":"singlepage/#medspacy.section_detection.util.is_start_line","title":"<code>is_start_line(idx, doc, pattern)</code>","text":"<p>Check whether the token at idx occurs at the start of the line.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The token index to check.</p> required <code>doc</code> <code>Doc</code> <p>The doc to check in.</p> required <code>pattern</code> <code>Pattern</code> <p>The newline pattern to check with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the token occurs at the start of a line.</p> Source code in <code>medspacy/section_detection/util.py</code> <pre><code>def is_start_line(idx: int, doc: Doc, pattern: re.Pattern) -&gt; bool:\n    \"\"\"\n    Check whether the token at idx occurs at the start of the line.\n\n    Args:\n        idx: The token index to check.\n        doc: The doc to check in.\n        pattern: The newline pattern to check with.\n\n    Returns:\n        Whether the token occurs at the start of a line.\n    \"\"\"\n    # If it's the start of the doc, return True\n    if idx == 0:\n        return True\n    # Otherwise, check if the preceding token ends with newlines\n    preceding_text = doc[idx - 1].text_with_ws\n    return pattern.search(preceding_text) is not None\n</code></pre>"},{"location":"singlepage/#medspacy.sentence_splitting","title":"<code>sentence_splitting</code>","text":""},{"location":"singlepage/#medspacy.sentence_splitting.PySBDSentenceSplitter","title":"<code>PySBDSentenceSplitter</code>","text":"Source code in <code>medspacy/sentence_splitting.py</code> <pre><code>@Language.factory(\"medspacy_pysbd\")\nclass PySBDSentenceSplitter:\n    def __init__(self, name, nlp, clean=False):\n        self.name = name\n        self.nlp = nlp\n        self.seg = pysbd.Segmenter(language=\"en\", clean=clean, char_span=True)\n\n    def __call__(self, doc):\n        \"\"\"\n        Spacy component based on: https://github.com/nipunsadvilkar/pySBD improved to work with spacy 3.0\n        \"\"\"\n        sents_char_spans = self.seg.segment(doc.text_with_ws)\n        start_token_ids = [sent.start for sent in sents_char_spans]\n        for token in doc:\n            token.is_sent_start = True if token.idx in start_token_ids else False\n        return doc\n</code></pre>"},{"location":"singlepage/#medspacy.sentence_splitting.PySBDSentenceSplitter.__call__","title":"<code>__call__(doc)</code>","text":"<p>Spacy component based on: https://github.com/nipunsadvilkar/pySBD improved to work with spacy 3.0</p> Source code in <code>medspacy/sentence_splitting.py</code> <pre><code>def __call__(self, doc):\n    \"\"\"\n    Spacy component based on: https://github.com/nipunsadvilkar/pySBD improved to work with spacy 3.0\n    \"\"\"\n    sents_char_spans = self.seg.segment(doc.text_with_ws)\n    start_token_ids = [sent.start for sent in sents_char_spans]\n    for token in doc:\n        token.is_sent_start = True if token.idx in start_token_ids else False\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher","title":"<code>target_matcher</code>","text":""},{"location":"singlepage/#medspacy.target_matcher.concept_tagger","title":"<code>concept_tagger</code>","text":""},{"location":"singlepage/#medspacy.target_matcher.concept_tagger.ConceptTagger","title":"<code>ConceptTagger</code>","text":"<p>ConceptTagger is a component for setting an attribute on tokens contained in spans extracted by TargetRules. This can be used for tasks such as semantic labeling or for normalizing tokens, making downstream extraction simpler.</p> <p>A common use case is when a single concept can have many synonyms or variants and downstream rules would be simplified by matching on a unified token tag for those synonyms rather than including the entire synonym list in each downstream rule.</p> Source code in <code>medspacy/target_matcher/concept_tagger.py</code> <pre><code>@Language.factory(\"medspacy_concept_tagger\")\nclass ConceptTagger:\n    \"\"\"ConceptTagger is a component for setting an attribute on tokens contained in spans extracted by TargetRules. This\n    can be used for tasks such as semantic labeling or for normalizing tokens, making downstream extraction simpler.\n\n    A common use case is when a single concept can have many synonyms or variants and downstream rules would be\n    simplified by matching on a unified token tag for those synonyms rather than including the entire synonym list in\n    each downstream rule.\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_concept_tagger\",\n        attr_name: str = \"concept_tag\",\n    ):\n        \"\"\"\n        Creates a new ConceptTagger.\n\n        Args:\n            nlp: A spaCy Language model.\n            name: The name of the ConceptTagger component. Must be a valid python variable name.\n            attr_name: The name of the attribute to set to tokens.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self._attr_name = attr_name\n        self.__matcher = MedspacyMatcher(nlp, name=name)\n\n        # If the token attribute hasn't been registered, add it now\n        # If it has already been set, then we can pass.\n        # This will happen, for example, if you've already instantiated\n        # the ConceptTagger and it registered the attribute.\n        if not Token.has_extension(attr_name):\n            Token.set_extension(attr_name, default=\"\")\n\n    @property\n    def attr_name(self) -&gt; str:\n        \"\"\"\n        The name of the attribute that will be set on each matched token.\n\n        Returns:\n            The attribute name.\n        \"\"\"\n        return self._attr_name\n\n    def add(self, rules: Union[TargetRule, List[TargetRule]]):\n        \"\"\"\n        Adds a single TargetRule or a list of TargetRules to the ConceptTagger.\n\n        Args:\n            rules: A single TargetRule or a collection of TargetRules.\n        \"\"\"\n        self.__matcher.add(rules)\n\n    def __call__(self, doc: Doc) -&gt; Doc:\n        \"\"\"\n        Call ConceptTagger on a doc. Matches spans and assigns attributes to all tokens contained in those spans, but\n        does not preserve the spans themselves.\n\n        Args:\n            doc: The spaCy Doc to process.\n\n        Returns:\n            The spaCy Doc processed.\n        \"\"\"\n        matches = self.__matcher(doc)\n        for (rule_id, start, end) in matches:\n            rule = self.__matcher.rule_map[self.nlp.vocab.strings[rule_id]]\n            for i in range(start, end):\n                setattr(doc[i]._, self.attr_name, rule.category)\n\n        return doc\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.concept_tagger.ConceptTagger.attr_name","title":"<code>attr_name</code>  <code>property</code>","text":"<p>The name of the attribute that will be set on each matched token.</p> <p>Returns:</p> Type Description <code>str</code> <p>The attribute name.</p>"},{"location":"singlepage/#medspacy.target_matcher.concept_tagger.ConceptTagger.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call ConceptTagger on a doc. Matches spans and assigns attributes to all tokens contained in those spans, but does not preserve the spans themselves.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy Doc to process.</p> required <p>Returns:</p> Type Description <code>Doc</code> <p>The spaCy Doc processed.</p> Source code in <code>medspacy/target_matcher/concept_tagger.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; Doc:\n    \"\"\"\n    Call ConceptTagger on a doc. Matches spans and assigns attributes to all tokens contained in those spans, but\n    does not preserve the spans themselves.\n\n    Args:\n        doc: The spaCy Doc to process.\n\n    Returns:\n        The spaCy Doc processed.\n    \"\"\"\n    matches = self.__matcher(doc)\n    for (rule_id, start, end) in matches:\n        rule = self.__matcher.rule_map[self.nlp.vocab.strings[rule_id]]\n        for i in range(start, end):\n            setattr(doc[i]._, self.attr_name, rule.category)\n\n    return doc\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.concept_tagger.ConceptTagger.__init__","title":"<code>__init__(nlp, name='medspacy_concept_tagger', attr_name='concept_tag')</code>","text":"<p>Creates a new ConceptTagger.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A spaCy Language model.</p> required <code>name</code> <code>str</code> <p>The name of the ConceptTagger component. Must be a valid python variable name.</p> <code>'medspacy_concept_tagger'</code> <code>attr_name</code> <code>str</code> <p>The name of the attribute to set to tokens.</p> <code>'concept_tag'</code> Source code in <code>medspacy/target_matcher/concept_tagger.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_concept_tagger\",\n    attr_name: str = \"concept_tag\",\n):\n    \"\"\"\n    Creates a new ConceptTagger.\n\n    Args:\n        nlp: A spaCy Language model.\n        name: The name of the ConceptTagger component. Must be a valid python variable name.\n        attr_name: The name of the attribute to set to tokens.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self._attr_name = attr_name\n    self.__matcher = MedspacyMatcher(nlp, name=name)\n\n    # If the token attribute hasn't been registered, add it now\n    # If it has already been set, then we can pass.\n    # This will happen, for example, if you've already instantiated\n    # the ConceptTagger and it registered the attribute.\n    if not Token.has_extension(attr_name):\n        Token.set_extension(attr_name, default=\"\")\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.concept_tagger.ConceptTagger.add","title":"<code>add(rules)</code>","text":"<p>Adds a single TargetRule or a list of TargetRules to the ConceptTagger.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[TargetRule, List[TargetRule]]</code> <p>A single TargetRule or a collection of TargetRules.</p> required Source code in <code>medspacy/target_matcher/concept_tagger.py</code> <pre><code>def add(self, rules: Union[TargetRule, List[TargetRule]]):\n    \"\"\"\n    Adds a single TargetRule or a list of TargetRules to the ConceptTagger.\n\n    Args:\n        rules: A single TargetRule or a collection of TargetRules.\n    \"\"\"\n    self.__matcher.add(rules)\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_matcher","title":"<code>target_matcher</code>","text":""},{"location":"singlepage/#medspacy.target_matcher.target_matcher.TargetMatcher","title":"<code>TargetMatcher</code>","text":"<p>TargetMatcher is a component for advanced direction-based text extraction. Rules are defined using <code>medspacy.target_matcher.TargetRule</code>.</p> <p>A <code>TargetMatcher</code> will use the added <code>TargetRule</code> objects to identify matches in the text and apply labels or modify attributes. It will either modify the input spaCy <code>Doc</code> with the result or return the spans as a list.</p> <p>In addition to extracting spans of text and setting labels, TargetRules can also define setting custom attributes and metadata. Additionally, each resulting span has an attribute span._.target_rule which maps a span to the TargetRule which set it.</p> Source code in <code>medspacy/target_matcher/target_matcher.py</code> <pre><code>@Language.factory(\"medspacy_target_matcher\")\nclass TargetMatcher:\n    \"\"\"\n    TargetMatcher is a component for advanced direction-based text extraction. Rules are defined using\n    `medspacy.target_matcher.TargetRule`.\n\n    A `TargetMatcher` will use the added `TargetRule` objects to identify matches in the text and apply labels or modify\n    attributes. It will either modify the input spaCy `Doc` with the result or return the spans as a list.\n\n    In addition to extracting spans of text and setting labels, TargetRules can also define setting custom attributes\n    and metadata. Additionally, each resulting span has an attribute span._.target_rule which maps a span to the\n    TargetRule which set it.\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_target_matcher\",\n        rules: Optional[str] = None,\n        phrase_matcher_attr: str = \"LOWER\",\n        result_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n        prune: bool = True\n    ):\n        \"\"\"\n        Creates a new TargetMatcher.\n\n        Args:\n            nlp: A spaCy Language model.\n            name: The name of the TargetMatcher component\n            rules: An optional filepath containing a JSON of TargetRules. If None, then no rules will be added. Default\n                None.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            result_type: \"ents\" (default), \"group\", or None. Determines where TargetMatcher will put the matched spans.\n                \"ents\" will add spans to doc.ents and add to any existing entities. If conflicts appear, existing\n                entities will take precedence. \"group\" will add spans to doc.spans under the specified group name. None\n                will return the list of spans rather than saving to the Doc.\n            span_group_name: The name of the span group used to store results when result_type is \"group\". Default is\n                \"medspacy_spans\".\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self._result_type = result_type\n        self._span_group_name = span_group_name\n        self._prune = prune\n\n        if rules:\n            self.add(TargetRule.from_json(rules))\n\n        self.__matcher = MedspacyMatcher(\n            nlp, name=name, phrase_matcher_attr=phrase_matcher_attr, prune=self._prune\n        )\n\n    @property\n    def rules(self) -&gt; List[TargetRule]:\n        \"\"\"\n        Gets the list of TargetRules for the TargetMatcher.\n\n        Returns:\n            A list of TargetRules.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def labels(self) -&gt; Set[str]:\n        \"\"\"\n        Gets the list of labels for the TargetMatcher. Based on rules added to the TargetMatcher.\n\n        Returns:\n            A list of all labels that the TargetMatcher can produce.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def result_type(self) -&gt; Union[str, None]:\n        \"\"\"\n        The result type of the TargetMatcher. \"ents\" indicates that calling TargetMatcher will store the results in\n        doc.ents, \"group\" indicates that the results will be stored in the span group indicated by `span_group_name`,\n        and None indicates that spans will be returned in a list.\n\n        Returns:\n            The result type string.\n        \"\"\"\n        return self._result_type\n\n    @result_type.setter\n    def result_type(self, result_type: Literal[\"ents\", \"group\"]):\n        if not (not result_type or result_type == \"group\" or result_type == \"ents\"):\n            raise ValueError('result_type must be \"ents\", \"group\" or None.')\n        self._result_type = result_type\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `result_type` is \"group\", calling this component will\n        place results in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules: Union[TargetRule, Iterable[TargetRule]]):\n        \"\"\"\n        Adds a single TargetRule or a list of TargetRules to the TargetMatcher.\n\n        Args:\n            rules: A single TargetRule or a collection of TargetRules.\n        \"\"\"\n        if isinstance(rules, TargetRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, TargetRule):\n                raise TypeError(\"Rules must be TargetRule, not\", type(rule))\n        self.__matcher.add(rules)\n\n    def __call__(self, doc: Doc) -&gt; Union[Doc, List[Span]]:\n        \"\"\"\n        Calls TargetMatcher on a Doc. By default and when `result_type` is \"ents\", adds results to doc.ents. If\n        `result_type` is \"group\", adds results to the span group specified by `span_group_name`. If `result_type` is\n        None, then returns a list of the matched Spans.\n\n        Args:\n            doc: The spaCy Doc to process.\n\n        Returns:\n            Returns a modified `doc` when `TargetMatcher.result_type` is \"ents\" or \"group\". Returns a list of\n            `Span` objects if `TargetMatcher.result_type` is None.\n        \"\"\"\n        matches = self.__matcher(doc)\n        spans = []\n        for rule_id, start, end in matches:\n            rule = self.__matcher.rule_map[self.nlp.vocab.strings[rule_id]]\n            span = Span(doc, start=start, end=end, label=rule.category)\n            span._.target_rule = rule\n            if rule.attributes is not None:\n                for attribute, value in rule.attributes.items():\n                    try:\n                        setattr(span._, attribute, value)\n                    except AttributeError as e:\n                        raise e\n            spans.append(span)\n\n        if not self.result_type:\n            return spans\n        elif self.result_type.lower() == \"ents\":\n            for span in spans:\n                try:\n                    doc.ents += (span,)\n                except ValueError:\n                    # spaCy will raise a value error if the token in span are already part of an entity (i.e., as part\n                    # of an upstream component). In that case, let the existing span supersede this one.\n                    warnings.warn(\n                        f'The result \"\"{span}\"\" conflicts with a pre-existing entity in doc.ents. This result has been '\n                        f\"skipped.\",\n                        RuntimeWarning,\n                    )\n            return doc\n        elif self.result_type.lower() == \"group\":\n            if self.span_group_name in doc.spans.keys():\n                doc.spans[self.span_group_name] += spans\n            else:\n                doc.spans[self.span_group_name] = spans\n            return doc\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_matcher.TargetMatcher.labels","title":"<code>labels</code>  <code>property</code>","text":"<p>Gets the list of labels for the TargetMatcher. Based on rules added to the TargetMatcher.</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>A list of all labels that the TargetMatcher can produce.</p>"},{"location":"singlepage/#medspacy.target_matcher.target_matcher.TargetMatcher.result_type","title":"<code>result_type</code>  <code>property</code> <code>writable</code>","text":"<p>The result type of the TargetMatcher. \"ents\" indicates that calling TargetMatcher will store the results in doc.ents, \"group\" indicates that the results will be stored in the span group indicated by <code>span_group_name</code>, and None indicates that spans will be returned in a list.</p> <p>Returns:</p> Type Description <code>Union[str, None]</code> <p>The result type string.</p>"},{"location":"singlepage/#medspacy.target_matcher.target_matcher.TargetMatcher.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets the list of TargetRules for the TargetMatcher.</p> <p>Returns:</p> Type Description <code>List[TargetRule]</code> <p>A list of TargetRules.</p>"},{"location":"singlepage/#medspacy.target_matcher.target_matcher.TargetMatcher.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>result_type</code> is \"group\", calling this component will place results in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"singlepage/#medspacy.target_matcher.target_matcher.TargetMatcher.__call__","title":"<code>__call__(doc)</code>","text":"<p>Calls TargetMatcher on a Doc. By default and when <code>result_type</code> is \"ents\", adds results to doc.ents. If <code>result_type</code> is \"group\", adds results to the span group specified by <code>span_group_name</code>. If <code>result_type</code> is None, then returns a list of the matched Spans.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy Doc to process.</p> required <p>Returns:</p> Type Description <code>Union[Doc, List[Span]]</code> <p>Returns a modified <code>doc</code> when <code>TargetMatcher.result_type</code> is \"ents\" or \"group\". Returns a list of</p> <code>Union[Doc, List[Span]]</code> <p><code>Span</code> objects if <code>TargetMatcher.result_type</code> is None.</p> Source code in <code>medspacy/target_matcher/target_matcher.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; Union[Doc, List[Span]]:\n    \"\"\"\n    Calls TargetMatcher on a Doc. By default and when `result_type` is \"ents\", adds results to doc.ents. If\n    `result_type` is \"group\", adds results to the span group specified by `span_group_name`. If `result_type` is\n    None, then returns a list of the matched Spans.\n\n    Args:\n        doc: The spaCy Doc to process.\n\n    Returns:\n        Returns a modified `doc` when `TargetMatcher.result_type` is \"ents\" or \"group\". Returns a list of\n        `Span` objects if `TargetMatcher.result_type` is None.\n    \"\"\"\n    matches = self.__matcher(doc)\n    spans = []\n    for rule_id, start, end in matches:\n        rule = self.__matcher.rule_map[self.nlp.vocab.strings[rule_id]]\n        span = Span(doc, start=start, end=end, label=rule.category)\n        span._.target_rule = rule\n        if rule.attributes is not None:\n            for attribute, value in rule.attributes.items():\n                try:\n                    setattr(span._, attribute, value)\n                except AttributeError as e:\n                    raise e\n        spans.append(span)\n\n    if not self.result_type:\n        return spans\n    elif self.result_type.lower() == \"ents\":\n        for span in spans:\n            try:\n                doc.ents += (span,)\n            except ValueError:\n                # spaCy will raise a value error if the token in span are already part of an entity (i.e., as part\n                # of an upstream component). In that case, let the existing span supersede this one.\n                warnings.warn(\n                    f'The result \"\"{span}\"\" conflicts with a pre-existing entity in doc.ents. This result has been '\n                    f\"skipped.\",\n                    RuntimeWarning,\n                )\n        return doc\n    elif self.result_type.lower() == \"group\":\n        if self.span_group_name in doc.spans.keys():\n            doc.spans[self.span_group_name] += spans\n        else:\n            doc.spans[self.span_group_name] = spans\n        return doc\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_matcher.TargetMatcher.__init__","title":"<code>__init__(nlp, name='medspacy_target_matcher', rules=None, phrase_matcher_attr='LOWER', result_type='ents', span_group_name='medspacy_spans', prune=True)</code>","text":"<p>Creates a new TargetMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A spaCy Language model.</p> required <code>name</code> <code>str</code> <p>The name of the TargetMatcher component</p> <code>'medspacy_target_matcher'</code> <code>rules</code> <code>Optional[str]</code> <p>An optional filepath containing a JSON of TargetRules. If None, then no rules will be added. Default None.</p> <code>None</code> <code>phrase_matcher_attr</code> <code>str</code> <p>The token attribute to use for PhraseMatcher for rules where <code>pattern</code> is None. Default is 'LOWER'.</p> <code>'LOWER'</code> <code>result_type</code> <code>Union[Literal['ents', 'group'], None]</code> <p>\"ents\" (default), \"group\", or None. Determines where TargetMatcher will put the matched spans. \"ents\" will add spans to doc.ents and add to any existing entities. If conflicts appear, existing entities will take precedence. \"group\" will add spans to doc.spans under the specified group name. None will return the list of spans rather than saving to the Doc.</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>The name of the span group used to store results when result_type is \"group\". Default is \"medspacy_spans\".</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/target_matcher/target_matcher.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_target_matcher\",\n    rules: Optional[str] = None,\n    phrase_matcher_attr: str = \"LOWER\",\n    result_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n    prune: bool = True\n):\n    \"\"\"\n    Creates a new TargetMatcher.\n\n    Args:\n        nlp: A spaCy Language model.\n        name: The name of the TargetMatcher component\n        rules: An optional filepath containing a JSON of TargetRules. If None, then no rules will be added. Default\n            None.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        result_type: \"ents\" (default), \"group\", or None. Determines where TargetMatcher will put the matched spans.\n            \"ents\" will add spans to doc.ents and add to any existing entities. If conflicts appear, existing\n            entities will take precedence. \"group\" will add spans to doc.spans under the specified group name. None\n            will return the list of spans rather than saving to the Doc.\n        span_group_name: The name of the span group used to store results when result_type is \"group\". Default is\n            \"medspacy_spans\".\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self._result_type = result_type\n    self._span_group_name = span_group_name\n    self._prune = prune\n\n    if rules:\n        self.add(TargetRule.from_json(rules))\n\n    self.__matcher = MedspacyMatcher(\n        nlp, name=name, phrase_matcher_attr=phrase_matcher_attr, prune=self._prune\n    )\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_matcher.TargetMatcher.add","title":"<code>add(rules)</code>","text":"<p>Adds a single TargetRule or a list of TargetRules to the TargetMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[TargetRule, Iterable[TargetRule]]</code> <p>A single TargetRule or a collection of TargetRules.</p> required Source code in <code>medspacy/target_matcher/target_matcher.py</code> <pre><code>def add(self, rules: Union[TargetRule, Iterable[TargetRule]]):\n    \"\"\"\n    Adds a single TargetRule or a list of TargetRules to the TargetMatcher.\n\n    Args:\n        rules: A single TargetRule or a collection of TargetRules.\n    \"\"\"\n    if isinstance(rules, TargetRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, TargetRule):\n            raise TypeError(\"Rules must be TargetRule, not\", type(rule))\n    self.__matcher.add(rules)\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_rule","title":"<code>target_rule</code>","text":""},{"location":"singlepage/#medspacy.target_matcher.target_rule.TargetRule","title":"<code>TargetRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>TargetRule defines rules for extracting entities from text using the TargetMatcher.</p> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>class TargetRule(BaseRule):\n    \"\"\"\n    TargetRule defines rules for extracting entities from text using the TargetMatcher.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"attributes\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        attributes: Optional[Dict[str, Any]] = None,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Creates a new TargetRule.\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            attributes: Optional custom attribute names to set for a Span matched by the direction. These attribute\n                names are stored under Span._.[attribute_name]. For example, if `attributes={'is_historical':True}`,\n                then any spans matched by this direction will have span._.is_historical = True\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category, pattern, on_match, metadata)\n        self.attributes = attributes\n        self._rule_id = None\n\n    @classmethod\n    def from_json(cls, filepath: str) -&gt; List[TargetRule]:\n        \"\"\"Read in a lexicon of modifiers from a JSON file.\n\n        Args:\n            filepath: the .json file containing modifier rules\n\n        Returns:\n            context_item: A list of ConTextRule objects.\n\n        Raises:\n            KeyError: If the dictionary contains any keys other than\n                those accepted by ConTextRule.__init__\n        \"\"\"\n        import json\n\n        with open(filepath) as file:\n            target_data = json.load(file)\n        target_rules = []\n        for data in target_data[\"target_rules\"]:\n            target_rules.append(TargetRule.from_dict(data))\n        return target_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict: Dict) -&gt; TargetRule:\n        \"\"\"Reads a dictionary into a ConTextRule. Used when reading from a json file.\n\n        Args:\n            rule_dict: the dictionary to convert\n\n        Returns:\n            The ConTextRule created from the dictionary\n\n        Raises:\n            ValueError: if the json is invalid\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                \"JSON object contains invalid keys: {0}.\\n\"\n                \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n            )\n            raise ValueError(msg)\n        rule = TargetRule(**rule_dict)\n        return rule\n\n    @classmethod\n    def to_json(cls, target_rules: List[TargetRule], filepath: str):\n        \"\"\"Writes ConTextItems to a json file.\n\n        Args:\n            target_rules: a list of TargetRules that will be written to a file.\n            filepath: the .json file to contain modifier rules\n        \"\"\"\n        import json\n\n        data = {\"target_rules\": [rule.to_dict() for rule in target_rules]}\n        with open(filepath, \"w\") as file:\n            json.dump(data, file, indent=4)\n\n    def to_dict(self):\n        \"\"\"Converts TargetRules to a python dictionary. Used when writing target rules to a json file.\n\n        Returns:\n            The dictionary containing the TargetRule info.\n        \"\"\"\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    def __repr__(self):\n        return f\"\"\"TargetRule(literal=\"{self.literal}\", category=\"{self.category}\", pattern={self.pattern}, attributes={self.attributes}, on_match={self.on_match})\"\"\"\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_rule.TargetRule.__init__","title":"<code>__init__(literal, category, pattern=None, on_match=None, attributes=None, metadata=None)</code>","text":"<p>Creates a new TargetRule.</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[List[Dict[str, str]], str]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>attributes</code> <code>Optional[Dict[str, Any]]</code> <p>Optional custom attribute names to set for a Span matched by the direction. These attribute names are stored under Span..[attribute_name]. For example, if <code>attributes={'is_historical':True}</code>, then any spans matched by this direction will have span..is_historical = True</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    attributes: Optional[Dict[str, Any]] = None,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Creates a new TargetRule.\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        attributes: Optional custom attribute names to set for a Span matched by the direction. These attribute\n            names are stored under Span._.[attribute_name]. For example, if `attributes={'is_historical':True}`,\n            then any spans matched by this direction will have span._.is_historical = True\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category, pattern, on_match, metadata)\n    self.attributes = attributes\n    self._rule_id = None\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_rule.TargetRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a ConTextRule. Used when reading from a json file.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <code>Dict</code> <p>the dictionary to convert</p> required <p>Returns:</p> Type Description <code>TargetRule</code> <p>The ConTextRule created from the dictionary</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the json is invalid</p> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict: Dict) -&gt; TargetRule:\n    \"\"\"Reads a dictionary into a ConTextRule. Used when reading from a json file.\n\n    Args:\n        rule_dict: the dictionary to convert\n\n    Returns:\n        The ConTextRule created from the dictionary\n\n    Raises:\n        ValueError: if the json is invalid\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            \"JSON object contains invalid keys: {0}.\\n\"\n            \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n        )\n        raise ValueError(msg)\n    rule = TargetRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_rule.TargetRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read in a lexicon of modifiers from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>the .json file containing modifier rules</p> required <p>Returns:</p> Name Type Description <code>context_item</code> <code>List[TargetRule]</code> <p>A list of ConTextRule objects.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the dictionary contains any keys other than those accepted by ConTextRule.init</p> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath: str) -&gt; List[TargetRule]:\n    \"\"\"Read in a lexicon of modifiers from a JSON file.\n\n    Args:\n        filepath: the .json file containing modifier rules\n\n    Returns:\n        context_item: A list of ConTextRule objects.\n\n    Raises:\n        KeyError: If the dictionary contains any keys other than\n            those accepted by ConTextRule.__init__\n    \"\"\"\n    import json\n\n    with open(filepath) as file:\n        target_data = json.load(file)\n    target_rules = []\n    for data in target_data[\"target_rules\"]:\n        target_rules.append(TargetRule.from_dict(data))\n    return target_rules\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_rule.TargetRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts TargetRules to a python dictionary. Used when writing target rules to a json file.</p> <p>Returns:</p> Type Description <p>The dictionary containing the TargetRule info.</p> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"Converts TargetRules to a python dictionary. Used when writing target rules to a json file.\n\n    Returns:\n        The dictionary containing the TargetRule info.\n    \"\"\"\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"singlepage/#medspacy.target_matcher.target_rule.TargetRule.to_json","title":"<code>to_json(target_rules, filepath)</code>  <code>classmethod</code>","text":"<p>Writes ConTextItems to a json file.</p> <p>Parameters:</p> Name Type Description Default <code>target_rules</code> <code>List[TargetRule]</code> <p>a list of TargetRules that will be written to a file.</p> required <code>filepath</code> <code>str</code> <p>the .json file to contain modifier rules</p> required Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>@classmethod\ndef to_json(cls, target_rules: List[TargetRule], filepath: str):\n    \"\"\"Writes ConTextItems to a json file.\n\n    Args:\n        target_rules: a list of TargetRules that will be written to a file.\n        filepath: the .json file to contain modifier rules\n    \"\"\"\n    import json\n\n    data = {\"target_rules\": [rule.to_dict() for rule in target_rules]}\n    with open(filepath, \"w\") as file:\n        json.dump(data, file, indent=4)\n</code></pre>"},{"location":"singlepage/#medspacy.util","title":"<code>util</code>","text":"<p>This module will contain helper functions and classes for common clinical processing tasks which will be used in many medspaCy components.</p>"},{"location":"singlepage/#medspacy.util._build_pipe_names","title":"<code>_build_pipe_names(enable, disable=None)</code>","text":"<p>Implement logic based on the pipenames defined in 'enable' and 'disable'. If enable and disable are both None, then it will load the default pipenames. Otherwise, will allow custom selection of components.</p> <p>Parameters:</p> Name Type Description Default <code>enable</code> <code>Union[str, Iterable[str]]</code> <p>\"all\" loads components from ALL_PIPE_NAMES. \"default\" loads components from DEFAULT_PIPE_NAMES. Otherwise, loads he list of components as components.</p> required <code>disable</code> <code>Optional[Iterable[str]]</code> <p>The optional list of components to disable. Set difference of enable.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Set[str], Set[str]]</code> <p>A complete list of enabled and disabled components, with all components listed and empty intersection.</p> Source code in <code>medspacy/util.py</code> <pre><code>def _build_pipe_names(\n    enable: Union[str, Iterable[str]], disable: Optional[Iterable[str]] = None\n) -&gt; Tuple[Set[str], Set[str]]:\n    \"\"\"\n    Implement logic based on the pipenames defined in 'enable' and 'disable'. If enable and disable are both None,\n    then it will load the default pipenames. Otherwise, will allow custom selection of components.\n\n    Args:\n        enable: \"all\" loads components from ALL_PIPE_NAMES. \"default\" loads components from DEFAULT_PIPE_NAMES.\n            Otherwise, loads he list of components as components.\n        disable: The optional list of components to disable. Set difference of enable.\n\n    Returns:\n        A complete list of enabled and disabled components, with all components listed and empty intersection.\n    \"\"\"\n    if not enable:\n        raise ValueError(\n            \"Enable cannot be none, please specify 'all', 'default' or a list of components.\"\n        )\n\n    # cannot allow lists of enabled and disabled components, what happens if \"context\" is both enabled and disabled?\n    if (not isinstance(enable, str) and isinstance(enable, Iterable)) and isinstance(\n        disable, Iterable\n    ):\n        raise ValueError(\"Both enable and disable cannot be collections of components.\")\n\n    # set which components are enabled first\n    if enable == \"all\":\n        enable = ALL_PIPE_NAMES\n    elif enable == \"default\":\n        enable = DEFAULT_PIPE_NAMES\n    else:\n        enable = set(enable)\n\n    # then find the difference with deactivated components\n    if disable is not None:\n        enable = enable.difference(set(disable))\n    else:\n        disable = set()  # otherwise disable is empty\n\n    return enable, disable\n</code></pre>"},{"location":"singlepage/#medspacy.util.load","title":"<code>load(model='default', medspacy_enable='default', medspacy_disable=None, language_code='en', load_rules=True, quickumls_path=None, **model_kwargs)</code>","text":"<p>Load a spaCy language object with medSpaCy pipeline components. By default, the base model will be a blank 'en' model with the following components:     - \"medspacy_tokenizer\": A customized, more aggressive tokenizer than the default spaCy tokenizer. This is set to         <code>nlp.tokenizer</code> and is not loaded as a pipeline component.     - \"medspacy_pyrush\": PyRuSH Sentencizer for sentence splitting     - \"medspacy_target_matcher\": TargetMatcher for extended pattern matching     - \"medspacy_context\": ConText for attribute assertion     - \"medspacy_quickumls\": QuickUMLS for UMLS concept mapping Args:     model: The base spaCy model to load. If 'default', will instantiate from a blank 'en' model. If it is a spaCy         language model, then it will simply add medspaCy components to the existing pipeline. If it is a string         other than 'default', passes the string to spacy.load(model, **model_kwargs).     medspacy_enable: Specifies which components to enable in the medspacy pipeline. If \"default\", will load all components         found in <code>DEFAULT_PIPE_NAMES</code>. These represent the simplest components used in a clinical NLP pipeline:         tokenization, sentence detection, concept identification, and ConText. If \"all\", all components in medspaCy         will be loaded. If a collection of strings, the components specified will be loaded.     medspacy_disable: A collection of component names to exclude. Requires \"all\" is the value for <code>enable</code>.     language_code: Language code to use (ISO code) as a default for loading additional resources.  See documentation         and also the /resources directory to see which resources might be available in each language.         Default is \"en\" for English.     load_rules: Whether to include default rules for available components. If True, sectionizer and context will         both be loaded with default rules. Default is True.     quickumls_path: Path to QuickUMLS dictionaries if it is included in the pipeline.     model_kwargs: Optional model keyword arguments to pass to spacy.load().</p> <p>Returns:</p> Type Description <p>A spaCy Language object containing the specified medspacy components.</p> Source code in <code>medspacy/util.py</code> <pre><code>def load(\n    model: Union[Literal[\"default\"], str, Language] = \"default\",\n    medspacy_enable: Union[Literal[\"all\", \"default\"], Iterable[str]] = \"default\",\n    medspacy_disable: Optional[Iterable[str]] = None,\n    language_code: str = \"en\",\n    load_rules: bool = True,\n    quickumls_path: Optional[str] = None,\n    **model_kwargs,\n):\n    \"\"\"Load a spaCy language object with medSpaCy pipeline components.\n    By default, the base model will be a blank 'en' model with the\n    following components:\n        - \"medspacy_tokenizer\": A customized, more aggressive tokenizer than the default spaCy tokenizer. This is set to\n            `nlp.tokenizer` and is not loaded as a pipeline component.\n        - \"medspacy_pyrush\": PyRuSH Sentencizer for sentence splitting\n        - \"medspacy_target_matcher\": TargetMatcher for extended pattern matching\n        - \"medspacy_context\": ConText for attribute assertion\n        - \"medspacy_quickumls\": QuickUMLS for UMLS concept mapping\n    Args:\n        model: The base spaCy model to load. If 'default', will instantiate from a blank 'en' model. If it is a spaCy\n            language model, then it will simply add medspaCy components to the existing pipeline. If it is a string\n            other than 'default', passes the string to spacy.load(model, **model_kwargs).\n        medspacy_enable: Specifies which components to enable in the medspacy pipeline. If \"default\", will load all components\n            found in `DEFAULT_PIPE_NAMES`. These represent the simplest components used in a clinical NLP pipeline:\n            tokenization, sentence detection, concept identification, and ConText. If \"all\", all components in medspaCy\n            will be loaded. If a collection of strings, the components specified will be loaded.\n        medspacy_disable: A collection of component names to exclude. Requires \"all\" is the value for `enable`.\n        language_code: Language code to use (ISO code) as a default for loading additional resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        load_rules: Whether to include default rules for available components. If True, sectionizer and context will\n            both be loaded with default rules. Default is True.\n        quickumls_path: Path to QuickUMLS dictionaries if it is included in the pipeline.\n        model_kwargs: Optional model keyword arguments to pass to spacy.load().\n\n    Returns:\n        A spaCy Language object containing the specified medspacy components.\n    \"\"\"\n\n    medspacy_enable, medspacy_disable = _build_pipe_names(\n        medspacy_enable, medspacy_disable\n    )\n\n    if model == \"default\":\n        nlp = spacy.blank(\"en\")\n    elif isinstance(model, Language):\n        nlp = model\n    elif isinstance(model, str):\n        nlp = spacy.load(model, **model_kwargs)\n    else:\n        raise ValueError(\n            \"model must be either 'default' or an actual spaCy Language object, not \",\n            type(model),\n        )\n\n    if \"medspacy_tokenizer\" in medspacy_enable:\n        from .custom_tokenizer import create_medspacy_tokenizer\n\n        medspacy_tokenizer = create_medspacy_tokenizer(nlp)\n        nlp.tokenizer = medspacy_tokenizer\n\n    if \"medspacy_preprocessor\" in medspacy_enable:\n        from .preprocess import Preprocessor\n\n        preprocessor = Preprocessor(nlp.tokenizer)\n        nlp.tokenizer = preprocessor\n\n    if \"medspacy_pyrush\" in medspacy_enable:\n        pyrush_path = path.join(\n            Path(__file__).resolve().parents[1], \"resources\", language_code.lower(), \"rush_rules.tsv\"\n        )\n        nlp.add_pipe(\"medspacy_pyrush\", config={\"rules_path\": pyrush_path})\n\n    if \"medspacy_target_matcher\" in medspacy_enable:\n        nlp.add_pipe(\"medspacy_target_matcher\")\n\n    if \"medspacy_quickumls\" in medspacy_enable:\n        if quickumls_path is None:\n            quickumls_path = get_quickumls_demo_dir(language_code)\n\n            print(\n                \"Loading QuickUMLS resources from a Medspacy-distributed SAMPLE of UMLS data from here: {}\".format(\n                    quickumls_path\n                )\n            )\n\n        nlp.add_pipe(\"medspacy_quickumls\", config={\"quickumls_fp\": quickumls_path})\n\n    if \"medspacy_context\" in medspacy_enable:\n        if load_rules is True:\n            config = {'language_code': language_code}\n        else:\n            config = {\"rules\": None,\n                      'language_code': language_code}\n        nlp.add_pipe(\"medspacy_context\", config=config)\n\n    if \"medspacy_sectionizer\" in medspacy_enable:\n        if load_rules is True:\n            config = {'language_code': language_code}\n        else:\n            config = {\"rules\": None,\n                      'language_code': language_code}\n        nlp.add_pipe(\"medspacy_sectionizer\", config=config)\n\n    if \"medspacy_postprocessor\" in medspacy_enable:\n        nlp.add_pipe(\"medspacy_postprocessor\")\n\n    if \"medspacy_doc_consumer\" in medspacy_enable:\n        nlp.add_pipe(\"medspacy_doc_consumer\")\n\n    return nlp\n</code></pre>"},{"location":"singlepage/#medspacy.util.tuple_overlaps","title":"<code>tuple_overlaps(a, b)</code>","text":"<p>Calculates whether two tuples overlap. Assumes tuples are sorted to be like spans (start, end)</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Tuple[int, int]</code> <p>A tuple representing a span (start, end).</p> required <code>b</code> <code>Tuple[int, int]</code> <p>A tuple representing a span (start, end).</p> required <p>Returns:</p> Type Description <p>Whether the tuples overlap.</p> Source code in <code>medspacy/util.py</code> <pre><code>def tuple_overlaps(a: Tuple[int, int], b: Tuple[int, int]):\n    \"\"\"\n    Calculates whether two tuples overlap. Assumes tuples are sorted to be like spans (start, end)\n\n    Args:\n        a: A tuple representing a span (start, end).\n        b: A tuple representing a span (start, end).\n\n    Returns:\n        Whether the tuples overlap.\n    \"\"\"\n    return a[0] &lt;= b[0] &lt; a[1] or a[0] &lt; b[1] &lt;= a[1]\n</code></pre>"},{"location":"singlepage/#medspacy.visualization","title":"<code>visualization</code>","text":""},{"location":"singlepage/#medspacy.visualization.MedspaCyVisualizerWidget","title":"<code>MedspaCyVisualizerWidget</code>","text":"Source code in <code>medspacy/visualization.py</code> <pre><code>class MedspaCyVisualizerWidget:\n    def __init__(self, docs, target_span_type: str = \"ents\", span_group_name: str = \"medspacy_spans\"):\n\n        \"\"\"Create an IPython Widget Box displaying medspaCy's visualizers.\n        The widget allows selecting visualization style (\"Ent\", \"Dep\", or \"Both\")\n        and a slider for selecting the index of docs.\n\n        For more information on IPython widgets, see:\n            https://ipywidgets.readthedocs.io/en/latest/index.html\n\n        Parameters:\n            docs: A list of docs processed by a medspaCy pipeline\n\n        \"\"\"\n\n        import ipywidgets as widgets\n\n        self.docs = docs\n        self.target_span_type = target_span_type \n        self.span_group_name = span_group_name\n        self.slider = widgets.IntSlider(\n            value=0,\n            min=0,\n            max=len(docs) - 1,\n            step=1,\n            description=\"Doc:\",\n            disabled=False,\n            continuous_update=False,\n            orientation=\"horizontal\",\n            readout=True,\n            readout_format=\"d\",\n        )\n        self.radio = widgets.RadioButtons(options=[\"Ent\", \"Dep\", \"Both\"])\n        self.layout = widgets.Layout(\n            display=\"flex\", flex_flow=\"column\", align_items=\"stretch\", width=\"100%\"\n        )\n        self.radio.observe(self._change_handler)\n        self.slider.observe(self._change_handler)\n        self.next_button = widgets.Button(description=\"Next\")\n        self.next_button.on_click(self._on_click_next)\n        self.previous_button = widgets.Button(description=\"Previous\")\n        self.previous_button.on_click(self._on_click_prev)\n        self.output = widgets.Output()\n        self.box = widgets.Box(\n            [\n                widgets.HBox([self.radio, self.previous_button, self.next_button]),\n                self.slider,\n                self.output,\n            ],\n            layout=self.layout,\n        )\n\n        self.display()\n        with self.output:\n            self._visualize_doc()\n\n    def display(self):\n        \"\"\"Display the Box widget in the current IPython cell.\"\"\"\n        from IPython.display import display as ipydisplay\n\n        ipydisplay(self.box)\n\n    def _change_handler(self, change):\n\n        with self.output:\n            self._visualize_doc()\n\n    def _visualize_doc(self):\n        self.output.clear_output()\n        doc = self.docs[self.slider.value]\n        if self.radio.value.lower() in (\"dep\", \"both\"):\n            visualize_dep(doc)\n        if self.radio.value.lower() in (\"ent\", \"both\"):\n            visualize_ent(doc, target_span_type=self.target_span_type, span_group_name=self.span_group_name)\n\n    def _on_click_next(self, b):\n        if self.slider.value &lt; len(self.docs) - 1:\n            self.slider.value += 1\n\n    def _on_click_prev(self, b):\n        if self.slider.value &gt; 0:\n            self.slider.value -= 1\n\n    def set_docs(self, docs):\n        \"Replace the list of docs to be visualized.\"\n        self.docs = docs\n        self._visualize_doc(self.docs[0])\n</code></pre>"},{"location":"singlepage/#medspacy.visualization.MedspaCyVisualizerWidget.__init__","title":"<code>__init__(docs, target_span_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Create an IPython Widget Box displaying medspaCy's visualizers. The widget allows selecting visualization style (\"Ent\", \"Dep\", or \"Both\") and a slider for selecting the index of docs.</p> <p>For more information on IPython widgets, see:     https://ipywidgets.readthedocs.io/en/latest/index.html</p> <p>Parameters:</p> Name Type Description Default <code>docs</code> <p>A list of docs processed by a medspaCy pipeline</p> required Source code in <code>medspacy/visualization.py</code> <pre><code>def __init__(self, docs, target_span_type: str = \"ents\", span_group_name: str = \"medspacy_spans\"):\n\n    \"\"\"Create an IPython Widget Box displaying medspaCy's visualizers.\n    The widget allows selecting visualization style (\"Ent\", \"Dep\", or \"Both\")\n    and a slider for selecting the index of docs.\n\n    For more information on IPython widgets, see:\n        https://ipywidgets.readthedocs.io/en/latest/index.html\n\n    Parameters:\n        docs: A list of docs processed by a medspaCy pipeline\n\n    \"\"\"\n\n    import ipywidgets as widgets\n\n    self.docs = docs\n    self.target_span_type = target_span_type \n    self.span_group_name = span_group_name\n    self.slider = widgets.IntSlider(\n        value=0,\n        min=0,\n        max=len(docs) - 1,\n        step=1,\n        description=\"Doc:\",\n        disabled=False,\n        continuous_update=False,\n        orientation=\"horizontal\",\n        readout=True,\n        readout_format=\"d\",\n    )\n    self.radio = widgets.RadioButtons(options=[\"Ent\", \"Dep\", \"Both\"])\n    self.layout = widgets.Layout(\n        display=\"flex\", flex_flow=\"column\", align_items=\"stretch\", width=\"100%\"\n    )\n    self.radio.observe(self._change_handler)\n    self.slider.observe(self._change_handler)\n    self.next_button = widgets.Button(description=\"Next\")\n    self.next_button.on_click(self._on_click_next)\n    self.previous_button = widgets.Button(description=\"Previous\")\n    self.previous_button.on_click(self._on_click_prev)\n    self.output = widgets.Output()\n    self.box = widgets.Box(\n        [\n            widgets.HBox([self.radio, self.previous_button, self.next_button]),\n            self.slider,\n            self.output,\n        ],\n        layout=self.layout,\n    )\n\n    self.display()\n    with self.output:\n        self._visualize_doc()\n</code></pre>"},{"location":"singlepage/#medspacy.visualization.MedspaCyVisualizerWidget.display","title":"<code>display()</code>","text":"<p>Display the Box widget in the current IPython cell.</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def display(self):\n    \"\"\"Display the Box widget in the current IPython cell.\"\"\"\n    from IPython.display import display as ipydisplay\n\n    ipydisplay(self.box)\n</code></pre>"},{"location":"singlepage/#medspacy.visualization.MedspaCyVisualizerWidget.set_docs","title":"<code>set_docs(docs)</code>","text":"<p>Replace the list of docs to be visualized.</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def set_docs(self, docs):\n    \"Replace the list of docs to be visualized.\"\n    self.docs = docs\n    self._visualize_doc(self.docs[0])\n</code></pre>"},{"location":"singlepage/#medspacy.visualization._create_color_generator","title":"<code>_create_color_generator()</code>","text":"<p>Create a generator which will cycle through a list of default matplotlib colors</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def _create_color_generator():\n    \"\"\"Create a generator which will cycle through a list of\n    default matplotlib colors\"\"\"\n    from itertools import cycle\n\n    colors = [\n        \"#1f77b4\",\n        \"#ff7f0e\",\n        \"#2ca02c\",\n        \"#d62728\",\n        \"#9467bd\",\n        \"#8c564b\",\n        \"#e377c2\",\n        \"#7f7f7f\",\n        \"#bcbd22\",\n        \"#17becf\",\n    ]\n    return cycle(colors)\n</code></pre>"},{"location":"singlepage/#medspacy.visualization.visualize_dep","title":"<code>visualize_dep(doc, jupyter=True)</code>","text":"<p>Create a dependency-style visualization for ConText targets and modifiers in doc. This will show the relationships between entities in doc and contextual modifiers.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spacy Doc to visualize.</p> required <code>jupyter</code> <code>bool</code> <p>Whether it is being rendered in a jupyter notebook.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>The visualization.</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def visualize_dep(doc: Doc, jupyter: bool = True) -&gt; str:\n    \"\"\"\n    Create a dependency-style visualization for ConText targets and modifiers in doc. This will show the relationships\n    between entities in doc and contextual modifiers.\n\n    Args:\n        doc: The spacy Doc to visualize.\n        jupyter: Whether it is being rendered in a jupyter notebook.\n\n    Returns:\n        The visualization.\n    \"\"\"\n    token_data = []\n    token_data_mapping = {}\n    for token in doc:\n        data = {\"text\": token.text, \"tag\": \"\", \"index\": token.i}\n        token_data.append(data)\n        token_data_mapping[token] = data\n\n    # Merge phrases\n    # targets_and_modifiers = [*doc._.context_graph.targets]\n    existing_tokens = set()\n    targets_and_modifiers = []\n    # Used to prevent duplication of token in targets or modifiers that appear twice due to being in a span group or, appearing twice as a modifier\n    for target_or_modifier in (list(doc._.context_graph.targets) + doc._.context_graph.modifiers):\n        if isinstance (target_or_modifier, Span):\n            span=target_or_modifier\n        else:\n            span=doc[target_or_modifier._start : target_or_modifier._end]\n        already_seen = False \n        for token in span:\n            if token in existing_tokens:\n                already_seen = True \n                break \n        if not already_seen:\n            targets_and_modifiers.append(target_or_modifier)\n            existing_tokens.update({token for token in span}) \n\n    for obj in targets_and_modifiers:\n        if isinstance(obj, Span):\n            first_token = obj[0]\n            data = token_data_mapping[first_token]\n            data[\"tag\"] = obj.label_\n            if len(obj) &gt; 1:\n                idx = data[\"index\"]\n                for other_token in obj[1:]:\n                    # Add the text to the display data for the first word\n                    # and remove the subsequent token\n                    data[\"text\"] += \" \" + other_token.text\n                    # Remove this token from the list of display data\n                    token_data.pop(idx + 1)\n                for other_data in token_data[idx + 1:]:\n                    other_data[\"index\"] -= len(obj) - 1\n        else:\n            span_tup = obj.modifier_span\n            first_token = doc[span_tup[0]]\n            data = token_data_mapping[first_token]\n            data[\"tag\"] = obj.category\n            if span_tup[1] - span_tup[0] &gt; 1:\n                span = doc[span_tup[0]: span_tup[1]]\n                idx = data[\"index\"]\n                for other_token in span[1:]:\n                    # Add the text to the display data for the first word\n                    # and remove the subsequent token\n                    data[\"text\"] += \" \" + other_token.text\n                    # Remove this token from the list of display data\n                    token_data.pop(idx + 1)\n                for other_data in token_data[idx + 1:]:\n                    other_data[\"index\"] -= len(span) - 1\n\n        # if len(span) == 1:\n        #     continue\n        #\n        # idx = data[\"index\"]\n        # for other_token in span[1:]:\n        #     # Add the text to the display data for the first word\n        #     # and remove the subsequent token\n        #     data[\"text\"] += \" \" + other_token.text\n        #     # Remove this token from the list of display data\n        #     token_data.pop(idx + 1)\n        #\n        # # Lower the index of the following tokens\n        # for other_data in token_data[idx + 1 :]:\n        #     other_data[\"index\"] -= len(span) - 1\n\n    dep_data = {\"words\": token_data, \"arcs\": []}\n\n    # Gather the edges between targets and modifiers\n    for target, modifier in doc._.context_graph.edges:\n        target_data = token_data_mapping[target[0]]\n        modifier_data = token_data_mapping[doc[modifier.modifier_span[0]]]\n        dep_data[\"arcs\"].append(\n            {\n                \"start\": min(target_data[\"index\"], modifier_data[\"index\"]),\n                \"end\": max(target_data[\"index\"], modifier_data[\"index\"]),\n                \"label\": modifier.category,\n                \"dir\": \"right\"\n                if target &gt; doc[modifier.modifier_span[0] : modifier.modifier_span[1]]\n                else \"left\",\n            }\n        )\n\n    return displacy.render(dep_data, manual=True, jupyter=jupyter)\n</code></pre>"},{"location":"singlepage/#medspacy.visualization.visualize_ent","title":"<code>visualize_ent(doc, context=True, sections=True, jupyter=True, colors=None, target_span_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Creates a NER-style visualization for targets and modifiers in Doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>A spacy doc to visualize.</p> required <code>context</code> <code>bool</code> <p>Whether to display the modifiers generated by medSpaCy's cycontext. If the doc has not been processed by context, this will be automatically changed to False. Default True.</p> <code>True</code> <code>sections</code> <code>bool</code> <p>Whether to display the section titles generated by medSpaCy's sectionizer (still in development). If the doc has not been processed by sectionizer , this will be automatically changed to False. This may also have some overlap with cycontext, in which case duplicate spans will be displayed. Default True.</p> <code>True</code> <code>jupyter</code> <code>bool</code> <p>If True, will render directly in a Jupyter notebook. If False, will return the HTML. Default True.</p> <code>True</code> <code>colors</code> <code>Dict[str, str]</code> <p>An optional dictionary which maps labels of targets and modifiers to color strings to be rendered. If None, will create a generator which cycles through the default matplotlib colors for ent and modifier labels and uses a light gray for section headers. Default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The visualization.</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def visualize_ent(\n    doc: Doc,\n    context: bool = True,\n    sections: bool = True,\n    jupyter: bool = True,\n    colors: Dict[str, str] = None,\n    target_span_type: str = \"ents\",\n    span_group_name: str = \"medspacy_spans\"\n) -&gt; str:\n    \"\"\"\n    Creates a NER-style visualization for targets and modifiers in Doc.\n\n    Args:\n        doc: A spacy doc to visualize.\n        context: Whether to display the modifiers generated by medSpaCy's cycontext. If the doc has not been processed\n            by context, this will be automatically changed to False. Default True.\n        sections: Whether to display the section titles generated by medSpaCy's sectionizer (still in development). If\n            the doc has not been processed by sectionizer , this will be automatically changed to False. This may also\n            have some overlap with cycontext, in which case duplicate spans will be displayed. Default True.\n        jupyter: If True, will render directly in a Jupyter notebook. If False, will return the HTML. Default True.\n        colors: An optional dictionary which maps labels of targets and modifiers to color strings to be rendered. If\n            None, will create a generator which cycles through the default matplotlib colors for ent and modifier labels\n            and uses a light gray for section headers. Default None.\n\n    Returns:\n        The visualization.\n    \"\"\"\n    # Make sure that doc has the custom medSpaCy attributes registered\n    if not hasattr(doc._, \"context_graph\"):\n        context = False\n    if not hasattr(doc._, \"sections\"):\n        sections = False\n\n    ents_data = []\n\n    if target_span_type == \"ents\":\n        targets = doc.ents\n    elif target_span_type == \"group\":\n        targets = doc.spans[span_group_name]\n    else:\n        raise ValueError(\"Target span type must be either ents or group.\")\n\n    for target in targets:\n        ent_data = {\n            \"start\": target.start_char,\n            \"end\": target.end_char,\n            \"label\": target.label_.upper(),\n        }\n        ents_data.append((ent_data, \"ent\"))\n\n    if context:\n        visualized_modifiers = set()\n        for target in doc.ents:\n            for modifier in target._.modifiers:\n                if modifier in visualized_modifiers:\n                    continue\n                span = doc[modifier.modifier_span[0]: modifier.modifier_span[1]]\n                ent_data = {\n                    \"start\": span.start_char,\n                    \"end\": span.end_char,\n                    \"label\": modifier.category,\n                }\n                ents_data.append((ent_data, \"modifier\"))\n                visualized_modifiers.add(modifier)\n    if sections:\n        for section in doc._.sections:\n            category = section.category\n            if category is None:\n                continue\n            span = doc[section.title_span[0]: section.title_span[1]]\n            ent_data = {\n                \"start\": span.start_char,\n                \"end\": span.end_char,\n                \"label\": f\"&lt;&lt; {category.upper()} &gt;&gt;\",\n            }\n            ents_data.append((ent_data, \"section\"))\n    if len(ents_data) == 0:  # No data to display\n        viz_data = [{\"text\": doc.text, \"ents\": []}]\n        options = dict()\n    else:\n        ents_data = sorted(ents_data, key=lambda x: x[0][\"start\"])\n\n        # If colors aren't defined, generate color mappings for each entity\n        # and modifier label and set all section titles to a light gray\n        if colors is None:\n            labels = set()\n            section_titles = set()\n            for (ent_data, ent_type) in ents_data:\n                if ent_type in (\"ent\", \"modifier\"):\n                    labels.add(ent_data[\"label\"])\n                elif ent_type == \"section\":\n                    section_titles.add(ent_data[\"label\"])\n            colors = _create_color_mapping(labels)\n            for title in section_titles:\n                colors[title] = \"#dee0e3\"\n        ents_display_data, _ = zip(*ents_data)\n        viz_data = [\n            {\n                \"text\": doc.text,\n                \"ents\": ents_display_data,\n            }\n        ]\n\n        options = {\n            \"colors\": colors,\n        }\n    return displacy.render(\n        viz_data, style=\"ent\", manual=True, options=options, jupyter=jupyter\n    )\n</code></pre>"},{"location":"reference/medspacy/","title":"medspacy","text":""},{"location":"reference/medspacy/common/","title":"medspacy.common","text":""},{"location":"reference/medspacy/common/base_rule/","title":"medspacy.common.base_rule","text":""},{"location":"reference/medspacy/common/base_rule/#medspacy.common.base_rule.BaseRule","title":"<code>BaseRule</code>","text":"<p>BaseRule is the basic class for the rules contained in the MedspacyMatcher class. It contains the basic structure for a rule to be used by the spaCy matchers or by the RegexMatcher class in order to produce match tuples for processing by a component such as the Sectionizer, ContextComponent or TargetMatcher</p> Source code in <code>medspacy/common/base_rule.py</code> <pre><code>class BaseRule:\n    \"\"\"\n    BaseRule is the basic class for the rules contained in the MedspacyMatcher class. It contains the basic structure\n    for a rule to be used by the spaCy matchers or by the RegexMatcher class in order to produce match tuples for\n    processing by a component such as the Sectionizer, ContextComponent or TargetMatcher\n    \"\"\"\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Base class for medspaCy rules such as TargetRule and ConTextRule.\n\n        Args:\n            literal: The plaintext form of the pattern. Can be a human-readable form of a more complex pattern or, if\n                `pattern` is None, the literal is used in a spaCy PhraseMatcher by the MedspacyMatcher.\n            category: The category for the match. Corresponds to ent.label_ for entities.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        self.literal = literal\n        self.category = category\n        self.pattern = pattern\n        self.on_match = on_match\n        self.metadata = metadata\n</code></pre>"},{"location":"reference/medspacy/common/base_rule/#medspacy.common.base_rule.BaseRule.__init__","title":"<code>__init__(literal, category, pattern=None, on_match=None, metadata=None)</code>","text":"<p>Base class for medspaCy rules such as TargetRule and ConTextRule.</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The plaintext form of the pattern. Can be a human-readable form of a more complex pattern or, if <code>pattern</code> is None, the literal is used in a spaCy PhraseMatcher by the MedspacyMatcher.</p> required <code>category</code> <code>str</code> <p>The category for the match. Corresponds to ent.label_ for entities.</p> required <code>pattern</code> <code>Optional[Union[str, List[Dict[str, str]]]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/common/base_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Base class for medspaCy rules such as TargetRule and ConTextRule.\n\n    Args:\n        literal: The plaintext form of the pattern. Can be a human-readable form of a more complex pattern or, if\n            `pattern` is None, the literal is used in a spaCy PhraseMatcher by the MedspacyMatcher.\n        category: The category for the match. Corresponds to ent.label_ for entities.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    self.literal = literal\n    self.category = category\n    self.pattern = pattern\n    self.on_match = on_match\n    self.metadata = metadata\n</code></pre>"},{"location":"reference/medspacy/common/medspacy_matcher/","title":"medspacy.common.medspacy_matcher","text":""},{"location":"reference/medspacy/common/medspacy_matcher/#medspacy.common.medspacy_matcher.MedspacyMatcher","title":"<code>MedspacyMatcher</code>","text":"<p>MedspacyMatcher is a class which combines spaCy's Matcher and PhraseMatcher classes along with medspaCy's RegexMatcher and acts as one single matcher using 3 different types of rules:     - Exact phrases     - List of dictionaries for matching on token attributes (see https://spacy.io/usage/rule-based-matching#matcher)     - Regular expression matches. Note that regular-expression matching is not natively supported by spaCy and could             result in unexpected matched spans if match boundaries do not align with token boundaries. Rules can be defined by any class which inherits from medspacy.common.BaseRule, such as:     medspacy.target_matcher.TargetRule     medspacy.context.ConTextRule</p> Source code in <code>medspacy/common/medspacy_matcher.py</code> <pre><code>class MedspacyMatcher:\n    \"\"\"\n    MedspacyMatcher is a class which combines spaCy's Matcher and PhraseMatcher classes along with medspaCy's\n    RegexMatcher and acts as one single matcher using 3 different types of rules:\n        - Exact phrases\n        - List of dictionaries for matching on token attributes (see https://spacy.io/usage/rule-based-matching#matcher)\n        - Regular expression matches. Note that regular-expression matching is not natively supported by spaCy and could\n                result in unexpected matched spans if match boundaries do not align with token boundaries.\n    Rules can be defined by any class which inherits from medspacy.common.BaseRule, such as:\n        medspacy.target_matcher.TargetRule\n        medspacy.context.ConTextRule\n    \"\"\"\n\n    name = \"medspacy_matcher\"\n\n    def __init__(\n        self, nlp: Language, name: str = \"medspacy_matcher\", phrase_matcher_attr: str = \"LOWER\", prune: bool = True\n    ):\n        \"\"\"\n        Creates a MedspacyMatcher.\n\n        Args:\n            nlp: A spaCy Language model.\n            name: The name of the component.\n            phrase_matcher_attr: The attribute to use for spaCy's PhraseMatcher. Default is 'LOWER'.\n            prune: Whether to prune matches that overlap or are substrings of another match. For example, if \"no history\n                of\" and \"history of\" are both matches, setting prune to True would drop \"history of\". Default is True.\n        \"\"\"\n        self.nlp = nlp.tokenizer # preserve only the tokenizer for creating phrasematcher rules\n        self._rule_ids = set()\n        self._labels = set()\n        self._rule_map = dict()\n        self._prune = prune\n        self.__matcher = Matcher(nlp.vocab)\n        self.__phrase_matcher = PhraseMatcher(nlp.vocab, attr=phrase_matcher_attr)\n        self.__regex_matcher = RegexMatcher(nlp.vocab)\n\n        self.__rule_count = 0\n        self.__phrase_matcher_attr = phrase_matcher_attr\n\n    @property\n    def rules(self) -&gt; List[BaseRule]:\n        \"\"\"\n        The list of rules used by the MedspacyMatcher.\n\n        Returns:\n            A list of rules, all of which inherit from BaseRule.\n        \"\"\"\n        return list(self._rule_map.values())\n\n    @property\n    def rule_map(self) -&gt; Dict[str, BaseRule]:\n        \"\"\"\n        The dictionary mapping a rule's id to the rule object.\n\n        Returns:\n            A dictionary mapping the rule's id to the rule.\n        \"\"\"\n        return self._rule_map\n\n    @property\n    def labels(self) -&gt; Set[str]:\n        \"\"\"\n        The set of labels available to the matcher.\n\n        Returns:\n            A set of labels containing the labels for all the rules added to the matcher.\n        \"\"\"\n        return self._labels\n\n    def add(self, rules: Iterable[BaseRule]):\n        \"\"\"\n        Adds a collection of rules to the matcher. Rules must inherit from `medspacy.common.BaseRule`.\n\n        Args:\n            rules: A collection of rules. Each rule must inherit from `medspacy.common.BaseRule`.\n        \"\"\"\n        for rule in rules:\n            if not isinstance(rule, BaseRule):\n                raise TypeError(\"Rules must inherit from medspacy.common.BaseRule.\")\n            self._labels.add(rule.category)\n            rule_id = f\"{rule.category}_{self.__rule_count}\"\n            rule._rule_id = rule_id\n            self._rule_map[rule_id] = rule\n            if rule.pattern is not None:\n                # If it's a string, add a RegEx\n                if isinstance(rule.pattern, str):\n                    self.__regex_matcher.add(rule_id, [rule.pattern], rule.on_match)\n                # If it's a list, add a pattern dictionary\n                elif isinstance(rule.pattern, list):\n                    self.__matcher.add(rule_id, [rule.pattern], on_match=rule.on_match)\n                else:\n                    raise ValueError(\n                        f\"The pattern argument must be either a string or a list, not {type(rule.pattern)}\"\n                    )\n            else:\n                if self.__phrase_matcher_attr.lower() == \"lower\":\n                    # only lowercase when the phrase matcher is looking for lowercase matches.\n                    text = rule.literal.lower()\n                else:\n                    # otherwise, expect users to handle phrases as aligned with their non-default phrase matching scheme\n                    # this prevents .lower() from blocking matches on attrs like ORTH or UPPER\n                    text = rule.literal\n                doc = self.nlp(text)\n                self.__phrase_matcher.add(\n                    rule_id,\n                    [doc],\n                    on_match=rule.on_match,\n                )\n            self.__rule_count += 1\n\n    def __call__(self, doc: Doc) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Call MedspacyMatcher on a doc and return a single list of matches. If self.prune is True,\n        in the case of overlapping matches the longest will be returned.\n\n        Args:\n            doc: The spaCy Doc to process.\n\n        Returns:\n            A list of tuples, each containing 3 ints representing the individual match (match_id, start, end).\n        \"\"\"\n        matches = self.__matcher(doc)\n        matches += self.__phrase_matcher(doc)\n        matches += self.__regex_matcher(doc)\n        if self._prune:\n            matches = prune_overlapping_matches(matches)\n        return matches\n</code></pre>"},{"location":"reference/medspacy/common/medspacy_matcher/#medspacy.common.medspacy_matcher.MedspacyMatcher.labels","title":"<code>labels</code>  <code>property</code>","text":"<p>The set of labels available to the matcher.</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>A set of labels containing the labels for all the rules added to the matcher.</p>"},{"location":"reference/medspacy/common/medspacy_matcher/#medspacy.common.medspacy_matcher.MedspacyMatcher.rule_map","title":"<code>rule_map</code>  <code>property</code>","text":"<p>The dictionary mapping a rule's id to the rule object.</p> <p>Returns:</p> Type Description <code>Dict[str, BaseRule]</code> <p>A dictionary mapping the rule's id to the rule.</p>"},{"location":"reference/medspacy/common/medspacy_matcher/#medspacy.common.medspacy_matcher.MedspacyMatcher.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>The list of rules used by the MedspacyMatcher.</p> <p>Returns:</p> Type Description <code>List[BaseRule]</code> <p>A list of rules, all of which inherit from BaseRule.</p>"},{"location":"reference/medspacy/common/medspacy_matcher/#medspacy.common.medspacy_matcher.MedspacyMatcher.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call MedspacyMatcher on a doc and return a single list of matches. If self.prune is True, in the case of overlapping matches the longest will be returned.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy Doc to process.</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of tuples, each containing 3 ints representing the individual match (match_id, start, end).</p> Source code in <code>medspacy/common/medspacy_matcher.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Call MedspacyMatcher on a doc and return a single list of matches. If self.prune is True,\n    in the case of overlapping matches the longest will be returned.\n\n    Args:\n        doc: The spaCy Doc to process.\n\n    Returns:\n        A list of tuples, each containing 3 ints representing the individual match (match_id, start, end).\n    \"\"\"\n    matches = self.__matcher(doc)\n    matches += self.__phrase_matcher(doc)\n    matches += self.__regex_matcher(doc)\n    if self._prune:\n        matches = prune_overlapping_matches(matches)\n    return matches\n</code></pre>"},{"location":"reference/medspacy/common/medspacy_matcher/#medspacy.common.medspacy_matcher.MedspacyMatcher.__init__","title":"<code>__init__(nlp, name='medspacy_matcher', phrase_matcher_attr='LOWER', prune=True)</code>","text":"<p>Creates a MedspacyMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A spaCy Language model.</p> required <code>name</code> <code>str</code> <p>The name of the component.</p> <code>'medspacy_matcher'</code> <code>phrase_matcher_attr</code> <code>str</code> <p>The attribute to use for spaCy's PhraseMatcher. Default is 'LOWER'.</p> <code>'LOWER'</code> <code>prune</code> <code>bool</code> <p>Whether to prune matches that overlap or are substrings of another match. For example, if \"no history of\" and \"history of\" are both matches, setting prune to True would drop \"history of\". Default is True.</p> <code>True</code> Source code in <code>medspacy/common/medspacy_matcher.py</code> <pre><code>def __init__(\n    self, nlp: Language, name: str = \"medspacy_matcher\", phrase_matcher_attr: str = \"LOWER\", prune: bool = True\n):\n    \"\"\"\n    Creates a MedspacyMatcher.\n\n    Args:\n        nlp: A spaCy Language model.\n        name: The name of the component.\n        phrase_matcher_attr: The attribute to use for spaCy's PhraseMatcher. Default is 'LOWER'.\n        prune: Whether to prune matches that overlap or are substrings of another match. For example, if \"no history\n            of\" and \"history of\" are both matches, setting prune to True would drop \"history of\". Default is True.\n    \"\"\"\n    self.nlp = nlp.tokenizer # preserve only the tokenizer for creating phrasematcher rules\n    self._rule_ids = set()\n    self._labels = set()\n    self._rule_map = dict()\n    self._prune = prune\n    self.__matcher = Matcher(nlp.vocab)\n    self.__phrase_matcher = PhraseMatcher(nlp.vocab, attr=phrase_matcher_attr)\n    self.__regex_matcher = RegexMatcher(nlp.vocab)\n\n    self.__rule_count = 0\n    self.__phrase_matcher_attr = phrase_matcher_attr\n</code></pre>"},{"location":"reference/medspacy/common/medspacy_matcher/#medspacy.common.medspacy_matcher.MedspacyMatcher.add","title":"<code>add(rules)</code>","text":"<p>Adds a collection of rules to the matcher. Rules must inherit from <code>medspacy.common.BaseRule</code>.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Iterable[BaseRule]</code> <p>A collection of rules. Each rule must inherit from <code>medspacy.common.BaseRule</code>.</p> required Source code in <code>medspacy/common/medspacy_matcher.py</code> <pre><code>def add(self, rules: Iterable[BaseRule]):\n    \"\"\"\n    Adds a collection of rules to the matcher. Rules must inherit from `medspacy.common.BaseRule`.\n\n    Args:\n        rules: A collection of rules. Each rule must inherit from `medspacy.common.BaseRule`.\n    \"\"\"\n    for rule in rules:\n        if not isinstance(rule, BaseRule):\n            raise TypeError(\"Rules must inherit from medspacy.common.BaseRule.\")\n        self._labels.add(rule.category)\n        rule_id = f\"{rule.category}_{self.__rule_count}\"\n        rule._rule_id = rule_id\n        self._rule_map[rule_id] = rule\n        if rule.pattern is not None:\n            # If it's a string, add a RegEx\n            if isinstance(rule.pattern, str):\n                self.__regex_matcher.add(rule_id, [rule.pattern], rule.on_match)\n            # If it's a list, add a pattern dictionary\n            elif isinstance(rule.pattern, list):\n                self.__matcher.add(rule_id, [rule.pattern], on_match=rule.on_match)\n            else:\n                raise ValueError(\n                    f\"The pattern argument must be either a string or a list, not {type(rule.pattern)}\"\n                )\n        else:\n            if self.__phrase_matcher_attr.lower() == \"lower\":\n                # only lowercase when the phrase matcher is looking for lowercase matches.\n                text = rule.literal.lower()\n            else:\n                # otherwise, expect users to handle phrases as aligned with their non-default phrase matching scheme\n                # this prevents .lower() from blocking matches on attrs like ORTH or UPPER\n                text = rule.literal\n            doc = self.nlp(text)\n            self.__phrase_matcher.add(\n                rule_id,\n                [doc],\n                on_match=rule.on_match,\n            )\n        self.__rule_count += 1\n</code></pre>"},{"location":"reference/medspacy/common/regex_matcher/","title":"medspacy.common.regex_matcher","text":""},{"location":"reference/medspacy/common/regex_matcher/#medspacy.common.regex_matcher.RegexMatcher","title":"<code>RegexMatcher</code>","text":"<p>The RegexMatcher is an alternative to spaCy's native Matcher and PhraseMatcher classes and allows matching based on typical regular expressions over the underlying doc text rather than spacy token attributes.</p> <p>This can be useful for allowing more traditional text matching methods, but can lead to issues if the matched spans in the text do not line up with spacy token boundaries. In this case, the RegexMatcher will by default resolve to the nearest token  boundaries by expanding to the left and right. This behavior can be configured using <code>resolve_start</code> and <code>resolve_end</code>. To avoid this, consider using a list of dicts, such as in a spacy Matcher. For more information, see: https://spacy.io/usage/rule-based-matching</p> <p>Examples of resolve_start/resolve_end: In the string 'SERVICE: Radiology' the pattern 'ICE: Rad' would match in the middle of the tokens 'SERVICE' and 'RADIOLOGY'. SpaCy would normally return None. The RegexMatcher will expand in the following ways: resolve_start='left': The resulting span will start at 'SERVICE' -&gt; 'SERVICE: Radiology' resolve_start='right': The resulting span will start at ':' -&gt; ': Radiology' resolve_end='left': The resulting span will end at ':': -&gt; 'SERVICE:' resolve_end='right': The resulting span will end at 'RADIOLOGY' -&gt; 'SERVICE: Radiology'</p> Source code in <code>medspacy/common/regex_matcher.py</code> <pre><code>class RegexMatcher:\n    \"\"\"\n    The RegexMatcher is an alternative to spaCy's native Matcher and PhraseMatcher classes and allows matching based on\n    typical regular expressions over the underlying doc text rather than spacy token attributes.\n\n    This can be useful for allowing more traditional text matching methods, but can lead to issues if the matched spans\n    in the text do not line up with spacy token boundaries. In this case, the RegexMatcher will by default resolve to\n    the nearest token  boundaries by expanding to the left and right. This behavior can be configured using\n    `resolve_start` and `resolve_end`. To avoid this, consider using a list of dicts, such as in a spacy Matcher.\n    For more information, see: https://spacy.io/usage/rule-based-matching\n\n    Examples of resolve_start/resolve_end:\n    In the string 'SERVICE: Radiology' the pattern 'ICE: Rad' would match in the middle of the tokens\n    'SERVICE' and 'RADIOLOGY'. SpaCy would normally return None. The RegexMatcher will expand in the following ways:\n    resolve_start='left': The resulting span will start at 'SERVICE' -&gt; 'SERVICE: Radiology'\n    resolve_start='right': The resulting span will start at ':' -&gt; ': Radiology'\n    resolve_end='left': The resulting span will end at ':': -&gt; 'SERVICE:'\n    resolve_end='right': The resulting span will end at 'RADIOLOGY' -&gt; 'SERVICE: Radiology'\n\n    \"\"\"\n\n    def __init__(\n        self,\n        vocab: Vocab,\n        flags: re.RegexFlag = re.IGNORECASE,\n        resolve_start: str = \"left\",\n        resolve_end: str = \"right\",\n    ):\n        \"\"\"\n        Creates a new RegexMatcher.\n\n        Args:\n            vocab: A spaCy model vocabulary\n            flags: Regular expression flag. Default re.IGNORECASE\n            resolve_start: How to resolve if the start character index of a match does not align with spacy token\n                boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character\n                index, leading to a longer than expected span. If 'right', will find the nearest token boundary to the\n                right of the unmatched character index, leading to a shorter than expected span.  Default 'left'.\n            resolve_end: How to resolve if the end character index of a match does not align with spacy token\n                boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character\n                index, leading to a shorter than expected span. If 'right', will find the nearest token boundary to the\n                right of the unmatched character index, leading to a longer than expected span. Default 'right'.\n        \"\"\"\n        self.vocab = vocab\n        self.flags = flags\n        self.resolve_start = resolve_start\n        self.resolve_end = resolve_end\n        self._patterns = {}\n        self._callbacks = {}\n        self.labels = set()\n        self._rule_item_mapping = dict()\n\n    def add(\n        self,\n        match_id: str,\n        regex_rules: Iterable[str],\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n    ):\n        \"\"\"\n        Add a rule with one or more regex patterns to one match id.\n\n        Args:\n            match_id: The name of the pattern.\n            regex_rules: The list of regex strings to associate with `match_id`.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        \"\"\"\n        # i am not sure if these warnings are more annoying than useful.\n        # warnings.warn(\n        #     \"You are using a TargetRule with a regex pattern, which is not \"\n        #     \"natively supported in spacy and may lead to unexpected match spans. \"\n        #     \"Consider using a list of dicts pattern instead. \"\n        #     \"See https://spacy.io/usage/rule-based-matching\",\n        #     RuntimeWarning,\n        # )\n        if match_id not in self.vocab:\n            self.vocab.strings.add(match_id)\n        self._patterns.setdefault(self.vocab.strings[match_id], [])\n        for pattern in regex_rules:\n            self._patterns[self.vocab.strings[match_id]].append(\n                re.compile(pattern, flags=self.flags)\n            )\n            self._callbacks[self.vocab.strings[match_id]] = on_match\n\n    def get(self, key):\n        return self._patterns.get(self.vocab.strings[key], [])\n\n    def __call__(self, doc: Doc) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Call the RegexMatcher on a spaCy Doc.\n\n        Args:\n            doc: The spaCy doc to process.\n\n        Returns:\n            The list of match tuples (match_id, start, end).\n        \"\"\"\n        matches = []\n        for (match_id, patterns) in self._patterns.items():\n            for pattern in patterns:\n                on_match = self._callbacks[match_id]\n                for re_match in pattern.finditer(doc.text_with_ws):\n                    span = doc.char_span(re_match.start(), re_match.end())\n                    if span is None:\n                        start = get_token_for_char(\n                            doc, re_match.start(), resolve=self.resolve_start\n                        )\n                        end = get_token_for_char(\n                            doc, re_match.end(), resolve=self.resolve_end\n                        )\n                        if end is None:\n                            end_index = len(doc)\n                        else:\n                            end_index = end.i\n                        span = doc[start.i : end_index]\n                    # If it's an empty span, then that means that the token resolution\n                    # must have resulted in no tokens being included.\n                    # Don't add the match\n                    if len(span):\n                        match = (match_id, span.start, span.end)\n                        matches.append(match)\n                    # If a callback function was defined,\n                    # call it according to the spaCy API:\n                    # https://spacy.io/usage/rule-based-matching#on_match\n                    if on_match is not None:\n                        on_match(self, doc, len(matches) - 1, matches)\n\n        return matches\n</code></pre>"},{"location":"reference/medspacy/common/regex_matcher/#medspacy.common.regex_matcher.RegexMatcher.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the RegexMatcher on a spaCy Doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy doc to process.</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>The list of match tuples (match_id, start, end).</p> Source code in <code>medspacy/common/regex_matcher.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Call the RegexMatcher on a spaCy Doc.\n\n    Args:\n        doc: The spaCy doc to process.\n\n    Returns:\n        The list of match tuples (match_id, start, end).\n    \"\"\"\n    matches = []\n    for (match_id, patterns) in self._patterns.items():\n        for pattern in patterns:\n            on_match = self._callbacks[match_id]\n            for re_match in pattern.finditer(doc.text_with_ws):\n                span = doc.char_span(re_match.start(), re_match.end())\n                if span is None:\n                    start = get_token_for_char(\n                        doc, re_match.start(), resolve=self.resolve_start\n                    )\n                    end = get_token_for_char(\n                        doc, re_match.end(), resolve=self.resolve_end\n                    )\n                    if end is None:\n                        end_index = len(doc)\n                    else:\n                        end_index = end.i\n                    span = doc[start.i : end_index]\n                # If it's an empty span, then that means that the token resolution\n                # must have resulted in no tokens being included.\n                # Don't add the match\n                if len(span):\n                    match = (match_id, span.start, span.end)\n                    matches.append(match)\n                # If a callback function was defined,\n                # call it according to the spaCy API:\n                # https://spacy.io/usage/rule-based-matching#on_match\n                if on_match is not None:\n                    on_match(self, doc, len(matches) - 1, matches)\n\n    return matches\n</code></pre>"},{"location":"reference/medspacy/common/regex_matcher/#medspacy.common.regex_matcher.RegexMatcher.__init__","title":"<code>__init__(vocab, flags=re.IGNORECASE, resolve_start='left', resolve_end='right')</code>","text":"<p>Creates a new RegexMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>vocab</code> <code>Vocab</code> <p>A spaCy model vocabulary</p> required <code>flags</code> <code>RegexFlag</code> <p>Regular expression flag. Default re.IGNORECASE</p> <code>IGNORECASE</code> <code>resolve_start</code> <code>str</code> <p>How to resolve if the start character index of a match does not align with spacy token boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character index, leading to a longer than expected span. If 'right', will find the nearest token boundary to the right of the unmatched character index, leading to a shorter than expected span.  Default 'left'.</p> <code>'left'</code> <code>resolve_end</code> <code>str</code> <p>How to resolve if the end character index of a match does not align with spacy token boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character index, leading to a shorter than expected span. If 'right', will find the nearest token boundary to the right of the unmatched character index, leading to a longer than expected span. Default 'right'.</p> <code>'right'</code> Source code in <code>medspacy/common/regex_matcher.py</code> <pre><code>def __init__(\n    self,\n    vocab: Vocab,\n    flags: re.RegexFlag = re.IGNORECASE,\n    resolve_start: str = \"left\",\n    resolve_end: str = \"right\",\n):\n    \"\"\"\n    Creates a new RegexMatcher.\n\n    Args:\n        vocab: A spaCy model vocabulary\n        flags: Regular expression flag. Default re.IGNORECASE\n        resolve_start: How to resolve if the start character index of a match does not align with spacy token\n            boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character\n            index, leading to a longer than expected span. If 'right', will find the nearest token boundary to the\n            right of the unmatched character index, leading to a shorter than expected span.  Default 'left'.\n        resolve_end: How to resolve if the end character index of a match does not align with spacy token\n            boundaries. If 'left', will find the nearest token boundary to the left of the unmatched character\n            index, leading to a shorter than expected span. If 'right', will find the nearest token boundary to the\n            right of the unmatched character index, leading to a longer than expected span. Default 'right'.\n    \"\"\"\n    self.vocab = vocab\n    self.flags = flags\n    self.resolve_start = resolve_start\n    self.resolve_end = resolve_end\n    self._patterns = {}\n    self._callbacks = {}\n    self.labels = set()\n    self._rule_item_mapping = dict()\n</code></pre>"},{"location":"reference/medspacy/common/regex_matcher/#medspacy.common.regex_matcher.RegexMatcher.add","title":"<code>add(match_id, regex_rules, on_match=None)</code>","text":"<p>Add a rule with one or more regex patterns to one match id.</p> <p>Parameters:</p> Name Type Description Default <code>match_id</code> <code>str</code> <p>The name of the pattern.</p> required <code>regex_rules</code> <code>Iterable[str]</code> <p>The list of regex strings to associate with <code>match_id</code>.</p> required <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> Source code in <code>medspacy/common/regex_matcher.py</code> <pre><code>def add(\n    self,\n    match_id: str,\n    regex_rules: Iterable[str],\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n):\n    \"\"\"\n    Add a rule with one or more regex patterns to one match id.\n\n    Args:\n        match_id: The name of the pattern.\n        regex_rules: The list of regex strings to associate with `match_id`.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n    \"\"\"\n    # i am not sure if these warnings are more annoying than useful.\n    # warnings.warn(\n    #     \"You are using a TargetRule with a regex pattern, which is not \"\n    #     \"natively supported in spacy and may lead to unexpected match spans. \"\n    #     \"Consider using a list of dicts pattern instead. \"\n    #     \"See https://spacy.io/usage/rule-based-matching\",\n    #     RuntimeWarning,\n    # )\n    if match_id not in self.vocab:\n        self.vocab.strings.add(match_id)\n    self._patterns.setdefault(self.vocab.strings[match_id], [])\n    for pattern in regex_rules:\n        self._patterns[self.vocab.strings[match_id]].append(\n            re.compile(pattern, flags=self.flags)\n        )\n        self._callbacks[self.vocab.strings[match_id]] = on_match\n</code></pre>"},{"location":"reference/medspacy/common/util/","title":"medspacy.common.util","text":"<p>This module will contain helper functions and classes for common clinical processing tasks which will be used in medspaCy's matcher objects.</p>"},{"location":"reference/medspacy/common/util/#medspacy.common.util.get_token_for_char","title":"<code>get_token_for_char(doc, char_idx, resolve='left')</code>","text":"<p>Get the token index that best matches a particular character index. Because regex find returns a character index and spaCy matches must align with token boundaries, each character index must be converted into a token index.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy Doc to search in.</p> required <code>char_idx</code> <code>int</code> <p>The character index to find the corresponding token for.</p> required <code>resolve</code> <code>str</code> <p>The resolution type. \"left\" will snap character to the token index to the left which precede the</p> <code>'left'</code> <p>Returns:</p> Type Description <code>Union[Token, None]</code> <p>The token that best fits the character index based on the resolution type.</p> Source code in <code>medspacy/common/util.py</code> <pre><code>def get_token_for_char(\n    doc: Doc, char_idx: int, resolve: str = \"left\"\n) -&gt; Union[Token, None]:\n    \"\"\"\n    Get the token index that best matches a particular character index. Because regex find returns a character index and\n    spaCy matches must align with token boundaries, each character index must be converted into a token index.\n\n    Args:\n        doc: The spaCy Doc to search in.\n        char_idx: The character index to find the corresponding token for.\n        resolve: The resolution type. \"left\" will snap character to the token index to the left which precede the\n        `char_idx`. \"right\" will snap character to the token index to the right, which follows the `char_idx`.\n\n    Returns:\n        The token that best fits the character index based on the resolution type.\n    \"\"\"\n    if char_idx &lt; 0:\n        raise ValueError(\"char_idx must be &gt; 0\")\n    if char_idx &gt; len(doc.text_with_ws):\n        raise ValueError(\n            \"char_idx {0} is out of range for text with length {1}\".format(\n                char_idx, len(doc.text_with_ws)\n            )\n        )\n    for i, token in enumerate(doc):\n        if char_idx &gt; token.idx:\n            continue\n        if char_idx == token.idx:\n            return token\n        if char_idx &lt; token.idx:\n            if resolve == \"left\":\n                return doc[i - 1]\n            elif resolve == \"right\":\n                return doc[i]\n            else:\n                raise ValueError(\"resolve must be either 'left' or 'right'\")\n    # Otherwise, we've reached the end of the doc, so this must be the final token\n    # If resolving to the left, return the final token\n    # If resolving to the right, return None, meaning it should go to the end of the doc\n    if resolve == \"left\":\n        return doc[-1]\n    if resolve == \"right\":\n        return None\n</code></pre>"},{"location":"reference/medspacy/common/util/#medspacy.common.util.matches_to_spans","title":"<code>matches_to_spans(doc, matches, set_label=True)</code>","text":"<p>Converts all identified matches to spans.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy doc corresponding to the matches.</p> required <code>matches</code> <code>List[Tuple[int, int, int]]</code> <p>The list of match Tuples (match_id, start, end).</p> required <code>set_label</code> <code>bool</code> <p>Whether to assign a label to the span based off the source rule. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>List[Span]</code> <p>A list of spacy spans corresponding to the input matches.</p> Source code in <code>medspacy/common/util.py</code> <pre><code>def matches_to_spans(\n    doc: Doc, matches: List[Tuple[int, int, int]], set_label: bool = True\n) -&gt; List[Span]:\n    \"\"\"\n    Converts all identified matches to spans.\n\n    Args:\n        doc: The spaCy doc corresponding to the matches.\n        matches: The list of match Tuples (match_id, start, end).\n        set_label: Whether to assign a label to the span based off the source rule. Default is True.\n\n    Returns:\n        A list of spacy spans corresponding to the input matches.\n    \"\"\"\n    spans = []\n    for (rule_id, start, end) in matches:\n        if set_label:\n            label = doc.vocab.strings[rule_id]\n        else:\n            label = None\n        spans.append(Span(doc, start=start, end=end, label=label))\n    return spans\n</code></pre>"},{"location":"reference/medspacy/common/util/#medspacy.common.util.overlaps","title":"<code>overlaps(a, b)</code>","text":"<p>Checks whether two match Tuples out of spacy matchers overlap.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Tuple[int, int, int]</code> <p>A match Tuple (match_id, start, end).</p> required <code>b</code> <code>Tuple[int, int, int]</code> <p>A match Tuple (match_id, start, end).</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the tuples overlap.</p> Source code in <code>medspacy/common/util.py</code> <pre><code>def overlaps(a: Tuple[int, int, int], b: Tuple[int, int, int]) -&gt; bool:\n    \"\"\"\n    Checks whether two match Tuples out of spacy matchers overlap.\n\n    Args:\n        a: A match Tuple (match_id, start, end).\n        b: A match Tuple (match_id, start, end).\n\n    Returns:\n        Whether the tuples overlap.\n    \"\"\"\n    _, a_start, a_end = a\n    _, b_start, b_end = b\n    return tuple_overlaps((a_start, a_end), (b_start, b_end))\n</code></pre>"},{"location":"reference/medspacy/common/util/#medspacy.common.util.prune_overlapping_matches","title":"<code>prune_overlapping_matches(matches, strategy='longest')</code>","text":"<p>Prunes overlapping matches from a list of spaCy match tuples (match_id, start, end).</p> <p>Parameters:</p> Name Type Description Default <code>matches</code> <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples of form (match_id, start, end).</p> required <code>strategy</code> <code>str</code> <p>The pruning strategy to use. At this time, the only available option is \"longest\" and will keep the longest of any two overlapping spans. Other behavior will be added in a future update.</p> <code>'longest'</code> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>The pruned list of matches.</p> Source code in <code>medspacy/common/util.py</code> <pre><code>def prune_overlapping_matches(\n    matches: List[Tuple[int, int, int]], strategy: str = \"longest\"\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Prunes overlapping matches from a list of spaCy match tuples (match_id, start, end).\n\n    Args:\n        matches: A list of match tuples of form (match_id, start, end).\n        strategy: The pruning strategy to use. At this time, the only available option is \"longest\" and will keep the\n            longest of any two overlapping spans. Other behavior will be added in a future update.\n\n    Returns:\n        The pruned list of matches.\n    \"\"\"\n    if strategy != \"longest\":\n        raise NotImplementedError(\n            \"No other filtering strategy has been implemented. Coming in a future update.\"\n        )\n\n    # Make a copy and sort\n    unpruned = sorted(matches, key=lambda x: (x[1], x[2]))\n    pruned = []\n    num_matches = len(matches)\n    if num_matches == 0:\n        return matches\n    curr_match = unpruned.pop(0)\n\n    while True:\n        if len(unpruned) == 0:\n            pruned.append(curr_match)\n            break\n        next_match = unpruned.pop(0)\n\n        # Check if they overlap\n        if overlaps(curr_match, next_match):\n            # Choose the larger span\n            longer_span = max(curr_match, next_match, key=lambda x: (x[2] - x[1]))\n            pruned.append(longer_span)\n            if len(unpruned) == 0:\n                break\n            curr_match = unpruned.pop(0)\n        else:\n            pruned.append(curr_match)\n            curr_match = next_match\n    # Recursive base point\n    if len(pruned) == num_matches:\n        return pruned\n    # Recursive function call\n    else:\n        return prune_overlapping_matches(pruned)\n</code></pre>"},{"location":"reference/medspacy/common/util/#medspacy.common.util.span_contains","title":"<code>span_contains(span, target, regex=True, case_insensitive=True)</code>","text":"<p>Return True if a Span object contains a target phrase.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Union[Doc, Span]</code> <p>A spaCy Doc or Span, such as an entity in doc.ents</p> required <code>target</code> <code>str</code> <p>A target phrase or iterable of phrases to check in span.text.lower().</p> required <code>regex</code> <code>bool</code> <p>Whether to search the span using a regular expression rather than a literal string. Default is True.</p> <code>True</code> <code>case_insensitive</code> <code>bool</code> <p>Whether the matching is case-insensitive. Default is True.</p> <code>True</code> Source code in <code>medspacy/common/util.py</code> <pre><code>def span_contains(\n    span: Union[Doc, Span],\n    target: str,\n    regex: bool = True,\n    case_insensitive: bool = True,\n) -&gt; bool:\n    \"\"\"\n    Return True if a Span object contains a target phrase.\n\n    Args:\n        span: A spaCy Doc or Span, such as an entity in doc.ents\n        target: A target phrase or iterable of phrases to check in span.text.lower().\n        regex: Whether to search the span using a regular expression rather than\n            a literal string. Default is True.\n        case_insensitive: Whether the matching is case-insensitive. Default is True.\n    \"\"\"\n    if regex is True:\n        if case_insensitive:\n            func = lambda x: re.search(x, span.text, flags=re.IGNORECASE) is not None\n        else:\n            func = lambda x: re.search(x, span.text) is not None\n    else:\n        if case_insensitive:\n            func = lambda x: x.lower() in span.text.lower()\n        else:\n            func = lambda x: x in span.text\n\n    if isinstance(target, str):\n        return func(target)\n\n    # If it's an iterable, check if any of the strings are in sent\n    for string in target:\n        if func(string):\n            return True\n    return False\n</code></pre>"},{"location":"reference/medspacy/components/","title":"medspacy.components","text":""},{"location":"reference/medspacy/context/","title":"medspacy.context","text":""},{"location":"reference/medspacy/context/#medspacy.context.ConText","title":"<code>ConText</code>","text":"<p>The ConText for spaCy processing.</p> <p>This component matches modifiers in a Doc, defines their scope, and identifies edges between targets and modifiers. Sets two spaCy extensions:         - Span..modifiers: a list of ConTextModifier objects which modify a target Span         - Doc..context_graph: a ConText graph object which contains the targets,             modifiers, and edges between them.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@Language.factory(\"medspacy_context\")\nclass ConText:\n    \"\"\"\n    The ConText for spaCy processing.\n\n    This component matches modifiers in a Doc, defines their scope, and identifies edges between targets and modifiers.\n    Sets two spaCy extensions:\n            - Span._.modifiers: a list of ConTextModifier objects which modify a target Span\n            - Doc._.context_graph: a ConText graph object which contains the targets,\n                modifiers, and edges between them.\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_context\",\n        rules: Optional[str] = \"default\",\n        language_code: str = 'en',\n        phrase_matcher_attr: str = \"LOWER\",\n        allowed_types: Optional[Set[str]] = None,\n        excluded_types: Optional[Set[str]] = None,\n        terminating_types: Optional[Dict[str, Iterable[str]]] = None,\n        max_scope: Optional[int] = None,\n        max_targets: Optional[int] = None,\n        prune_on_modifier_overlap: bool = True,\n        prune_on_target_overlap: bool = False,\n        span_attrs: Union[\n            Literal[\"default\"], Dict[str, Dict[str, Any]], None\n        ] = \"default\",\n        input_span_type: Union[Literal[\"ents\", \"group\"]] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        \"\"\"\n        Creates a new ConText object.\n\n        Args:\n            nlp: A SpaCy Language object.\n            name: The name of the component.\n            rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n                original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If\n                None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules\n                directly through `ConText.add`.\n            language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n                and also the /resources directory to see which resources might be available in each language.\n                Default is \"en\" for English.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            allowed_types: A global list of types included by context. Rules will operate on only spans with these\n                labels.\n            excluded_types: A global list of types excluded by context. Rules will not operate on spans with these\n                labels.\n            terminating_types: A global map of types to the types that can terminate them. This can be used to apply\n                terminations to all rules of a particular type rather than adding to every rule individually in the\n                ContextRule object.\n            max_scope: The number of tokens around a modifier in a target can be modified. Default value is None,\n                Context will use the sentence boundaries. If a value greater than zero, applies the window globally.\n                Both options will be overridden by a more specific value in a ContextRule.\n            max_targets: The maximum number of targets a modifier can modify. Default value is None, context will modify\n                all targets in its scope. If a value greater than zero, applies this value globally. Both options will\n                be overridden by a more specific value in a ContextRule.\n            prune_on_modifier_overlap: Whether to prune modifiers which are substrings of another modifier. If True,\n                will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both\n                ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify\n                afib. Default True.\n            prune_on_target_overlap: Whether to remove any matched modifiers which overlap with target entities. If\n                False, any overlapping modifiers will not modify the overlapping entity but will still modify any other\n                targets in its scope. Default False.\n            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n                `DEFAULT_ATTRIBUTES`. If a dictionary, format is mapping context modifier categories to a dictionary\n                containing the attribute name and the value to set the attribute to when a  span is modified by a\n                modifier of that category. If None, no attributes will be modified.\n            input_span_type: \"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans\n                in doc.ents. \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n                \"medspacy_spans\".\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self.prune_on_modifier_overlap = prune_on_modifier_overlap\n        self.prune_on_target_overlap = prune_on_target_overlap\n        self.input_span_type = input_span_type\n        self.span_group_name = span_group_name\n        self.context_attributes_mapping = None\n\n        self.DEFAULT_RULES_FILEPATH = path.join(\n            Path(__file__).resolve().parents[2], \"resources\", language_code.lower(), \"context_rules.json\"\n        )\n\n        self.__matcher = MedspacyMatcher(\n            nlp,\n            name=name,\n            phrase_matcher_attr=phrase_matcher_attr,\n            prune=prune_on_modifier_overlap,\n        )\n\n        if span_attrs == \"default\":\n            self.context_attributes_mapping = DEFAULT_ATTRIBUTES\n            self.register_default_attributes()\n        elif span_attrs:\n            for _, attr_dict in span_attrs.items():\n                for attr_name in attr_dict.keys():\n                    if not Span.has_extension(attr_name):\n                        raise ValueError(\n                            f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                            f\"called for your pipeline's custom extensions.\"\n                        )\n            self.context_attributes_mapping = span_attrs\n\n        self.register_graph_attributes()\n\n        if max_scope is not None:\n            if not (isinstance(max_scope, int) and max_scope &gt; 0):\n                raise ValueError(\n                    f\"If 'max_scope' must be a value greater than 0, not the current value: {max_scope}\"\n                )\n        self.max_scope = max_scope\n\n        self.allowed_types = allowed_types\n        self.excluded_types = excluded_types\n        self.max_targets = max_targets\n\n        self.terminating_types = dict()\n        if terminating_types:\n            self.terminating_types = {\n                k.upper(): v for (k, v) in terminating_types.items()\n            }\n\n        rule_path = None\n        if rules == \"default\":\n            rule_path = self.DEFAULT_RULES_FILEPATH\n        else:\n            rule_path = rules\n\n        if rule_path:\n            self.add(ConTextRule.from_json(rule_path))\n\n    @property\n    def rules(self):\n        \"\"\"\n        Returns list of ConTextRules available to context.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def categories(self):\n        \"\"\"\n        Returns list of categories available that Context might produce.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules):\n        \"\"\"\n        Adds ConTextRules to Context.\n\n        Args:\n            rules: A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.\n        \"\"\"\n        if isinstance(rules, ConTextRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, ConTextRule):\n                raise TypeError(f\"Rules must type ConTextRule, not {type(rule)}.\")\n\n            # If global attributes like allowed_types and max_scope are defined,\n            # check if the ConTextRule has them defined. If not, set to the global\n            for attr in (\n                \"allowed_types\",\n                \"excluded_types\",\n                \"max_scope\",\n                \"max_targets\",\n            ):\n                value = getattr(self, attr)\n                if value is None:  # No global value set\n                    continue\n                if (\n                    getattr(rule, attr) is None\n                ):  # If the direction itself has it defined, don't override\n                    setattr(rule, attr, value)\n\n            # Check custom termination points\n            if rule.category.upper() in self.terminating_types:\n                for other_modifier in self.terminating_types[rule.category.upper()]:\n                    rule.terminated_by.add(other_modifier.upper())\n\n        self.__matcher.add(rules)\n\n    @classmethod\n    def register_graph_attributes(cls):\n        \"\"\"\n        Registers spaCy attribute extensions: Span._.modifiers and Doc._.context_graph.\n        \"\"\"\n        try:\n            Span.set_extension(\"modifiers\", default=(), force=True)\n            Doc.set_extension(\"context_graph\", default=None, force=True)\n        except ValueError:  # Extension already set\n            pass\n\n    @classmethod\n    def register_default_attributes(cls):\n        \"\"\"\n        Registers the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n        \"\"\"\n        for attr_name in [\n            \"is_negated\",\n            \"is_uncertain\",\n            \"is_historical\",\n            \"is_hypothetical\",\n            \"is_family\",\n        ]:\n            try:\n                Span.set_extension(attr_name, default=False)\n            except ValueError:  # Extension already set\n                pass\n\n    def set_context_attributes(self, edges):\n        \"\"\"\n        Adds Span-level attributes to targets with modifiers.\n\n        Args:\n            edges: The edges of the ContextGraph to modify.\n        \"\"\"\n        for (target, modifier) in edges:\n            if modifier.category in self.context_attributes_mapping:\n                attr_dict = self.context_attributes_mapping[modifier.category]\n                for attr_name, attr_value in attr_dict.items():\n                    setattr(target._, attr_name, attr_value)\n\n    def __call__(self, doc, targets: str = None) -&gt; Doc:\n        \"\"\"\n        Applies the ConText algorithm to a Doc.\n\n        Args:\n            doc: The spaCy Doc to process.\n            targets: The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects\n\n        Returns:\n            The processed spaCy Doc.\n        \"\"\"\n        if not targets and self.input_span_type == \"ents\":\n            targets = doc.ents\n        elif not targets and self.input_span_type == \"group\":\n            targets = doc.spans[self.span_group_name]\n        elif targets:\n            targets = getattr(doc._, targets)\n        # Store data in ConTextGraph object\n        # TODO: move some of this over to ConTextGraph\n        context_graph = ConTextGraph(\n            prune_on_modifier_overlap=self.prune_on_target_overlap\n        )\n\n        context_graph.targets = targets\n\n        context_graph.modifiers = []\n        matches = self.__matcher(doc)\n\n        for (match_id, start, end) in matches:\n            # Get the ConTextRule object defining this modifier\n            rule = self.__matcher.rule_map[self.nlp.vocab[match_id].text]\n            modifier = ConTextModifier(rule, start, end, doc, max_scope=self.max_scope)\n            context_graph.modifiers.append(modifier)\n\n        context_graph.update_scopes()\n        context_graph.apply_modifiers()\n\n        # Link targets to their modifiers\n        for target, modifier in context_graph.edges:\n            target._.modifiers += (modifier,)\n\n        # If attributes need to be modified\n        if self.context_attributes_mapping:\n            self.set_context_attributes(context_graph.edges)\n\n        doc._.context_graph = context_graph\n\n        return doc\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.categories","title":"<code>categories</code>  <code>property</code>","text":"<p>Returns list of categories available that Context might produce.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Returns list of ConTextRules available to context.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.__call__","title":"<code>__call__(doc, targets=None)</code>","text":"<p>Applies the ConText algorithm to a Doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <p>The spaCy Doc to process.</p> required <code>targets</code> <code>str</code> <p>The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects</p> <code>None</code> <p>Returns:</p> Type Description <code>Doc</code> <p>The processed spaCy Doc.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>def __call__(self, doc, targets: str = None) -&gt; Doc:\n    \"\"\"\n    Applies the ConText algorithm to a Doc.\n\n    Args:\n        doc: The spaCy Doc to process.\n        targets: The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects\n\n    Returns:\n        The processed spaCy Doc.\n    \"\"\"\n    if not targets and self.input_span_type == \"ents\":\n        targets = doc.ents\n    elif not targets and self.input_span_type == \"group\":\n        targets = doc.spans[self.span_group_name]\n    elif targets:\n        targets = getattr(doc._, targets)\n    # Store data in ConTextGraph object\n    # TODO: move some of this over to ConTextGraph\n    context_graph = ConTextGraph(\n        prune_on_modifier_overlap=self.prune_on_target_overlap\n    )\n\n    context_graph.targets = targets\n\n    context_graph.modifiers = []\n    matches = self.__matcher(doc)\n\n    for (match_id, start, end) in matches:\n        # Get the ConTextRule object defining this modifier\n        rule = self.__matcher.rule_map[self.nlp.vocab[match_id].text]\n        modifier = ConTextModifier(rule, start, end, doc, max_scope=self.max_scope)\n        context_graph.modifiers.append(modifier)\n\n    context_graph.update_scopes()\n    context_graph.apply_modifiers()\n\n    # Link targets to their modifiers\n    for target, modifier in context_graph.edges:\n        target._.modifiers += (modifier,)\n\n    # If attributes need to be modified\n    if self.context_attributes_mapping:\n        self.set_context_attributes(context_graph.edges)\n\n    doc._.context_graph = context_graph\n\n    return doc\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.__init__","title":"<code>__init__(nlp, name='medspacy_context', rules='default', language_code='en', phrase_matcher_attr='LOWER', allowed_types=None, excluded_types=None, terminating_types=None, max_scope=None, max_targets=None, prune_on_modifier_overlap=True, prune_on_target_overlap=False, span_attrs='default', input_span_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Creates a new ConText object.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A SpaCy Language object.</p> required <code>name</code> <code>str</code> <p>The name of the component.</p> <code>'medspacy_context'</code> <code>rules</code> <code>Optional[str]</code> <p>The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules directly through <code>ConText.add</code>.</p> <code>'default'</code> <code>language_code</code> <code>str</code> <p>Language code to use (ISO code) as a default for loading resources.  See documentation and also the /resources directory to see which resources might be available in each language. Default is \"en\" for English.</p> <code>'en'</code> <code>phrase_matcher_attr</code> <code>str</code> <p>The token attribute to use for PhraseMatcher for rules where <code>pattern</code> is None. Default is 'LOWER'.</p> <code>'LOWER'</code> <code>allowed_types</code> <code>Optional[Set[str]]</code> <p>A global list of types included by context. Rules will operate on only spans with these labels.</p> <code>None</code> <code>excluded_types</code> <code>Optional[Set[str]]</code> <p>A global list of types excluded by context. Rules will not operate on spans with these labels.</p> <code>None</code> <code>terminating_types</code> <code>Optional[Dict[str, Iterable[str]]]</code> <p>A global map of types to the types that can terminate them. This can be used to apply terminations to all rules of a particular type rather than adding to every rule individually in the ContextRule object.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>The number of tokens around a modifier in a target can be modified. Default value is None, Context will use the sentence boundaries. If a value greater than zero, applies the window globally. Both options will be overridden by a more specific value in a ContextRule.</p> <code>None</code> <code>max_targets</code> <code>Optional[int]</code> <p>The maximum number of targets a modifier can modify. Default value is None, context will modify all targets in its scope. If a value greater than zero, applies this value globally. Both options will be overridden by a more specific value in a ContextRule.</p> <code>None</code> <code>prune_on_modifier_overlap</code> <code>bool</code> <p>Whether to prune modifiers which are substrings of another modifier. If True, will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify afib. Default True.</p> <code>True</code> <code>prune_on_target_overlap</code> <code>bool</code> <p>Whether to remove any matched modifiers which overlap with target entities. If False, any overlapping modifiers will not modify the overlapping entity but will still modify any other targets in its scope. Default False.</p> <code>False</code> <code>span_attrs</code> <code>Union[Literal['default'], Dict[str, Dict[str, Any]], None]</code> <p>The optional span attributes to modify. Default option \"default\" uses attributes in <code>DEFAULT_ATTRIBUTES</code>. If a dictionary, format is mapping context modifier categories to a dictionary containing the attribute name and the value to set the attribute to when a  span is modified by a modifier of that category. If None, no attributes will be modified.</p> <code>'default'</code> <code>input_span_type</code> <code>Union[Literal['ents', 'group']]</code> <p>\"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans in doc.ents. \"group\" will modify attributes of spans in the span group specified by <code>span_group_name</code>.</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>The name of the span group used when <code>input_span_type</code> is \"group\". Default is \"medspacy_spans\".</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/context/context.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_context\",\n    rules: Optional[str] = \"default\",\n    language_code: str = 'en',\n    phrase_matcher_attr: str = \"LOWER\",\n    allowed_types: Optional[Set[str]] = None,\n    excluded_types: Optional[Set[str]] = None,\n    terminating_types: Optional[Dict[str, Iterable[str]]] = None,\n    max_scope: Optional[int] = None,\n    max_targets: Optional[int] = None,\n    prune_on_modifier_overlap: bool = True,\n    prune_on_target_overlap: bool = False,\n    span_attrs: Union[\n        Literal[\"default\"], Dict[str, Dict[str, Any]], None\n    ] = \"default\",\n    input_span_type: Union[Literal[\"ents\", \"group\"]] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Creates a new ConText object.\n\n    Args:\n        nlp: A SpaCy Language object.\n        name: The name of the component.\n        rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n            original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If\n            None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules\n            directly through `ConText.add`.\n        language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        allowed_types: A global list of types included by context. Rules will operate on only spans with these\n            labels.\n        excluded_types: A global list of types excluded by context. Rules will not operate on spans with these\n            labels.\n        terminating_types: A global map of types to the types that can terminate them. This can be used to apply\n            terminations to all rules of a particular type rather than adding to every rule individually in the\n            ContextRule object.\n        max_scope: The number of tokens around a modifier in a target can be modified. Default value is None,\n            Context will use the sentence boundaries. If a value greater than zero, applies the window globally.\n            Both options will be overridden by a more specific value in a ContextRule.\n        max_targets: The maximum number of targets a modifier can modify. Default value is None, context will modify\n            all targets in its scope. If a value greater than zero, applies this value globally. Both options will\n            be overridden by a more specific value in a ContextRule.\n        prune_on_modifier_overlap: Whether to prune modifiers which are substrings of another modifier. If True,\n            will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both\n            ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify\n            afib. Default True.\n        prune_on_target_overlap: Whether to remove any matched modifiers which overlap with target entities. If\n            False, any overlapping modifiers will not modify the overlapping entity but will still modify any other\n            targets in its scope. Default False.\n        span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n            `DEFAULT_ATTRIBUTES`. If a dictionary, format is mapping context modifier categories to a dictionary\n            containing the attribute name and the value to set the attribute to when a  span is modified by a\n            modifier of that category. If None, no attributes will be modified.\n        input_span_type: \"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans\n            in doc.ents. \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n            \"medspacy_spans\".\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self.prune_on_modifier_overlap = prune_on_modifier_overlap\n    self.prune_on_target_overlap = prune_on_target_overlap\n    self.input_span_type = input_span_type\n    self.span_group_name = span_group_name\n    self.context_attributes_mapping = None\n\n    self.DEFAULT_RULES_FILEPATH = path.join(\n        Path(__file__).resolve().parents[2], \"resources\", language_code.lower(), \"context_rules.json\"\n    )\n\n    self.__matcher = MedspacyMatcher(\n        nlp,\n        name=name,\n        phrase_matcher_attr=phrase_matcher_attr,\n        prune=prune_on_modifier_overlap,\n    )\n\n    if span_attrs == \"default\":\n        self.context_attributes_mapping = DEFAULT_ATTRIBUTES\n        self.register_default_attributes()\n    elif span_attrs:\n        for _, attr_dict in span_attrs.items():\n            for attr_name in attr_dict.keys():\n                if not Span.has_extension(attr_name):\n                    raise ValueError(\n                        f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                        f\"called for your pipeline's custom extensions.\"\n                    )\n        self.context_attributes_mapping = span_attrs\n\n    self.register_graph_attributes()\n\n    if max_scope is not None:\n        if not (isinstance(max_scope, int) and max_scope &gt; 0):\n            raise ValueError(\n                f\"If 'max_scope' must be a value greater than 0, not the current value: {max_scope}\"\n            )\n    self.max_scope = max_scope\n\n    self.allowed_types = allowed_types\n    self.excluded_types = excluded_types\n    self.max_targets = max_targets\n\n    self.terminating_types = dict()\n    if terminating_types:\n        self.terminating_types = {\n            k.upper(): v for (k, v) in terminating_types.items()\n        }\n\n    rule_path = None\n    if rules == \"default\":\n        rule_path = self.DEFAULT_RULES_FILEPATH\n    else:\n        rule_path = rules\n\n    if rule_path:\n        self.add(ConTextRule.from_json(rule_path))\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.add","title":"<code>add(rules)</code>","text":"<p>Adds ConTextRules to Context.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <p>A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.</p> required Source code in <code>medspacy/context/context.py</code> <pre><code>def add(self, rules):\n    \"\"\"\n    Adds ConTextRules to Context.\n\n    Args:\n        rules: A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.\n    \"\"\"\n    if isinstance(rules, ConTextRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, ConTextRule):\n            raise TypeError(f\"Rules must type ConTextRule, not {type(rule)}.\")\n\n        # If global attributes like allowed_types and max_scope are defined,\n        # check if the ConTextRule has them defined. If not, set to the global\n        for attr in (\n            \"allowed_types\",\n            \"excluded_types\",\n            \"max_scope\",\n            \"max_targets\",\n        ):\n            value = getattr(self, attr)\n            if value is None:  # No global value set\n                continue\n            if (\n                getattr(rule, attr) is None\n            ):  # If the direction itself has it defined, don't override\n                setattr(rule, attr, value)\n\n        # Check custom termination points\n        if rule.category.upper() in self.terminating_types:\n            for other_modifier in self.terminating_types[rule.category.upper()]:\n                rule.terminated_by.add(other_modifier.upper())\n\n    self.__matcher.add(rules)\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.register_default_attributes","title":"<code>register_default_attributes()</code>  <code>classmethod</code>","text":"<p>Registers the default values for the Span attributes defined in <code>DEFAULT_ATTRIBUTES</code>.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@classmethod\ndef register_default_attributes(cls):\n    \"\"\"\n    Registers the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n    \"\"\"\n    for attr_name in [\n        \"is_negated\",\n        \"is_uncertain\",\n        \"is_historical\",\n        \"is_hypothetical\",\n        \"is_family\",\n    ]:\n        try:\n            Span.set_extension(attr_name, default=False)\n        except ValueError:  # Extension already set\n            pass\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.register_graph_attributes","title":"<code>register_graph_attributes()</code>  <code>classmethod</code>","text":"<p>Registers spaCy attribute extensions: Span..modifiers and Doc..context_graph.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@classmethod\ndef register_graph_attributes(cls):\n    \"\"\"\n    Registers spaCy attribute extensions: Span._.modifiers and Doc._.context_graph.\n    \"\"\"\n    try:\n        Span.set_extension(\"modifiers\", default=(), force=True)\n        Doc.set_extension(\"context_graph\", default=None, force=True)\n    except ValueError:  # Extension already set\n        pass\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConText.set_context_attributes","title":"<code>set_context_attributes(edges)</code>","text":"<p>Adds Span-level attributes to targets with modifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <p>The edges of the ContextGraph to modify.</p> required Source code in <code>medspacy/context/context.py</code> <pre><code>def set_context_attributes(self, edges):\n    \"\"\"\n    Adds Span-level attributes to targets with modifiers.\n\n    Args:\n        edges: The edges of the ContextGraph to modify.\n    \"\"\"\n    for (target, modifier) in edges:\n        if modifier.category in self.context_attributes_mapping:\n            attr_dict = self.context_attributes_mapping[modifier.category]\n            for attr_name, attr_value in attr_dict.items():\n                setattr(target._, attr_name, attr_value)\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextGraph","title":"<code>ConTextGraph</code>","text":"<p>The ConTextGraph class defines the internal structure of the ConText algorithm. It stores a collection of modifiers, matched with ConTextRules, and targets from some other source such as the TargetMatcher or a spaCy NER model.</p> <p>Each modifier can have some number of associated targets that it modifies. This relationship is stored as edges of of the graph.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>class ConTextGraph:\n    \"\"\"\n    The ConTextGraph class defines the internal structure of the ConText algorithm. It stores a collection of modifiers,\n    matched with ConTextRules, and targets from some other source such as the TargetMatcher or a spaCy NER model.\n\n    Each modifier can have some number of associated targets that it modifies. This relationship is stored as edges of\n    of the graph.\n    \"\"\"\n\n    def __init__(\n        self,\n        targets: Optional[List[Span]] = None,\n        modifiers: Optional[List[ConTextModifier]] = None,\n        edges: Optional[List] = None,\n        prune_on_modifier_overlap: bool = False,\n    ):\n        \"\"\"\n        Creates a new ConTextGraph object.\n\n        Args:\n            targets: A spans that context might modify.\n            modifiers: A list of ConTextModifiers that might modify the targets.\n            edges: A list of edges between targets and modifiers representing the modification relationship.\n            prune_on_modifier_overlap: Whether to prune modifiers when one modifier completely covers another.\n        \"\"\"\n        self.targets = targets if targets is not None else []\n        self.modifiers = modifiers if modifiers is not None else []\n        self.edges = edges if edges is not None else []\n        self.prune_on_modifier_overlap = prune_on_modifier_overlap\n\n    def update_scopes(self):\n        \"\"\"\n        Update the scope of all ConTextModifier.\n\n        For each modifier in a list of ConTextModifiers, check against each other\n        modifier to see if one of the modifiers should update the other.\n        This allows neighboring similar modifiers to extend each other's\n        scope and allows \"terminate\" modifiers to end a modifier's scope.\n        \"\"\"\n        for i in range(len(self.modifiers) - 1):\n            modifier1 = self.modifiers[i]\n            for j in range(i + 1, len(self.modifiers)):\n                modifier2 = self.modifiers[j]\n                # TODO: Add modifier -&gt; modifier edges\n                modifier1.limit_scope(modifier2)\n                modifier2.limit_scope(modifier1)\n\n    def apply_modifiers(self):\n        \"\"\"\n        Checks each target/modifier pair. If modifier modifies target,\n        create an edge between them.\n        \"\"\"\n        if self.prune_on_modifier_overlap:\n            for i in range(len(self.modifiers) - 1, -1, -1):\n                modifier = self.modifiers[i]\n                for target in self.targets:\n                    if tuple_overlaps(\n                        (target.start, target.end), modifier.modifier_span\n                    ):\n                        self.modifiers.pop(i)\n                        break\n\n        edges = []\n        for target in self.targets:\n            for modifier in self.modifiers:\n                if modifier.modifies(target):\n                    modifier.modify(target)\n\n        # Now do a second pass and reduce the number of targets\n        # for any modifiers with a max_targets int\n        for modifier in self.modifiers:\n            modifier.reduce_targets()\n            for target in modifier._targets:\n                edges.append((target, modifier))\n\n        self.edges = edges\n\n    def __repr__(self):\n        return f\"&lt;ConTextGraph&gt; with {len(self.targets)} targets and {len(self.modifiers)} modifiers\"\n\n    def serialized_representation(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the serialized representation of the ConTextGraph\n        \"\"\"\n        return self.__dict__\n\n    @classmethod\n    def from_serialized_representation(cls, serialized_representation) -&gt; ConTextGraph:\n        \"\"\"\n        Creates the ConTextGraph from the serialized representation\n        \"\"\"\n        context_graph = ConTextGraph(**serialized_representation)\n\n        return context_graph\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextGraph.__init__","title":"<code>__init__(targets=None, modifiers=None, edges=None, prune_on_modifier_overlap=False)</code>","text":"<p>Creates a new ConTextGraph object.</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>Optional[List[Span]]</code> <p>A spans that context might modify.</p> <code>None</code> <code>modifiers</code> <code>Optional[List[ConTextModifier]]</code> <p>A list of ConTextModifiers that might modify the targets.</p> <code>None</code> <code>edges</code> <code>Optional[List]</code> <p>A list of edges between targets and modifiers representing the modification relationship.</p> <code>None</code> <code>prune_on_modifier_overlap</code> <code>bool</code> <p>Whether to prune modifiers when one modifier completely covers another.</p> <code>False</code> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def __init__(\n    self,\n    targets: Optional[List[Span]] = None,\n    modifiers: Optional[List[ConTextModifier]] = None,\n    edges: Optional[List] = None,\n    prune_on_modifier_overlap: bool = False,\n):\n    \"\"\"\n    Creates a new ConTextGraph object.\n\n    Args:\n        targets: A spans that context might modify.\n        modifiers: A list of ConTextModifiers that might modify the targets.\n        edges: A list of edges between targets and modifiers representing the modification relationship.\n        prune_on_modifier_overlap: Whether to prune modifiers when one modifier completely covers another.\n    \"\"\"\n    self.targets = targets if targets is not None else []\n    self.modifiers = modifiers if modifiers is not None else []\n    self.edges = edges if edges is not None else []\n    self.prune_on_modifier_overlap = prune_on_modifier_overlap\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextGraph.apply_modifiers","title":"<code>apply_modifiers()</code>","text":"<p>Checks each target/modifier pair. If modifier modifies target, create an edge between them.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def apply_modifiers(self):\n    \"\"\"\n    Checks each target/modifier pair. If modifier modifies target,\n    create an edge between them.\n    \"\"\"\n    if self.prune_on_modifier_overlap:\n        for i in range(len(self.modifiers) - 1, -1, -1):\n            modifier = self.modifiers[i]\n            for target in self.targets:\n                if tuple_overlaps(\n                    (target.start, target.end), modifier.modifier_span\n                ):\n                    self.modifiers.pop(i)\n                    break\n\n    edges = []\n    for target in self.targets:\n        for modifier in self.modifiers:\n            if modifier.modifies(target):\n                modifier.modify(target)\n\n    # Now do a second pass and reduce the number of targets\n    # for any modifiers with a max_targets int\n    for modifier in self.modifiers:\n        modifier.reduce_targets()\n        for target in modifier._targets:\n            edges.append((target, modifier))\n\n    self.edges = edges\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextGraph.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Creates the ConTextGraph from the serialized representation</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>@classmethod\ndef from_serialized_representation(cls, serialized_representation) -&gt; ConTextGraph:\n    \"\"\"\n    Creates the ConTextGraph from the serialized representation\n    \"\"\"\n    context_graph = ConTextGraph(**serialized_representation)\n\n    return context_graph\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextGraph.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Returns the serialized representation of the ConTextGraph</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def serialized_representation(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the serialized representation of the ConTextGraph\n    \"\"\"\n    return self.__dict__\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextGraph.update_scopes","title":"<code>update_scopes()</code>","text":"<p>Update the scope of all ConTextModifier.</p> <p>For each modifier in a list of ConTextModifiers, check against each other modifier to see if one of the modifiers should update the other. This allows neighboring similar modifiers to extend each other's scope and allows \"terminate\" modifiers to end a modifier's scope.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def update_scopes(self):\n    \"\"\"\n    Update the scope of all ConTextModifier.\n\n    For each modifier in a list of ConTextModifiers, check against each other\n    modifier to see if one of the modifiers should update the other.\n    This allows neighboring similar modifiers to extend each other's\n    scope and allows \"terminate\" modifiers to end a modifier's scope.\n    \"\"\"\n    for i in range(len(self.modifiers) - 1):\n        modifier1 = self.modifiers[i]\n        for j in range(i + 1, len(self.modifiers)):\n            modifier2 = self.modifiers[j]\n            # TODO: Add modifier -&gt; modifier edges\n            modifier1.limit_scope(modifier2)\n            modifier2.limit_scope(modifier1)\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier","title":"<code>ConTextModifier</code>","text":"<p>Represents a concept found by ConText in a document. An instance of this class is the result of ConTextRule matching text in a Doc.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>class ConTextModifier:\n    \"\"\"\n    Represents a concept found by ConText in a document. An instance of this class is the result of ConTextRule matching\n    text in a Doc.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_rule: ConTextRule,\n        start: int,\n        end: int,\n        doc: Doc,\n        scope_start: Optional[int] = None,\n        scope_end: Optional[int] = None,\n        max_scope: Optional[int] = None,\n    ):\n        \"\"\"\n        Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding\n        window. Spans such as entities or other members of span groups that occur within this window can be modified by\n        this ConTextModifier.\n\n        Args:\n            context_rule: The ConTextRule object which defines the modifier.\n            start: The start token index.\n            end: The end token index (non-inclusive).\n            doc: The spaCy Doc which contains this span. This is needed to initialize the modifier but is not\n                maintained.\n            scope_start: The start token index of the scope.\n            scope_end: The end index of the scope.\n            max_scope: Whether to use scope values rather than sentence boundaries for modifications.\n        \"\"\"\n        self._context_rule = context_rule\n        self._start = start\n        self._end = end\n\n        self._targets = []\n        self._num_targets = 0\n\n        self._max_scope = max_scope\n        self._scope_start = scope_start\n        self._scope_end = scope_end\n        if doc is not None and (self._scope_end is None or self._scope_start is None):\n            self.__set_scope(doc)\n\n    @property\n    def modifier_span(self) -&gt; Tuple[int, int]:\n        \"\"\"\n        The spaCy Span object, which is a view of self.doc, covered by this match.\n        \"\"\"\n        return self._start, self._end\n\n    @property\n    def rule(self) -&gt; ConTextRule:\n        \"\"\"\n        Returns the associated context rule.\n        \"\"\"\n        return self._context_rule\n\n    @property\n    def direction(self) -&gt; str:\n        \"\"\"\n        Returns the associated direction.\n        \"\"\"\n        return self.rule.direction\n\n    @property\n    def category(self) -&gt; str:\n        \"\"\"\n        Returns the associated category.\n        \"\"\"\n        return self.rule.category\n\n    @property\n    def scope_span(self) -&gt; Tuple[int, int]:\n        \"\"\"\n        Returns the associated scope.\n        \"\"\"\n        return self._scope_start, self._scope_end\n\n    @property\n    def allowed_types(self) -&gt; Set[str]:\n        \"\"\"\n        Returns the associated allowed types.\n        \"\"\"\n        return self.rule.allowed_types\n\n    @property\n    def excluded_types(self) -&gt; Set[str]:\n        \"\"\"\n        Returns the associated excluded types.\n        \"\"\"\n        return self.rule.excluded_types\n\n    @property\n    def num_targets(self) -&gt; int:\n        \"\"\"\n        Returns the associated number of targets.\n        \"\"\"\n        return self._num_targets\n\n    @property\n    def max_targets(self) -&gt; Union[int, None]:\n        \"\"\"\n        Returns the associated maximum number of targets.\n        \"\"\"\n        return self.rule.max_targets\n\n    @property\n    def max_scope(self) -&gt; Union[int, None]:\n        \"\"\"\n        Returns the associated maximum scope.\n        \"\"\"\n        return self.rule.max_scope\n\n    def __set_scope(self, doc: Doc):\n        \"\"\"\n        Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If\n        self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by\n        self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the\n        direction is \"backward\", it will be [self.start: sentence.start].\n\n        If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be\n        reduced to self.max_scope.\n\n        Args:\n            doc: The spaCy doc to use to set scope.\n        \"\"\"\n        # If ConText is set to use defined windows, do that instead of sentence splitting\n        if self._max_scope:\n            full_scope_span = doc[self._start : self._end]._.window(\n                n=self.rule.max_scope\n            )\n        # Otherwise, use the sentence\n        else:\n            full_scope_span = doc[self._start].sent\n            if full_scope_span is None:\n                raise ValueError(\n                    \"ConText failed because sentence boundaries have not been set. Add an upstream component such as the \"\n                    \"dependency parser, Sentencizer, or PyRuSH to detect sentence boundaries or initialize ConText with \"\n                    \"`max_scope` set to a value greater than 0.\"\n                )\n\n        if self.direction.lower() == \"forward\":\n            self._scope_start, self._scope_end = self._end, full_scope_span.end\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_end = self._end + self.max_scope\n\n        elif self.direction.lower() == \"backward\":\n            self._scope_start, self._scope_end = (\n                full_scope_span.start,\n                self._start,\n            )\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_start = self._start - self.max_scope\n\n        else:  # bidirectional\n            self._scope_start, self._scope_end = (\n                full_scope_span.start,\n                full_scope_span.end,\n            )\n\n            # Set the max scope on either side\n            # Backwards\n            if (\n                self.max_scope is not None\n                and (self._start - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_start = self._start - self.max_scope\n            # Forwards\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._end) &gt; self.max_scope\n            ):\n                self._scope_end = self._end + self.max_scope\n\n    def update_scope(self, span: Span):\n        \"\"\"\n        Changes the scope of self to be the given spaCy span.\n\n        Args:\n            span: a spaCy Span which contains the scope which a modifier should cover.\n        \"\"\"\n        self._scope_start = span.start\n        self._scope_end = span.end\n\n    def limit_scope(self, other: ConTextModifier) -&gt; bool:\n        \"\"\"\n        If self and other have the same category or if other has a directionality of 'terminate', use the span of other\n        to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of\n        modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not\n        'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of\n        CHF, but there is pneumonia'\n\n        Args:\n            other: The modifier to check against.\n\n        Returns:\n            Whether the other modifier modified the scope of self.\n        \"\"\"\n        if not tuple_overlaps(self.scope_span, other.scope_span):\n            return False\n        if self.direction.upper() == \"TERMINATE\":\n            return False\n        # Check if the other modifier is a type which can modify self\n        # or if they are the same category. If not, don't reduce scope.\n        if (\n            (other.direction.upper() != \"TERMINATE\")\n            and (other.category.upper() not in self.rule.terminated_by)\n            and (other.category.upper() != self.category.upper())\n        ):\n            return False\n\n        # If two modifiers have the same category but modify different target types,\n        # don't limit scope.\n        if self.category == other.category and (\n            (self.allowed_types != other.allowed_types)\n            or (self.excluded_types != other.excluded_types)\n        ):\n            return False\n\n        orig_scope = self.scope_span\n        if self.direction.lower() in (\"forward\", \"bidirectional\"):\n            if other &gt; self:\n                self._scope_end = min(self._scope_end, other.modifier_span[0])\n        if self.direction.lower() in (\"backward\", \"bidirectional\"):\n            if other &lt; self:\n                self._scope_start = max(self._scope_start, other.modifier_span[1])\n        return orig_scope != self.scope_span\n\n    def modifies(self, target: Span) -&gt; bool:\n        \"\"\"\n        Checks whether the target is within the modifier scope and if self is allowed to modify target.\n\n        Args:\n            target: a spaCy span representing a target concept.\n\n        Returns:\n            Whether the target is within `modifier_scope` and if self is allowed to modify the target.\n        \"\"\"\n        # If the target and modifier overlap, meaning at least one token\n        # one extracted as both a target and modifier, return False\n        # to avoid self-modifying concepts\n\n        if tuple_overlaps(\n            self.modifier_span, (target.start, target.end)\n        ):  # self.overlaps(target):\n            return False\n        if self.direction in (\"TERMINATE\", \"PSEUDO\"):\n            return False\n        if not self.allows(target.label_.upper()):\n            return False\n\n        if tuple_overlaps(self.scope_span, (target.start, target.end)):\n            if not self.on_modifies(target):\n                return False\n            else:\n                return True\n        return False\n\n    def allows(self, target_label: str) -&gt; bool:\n        \"\"\"\n        Returns whether if a modifier is able to modify a target type.\n\n        Args:\n            target_label: The target type to check.\n\n        Returns:\n            Whether the modifier is allowed to modify a target of the specified type. True if `target_label` in\n            `self.allowed_types` or if `target_label` not in `self.excluded_tupes`. False otherwise.\n        \"\"\"\n        if self.allowed_types is not None:\n            return target_label in self.allowed_types\n        if self.excluded_types is not None:\n            return target_label not in self.excluded_types\n        return True\n\n    def on_modifies(self, target: Span) -&gt; bool:\n        \"\"\"\n        If the ConTextRule used to define a ConTextModifier has an `on_modifies` callback function, evaluate and return\n        either True or False.\n\n        Args:\n            target: The spaCy span to evaluate.\n\n        Returns:\n            The result of the `on_modifies` callback for the rule. True if the callback is None.\n        \"\"\"\n        if self.rule.on_modifies is None:\n            return True\n        # Find the span in between the target and modifier\n        start = min(target.end, self._end)\n        end = max(target.start, self._end)\n        span_between = target.doc[start:end]\n        rslt = self.rule.on_modifies(\n            target, target.doc[self._start : self._end], span_between\n        )\n        if rslt not in (True, False):\n            raise ValueError(\n                \"The on_modifies function must return either True or False indicating \"\n                \"whether a modify modifies a target. Actual value: {0}\".format(rslt)\n            )\n        return rslt\n\n    def modify(self, target: Span):\n        \"\"\"\n        Add target to the list of self._targets and increment self._num_targets.\n\n        Args:\n            target: The spaCy span to add.\n        \"\"\"\n        self._targets.append(target)\n        self._num_targets += 1\n\n    def reduce_targets(self):\n        \"\"\"\n        Reduces the number of targets to the n-closest targets based on the value of `self.max_targets`. If\n        `self.max_targets` is None, no pruning is done.\n        \"\"\"\n        if self.max_targets is None or self.num_targets &lt;= self.max_targets:\n            return\n\n        target_dists = []\n        for target in self._targets:\n            dist = min(abs(self._start - target.end), abs(target.start - self._end))\n            target_dists.append((target, dist))\n        srtd_targets, _ = zip(*sorted(target_dists, key=lambda x: x[1]))\n        self._targets = srtd_targets[: self.max_targets]\n        self._num_targets = len(self._targets)\n\n    def __gt__(self, other: ConTextModifier):\n        return self._start &gt; other.modifier_span[0]\n\n    def __ge__(self, other):\n        return self._start &gt;= other.modifier_span[0]\n\n    def __lt__(self, other):\n        return self._end &lt; other.modifier_span[1]\n\n    def __le__(self, other):\n        return self._end &lt;= other.modifier_span[1]\n\n    def __len__(self):\n        return self._end - self._start\n\n    def __repr__(self):\n        return f\"&lt;ConTextModifier&gt; [{self._start}, {self._end}, {self.category}]\"\n\n    def serialized_representation(self):\n        \"\"\"\n        Serialized Representation of the modifier\n        \"\"\"\n        dict_repr = dict()\n        dict_repr[\"context_rule\"] = self.rule.to_dict()\n        dict_repr[\"start\"] = self._start\n        dict_repr[\"end\"] = self._end\n        dict_repr[\"max_scope\"] = self._max_scope\n        dict_repr[\"scope_start\"] = self._scope_start\n        dict_repr[\"scope_end\"] = self._scope_end\n\n        return dict_repr\n\n    @classmethod\n    def from_serialized_representation(\n        cls, serialized_representation\n    ) -&gt; ConTextModifier:\n        \"\"\"\n        Instantiates the class from the serialized representation\n        \"\"\"\n        rule = ConTextRule.from_dict(serialized_representation[\"context_rule\"])\n\n        serialized_representation[\"context_rule\"] = rule\n        serialized_representation[\"doc\"] = None\n\n        return ConTextModifier(**serialized_representation)\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.allowed_types","title":"<code>allowed_types</code>  <code>property</code>","text":"<p>Returns the associated allowed types.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.category","title":"<code>category</code>  <code>property</code>","text":"<p>Returns the associated category.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.direction","title":"<code>direction</code>  <code>property</code>","text":"<p>Returns the associated direction.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.excluded_types","title":"<code>excluded_types</code>  <code>property</code>","text":"<p>Returns the associated excluded types.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.max_scope","title":"<code>max_scope</code>  <code>property</code>","text":"<p>Returns the associated maximum scope.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.max_targets","title":"<code>max_targets</code>  <code>property</code>","text":"<p>Returns the associated maximum number of targets.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.modifier_span","title":"<code>modifier_span</code>  <code>property</code>","text":"<p>The spaCy Span object, which is a view of self.doc, covered by this match.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.num_targets","title":"<code>num_targets</code>  <code>property</code>","text":"<p>Returns the associated number of targets.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.rule","title":"<code>rule</code>  <code>property</code>","text":"<p>Returns the associated context rule.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.scope_span","title":"<code>scope_span</code>  <code>property</code>","text":"<p>Returns the associated scope.</p>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.__init__","title":"<code>__init__(context_rule, start, end, doc, scope_start=None, scope_end=None, max_scope=None)</code>","text":"<p>Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding window. Spans such as entities or other members of span groups that occur within this window can be modified by this ConTextModifier.</p> <p>Parameters:</p> Name Type Description Default <code>context_rule</code> <code>ConTextRule</code> <p>The ConTextRule object which defines the modifier.</p> required <code>start</code> <code>int</code> <p>The start token index.</p> required <code>end</code> <code>int</code> <p>The end token index (non-inclusive).</p> required <code>doc</code> <code>Doc</code> <p>The spaCy Doc which contains this span. This is needed to initialize the modifier but is not maintained.</p> required <code>scope_start</code> <code>Optional[int]</code> <p>The start token index of the scope.</p> <code>None</code> <code>scope_end</code> <code>Optional[int]</code> <p>The end index of the scope.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>Whether to use scope values rather than sentence boundaries for modifications.</p> <code>None</code> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def __init__(\n    self,\n    context_rule: ConTextRule,\n    start: int,\n    end: int,\n    doc: Doc,\n    scope_start: Optional[int] = None,\n    scope_end: Optional[int] = None,\n    max_scope: Optional[int] = None,\n):\n    \"\"\"\n    Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding\n    window. Spans such as entities or other members of span groups that occur within this window can be modified by\n    this ConTextModifier.\n\n    Args:\n        context_rule: The ConTextRule object which defines the modifier.\n        start: The start token index.\n        end: The end token index (non-inclusive).\n        doc: The spaCy Doc which contains this span. This is needed to initialize the modifier but is not\n            maintained.\n        scope_start: The start token index of the scope.\n        scope_end: The end index of the scope.\n        max_scope: Whether to use scope values rather than sentence boundaries for modifications.\n    \"\"\"\n    self._context_rule = context_rule\n    self._start = start\n    self._end = end\n\n    self._targets = []\n    self._num_targets = 0\n\n    self._max_scope = max_scope\n    self._scope_start = scope_start\n    self._scope_end = scope_end\n    if doc is not None and (self._scope_end is None or self._scope_start is None):\n        self.__set_scope(doc)\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.__set_scope","title":"<code>__set_scope(doc)</code>","text":"<p>Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the direction is \"backward\", it will be [self.start: sentence.start].</p> <p>If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be reduced to self.max_scope.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy doc to use to set scope.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def __set_scope(self, doc: Doc):\n    \"\"\"\n    Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If\n    self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by\n    self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the\n    direction is \"backward\", it will be [self.start: sentence.start].\n\n    If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be\n    reduced to self.max_scope.\n\n    Args:\n        doc: The spaCy doc to use to set scope.\n    \"\"\"\n    # If ConText is set to use defined windows, do that instead of sentence splitting\n    if self._max_scope:\n        full_scope_span = doc[self._start : self._end]._.window(\n            n=self.rule.max_scope\n        )\n    # Otherwise, use the sentence\n    else:\n        full_scope_span = doc[self._start].sent\n        if full_scope_span is None:\n            raise ValueError(\n                \"ConText failed because sentence boundaries have not been set. Add an upstream component such as the \"\n                \"dependency parser, Sentencizer, or PyRuSH to detect sentence boundaries or initialize ConText with \"\n                \"`max_scope` set to a value greater than 0.\"\n            )\n\n    if self.direction.lower() == \"forward\":\n        self._scope_start, self._scope_end = self._end, full_scope_span.end\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_end = self._end + self.max_scope\n\n    elif self.direction.lower() == \"backward\":\n        self._scope_start, self._scope_end = (\n            full_scope_span.start,\n            self._start,\n        )\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_start = self._start - self.max_scope\n\n    else:  # bidirectional\n        self._scope_start, self._scope_end = (\n            full_scope_span.start,\n            full_scope_span.end,\n        )\n\n        # Set the max scope on either side\n        # Backwards\n        if (\n            self.max_scope is not None\n            and (self._start - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_start = self._start - self.max_scope\n        # Forwards\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._end) &gt; self.max_scope\n        ):\n            self._scope_end = self._end + self.max_scope\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.allows","title":"<code>allows(target_label)</code>","text":"<p>Returns whether if a modifier is able to modify a target type.</p> <p>Parameters:</p> Name Type Description Default <code>target_label</code> <code>str</code> <p>The target type to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the modifier is allowed to modify a target of the specified type. True if <code>target_label</code> in</p> <code>bool</code> <p><code>self.allowed_types</code> or if <code>target_label</code> not in <code>self.excluded_tupes</code>. False otherwise.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def allows(self, target_label: str) -&gt; bool:\n    \"\"\"\n    Returns whether if a modifier is able to modify a target type.\n\n    Args:\n        target_label: The target type to check.\n\n    Returns:\n        Whether the modifier is allowed to modify a target of the specified type. True if `target_label` in\n        `self.allowed_types` or if `target_label` not in `self.excluded_tupes`. False otherwise.\n    \"\"\"\n    if self.allowed_types is not None:\n        return target_label in self.allowed_types\n    if self.excluded_types is not None:\n        return target_label not in self.excluded_types\n    return True\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Instantiates the class from the serialized representation</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>@classmethod\ndef from_serialized_representation(\n    cls, serialized_representation\n) -&gt; ConTextModifier:\n    \"\"\"\n    Instantiates the class from the serialized representation\n    \"\"\"\n    rule = ConTextRule.from_dict(serialized_representation[\"context_rule\"])\n\n    serialized_representation[\"context_rule\"] = rule\n    serialized_representation[\"doc\"] = None\n\n    return ConTextModifier(**serialized_representation)\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.limit_scope","title":"<code>limit_scope(other)</code>","text":"<p>If self and other have the same category or if other has a directionality of 'terminate', use the span of other to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not 'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of CHF, but there is pneumonia'</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ConTextModifier</code> <p>The modifier to check against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the other modifier modified the scope of self.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def limit_scope(self, other: ConTextModifier) -&gt; bool:\n    \"\"\"\n    If self and other have the same category or if other has a directionality of 'terminate', use the span of other\n    to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of\n    modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not\n    'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of\n    CHF, but there is pneumonia'\n\n    Args:\n        other: The modifier to check against.\n\n    Returns:\n        Whether the other modifier modified the scope of self.\n    \"\"\"\n    if not tuple_overlaps(self.scope_span, other.scope_span):\n        return False\n    if self.direction.upper() == \"TERMINATE\":\n        return False\n    # Check if the other modifier is a type which can modify self\n    # or if they are the same category. If not, don't reduce scope.\n    if (\n        (other.direction.upper() != \"TERMINATE\")\n        and (other.category.upper() not in self.rule.terminated_by)\n        and (other.category.upper() != self.category.upper())\n    ):\n        return False\n\n    # If two modifiers have the same category but modify different target types,\n    # don't limit scope.\n    if self.category == other.category and (\n        (self.allowed_types != other.allowed_types)\n        or (self.excluded_types != other.excluded_types)\n    ):\n        return False\n\n    orig_scope = self.scope_span\n    if self.direction.lower() in (\"forward\", \"bidirectional\"):\n        if other &gt; self:\n            self._scope_end = min(self._scope_end, other.modifier_span[0])\n    if self.direction.lower() in (\"backward\", \"bidirectional\"):\n        if other &lt; self:\n            self._scope_start = max(self._scope_start, other.modifier_span[1])\n    return orig_scope != self.scope_span\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.modifies","title":"<code>modifies(target)</code>","text":"<p>Checks whether the target is within the modifier scope and if self is allowed to modify target.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>a spaCy span representing a target concept.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the target is within <code>modifier_scope</code> and if self is allowed to modify the target.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def modifies(self, target: Span) -&gt; bool:\n    \"\"\"\n    Checks whether the target is within the modifier scope and if self is allowed to modify target.\n\n    Args:\n        target: a spaCy span representing a target concept.\n\n    Returns:\n        Whether the target is within `modifier_scope` and if self is allowed to modify the target.\n    \"\"\"\n    # If the target and modifier overlap, meaning at least one token\n    # one extracted as both a target and modifier, return False\n    # to avoid self-modifying concepts\n\n    if tuple_overlaps(\n        self.modifier_span, (target.start, target.end)\n    ):  # self.overlaps(target):\n        return False\n    if self.direction in (\"TERMINATE\", \"PSEUDO\"):\n        return False\n    if not self.allows(target.label_.upper()):\n        return False\n\n    if tuple_overlaps(self.scope_span, (target.start, target.end)):\n        if not self.on_modifies(target):\n            return False\n        else:\n            return True\n    return False\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.modify","title":"<code>modify(target)</code>","text":"<p>Add target to the list of self._targets and increment self._num_targets.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>The spaCy span to add.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def modify(self, target: Span):\n    \"\"\"\n    Add target to the list of self._targets and increment self._num_targets.\n\n    Args:\n        target: The spaCy span to add.\n    \"\"\"\n    self._targets.append(target)\n    self._num_targets += 1\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.on_modifies","title":"<code>on_modifies(target)</code>","text":"<p>If the ConTextRule used to define a ConTextModifier has an <code>on_modifies</code> callback function, evaluate and return either True or False.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>The spaCy span to evaluate.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>The result of the <code>on_modifies</code> callback for the rule. True if the callback is None.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def on_modifies(self, target: Span) -&gt; bool:\n    \"\"\"\n    If the ConTextRule used to define a ConTextModifier has an `on_modifies` callback function, evaluate and return\n    either True or False.\n\n    Args:\n        target: The spaCy span to evaluate.\n\n    Returns:\n        The result of the `on_modifies` callback for the rule. True if the callback is None.\n    \"\"\"\n    if self.rule.on_modifies is None:\n        return True\n    # Find the span in between the target and modifier\n    start = min(target.end, self._end)\n    end = max(target.start, self._end)\n    span_between = target.doc[start:end]\n    rslt = self.rule.on_modifies(\n        target, target.doc[self._start : self._end], span_between\n    )\n    if rslt not in (True, False):\n        raise ValueError(\n            \"The on_modifies function must return either True or False indicating \"\n            \"whether a modify modifies a target. Actual value: {0}\".format(rslt)\n        )\n    return rslt\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.reduce_targets","title":"<code>reduce_targets()</code>","text":"<p>Reduces the number of targets to the n-closest targets based on the value of <code>self.max_targets</code>. If <code>self.max_targets</code> is None, no pruning is done.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def reduce_targets(self):\n    \"\"\"\n    Reduces the number of targets to the n-closest targets based on the value of `self.max_targets`. If\n    `self.max_targets` is None, no pruning is done.\n    \"\"\"\n    if self.max_targets is None or self.num_targets &lt;= self.max_targets:\n        return\n\n    target_dists = []\n    for target in self._targets:\n        dist = min(abs(self._start - target.end), abs(target.start - self._end))\n        target_dists.append((target, dist))\n    srtd_targets, _ = zip(*sorted(target_dists, key=lambda x: x[1]))\n    self._targets = srtd_targets[: self.max_targets]\n    self._num_targets = len(self._targets)\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Serialized Representation of the modifier</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def serialized_representation(self):\n    \"\"\"\n    Serialized Representation of the modifier\n    \"\"\"\n    dict_repr = dict()\n    dict_repr[\"context_rule\"] = self.rule.to_dict()\n    dict_repr[\"start\"] = self._start\n    dict_repr[\"end\"] = self._end\n    dict_repr[\"max_scope\"] = self._max_scope\n    dict_repr[\"scope_start\"] = self._scope_start\n    dict_repr[\"scope_end\"] = self._scope_end\n\n    return dict_repr\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextModifier.update_scope","title":"<code>update_scope(span)</code>","text":"<p>Changes the scope of self to be the given spaCy span.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>a spaCy Span which contains the scope which a modifier should cover.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def update_scope(self, span: Span):\n    \"\"\"\n    Changes the scope of self to be the given spaCy span.\n\n    Args:\n        span: a spaCy Span which contains the scope which a modifier should cover.\n    \"\"\"\n    self._scope_start = span.start\n    self._scope_end = span.end\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextRule","title":"<code>ConTextRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>A ConTextRule defines a ConText modifier. ConTextRules are rules which define which spans are extracted as modifiers and how they behave, such as the phrase to be matched, the category/semantic class, the direction of the modifier in the text, and what types of target spans can be modified.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>class ConTextRule(BaseRule):\n    \"\"\"\n    A ConTextRule defines a ConText modifier. ConTextRules are rules which define which spans are extracted as modifiers\n    and how they behave, such as the phrase to be matched, the category/semantic class, the direction of the modifier in\n    the text, and what types of target spans can be modified.\n    \"\"\"\n\n    _ALLOWED_DIRECTIONS = (\n        \"FORWARD\",\n        \"BACKWARD\",\n        \"BIDIRECTIONAL\",\n        \"TERMINATE\",\n        \"PSEUDO\"\n    )\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"direction\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"allowed_types\",\n        \"excluded_types\",\n        \"max_targets\",\n        \"max_scope\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n        direction: str = \"BIDIRECTIONAL\",\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        on_modifies: Optional[Callable[[Span, Span, Span], bool]] = None,\n        allowed_types: Optional[Set[str]] = None,\n        excluded_types: Optional[Set[str]] = None,\n        max_scope: Optional[int] = None,\n        max_targets: Optional[int] = None,\n        terminated_by: Optional[Set[str]] = None,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Creates a ConTextRule object.\n\n        The primary arguments of `literal` `category`, and `direction` define the span of text to be matched, the\n        semantic category, and the direction within the sentence in which the modifier operates.\n        Other arguments specify additional custom logic such as:\n            - Additional control over what text can be matched as a modifier (pattern and on_match)\n            - Which types of targets can be modified (allowed_types, excluded_types)\n            - The scope size and number of targets that a modifier can modify (max_targets, max_scope)\n            - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,\n            terminated_by)\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            direction: The directionality or action of a modifier. This defines which part of a sentence a modifier will\n                include as its scope. Entities within the scope will be considered to be modified.\n                Valid values are:\n                - \"FORWARD\": Scope will begin after the end of a modifier and move to the right\n                - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left\n                - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier\n                - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:\n                    \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying\n                    \"pneumonia\"\n                - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating\n                    superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the\n                    phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a\n                    modifier.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            on_modifies: Callback function to run when building an edge between a target and a modifier. This allows\n                specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The\n                callable should take 3 arguments:\n                    target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')\n                    modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')\n                    span_between: The Span between the target and modifier in question.\n                Should return either True or False. If returns False, then the modifier will not modify the target.\n            allowed_types: A collection of target labels to allow a modifier to modify. If None, will apply to any type\n                not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used.\n                An error will be thrown if both are not None.\n            excluded_types: A collection of target labels which this modifier cannot modify. If None, will apply to all\n                target types unless allowed_types is not None.\n            max_scope: A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will\n                include the entire sentence in the direction of `direction` and the entire sentence for \"BIDIRECTIONAL\".\n                This is useful for requiring modifiers be very close to a concept in the text or for preventing long\n                modifier ranges caused by sentence splitting problems.\n            max_targets: The maximum number of targets which a modifier can modify. If None, will modify all targets in\n                its scope.\n            terminated_by: An optional collection of other modifier categories which will terminate the scope of this\n                modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has\n                terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the\n                positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\".\n                This helps prevent multiple conflicting modifiers from distributing too far across a sentence.\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category.upper(), pattern, on_match, metadata)\n        self.on_modifies = on_modifies\n\n        if allowed_types is not None and excluded_types is not None:\n            raise ValueError(\n                \"A ConTextRule was instantiated with non-null values for both allowed_types and excluded_types. \"\n                \"Only one of these can be non-null.\"\n            )\n        if allowed_types is not None:\n            self.allowed_types = {label.upper() for label in allowed_types}\n        else:\n            self.allowed_types = None\n        if excluded_types is not None:\n            self.excluded_types = {label.upper() for label in excluded_types}\n        else:\n            self.excluded_types = None\n\n        if max_targets is not None and max_targets &lt;= 0:\n            raise ValueError(\"max_targets must be &gt;= 0 or None.\")\n        self.max_targets = max_targets\n        if max_scope is not None and max_scope &lt;= 0:\n            raise ValueError(\"max_scope must be &gt;= 0 or None.\")\n        self.max_scope = max_scope\n        if terminated_by is None:\n            terminated_by = set()\n        else:\n            if isinstance(terminated_by, str):\n                raise ValueError(\n                    f\"terminated_by must be an iterable, such as a list or set, not {terminated_by}.\"\n                )\n            terminated_by = {string.upper() for string in terminated_by}\n\n        self.terminated_by = terminated_by\n\n        self.metadata = metadata\n\n        if direction.upper() not in self._ALLOWED_DIRECTIONS:\n            raise ValueError(\n                \"Direction {0} not recognized. Must be one of: {1}\".format(\n                    direction, self._ALLOWED_DIRECTIONS\n                )\n            )\n        self.direction = direction.upper()\n\n    @classmethod\n    def from_json(cls, filepath) -&gt; List[ConTextRule]:\n        \"\"\"\n        Reads in a lexicon of modifiers from a JSON file under the key `context_rules`.\n\n        Args:\n            filepath: The .json file containing modifier rules. Must contain `context_rules` key containing the rule\n                JSONs.\n\n        Returns:\n            A list of ConTextRules objects read from the JSON.\n        \"\"\"\n\n        with open(filepath) as file:\n            modifier_data = json.load(file)\n        context_rules = []\n        for data in modifier_data[\"context_rules\"]:\n            context_rules.append(ConTextRule.from_dict(data))\n        return context_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict) -&gt; ConTextRule:\n        \"\"\"\n        Reads a dictionary into a ConTextRule.\n\n        Args:\n            rule_dict: The dictionary to convert.\n\n        Returns:\n            The ConTextRule created from the dictionary.\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                \"JSON object contains invalid keys: {0}.\\n\"\n                \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n            )\n            raise ValueError(msg)\n        rule = ConTextRule(**rule_dict)\n        return rule\n\n    def to_dict(self):\n        \"\"\"\n        Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.\n\n        Returns:\n            The dictionary containing the ConTextRule info.\n        \"\"\"\n\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if isinstance(value, set):\n                value = list(value)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    @classmethod\n    def to_json(cls, context_rules: List[ConTextRule], filepath: str):\n        \"\"\"Writes ConTextItems to a json file.\n\n            Args:\n            context_rules: a list of ContextRules that will be written to a file.\n            filepath: the .json file to contain modifier rules\n        \"\"\"\n        import json\n\n        data = {\"context_rules\": [rule.to_dict() for rule in context_rules]}\n        with open(filepath, \"w\") as file:\n            json.dump(data, file, indent=4)\n\n    def __repr__(self):\n        return (\n            f\"ConTextRule(literal='{self.literal}', category='{self.category}', pattern={self.pattern}, \"\n            f\"direction='{self.direction}')\"\n        )\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextRule.__init__","title":"<code>__init__(literal, category, pattern=None, direction='BIDIRECTIONAL', on_match=None, on_modifies=None, allowed_types=None, excluded_types=None, max_scope=None, max_targets=None, terminated_by=None, metadata=None)</code>","text":"<p>Creates a ConTextRule object.</p> <p>The primary arguments of <code>literal</code> <code>category</code>, and <code>direction</code> define the span of text to be matched, the semantic category, and the direction within the sentence in which the modifier operates. Other arguments specify additional custom logic such as:     - Additional control over what text can be matched as a modifier (pattern and on_match)     - Which types of targets can be modified (allowed_types, excluded_types)     - The scope size and number of targets that a modifier can modify (max_targets, max_scope)     - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,     terminated_by)</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[str, List[Dict[str, str]]]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>direction</code> <code>str</code> <p>The directionality or action of a modifier. This defines which part of a sentence a modifier will include as its scope. Entities within the scope will be considered to be modified. Valid values are: - \"FORWARD\": Scope will begin after the end of a modifier and move to the right - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:     \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying     \"pneumonia\" - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating     superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the     phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a     modifier.</p> <code>'BIDIRECTIONAL'</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>on_modifies</code> <code>Optional[Callable[[Span, Span, Span], bool]]</code> <p>Callback function to run when building an edge between a target and a modifier. This allows specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The callable should take 3 arguments:     target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')     modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')     span_between: The Span between the target and modifier in question. Should return either True or False. If returns False, then the modifier will not modify the target.</p> <code>None</code> <code>allowed_types</code> <code>Optional[Set[str]]</code> <p>A collection of target labels to allow a modifier to modify. If None, will apply to any type not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used. An error will be thrown if both are not None.</p> <code>None</code> <code>excluded_types</code> <code>Optional[Set[str]]</code> <p>A collection of target labels which this modifier cannot modify. If None, will apply to all target types unless allowed_types is not None.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will include the entire sentence in the direction of <code>direction</code> and the entire sentence for \"BIDIRECTIONAL\". This is useful for requiring modifiers be very close to a concept in the text or for preventing long modifier ranges caused by sentence splitting problems.</p> <code>None</code> <code>max_targets</code> <code>Optional[int]</code> <p>The maximum number of targets which a modifier can modify. If None, will modify all targets in its scope.</p> <code>None</code> <code>terminated_by</code> <code>Optional[Set[str]]</code> <p>An optional collection of other modifier categories which will terminate the scope of this modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\". This helps prevent multiple conflicting modifiers from distributing too far across a sentence.</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n    direction: str = \"BIDIRECTIONAL\",\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    on_modifies: Optional[Callable[[Span, Span, Span], bool]] = None,\n    allowed_types: Optional[Set[str]] = None,\n    excluded_types: Optional[Set[str]] = None,\n    max_scope: Optional[int] = None,\n    max_targets: Optional[int] = None,\n    terminated_by: Optional[Set[str]] = None,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Creates a ConTextRule object.\n\n    The primary arguments of `literal` `category`, and `direction` define the span of text to be matched, the\n    semantic category, and the direction within the sentence in which the modifier operates.\n    Other arguments specify additional custom logic such as:\n        - Additional control over what text can be matched as a modifier (pattern and on_match)\n        - Which types of targets can be modified (allowed_types, excluded_types)\n        - The scope size and number of targets that a modifier can modify (max_targets, max_scope)\n        - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,\n        terminated_by)\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        direction: The directionality or action of a modifier. This defines which part of a sentence a modifier will\n            include as its scope. Entities within the scope will be considered to be modified.\n            Valid values are:\n            - \"FORWARD\": Scope will begin after the end of a modifier and move to the right\n            - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left\n            - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier\n            - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:\n                \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying\n                \"pneumonia\"\n            - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating\n                superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the\n                phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a\n                modifier.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        on_modifies: Callback function to run when building an edge between a target and a modifier. This allows\n            specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The\n            callable should take 3 arguments:\n                target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')\n                modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')\n                span_between: The Span between the target and modifier in question.\n            Should return either True or False. If returns False, then the modifier will not modify the target.\n        allowed_types: A collection of target labels to allow a modifier to modify. If None, will apply to any type\n            not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used.\n            An error will be thrown if both are not None.\n        excluded_types: A collection of target labels which this modifier cannot modify. If None, will apply to all\n            target types unless allowed_types is not None.\n        max_scope: A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will\n            include the entire sentence in the direction of `direction` and the entire sentence for \"BIDIRECTIONAL\".\n            This is useful for requiring modifiers be very close to a concept in the text or for preventing long\n            modifier ranges caused by sentence splitting problems.\n        max_targets: The maximum number of targets which a modifier can modify. If None, will modify all targets in\n            its scope.\n        terminated_by: An optional collection of other modifier categories which will terminate the scope of this\n            modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has\n            terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the\n            positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\".\n            This helps prevent multiple conflicting modifiers from distributing too far across a sentence.\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category.upper(), pattern, on_match, metadata)\n    self.on_modifies = on_modifies\n\n    if allowed_types is not None and excluded_types is not None:\n        raise ValueError(\n            \"A ConTextRule was instantiated with non-null values for both allowed_types and excluded_types. \"\n            \"Only one of these can be non-null.\"\n        )\n    if allowed_types is not None:\n        self.allowed_types = {label.upper() for label in allowed_types}\n    else:\n        self.allowed_types = None\n    if excluded_types is not None:\n        self.excluded_types = {label.upper() for label in excluded_types}\n    else:\n        self.excluded_types = None\n\n    if max_targets is not None and max_targets &lt;= 0:\n        raise ValueError(\"max_targets must be &gt;= 0 or None.\")\n    self.max_targets = max_targets\n    if max_scope is not None and max_scope &lt;= 0:\n        raise ValueError(\"max_scope must be &gt;= 0 or None.\")\n    self.max_scope = max_scope\n    if terminated_by is None:\n        terminated_by = set()\n    else:\n        if isinstance(terminated_by, str):\n            raise ValueError(\n                f\"terminated_by must be an iterable, such as a list or set, not {terminated_by}.\"\n            )\n        terminated_by = {string.upper() for string in terminated_by}\n\n    self.terminated_by = terminated_by\n\n    self.metadata = metadata\n\n    if direction.upper() not in self._ALLOWED_DIRECTIONS:\n        raise ValueError(\n            \"Direction {0} not recognized. Must be one of: {1}\".format(\n                direction, self._ALLOWED_DIRECTIONS\n            )\n        )\n    self.direction = direction.upper()\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a ConTextRule.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <p>The dictionary to convert.</p> required <p>Returns:</p> Type Description <code>ConTextRule</code> <p>The ConTextRule created from the dictionary.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict) -&gt; ConTextRule:\n    \"\"\"\n    Reads a dictionary into a ConTextRule.\n\n    Args:\n        rule_dict: The dictionary to convert.\n\n    Returns:\n        The ConTextRule created from the dictionary.\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            \"JSON object contains invalid keys: {0}.\\n\"\n            \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n        )\n        raise ValueError(msg)\n    rule = ConTextRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Reads in a lexicon of modifiers from a JSON file under the key <code>context_rules</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>The .json file containing modifier rules. Must contain <code>context_rules</code> key containing the rule JSONs.</p> required <p>Returns:</p> Type Description <code>List[ConTextRule]</code> <p>A list of ConTextRules objects read from the JSON.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath) -&gt; List[ConTextRule]:\n    \"\"\"\n    Reads in a lexicon of modifiers from a JSON file under the key `context_rules`.\n\n    Args:\n        filepath: The .json file containing modifier rules. Must contain `context_rules` key containing the rule\n            JSONs.\n\n    Returns:\n        A list of ConTextRules objects read from the JSON.\n    \"\"\"\n\n    with open(filepath) as file:\n        modifier_data = json.load(file)\n    context_rules = []\n    for data in modifier_data[\"context_rules\"]:\n        context_rules.append(ConTextRule.from_dict(data))\n    return context_rules\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.</p> <p>Returns:</p> Type Description <p>The dictionary containing the ConTextRule info.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.\n\n    Returns:\n        The dictionary containing the ConTextRule info.\n    \"\"\"\n\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if isinstance(value, set):\n            value = list(value)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"reference/medspacy/context/#medspacy.context.ConTextRule.to_json","title":"<code>to_json(context_rules, filepath)</code>  <code>classmethod</code>","text":"<p>Writes ConTextItems to a json file.</p> <p>Args: context_rules: a list of ContextRules that will be written to a file. filepath: the .json file to contain modifier rules</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef to_json(cls, context_rules: List[ConTextRule], filepath: str):\n    \"\"\"Writes ConTextItems to a json file.\n\n        Args:\n        context_rules: a list of ContextRules that will be written to a file.\n        filepath: the .json file to contain modifier rules\n    \"\"\"\n    import json\n\n    data = {\"context_rules\": [rule.to_dict() for rule in context_rules]}\n    with open(filepath, \"w\") as file:\n        json.dump(data, file, indent=4)\n</code></pre>"},{"location":"reference/medspacy/context/context/","title":"medspacy.context.context","text":"<p>The ConText definiton.</p>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText","title":"<code>ConText</code>","text":"<p>The ConText for spaCy processing.</p> <p>This component matches modifiers in a Doc, defines their scope, and identifies edges between targets and modifiers. Sets two spaCy extensions:         - Span..modifiers: a list of ConTextModifier objects which modify a target Span         - Doc..context_graph: a ConText graph object which contains the targets,             modifiers, and edges between them.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@Language.factory(\"medspacy_context\")\nclass ConText:\n    \"\"\"\n    The ConText for spaCy processing.\n\n    This component matches modifiers in a Doc, defines their scope, and identifies edges between targets and modifiers.\n    Sets two spaCy extensions:\n            - Span._.modifiers: a list of ConTextModifier objects which modify a target Span\n            - Doc._.context_graph: a ConText graph object which contains the targets,\n                modifiers, and edges between them.\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_context\",\n        rules: Optional[str] = \"default\",\n        language_code: str = 'en',\n        phrase_matcher_attr: str = \"LOWER\",\n        allowed_types: Optional[Set[str]] = None,\n        excluded_types: Optional[Set[str]] = None,\n        terminating_types: Optional[Dict[str, Iterable[str]]] = None,\n        max_scope: Optional[int] = None,\n        max_targets: Optional[int] = None,\n        prune_on_modifier_overlap: bool = True,\n        prune_on_target_overlap: bool = False,\n        span_attrs: Union[\n            Literal[\"default\"], Dict[str, Dict[str, Any]], None\n        ] = \"default\",\n        input_span_type: Union[Literal[\"ents\", \"group\"]] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        \"\"\"\n        Creates a new ConText object.\n\n        Args:\n            nlp: A SpaCy Language object.\n            name: The name of the component.\n            rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n                original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If\n                None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules\n                directly through `ConText.add`.\n            language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n                and also the /resources directory to see which resources might be available in each language.\n                Default is \"en\" for English.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            allowed_types: A global list of types included by context. Rules will operate on only spans with these\n                labels.\n            excluded_types: A global list of types excluded by context. Rules will not operate on spans with these\n                labels.\n            terminating_types: A global map of types to the types that can terminate them. This can be used to apply\n                terminations to all rules of a particular type rather than adding to every rule individually in the\n                ContextRule object.\n            max_scope: The number of tokens around a modifier in a target can be modified. Default value is None,\n                Context will use the sentence boundaries. If a value greater than zero, applies the window globally.\n                Both options will be overridden by a more specific value in a ContextRule.\n            max_targets: The maximum number of targets a modifier can modify. Default value is None, context will modify\n                all targets in its scope. If a value greater than zero, applies this value globally. Both options will\n                be overridden by a more specific value in a ContextRule.\n            prune_on_modifier_overlap: Whether to prune modifiers which are substrings of another modifier. If True,\n                will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both\n                ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify\n                afib. Default True.\n            prune_on_target_overlap: Whether to remove any matched modifiers which overlap with target entities. If\n                False, any overlapping modifiers will not modify the overlapping entity but will still modify any other\n                targets in its scope. Default False.\n            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n                `DEFAULT_ATTRIBUTES`. If a dictionary, format is mapping context modifier categories to a dictionary\n                containing the attribute name and the value to set the attribute to when a  span is modified by a\n                modifier of that category. If None, no attributes will be modified.\n            input_span_type: \"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans\n                in doc.ents. \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n                \"medspacy_spans\".\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self.prune_on_modifier_overlap = prune_on_modifier_overlap\n        self.prune_on_target_overlap = prune_on_target_overlap\n        self.input_span_type = input_span_type\n        self.span_group_name = span_group_name\n        self.context_attributes_mapping = None\n\n        self.DEFAULT_RULES_FILEPATH = path.join(\n            Path(__file__).resolve().parents[2], \"resources\", language_code.lower(), \"context_rules.json\"\n        )\n\n        self.__matcher = MedspacyMatcher(\n            nlp,\n            name=name,\n            phrase_matcher_attr=phrase_matcher_attr,\n            prune=prune_on_modifier_overlap,\n        )\n\n        if span_attrs == \"default\":\n            self.context_attributes_mapping = DEFAULT_ATTRIBUTES\n            self.register_default_attributes()\n        elif span_attrs:\n            for _, attr_dict in span_attrs.items():\n                for attr_name in attr_dict.keys():\n                    if not Span.has_extension(attr_name):\n                        raise ValueError(\n                            f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                            f\"called for your pipeline's custom extensions.\"\n                        )\n            self.context_attributes_mapping = span_attrs\n\n        self.register_graph_attributes()\n\n        if max_scope is not None:\n            if not (isinstance(max_scope, int) and max_scope &gt; 0):\n                raise ValueError(\n                    f\"If 'max_scope' must be a value greater than 0, not the current value: {max_scope}\"\n                )\n        self.max_scope = max_scope\n\n        self.allowed_types = allowed_types\n        self.excluded_types = excluded_types\n        self.max_targets = max_targets\n\n        self.terminating_types = dict()\n        if terminating_types:\n            self.terminating_types = {\n                k.upper(): v for (k, v) in terminating_types.items()\n            }\n\n        rule_path = None\n        if rules == \"default\":\n            rule_path = self.DEFAULT_RULES_FILEPATH\n        else:\n            rule_path = rules\n\n        if rule_path:\n            self.add(ConTextRule.from_json(rule_path))\n\n    @property\n    def rules(self):\n        \"\"\"\n        Returns list of ConTextRules available to context.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def categories(self):\n        \"\"\"\n        Returns list of categories available that Context might produce.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules):\n        \"\"\"\n        Adds ConTextRules to Context.\n\n        Args:\n            rules: A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.\n        \"\"\"\n        if isinstance(rules, ConTextRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, ConTextRule):\n                raise TypeError(f\"Rules must type ConTextRule, not {type(rule)}.\")\n\n            # If global attributes like allowed_types and max_scope are defined,\n            # check if the ConTextRule has them defined. If not, set to the global\n            for attr in (\n                \"allowed_types\",\n                \"excluded_types\",\n                \"max_scope\",\n                \"max_targets\",\n            ):\n                value = getattr(self, attr)\n                if value is None:  # No global value set\n                    continue\n                if (\n                    getattr(rule, attr) is None\n                ):  # If the direction itself has it defined, don't override\n                    setattr(rule, attr, value)\n\n            # Check custom termination points\n            if rule.category.upper() in self.terminating_types:\n                for other_modifier in self.terminating_types[rule.category.upper()]:\n                    rule.terminated_by.add(other_modifier.upper())\n\n        self.__matcher.add(rules)\n\n    @classmethod\n    def register_graph_attributes(cls):\n        \"\"\"\n        Registers spaCy attribute extensions: Span._.modifiers and Doc._.context_graph.\n        \"\"\"\n        try:\n            Span.set_extension(\"modifiers\", default=(), force=True)\n            Doc.set_extension(\"context_graph\", default=None, force=True)\n        except ValueError:  # Extension already set\n            pass\n\n    @classmethod\n    def register_default_attributes(cls):\n        \"\"\"\n        Registers the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n        \"\"\"\n        for attr_name in [\n            \"is_negated\",\n            \"is_uncertain\",\n            \"is_historical\",\n            \"is_hypothetical\",\n            \"is_family\",\n        ]:\n            try:\n                Span.set_extension(attr_name, default=False)\n            except ValueError:  # Extension already set\n                pass\n\n    def set_context_attributes(self, edges):\n        \"\"\"\n        Adds Span-level attributes to targets with modifiers.\n\n        Args:\n            edges: The edges of the ContextGraph to modify.\n        \"\"\"\n        for (target, modifier) in edges:\n            if modifier.category in self.context_attributes_mapping:\n                attr_dict = self.context_attributes_mapping[modifier.category]\n                for attr_name, attr_value in attr_dict.items():\n                    setattr(target._, attr_name, attr_value)\n\n    def __call__(self, doc, targets: str = None) -&gt; Doc:\n        \"\"\"\n        Applies the ConText algorithm to a Doc.\n\n        Args:\n            doc: The spaCy Doc to process.\n            targets: The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects\n\n        Returns:\n            The processed spaCy Doc.\n        \"\"\"\n        if not targets and self.input_span_type == \"ents\":\n            targets = doc.ents\n        elif not targets and self.input_span_type == \"group\":\n            targets = doc.spans[self.span_group_name]\n        elif targets:\n            targets = getattr(doc._, targets)\n        # Store data in ConTextGraph object\n        # TODO: move some of this over to ConTextGraph\n        context_graph = ConTextGraph(\n            prune_on_modifier_overlap=self.prune_on_target_overlap\n        )\n\n        context_graph.targets = targets\n\n        context_graph.modifiers = []\n        matches = self.__matcher(doc)\n\n        for (match_id, start, end) in matches:\n            # Get the ConTextRule object defining this modifier\n            rule = self.__matcher.rule_map[self.nlp.vocab[match_id].text]\n            modifier = ConTextModifier(rule, start, end, doc, max_scope=self.max_scope)\n            context_graph.modifiers.append(modifier)\n\n        context_graph.update_scopes()\n        context_graph.apply_modifiers()\n\n        # Link targets to their modifiers\n        for target, modifier in context_graph.edges:\n            target._.modifiers += (modifier,)\n\n        # If attributes need to be modified\n        if self.context_attributes_mapping:\n            self.set_context_attributes(context_graph.edges)\n\n        doc._.context_graph = context_graph\n\n        return doc\n</code></pre>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.categories","title":"<code>categories</code>  <code>property</code>","text":"<p>Returns list of categories available that Context might produce.</p>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Returns list of ConTextRules available to context.</p>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.__call__","title":"<code>__call__(doc, targets=None)</code>","text":"<p>Applies the ConText algorithm to a Doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <p>The spaCy Doc to process.</p> required <code>targets</code> <code>str</code> <p>The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects</p> <code>None</code> <p>Returns:</p> Type Description <code>Doc</code> <p>The processed spaCy Doc.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>def __call__(self, doc, targets: str = None) -&gt; Doc:\n    \"\"\"\n    Applies the ConText algorithm to a Doc.\n\n    Args:\n        doc: The spaCy Doc to process.\n        targets: The optional custom attribute extension on doc to run over. Must contain an iterable of Span objects\n\n    Returns:\n        The processed spaCy Doc.\n    \"\"\"\n    if not targets and self.input_span_type == \"ents\":\n        targets = doc.ents\n    elif not targets and self.input_span_type == \"group\":\n        targets = doc.spans[self.span_group_name]\n    elif targets:\n        targets = getattr(doc._, targets)\n    # Store data in ConTextGraph object\n    # TODO: move some of this over to ConTextGraph\n    context_graph = ConTextGraph(\n        prune_on_modifier_overlap=self.prune_on_target_overlap\n    )\n\n    context_graph.targets = targets\n\n    context_graph.modifiers = []\n    matches = self.__matcher(doc)\n\n    for (match_id, start, end) in matches:\n        # Get the ConTextRule object defining this modifier\n        rule = self.__matcher.rule_map[self.nlp.vocab[match_id].text]\n        modifier = ConTextModifier(rule, start, end, doc, max_scope=self.max_scope)\n        context_graph.modifiers.append(modifier)\n\n    context_graph.update_scopes()\n    context_graph.apply_modifiers()\n\n    # Link targets to their modifiers\n    for target, modifier in context_graph.edges:\n        target._.modifiers += (modifier,)\n\n    # If attributes need to be modified\n    if self.context_attributes_mapping:\n        self.set_context_attributes(context_graph.edges)\n\n    doc._.context_graph = context_graph\n\n    return doc\n</code></pre>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.__init__","title":"<code>__init__(nlp, name='medspacy_context', rules='default', language_code='en', phrase_matcher_attr='LOWER', allowed_types=None, excluded_types=None, terminating_types=None, max_scope=None, max_targets=None, prune_on_modifier_overlap=True, prune_on_target_overlap=False, span_attrs='default', input_span_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Creates a new ConText object.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A SpaCy Language object.</p> required <code>name</code> <code>str</code> <p>The name of the component.</p> <code>'medspacy_context'</code> <code>rules</code> <code>Optional[str]</code> <p>The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules directly through <code>ConText.add</code>.</p> <code>'default'</code> <code>language_code</code> <code>str</code> <p>Language code to use (ISO code) as a default for loading resources.  See documentation and also the /resources directory to see which resources might be available in each language. Default is \"en\" for English.</p> <code>'en'</code> <code>phrase_matcher_attr</code> <code>str</code> <p>The token attribute to use for PhraseMatcher for rules where <code>pattern</code> is None. Default is 'LOWER'.</p> <code>'LOWER'</code> <code>allowed_types</code> <code>Optional[Set[str]]</code> <p>A global list of types included by context. Rules will operate on only spans with these labels.</p> <code>None</code> <code>excluded_types</code> <code>Optional[Set[str]]</code> <p>A global list of types excluded by context. Rules will not operate on spans with these labels.</p> <code>None</code> <code>terminating_types</code> <code>Optional[Dict[str, Iterable[str]]]</code> <p>A global map of types to the types that can terminate them. This can be used to apply terminations to all rules of a particular type rather than adding to every rule individually in the ContextRule object.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>The number of tokens around a modifier in a target can be modified. Default value is None, Context will use the sentence boundaries. If a value greater than zero, applies the window globally. Both options will be overridden by a more specific value in a ContextRule.</p> <code>None</code> <code>max_targets</code> <code>Optional[int]</code> <p>The maximum number of targets a modifier can modify. Default value is None, context will modify all targets in its scope. If a value greater than zero, applies this value globally. Both options will be overridden by a more specific value in a ContextRule.</p> <code>None</code> <code>prune_on_modifier_overlap</code> <code>bool</code> <p>Whether to prune modifiers which are substrings of another modifier. If True, will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify afib. Default True.</p> <code>True</code> <code>prune_on_target_overlap</code> <code>bool</code> <p>Whether to remove any matched modifiers which overlap with target entities. If False, any overlapping modifiers will not modify the overlapping entity but will still modify any other targets in its scope. Default False.</p> <code>False</code> <code>span_attrs</code> <code>Union[Literal['default'], Dict[str, Dict[str, Any]], None]</code> <p>The optional span attributes to modify. Default option \"default\" uses attributes in <code>DEFAULT_ATTRIBUTES</code>. If a dictionary, format is mapping context modifier categories to a dictionary containing the attribute name and the value to set the attribute to when a  span is modified by a modifier of that category. If None, no attributes will be modified.</p> <code>'default'</code> <code>input_span_type</code> <code>Union[Literal['ents', 'group']]</code> <p>\"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans in doc.ents. \"group\" will modify attributes of spans in the span group specified by <code>span_group_name</code>.</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>The name of the span group used when <code>input_span_type</code> is \"group\". Default is \"medspacy_spans\".</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/context/context.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_context\",\n    rules: Optional[str] = \"default\",\n    language_code: str = 'en',\n    phrase_matcher_attr: str = \"LOWER\",\n    allowed_types: Optional[Set[str]] = None,\n    excluded_types: Optional[Set[str]] = None,\n    terminating_types: Optional[Dict[str, Iterable[str]]] = None,\n    max_scope: Optional[int] = None,\n    max_targets: Optional[int] = None,\n    prune_on_modifier_overlap: bool = True,\n    prune_on_target_overlap: bool = False,\n    span_attrs: Union[\n        Literal[\"default\"], Dict[str, Dict[str, Any]], None\n    ] = \"default\",\n    input_span_type: Union[Literal[\"ents\", \"group\"]] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Creates a new ConText object.\n\n    Args:\n        nlp: A SpaCy Language object.\n        name: The name of the component.\n        rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n            original ConText rules and years of practical applications at the US Department of Veterans Affairs.  If\n            None, no rules are loaded. Otherwise, must be a path to a json file containing rules. Add ConTextRules\n            directly through `ConText.add`.\n        language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        allowed_types: A global list of types included by context. Rules will operate on only spans with these\n            labels.\n        excluded_types: A global list of types excluded by context. Rules will not operate on spans with these\n            labels.\n        terminating_types: A global map of types to the types that can terminate them. This can be used to apply\n            terminations to all rules of a particular type rather than adding to every rule individually in the\n            ContextRule object.\n        max_scope: The number of tokens around a modifier in a target can be modified. Default value is None,\n            Context will use the sentence boundaries. If a value greater than zero, applies the window globally.\n            Both options will be overridden by a more specific value in a ContextRule.\n        max_targets: The maximum number of targets a modifier can modify. Default value is None, context will modify\n            all targets in its scope. If a value greater than zero, applies this value globally. Both options will\n            be overridden by a more specific value in a ContextRule.\n        prune_on_modifier_overlap: Whether to prune modifiers which are substrings of another modifier. If True,\n            will drop substrings completely. For example, if \"no history of\"  and \"history of\" are both\n            ConTextRules,both will match the text \"no history of afib\", but only \"no  history of\" should modify\n            afib. Default True.\n        prune_on_target_overlap: Whether to remove any matched modifiers which overlap with target entities. If\n            False, any overlapping modifiers will not modify the overlapping entity but will still modify any other\n            targets in its scope. Default False.\n        span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n            `DEFAULT_ATTRIBUTES`. If a dictionary, format is mapping context modifier categories to a dictionary\n            containing the attribute name and the value to set the attribute to when a  span is modified by a\n            modifier of that category. If None, no attributes will be modified.\n        input_span_type: \"ents\" or \"group\". Where to look for targets. \"ents\" will modify attributes of spans\n            in doc.ents. \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n            \"medspacy_spans\".\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self.prune_on_modifier_overlap = prune_on_modifier_overlap\n    self.prune_on_target_overlap = prune_on_target_overlap\n    self.input_span_type = input_span_type\n    self.span_group_name = span_group_name\n    self.context_attributes_mapping = None\n\n    self.DEFAULT_RULES_FILEPATH = path.join(\n        Path(__file__).resolve().parents[2], \"resources\", language_code.lower(), \"context_rules.json\"\n    )\n\n    self.__matcher = MedspacyMatcher(\n        nlp,\n        name=name,\n        phrase_matcher_attr=phrase_matcher_attr,\n        prune=prune_on_modifier_overlap,\n    )\n\n    if span_attrs == \"default\":\n        self.context_attributes_mapping = DEFAULT_ATTRIBUTES\n        self.register_default_attributes()\n    elif span_attrs:\n        for _, attr_dict in span_attrs.items():\n            for attr_name in attr_dict.keys():\n                if not Span.has_extension(attr_name):\n                    raise ValueError(\n                        f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                        f\"called for your pipeline's custom extensions.\"\n                    )\n        self.context_attributes_mapping = span_attrs\n\n    self.register_graph_attributes()\n\n    if max_scope is not None:\n        if not (isinstance(max_scope, int) and max_scope &gt; 0):\n            raise ValueError(\n                f\"If 'max_scope' must be a value greater than 0, not the current value: {max_scope}\"\n            )\n    self.max_scope = max_scope\n\n    self.allowed_types = allowed_types\n    self.excluded_types = excluded_types\n    self.max_targets = max_targets\n\n    self.terminating_types = dict()\n    if terminating_types:\n        self.terminating_types = {\n            k.upper(): v for (k, v) in terminating_types.items()\n        }\n\n    rule_path = None\n    if rules == \"default\":\n        rule_path = self.DEFAULT_RULES_FILEPATH\n    else:\n        rule_path = rules\n\n    if rule_path:\n        self.add(ConTextRule.from_json(rule_path))\n</code></pre>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.add","title":"<code>add(rules)</code>","text":"<p>Adds ConTextRules to Context.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <p>A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.</p> required Source code in <code>medspacy/context/context.py</code> <pre><code>def add(self, rules):\n    \"\"\"\n    Adds ConTextRules to Context.\n\n    Args:\n        rules: A single ConTextRule or a collection of ConTextRules to add to the Sectionizer.\n    \"\"\"\n    if isinstance(rules, ConTextRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, ConTextRule):\n            raise TypeError(f\"Rules must type ConTextRule, not {type(rule)}.\")\n\n        # If global attributes like allowed_types and max_scope are defined,\n        # check if the ConTextRule has them defined. If not, set to the global\n        for attr in (\n            \"allowed_types\",\n            \"excluded_types\",\n            \"max_scope\",\n            \"max_targets\",\n        ):\n            value = getattr(self, attr)\n            if value is None:  # No global value set\n                continue\n            if (\n                getattr(rule, attr) is None\n            ):  # If the direction itself has it defined, don't override\n                setattr(rule, attr, value)\n\n        # Check custom termination points\n        if rule.category.upper() in self.terminating_types:\n            for other_modifier in self.terminating_types[rule.category.upper()]:\n                rule.terminated_by.add(other_modifier.upper())\n\n    self.__matcher.add(rules)\n</code></pre>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.register_default_attributes","title":"<code>register_default_attributes()</code>  <code>classmethod</code>","text":"<p>Registers the default values for the Span attributes defined in <code>DEFAULT_ATTRIBUTES</code>.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@classmethod\ndef register_default_attributes(cls):\n    \"\"\"\n    Registers the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n    \"\"\"\n    for attr_name in [\n        \"is_negated\",\n        \"is_uncertain\",\n        \"is_historical\",\n        \"is_hypothetical\",\n        \"is_family\",\n    ]:\n        try:\n            Span.set_extension(attr_name, default=False)\n        except ValueError:  # Extension already set\n            pass\n</code></pre>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.register_graph_attributes","title":"<code>register_graph_attributes()</code>  <code>classmethod</code>","text":"<p>Registers spaCy attribute extensions: Span..modifiers and Doc..context_graph.</p> Source code in <code>medspacy/context/context.py</code> <pre><code>@classmethod\ndef register_graph_attributes(cls):\n    \"\"\"\n    Registers spaCy attribute extensions: Span._.modifiers and Doc._.context_graph.\n    \"\"\"\n    try:\n        Span.set_extension(\"modifiers\", default=(), force=True)\n        Doc.set_extension(\"context_graph\", default=None, force=True)\n    except ValueError:  # Extension already set\n        pass\n</code></pre>"},{"location":"reference/medspacy/context/context/#medspacy.context.context.ConText.set_context_attributes","title":"<code>set_context_attributes(edges)</code>","text":"<p>Adds Span-level attributes to targets with modifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <p>The edges of the ContextGraph to modify.</p> required Source code in <code>medspacy/context/context.py</code> <pre><code>def set_context_attributes(self, edges):\n    \"\"\"\n    Adds Span-level attributes to targets with modifiers.\n\n    Args:\n        edges: The edges of the ContextGraph to modify.\n    \"\"\"\n    for (target, modifier) in edges:\n        if modifier.category in self.context_attributes_mapping:\n            attr_dict = self.context_attributes_mapping[modifier.category]\n            for attr_name, attr_value in attr_dict.items():\n                setattr(target._, attr_name, attr_value)\n</code></pre>"},{"location":"reference/medspacy/context/context_graph/","title":"medspacy.context.context_graph","text":""},{"location":"reference/medspacy/context/context_graph/#medspacy.context.context_graph.ConTextGraph","title":"<code>ConTextGraph</code>","text":"<p>The ConTextGraph class defines the internal structure of the ConText algorithm. It stores a collection of modifiers, matched with ConTextRules, and targets from some other source such as the TargetMatcher or a spaCy NER model.</p> <p>Each modifier can have some number of associated targets that it modifies. This relationship is stored as edges of of the graph.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>class ConTextGraph:\n    \"\"\"\n    The ConTextGraph class defines the internal structure of the ConText algorithm. It stores a collection of modifiers,\n    matched with ConTextRules, and targets from some other source such as the TargetMatcher or a spaCy NER model.\n\n    Each modifier can have some number of associated targets that it modifies. This relationship is stored as edges of\n    of the graph.\n    \"\"\"\n\n    def __init__(\n        self,\n        targets: Optional[List[Span]] = None,\n        modifiers: Optional[List[ConTextModifier]] = None,\n        edges: Optional[List] = None,\n        prune_on_modifier_overlap: bool = False,\n    ):\n        \"\"\"\n        Creates a new ConTextGraph object.\n\n        Args:\n            targets: A spans that context might modify.\n            modifiers: A list of ConTextModifiers that might modify the targets.\n            edges: A list of edges between targets and modifiers representing the modification relationship.\n            prune_on_modifier_overlap: Whether to prune modifiers when one modifier completely covers another.\n        \"\"\"\n        self.targets = targets if targets is not None else []\n        self.modifiers = modifiers if modifiers is not None else []\n        self.edges = edges if edges is not None else []\n        self.prune_on_modifier_overlap = prune_on_modifier_overlap\n\n    def update_scopes(self):\n        \"\"\"\n        Update the scope of all ConTextModifier.\n\n        For each modifier in a list of ConTextModifiers, check against each other\n        modifier to see if one of the modifiers should update the other.\n        This allows neighboring similar modifiers to extend each other's\n        scope and allows \"terminate\" modifiers to end a modifier's scope.\n        \"\"\"\n        for i in range(len(self.modifiers) - 1):\n            modifier1 = self.modifiers[i]\n            for j in range(i + 1, len(self.modifiers)):\n                modifier2 = self.modifiers[j]\n                # TODO: Add modifier -&gt; modifier edges\n                modifier1.limit_scope(modifier2)\n                modifier2.limit_scope(modifier1)\n\n    def apply_modifiers(self):\n        \"\"\"\n        Checks each target/modifier pair. If modifier modifies target,\n        create an edge between them.\n        \"\"\"\n        if self.prune_on_modifier_overlap:\n            for i in range(len(self.modifiers) - 1, -1, -1):\n                modifier = self.modifiers[i]\n                for target in self.targets:\n                    if tuple_overlaps(\n                        (target.start, target.end), modifier.modifier_span\n                    ):\n                        self.modifiers.pop(i)\n                        break\n\n        edges = []\n        for target in self.targets:\n            for modifier in self.modifiers:\n                if modifier.modifies(target):\n                    modifier.modify(target)\n\n        # Now do a second pass and reduce the number of targets\n        # for any modifiers with a max_targets int\n        for modifier in self.modifiers:\n            modifier.reduce_targets()\n            for target in modifier._targets:\n                edges.append((target, modifier))\n\n        self.edges = edges\n\n    def __repr__(self):\n        return f\"&lt;ConTextGraph&gt; with {len(self.targets)} targets and {len(self.modifiers)} modifiers\"\n\n    def serialized_representation(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the serialized representation of the ConTextGraph\n        \"\"\"\n        return self.__dict__\n\n    @classmethod\n    def from_serialized_representation(cls, serialized_representation) -&gt; ConTextGraph:\n        \"\"\"\n        Creates the ConTextGraph from the serialized representation\n        \"\"\"\n        context_graph = ConTextGraph(**serialized_representation)\n\n        return context_graph\n</code></pre>"},{"location":"reference/medspacy/context/context_graph/#medspacy.context.context_graph.ConTextGraph.__init__","title":"<code>__init__(targets=None, modifiers=None, edges=None, prune_on_modifier_overlap=False)</code>","text":"<p>Creates a new ConTextGraph object.</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>Optional[List[Span]]</code> <p>A spans that context might modify.</p> <code>None</code> <code>modifiers</code> <code>Optional[List[ConTextModifier]]</code> <p>A list of ConTextModifiers that might modify the targets.</p> <code>None</code> <code>edges</code> <code>Optional[List]</code> <p>A list of edges between targets and modifiers representing the modification relationship.</p> <code>None</code> <code>prune_on_modifier_overlap</code> <code>bool</code> <p>Whether to prune modifiers when one modifier completely covers another.</p> <code>False</code> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def __init__(\n    self,\n    targets: Optional[List[Span]] = None,\n    modifiers: Optional[List[ConTextModifier]] = None,\n    edges: Optional[List] = None,\n    prune_on_modifier_overlap: bool = False,\n):\n    \"\"\"\n    Creates a new ConTextGraph object.\n\n    Args:\n        targets: A spans that context might modify.\n        modifiers: A list of ConTextModifiers that might modify the targets.\n        edges: A list of edges between targets and modifiers representing the modification relationship.\n        prune_on_modifier_overlap: Whether to prune modifiers when one modifier completely covers another.\n    \"\"\"\n    self.targets = targets if targets is not None else []\n    self.modifiers = modifiers if modifiers is not None else []\n    self.edges = edges if edges is not None else []\n    self.prune_on_modifier_overlap = prune_on_modifier_overlap\n</code></pre>"},{"location":"reference/medspacy/context/context_graph/#medspacy.context.context_graph.ConTextGraph.apply_modifiers","title":"<code>apply_modifiers()</code>","text":"<p>Checks each target/modifier pair. If modifier modifies target, create an edge between them.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def apply_modifiers(self):\n    \"\"\"\n    Checks each target/modifier pair. If modifier modifies target,\n    create an edge between them.\n    \"\"\"\n    if self.prune_on_modifier_overlap:\n        for i in range(len(self.modifiers) - 1, -1, -1):\n            modifier = self.modifiers[i]\n            for target in self.targets:\n                if tuple_overlaps(\n                    (target.start, target.end), modifier.modifier_span\n                ):\n                    self.modifiers.pop(i)\n                    break\n\n    edges = []\n    for target in self.targets:\n        for modifier in self.modifiers:\n            if modifier.modifies(target):\n                modifier.modify(target)\n\n    # Now do a second pass and reduce the number of targets\n    # for any modifiers with a max_targets int\n    for modifier in self.modifiers:\n        modifier.reduce_targets()\n        for target in modifier._targets:\n            edges.append((target, modifier))\n\n    self.edges = edges\n</code></pre>"},{"location":"reference/medspacy/context/context_graph/#medspacy.context.context_graph.ConTextGraph.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Creates the ConTextGraph from the serialized representation</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>@classmethod\ndef from_serialized_representation(cls, serialized_representation) -&gt; ConTextGraph:\n    \"\"\"\n    Creates the ConTextGraph from the serialized representation\n    \"\"\"\n    context_graph = ConTextGraph(**serialized_representation)\n\n    return context_graph\n</code></pre>"},{"location":"reference/medspacy/context/context_graph/#medspacy.context.context_graph.ConTextGraph.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Returns the serialized representation of the ConTextGraph</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def serialized_representation(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the serialized representation of the ConTextGraph\n    \"\"\"\n    return self.__dict__\n</code></pre>"},{"location":"reference/medspacy/context/context_graph/#medspacy.context.context_graph.ConTextGraph.update_scopes","title":"<code>update_scopes()</code>","text":"<p>Update the scope of all ConTextModifier.</p> <p>For each modifier in a list of ConTextModifiers, check against each other modifier to see if one of the modifiers should update the other. This allows neighboring similar modifiers to extend each other's scope and allows \"terminate\" modifiers to end a modifier's scope.</p> Source code in <code>medspacy/context/context_graph.py</code> <pre><code>def update_scopes(self):\n    \"\"\"\n    Update the scope of all ConTextModifier.\n\n    For each modifier in a list of ConTextModifiers, check against each other\n    modifier to see if one of the modifiers should update the other.\n    This allows neighboring similar modifiers to extend each other's\n    scope and allows \"terminate\" modifiers to end a modifier's scope.\n    \"\"\"\n    for i in range(len(self.modifiers) - 1):\n        modifier1 = self.modifiers[i]\n        for j in range(i + 1, len(self.modifiers)):\n            modifier2 = self.modifiers[j]\n            # TODO: Add modifier -&gt; modifier edges\n            modifier1.limit_scope(modifier2)\n            modifier2.limit_scope(modifier1)\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/","title":"medspacy.context.context_modifier","text":""},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier","title":"<code>ConTextModifier</code>","text":"<p>Represents a concept found by ConText in a document. An instance of this class is the result of ConTextRule matching text in a Doc.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>class ConTextModifier:\n    \"\"\"\n    Represents a concept found by ConText in a document. An instance of this class is the result of ConTextRule matching\n    text in a Doc.\n    \"\"\"\n\n    def __init__(\n        self,\n        context_rule: ConTextRule,\n        start: int,\n        end: int,\n        doc: Doc,\n        scope_start: Optional[int] = None,\n        scope_end: Optional[int] = None,\n        max_scope: Optional[int] = None,\n    ):\n        \"\"\"\n        Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding\n        window. Spans such as entities or other members of span groups that occur within this window can be modified by\n        this ConTextModifier.\n\n        Args:\n            context_rule: The ConTextRule object which defines the modifier.\n            start: The start token index.\n            end: The end token index (non-inclusive).\n            doc: The spaCy Doc which contains this span. This is needed to initialize the modifier but is not\n                maintained.\n            scope_start: The start token index of the scope.\n            scope_end: The end index of the scope.\n            max_scope: Whether to use scope values rather than sentence boundaries for modifications.\n        \"\"\"\n        self._context_rule = context_rule\n        self._start = start\n        self._end = end\n\n        self._targets = []\n        self._num_targets = 0\n\n        self._max_scope = max_scope\n        self._scope_start = scope_start\n        self._scope_end = scope_end\n        if doc is not None and (self._scope_end is None or self._scope_start is None):\n            self.__set_scope(doc)\n\n    @property\n    def modifier_span(self) -&gt; Tuple[int, int]:\n        \"\"\"\n        The spaCy Span object, which is a view of self.doc, covered by this match.\n        \"\"\"\n        return self._start, self._end\n\n    @property\n    def rule(self) -&gt; ConTextRule:\n        \"\"\"\n        Returns the associated context rule.\n        \"\"\"\n        return self._context_rule\n\n    @property\n    def direction(self) -&gt; str:\n        \"\"\"\n        Returns the associated direction.\n        \"\"\"\n        return self.rule.direction\n\n    @property\n    def category(self) -&gt; str:\n        \"\"\"\n        Returns the associated category.\n        \"\"\"\n        return self.rule.category\n\n    @property\n    def scope_span(self) -&gt; Tuple[int, int]:\n        \"\"\"\n        Returns the associated scope.\n        \"\"\"\n        return self._scope_start, self._scope_end\n\n    @property\n    def allowed_types(self) -&gt; Set[str]:\n        \"\"\"\n        Returns the associated allowed types.\n        \"\"\"\n        return self.rule.allowed_types\n\n    @property\n    def excluded_types(self) -&gt; Set[str]:\n        \"\"\"\n        Returns the associated excluded types.\n        \"\"\"\n        return self.rule.excluded_types\n\n    @property\n    def num_targets(self) -&gt; int:\n        \"\"\"\n        Returns the associated number of targets.\n        \"\"\"\n        return self._num_targets\n\n    @property\n    def max_targets(self) -&gt; Union[int, None]:\n        \"\"\"\n        Returns the associated maximum number of targets.\n        \"\"\"\n        return self.rule.max_targets\n\n    @property\n    def max_scope(self) -&gt; Union[int, None]:\n        \"\"\"\n        Returns the associated maximum scope.\n        \"\"\"\n        return self.rule.max_scope\n\n    def __set_scope(self, doc: Doc):\n        \"\"\"\n        Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If\n        self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by\n        self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the\n        direction is \"backward\", it will be [self.start: sentence.start].\n\n        If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be\n        reduced to self.max_scope.\n\n        Args:\n            doc: The spaCy doc to use to set scope.\n        \"\"\"\n        # If ConText is set to use defined windows, do that instead of sentence splitting\n        if self._max_scope:\n            full_scope_span = doc[self._start : self._end]._.window(\n                n=self.rule.max_scope\n            )\n        # Otherwise, use the sentence\n        else:\n            full_scope_span = doc[self._start].sent\n            if full_scope_span is None:\n                raise ValueError(\n                    \"ConText failed because sentence boundaries have not been set. Add an upstream component such as the \"\n                    \"dependency parser, Sentencizer, or PyRuSH to detect sentence boundaries or initialize ConText with \"\n                    \"`max_scope` set to a value greater than 0.\"\n                )\n\n        if self.direction.lower() == \"forward\":\n            self._scope_start, self._scope_end = self._end, full_scope_span.end\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_end = self._end + self.max_scope\n\n        elif self.direction.lower() == \"backward\":\n            self._scope_start, self._scope_end = (\n                full_scope_span.start,\n                self._start,\n            )\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_start = self._start - self.max_scope\n\n        else:  # bidirectional\n            self._scope_start, self._scope_end = (\n                full_scope_span.start,\n                full_scope_span.end,\n            )\n\n            # Set the max scope on either side\n            # Backwards\n            if (\n                self.max_scope is not None\n                and (self._start - self._scope_start) &gt; self.max_scope\n            ):\n                self._scope_start = self._start - self.max_scope\n            # Forwards\n            if (\n                self.max_scope is not None\n                and (self._scope_end - self._end) &gt; self.max_scope\n            ):\n                self._scope_end = self._end + self.max_scope\n\n    def update_scope(self, span: Span):\n        \"\"\"\n        Changes the scope of self to be the given spaCy span.\n\n        Args:\n            span: a spaCy Span which contains the scope which a modifier should cover.\n        \"\"\"\n        self._scope_start = span.start\n        self._scope_end = span.end\n\n    def limit_scope(self, other: ConTextModifier) -&gt; bool:\n        \"\"\"\n        If self and other have the same category or if other has a directionality of 'terminate', use the span of other\n        to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of\n        modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not\n        'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of\n        CHF, but there is pneumonia'\n\n        Args:\n            other: The modifier to check against.\n\n        Returns:\n            Whether the other modifier modified the scope of self.\n        \"\"\"\n        if not tuple_overlaps(self.scope_span, other.scope_span):\n            return False\n        if self.direction.upper() == \"TERMINATE\":\n            return False\n        # Check if the other modifier is a type which can modify self\n        # or if they are the same category. If not, don't reduce scope.\n        if (\n            (other.direction.upper() != \"TERMINATE\")\n            and (other.category.upper() not in self.rule.terminated_by)\n            and (other.category.upper() != self.category.upper())\n        ):\n            return False\n\n        # If two modifiers have the same category but modify different target types,\n        # don't limit scope.\n        if self.category == other.category and (\n            (self.allowed_types != other.allowed_types)\n            or (self.excluded_types != other.excluded_types)\n        ):\n            return False\n\n        orig_scope = self.scope_span\n        if self.direction.lower() in (\"forward\", \"bidirectional\"):\n            if other &gt; self:\n                self._scope_end = min(self._scope_end, other.modifier_span[0])\n        if self.direction.lower() in (\"backward\", \"bidirectional\"):\n            if other &lt; self:\n                self._scope_start = max(self._scope_start, other.modifier_span[1])\n        return orig_scope != self.scope_span\n\n    def modifies(self, target: Span) -&gt; bool:\n        \"\"\"\n        Checks whether the target is within the modifier scope and if self is allowed to modify target.\n\n        Args:\n            target: a spaCy span representing a target concept.\n\n        Returns:\n            Whether the target is within `modifier_scope` and if self is allowed to modify the target.\n        \"\"\"\n        # If the target and modifier overlap, meaning at least one token\n        # one extracted as both a target and modifier, return False\n        # to avoid self-modifying concepts\n\n        if tuple_overlaps(\n            self.modifier_span, (target.start, target.end)\n        ):  # self.overlaps(target):\n            return False\n        if self.direction in (\"TERMINATE\", \"PSEUDO\"):\n            return False\n        if not self.allows(target.label_.upper()):\n            return False\n\n        if tuple_overlaps(self.scope_span, (target.start, target.end)):\n            if not self.on_modifies(target):\n                return False\n            else:\n                return True\n        return False\n\n    def allows(self, target_label: str) -&gt; bool:\n        \"\"\"\n        Returns whether if a modifier is able to modify a target type.\n\n        Args:\n            target_label: The target type to check.\n\n        Returns:\n            Whether the modifier is allowed to modify a target of the specified type. True if `target_label` in\n            `self.allowed_types` or if `target_label` not in `self.excluded_tupes`. False otherwise.\n        \"\"\"\n        if self.allowed_types is not None:\n            return target_label in self.allowed_types\n        if self.excluded_types is not None:\n            return target_label not in self.excluded_types\n        return True\n\n    def on_modifies(self, target: Span) -&gt; bool:\n        \"\"\"\n        If the ConTextRule used to define a ConTextModifier has an `on_modifies` callback function, evaluate and return\n        either True or False.\n\n        Args:\n            target: The spaCy span to evaluate.\n\n        Returns:\n            The result of the `on_modifies` callback for the rule. True if the callback is None.\n        \"\"\"\n        if self.rule.on_modifies is None:\n            return True\n        # Find the span in between the target and modifier\n        start = min(target.end, self._end)\n        end = max(target.start, self._end)\n        span_between = target.doc[start:end]\n        rslt = self.rule.on_modifies(\n            target, target.doc[self._start : self._end], span_between\n        )\n        if rslt not in (True, False):\n            raise ValueError(\n                \"The on_modifies function must return either True or False indicating \"\n                \"whether a modify modifies a target. Actual value: {0}\".format(rslt)\n            )\n        return rslt\n\n    def modify(self, target: Span):\n        \"\"\"\n        Add target to the list of self._targets and increment self._num_targets.\n\n        Args:\n            target: The spaCy span to add.\n        \"\"\"\n        self._targets.append(target)\n        self._num_targets += 1\n\n    def reduce_targets(self):\n        \"\"\"\n        Reduces the number of targets to the n-closest targets based on the value of `self.max_targets`. If\n        `self.max_targets` is None, no pruning is done.\n        \"\"\"\n        if self.max_targets is None or self.num_targets &lt;= self.max_targets:\n            return\n\n        target_dists = []\n        for target in self._targets:\n            dist = min(abs(self._start - target.end), abs(target.start - self._end))\n            target_dists.append((target, dist))\n        srtd_targets, _ = zip(*sorted(target_dists, key=lambda x: x[1]))\n        self._targets = srtd_targets[: self.max_targets]\n        self._num_targets = len(self._targets)\n\n    def __gt__(self, other: ConTextModifier):\n        return self._start &gt; other.modifier_span[0]\n\n    def __ge__(self, other):\n        return self._start &gt;= other.modifier_span[0]\n\n    def __lt__(self, other):\n        return self._end &lt; other.modifier_span[1]\n\n    def __le__(self, other):\n        return self._end &lt;= other.modifier_span[1]\n\n    def __len__(self):\n        return self._end - self._start\n\n    def __repr__(self):\n        return f\"&lt;ConTextModifier&gt; [{self._start}, {self._end}, {self.category}]\"\n\n    def serialized_representation(self):\n        \"\"\"\n        Serialized Representation of the modifier\n        \"\"\"\n        dict_repr = dict()\n        dict_repr[\"context_rule\"] = self.rule.to_dict()\n        dict_repr[\"start\"] = self._start\n        dict_repr[\"end\"] = self._end\n        dict_repr[\"max_scope\"] = self._max_scope\n        dict_repr[\"scope_start\"] = self._scope_start\n        dict_repr[\"scope_end\"] = self._scope_end\n\n        return dict_repr\n\n    @classmethod\n    def from_serialized_representation(\n        cls, serialized_representation\n    ) -&gt; ConTextModifier:\n        \"\"\"\n        Instantiates the class from the serialized representation\n        \"\"\"\n        rule = ConTextRule.from_dict(serialized_representation[\"context_rule\"])\n\n        serialized_representation[\"context_rule\"] = rule\n        serialized_representation[\"doc\"] = None\n\n        return ConTextModifier(**serialized_representation)\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.allowed_types","title":"<code>allowed_types</code>  <code>property</code>","text":"<p>Returns the associated allowed types.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.category","title":"<code>category</code>  <code>property</code>","text":"<p>Returns the associated category.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.direction","title":"<code>direction</code>  <code>property</code>","text":"<p>Returns the associated direction.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.excluded_types","title":"<code>excluded_types</code>  <code>property</code>","text":"<p>Returns the associated excluded types.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.max_scope","title":"<code>max_scope</code>  <code>property</code>","text":"<p>Returns the associated maximum scope.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.max_targets","title":"<code>max_targets</code>  <code>property</code>","text":"<p>Returns the associated maximum number of targets.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.modifier_span","title":"<code>modifier_span</code>  <code>property</code>","text":"<p>The spaCy Span object, which is a view of self.doc, covered by this match.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.num_targets","title":"<code>num_targets</code>  <code>property</code>","text":"<p>Returns the associated number of targets.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.rule","title":"<code>rule</code>  <code>property</code>","text":"<p>Returns the associated context rule.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.scope_span","title":"<code>scope_span</code>  <code>property</code>","text":"<p>Returns the associated scope.</p>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.__init__","title":"<code>__init__(context_rule, start, end, doc, scope_start=None, scope_end=None, max_scope=None)</code>","text":"<p>Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding window. Spans such as entities or other members of span groups that occur within this window can be modified by this ConTextModifier.</p> <p>Parameters:</p> Name Type Description Default <code>context_rule</code> <code>ConTextRule</code> <p>The ConTextRule object which defines the modifier.</p> required <code>start</code> <code>int</code> <p>The start token index.</p> required <code>end</code> <code>int</code> <p>The end token index (non-inclusive).</p> required <code>doc</code> <code>Doc</code> <p>The spaCy Doc which contains this span. This is needed to initialize the modifier but is not maintained.</p> required <code>scope_start</code> <code>Optional[int]</code> <p>The start token index of the scope.</p> <code>None</code> <code>scope_end</code> <code>Optional[int]</code> <p>The end index of the scope.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>Whether to use scope values rather than sentence boundaries for modifications.</p> <code>None</code> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def __init__(\n    self,\n    context_rule: ConTextRule,\n    start: int,\n    end: int,\n    doc: Doc,\n    scope_start: Optional[int] = None,\n    scope_end: Optional[int] = None,\n    max_scope: Optional[int] = None,\n):\n    \"\"\"\n    Create a new ConTextModifier from a document span. Each modifier represents a span in the text and a surrounding\n    window. Spans such as entities or other members of span groups that occur within this window can be modified by\n    this ConTextModifier.\n\n    Args:\n        context_rule: The ConTextRule object which defines the modifier.\n        start: The start token index.\n        end: The end token index (non-inclusive).\n        doc: The spaCy Doc which contains this span. This is needed to initialize the modifier but is not\n            maintained.\n        scope_start: The start token index of the scope.\n        scope_end: The end index of the scope.\n        max_scope: Whether to use scope values rather than sentence boundaries for modifications.\n    \"\"\"\n    self._context_rule = context_rule\n    self._start = start\n    self._end = end\n\n    self._targets = []\n    self._num_targets = 0\n\n    self._max_scope = max_scope\n    self._scope_start = scope_start\n    self._scope_end = scope_end\n    if doc is not None and (self._scope_end is None or self._scope_start is None):\n        self.__set_scope(doc)\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.__set_scope","title":"<code>__set_scope(doc)</code>","text":"<p>Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the direction is \"backward\", it will be [self.start: sentence.start].</p> <p>If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be reduced to self.max_scope.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy doc to use to set scope.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def __set_scope(self, doc: Doc):\n    \"\"\"\n    Applies the direction of the ConTextRule which generated this ConTextModifier to define a scope. If\n    self._max_scope is None, then the default scope is the sentence which it occurs in whichever direction defined by\n    self.direction. For example, if the direction is \"forward\", the scope will be [self.end: sentence.end]. If the\n    direction is \"backward\", it will be [self.start: sentence.start].\n\n    If self.max_scope is not None and the length of the default scope is longer than self.max_scope, it will be\n    reduced to self.max_scope.\n\n    Args:\n        doc: The spaCy doc to use to set scope.\n    \"\"\"\n    # If ConText is set to use defined windows, do that instead of sentence splitting\n    if self._max_scope:\n        full_scope_span = doc[self._start : self._end]._.window(\n            n=self.rule.max_scope\n        )\n    # Otherwise, use the sentence\n    else:\n        full_scope_span = doc[self._start].sent\n        if full_scope_span is None:\n            raise ValueError(\n                \"ConText failed because sentence boundaries have not been set. Add an upstream component such as the \"\n                \"dependency parser, Sentencizer, or PyRuSH to detect sentence boundaries or initialize ConText with \"\n                \"`max_scope` set to a value greater than 0.\"\n            )\n\n    if self.direction.lower() == \"forward\":\n        self._scope_start, self._scope_end = self._end, full_scope_span.end\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_end = self._end + self.max_scope\n\n    elif self.direction.lower() == \"backward\":\n        self._scope_start, self._scope_end = (\n            full_scope_span.start,\n            self._start,\n        )\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_start = self._start - self.max_scope\n\n    else:  # bidirectional\n        self._scope_start, self._scope_end = (\n            full_scope_span.start,\n            full_scope_span.end,\n        )\n\n        # Set the max scope on either side\n        # Backwards\n        if (\n            self.max_scope is not None\n            and (self._start - self._scope_start) &gt; self.max_scope\n        ):\n            self._scope_start = self._start - self.max_scope\n        # Forwards\n        if (\n            self.max_scope is not None\n            and (self._scope_end - self._end) &gt; self.max_scope\n        ):\n            self._scope_end = self._end + self.max_scope\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.allows","title":"<code>allows(target_label)</code>","text":"<p>Returns whether if a modifier is able to modify a target type.</p> <p>Parameters:</p> Name Type Description Default <code>target_label</code> <code>str</code> <p>The target type to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the modifier is allowed to modify a target of the specified type. True if <code>target_label</code> in</p> <code>bool</code> <p><code>self.allowed_types</code> or if <code>target_label</code> not in <code>self.excluded_tupes</code>. False otherwise.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def allows(self, target_label: str) -&gt; bool:\n    \"\"\"\n    Returns whether if a modifier is able to modify a target type.\n\n    Args:\n        target_label: The target type to check.\n\n    Returns:\n        Whether the modifier is allowed to modify a target of the specified type. True if `target_label` in\n        `self.allowed_types` or if `target_label` not in `self.excluded_tupes`. False otherwise.\n    \"\"\"\n    if self.allowed_types is not None:\n        return target_label in self.allowed_types\n    if self.excluded_types is not None:\n        return target_label not in self.excluded_types\n    return True\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Instantiates the class from the serialized representation</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>@classmethod\ndef from_serialized_representation(\n    cls, serialized_representation\n) -&gt; ConTextModifier:\n    \"\"\"\n    Instantiates the class from the serialized representation\n    \"\"\"\n    rule = ConTextRule.from_dict(serialized_representation[\"context_rule\"])\n\n    serialized_representation[\"context_rule\"] = rule\n    serialized_representation[\"doc\"] = None\n\n    return ConTextModifier(**serialized_representation)\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.limit_scope","title":"<code>limit_scope(other)</code>","text":"<p>If self and other have the same category or if other has a directionality of 'terminate', use the span of other to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not 'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of CHF, but there is pneumonia'</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ConTextModifier</code> <p>The modifier to check against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the other modifier modified the scope of self.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def limit_scope(self, other: ConTextModifier) -&gt; bool:\n    \"\"\"\n    If self and other have the same category or if other has a directionality of 'terminate', use the span of other\n    to update the scope of self. Limiting the scope of two modifiers of the same category reduces the number of\n    modifiers. For example, in 'no evidence of CHF, no pneumonia', 'pneumonia' will only be modified by 'no', not\n    'no evidence of'. 'terminate' modifiers limit the scope of a modifier like 'no evidence of' in 'no evidence of\n    CHF, but there is pneumonia'\n\n    Args:\n        other: The modifier to check against.\n\n    Returns:\n        Whether the other modifier modified the scope of self.\n    \"\"\"\n    if not tuple_overlaps(self.scope_span, other.scope_span):\n        return False\n    if self.direction.upper() == \"TERMINATE\":\n        return False\n    # Check if the other modifier is a type which can modify self\n    # or if they are the same category. If not, don't reduce scope.\n    if (\n        (other.direction.upper() != \"TERMINATE\")\n        and (other.category.upper() not in self.rule.terminated_by)\n        and (other.category.upper() != self.category.upper())\n    ):\n        return False\n\n    # If two modifiers have the same category but modify different target types,\n    # don't limit scope.\n    if self.category == other.category and (\n        (self.allowed_types != other.allowed_types)\n        or (self.excluded_types != other.excluded_types)\n    ):\n        return False\n\n    orig_scope = self.scope_span\n    if self.direction.lower() in (\"forward\", \"bidirectional\"):\n        if other &gt; self:\n            self._scope_end = min(self._scope_end, other.modifier_span[0])\n    if self.direction.lower() in (\"backward\", \"bidirectional\"):\n        if other &lt; self:\n            self._scope_start = max(self._scope_start, other.modifier_span[1])\n    return orig_scope != self.scope_span\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.modifies","title":"<code>modifies(target)</code>","text":"<p>Checks whether the target is within the modifier scope and if self is allowed to modify target.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>a spaCy span representing a target concept.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the target is within <code>modifier_scope</code> and if self is allowed to modify the target.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def modifies(self, target: Span) -&gt; bool:\n    \"\"\"\n    Checks whether the target is within the modifier scope and if self is allowed to modify target.\n\n    Args:\n        target: a spaCy span representing a target concept.\n\n    Returns:\n        Whether the target is within `modifier_scope` and if self is allowed to modify the target.\n    \"\"\"\n    # If the target and modifier overlap, meaning at least one token\n    # one extracted as both a target and modifier, return False\n    # to avoid self-modifying concepts\n\n    if tuple_overlaps(\n        self.modifier_span, (target.start, target.end)\n    ):  # self.overlaps(target):\n        return False\n    if self.direction in (\"TERMINATE\", \"PSEUDO\"):\n        return False\n    if not self.allows(target.label_.upper()):\n        return False\n\n    if tuple_overlaps(self.scope_span, (target.start, target.end)):\n        if not self.on_modifies(target):\n            return False\n        else:\n            return True\n    return False\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.modify","title":"<code>modify(target)</code>","text":"<p>Add target to the list of self._targets and increment self._num_targets.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>The spaCy span to add.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def modify(self, target: Span):\n    \"\"\"\n    Add target to the list of self._targets and increment self._num_targets.\n\n    Args:\n        target: The spaCy span to add.\n    \"\"\"\n    self._targets.append(target)\n    self._num_targets += 1\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.on_modifies","title":"<code>on_modifies(target)</code>","text":"<p>If the ConTextRule used to define a ConTextModifier has an <code>on_modifies</code> callback function, evaluate and return either True or False.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Span</code> <p>The spaCy span to evaluate.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>The result of the <code>on_modifies</code> callback for the rule. True if the callback is None.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def on_modifies(self, target: Span) -&gt; bool:\n    \"\"\"\n    If the ConTextRule used to define a ConTextModifier has an `on_modifies` callback function, evaluate and return\n    either True or False.\n\n    Args:\n        target: The spaCy span to evaluate.\n\n    Returns:\n        The result of the `on_modifies` callback for the rule. True if the callback is None.\n    \"\"\"\n    if self.rule.on_modifies is None:\n        return True\n    # Find the span in between the target and modifier\n    start = min(target.end, self._end)\n    end = max(target.start, self._end)\n    span_between = target.doc[start:end]\n    rslt = self.rule.on_modifies(\n        target, target.doc[self._start : self._end], span_between\n    )\n    if rslt not in (True, False):\n        raise ValueError(\n            \"The on_modifies function must return either True or False indicating \"\n            \"whether a modify modifies a target. Actual value: {0}\".format(rslt)\n        )\n    return rslt\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.reduce_targets","title":"<code>reduce_targets()</code>","text":"<p>Reduces the number of targets to the n-closest targets based on the value of <code>self.max_targets</code>. If <code>self.max_targets</code> is None, no pruning is done.</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def reduce_targets(self):\n    \"\"\"\n    Reduces the number of targets to the n-closest targets based on the value of `self.max_targets`. If\n    `self.max_targets` is None, no pruning is done.\n    \"\"\"\n    if self.max_targets is None or self.num_targets &lt;= self.max_targets:\n        return\n\n    target_dists = []\n    for target in self._targets:\n        dist = min(abs(self._start - target.end), abs(target.start - self._end))\n        target_dists.append((target, dist))\n    srtd_targets, _ = zip(*sorted(target_dists, key=lambda x: x[1]))\n    self._targets = srtd_targets[: self.max_targets]\n    self._num_targets = len(self._targets)\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Serialized Representation of the modifier</p> Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def serialized_representation(self):\n    \"\"\"\n    Serialized Representation of the modifier\n    \"\"\"\n    dict_repr = dict()\n    dict_repr[\"context_rule\"] = self.rule.to_dict()\n    dict_repr[\"start\"] = self._start\n    dict_repr[\"end\"] = self._end\n    dict_repr[\"max_scope\"] = self._max_scope\n    dict_repr[\"scope_start\"] = self._scope_start\n    dict_repr[\"scope_end\"] = self._scope_end\n\n    return dict_repr\n</code></pre>"},{"location":"reference/medspacy/context/context_modifier/#medspacy.context.context_modifier.ConTextModifier.update_scope","title":"<code>update_scope(span)</code>","text":"<p>Changes the scope of self to be the given spaCy span.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>a spaCy Span which contains the scope which a modifier should cover.</p> required Source code in <code>medspacy/context/context_modifier.py</code> <pre><code>def update_scope(self, span: Span):\n    \"\"\"\n    Changes the scope of self to be the given spaCy span.\n\n    Args:\n        span: a spaCy Span which contains the scope which a modifier should cover.\n    \"\"\"\n    self._scope_start = span.start\n    self._scope_end = span.end\n</code></pre>"},{"location":"reference/medspacy/context/context_rule/","title":"medspacy.context.context_rule","text":""},{"location":"reference/medspacy/context/context_rule/#medspacy.context.context_rule.ConTextRule","title":"<code>ConTextRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>A ConTextRule defines a ConText modifier. ConTextRules are rules which define which spans are extracted as modifiers and how they behave, such as the phrase to be matched, the category/semantic class, the direction of the modifier in the text, and what types of target spans can be modified.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>class ConTextRule(BaseRule):\n    \"\"\"\n    A ConTextRule defines a ConText modifier. ConTextRules are rules which define which spans are extracted as modifiers\n    and how they behave, such as the phrase to be matched, the category/semantic class, the direction of the modifier in\n    the text, and what types of target spans can be modified.\n    \"\"\"\n\n    _ALLOWED_DIRECTIONS = (\n        \"FORWARD\",\n        \"BACKWARD\",\n        \"BIDIRECTIONAL\",\n        \"TERMINATE\",\n        \"PSEUDO\"\n    )\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"direction\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"allowed_types\",\n        \"excluded_types\",\n        \"max_targets\",\n        \"max_scope\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n        direction: str = \"BIDIRECTIONAL\",\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        on_modifies: Optional[Callable[[Span, Span, Span], bool]] = None,\n        allowed_types: Optional[Set[str]] = None,\n        excluded_types: Optional[Set[str]] = None,\n        max_scope: Optional[int] = None,\n        max_targets: Optional[int] = None,\n        terminated_by: Optional[Set[str]] = None,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Creates a ConTextRule object.\n\n        The primary arguments of `literal` `category`, and `direction` define the span of text to be matched, the\n        semantic category, and the direction within the sentence in which the modifier operates.\n        Other arguments specify additional custom logic such as:\n            - Additional control over what text can be matched as a modifier (pattern and on_match)\n            - Which types of targets can be modified (allowed_types, excluded_types)\n            - The scope size and number of targets that a modifier can modify (max_targets, max_scope)\n            - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,\n            terminated_by)\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            direction: The directionality or action of a modifier. This defines which part of a sentence a modifier will\n                include as its scope. Entities within the scope will be considered to be modified.\n                Valid values are:\n                - \"FORWARD\": Scope will begin after the end of a modifier and move to the right\n                - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left\n                - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier\n                - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:\n                    \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying\n                    \"pneumonia\"\n                - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating\n                    superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the\n                    phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a\n                    modifier.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            on_modifies: Callback function to run when building an edge between a target and a modifier. This allows\n                specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The\n                callable should take 3 arguments:\n                    target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')\n                    modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')\n                    span_between: The Span between the target and modifier in question.\n                Should return either True or False. If returns False, then the modifier will not modify the target.\n            allowed_types: A collection of target labels to allow a modifier to modify. If None, will apply to any type\n                not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used.\n                An error will be thrown if both are not None.\n            excluded_types: A collection of target labels which this modifier cannot modify. If None, will apply to all\n                target types unless allowed_types is not None.\n            max_scope: A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will\n                include the entire sentence in the direction of `direction` and the entire sentence for \"BIDIRECTIONAL\".\n                This is useful for requiring modifiers be very close to a concept in the text or for preventing long\n                modifier ranges caused by sentence splitting problems.\n            max_targets: The maximum number of targets which a modifier can modify. If None, will modify all targets in\n                its scope.\n            terminated_by: An optional collection of other modifier categories which will terminate the scope of this\n                modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has\n                terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the\n                positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\".\n                This helps prevent multiple conflicting modifiers from distributing too far across a sentence.\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category.upper(), pattern, on_match, metadata)\n        self.on_modifies = on_modifies\n\n        if allowed_types is not None and excluded_types is not None:\n            raise ValueError(\n                \"A ConTextRule was instantiated with non-null values for both allowed_types and excluded_types. \"\n                \"Only one of these can be non-null.\"\n            )\n        if allowed_types is not None:\n            self.allowed_types = {label.upper() for label in allowed_types}\n        else:\n            self.allowed_types = None\n        if excluded_types is not None:\n            self.excluded_types = {label.upper() for label in excluded_types}\n        else:\n            self.excluded_types = None\n\n        if max_targets is not None and max_targets &lt;= 0:\n            raise ValueError(\"max_targets must be &gt;= 0 or None.\")\n        self.max_targets = max_targets\n        if max_scope is not None and max_scope &lt;= 0:\n            raise ValueError(\"max_scope must be &gt;= 0 or None.\")\n        self.max_scope = max_scope\n        if terminated_by is None:\n            terminated_by = set()\n        else:\n            if isinstance(terminated_by, str):\n                raise ValueError(\n                    f\"terminated_by must be an iterable, such as a list or set, not {terminated_by}.\"\n                )\n            terminated_by = {string.upper() for string in terminated_by}\n\n        self.terminated_by = terminated_by\n\n        self.metadata = metadata\n\n        if direction.upper() not in self._ALLOWED_DIRECTIONS:\n            raise ValueError(\n                \"Direction {0} not recognized. Must be one of: {1}\".format(\n                    direction, self._ALLOWED_DIRECTIONS\n                )\n            )\n        self.direction = direction.upper()\n\n    @classmethod\n    def from_json(cls, filepath) -&gt; List[ConTextRule]:\n        \"\"\"\n        Reads in a lexicon of modifiers from a JSON file under the key `context_rules`.\n\n        Args:\n            filepath: The .json file containing modifier rules. Must contain `context_rules` key containing the rule\n                JSONs.\n\n        Returns:\n            A list of ConTextRules objects read from the JSON.\n        \"\"\"\n\n        with open(filepath) as file:\n            modifier_data = json.load(file)\n        context_rules = []\n        for data in modifier_data[\"context_rules\"]:\n            context_rules.append(ConTextRule.from_dict(data))\n        return context_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict) -&gt; ConTextRule:\n        \"\"\"\n        Reads a dictionary into a ConTextRule.\n\n        Args:\n            rule_dict: The dictionary to convert.\n\n        Returns:\n            The ConTextRule created from the dictionary.\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                \"JSON object contains invalid keys: {0}.\\n\"\n                \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n            )\n            raise ValueError(msg)\n        rule = ConTextRule(**rule_dict)\n        return rule\n\n    def to_dict(self):\n        \"\"\"\n        Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.\n\n        Returns:\n            The dictionary containing the ConTextRule info.\n        \"\"\"\n\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if isinstance(value, set):\n                value = list(value)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    @classmethod\n    def to_json(cls, context_rules: List[ConTextRule], filepath: str):\n        \"\"\"Writes ConTextItems to a json file.\n\n            Args:\n            context_rules: a list of ContextRules that will be written to a file.\n            filepath: the .json file to contain modifier rules\n        \"\"\"\n        import json\n\n        data = {\"context_rules\": [rule.to_dict() for rule in context_rules]}\n        with open(filepath, \"w\") as file:\n            json.dump(data, file, indent=4)\n\n    def __repr__(self):\n        return (\n            f\"ConTextRule(literal='{self.literal}', category='{self.category}', pattern={self.pattern}, \"\n            f\"direction='{self.direction}')\"\n        )\n</code></pre>"},{"location":"reference/medspacy/context/context_rule/#medspacy.context.context_rule.ConTextRule.__init__","title":"<code>__init__(literal, category, pattern=None, direction='BIDIRECTIONAL', on_match=None, on_modifies=None, allowed_types=None, excluded_types=None, max_scope=None, max_targets=None, terminated_by=None, metadata=None)</code>","text":"<p>Creates a ConTextRule object.</p> <p>The primary arguments of <code>literal</code> <code>category</code>, and <code>direction</code> define the span of text to be matched, the semantic category, and the direction within the sentence in which the modifier operates. Other arguments specify additional custom logic such as:     - Additional control over what text can be matched as a modifier (pattern and on_match)     - Which types of targets can be modified (allowed_types, excluded_types)     - The scope size and number of targets that a modifier can modify (max_targets, max_scope)     - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,     terminated_by)</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[str, List[Dict[str, str]]]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>direction</code> <code>str</code> <p>The directionality or action of a modifier. This defines which part of a sentence a modifier will include as its scope. Entities within the scope will be considered to be modified. Valid values are: - \"FORWARD\": Scope will begin after the end of a modifier and move to the right - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:     \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying     \"pneumonia\" - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating     superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the     phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a     modifier.</p> <code>'BIDIRECTIONAL'</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>on_modifies</code> <code>Optional[Callable[[Span, Span, Span], bool]]</code> <p>Callback function to run when building an edge between a target and a modifier. This allows specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The callable should take 3 arguments:     target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')     modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')     span_between: The Span between the target and modifier in question. Should return either True or False. If returns False, then the modifier will not modify the target.</p> <code>None</code> <code>allowed_types</code> <code>Optional[Set[str]]</code> <p>A collection of target labels to allow a modifier to modify. If None, will apply to any type not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used. An error will be thrown if both are not None.</p> <code>None</code> <code>excluded_types</code> <code>Optional[Set[str]]</code> <p>A collection of target labels which this modifier cannot modify. If None, will apply to all target types unless allowed_types is not None.</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will include the entire sentence in the direction of <code>direction</code> and the entire sentence for \"BIDIRECTIONAL\". This is useful for requiring modifiers be very close to a concept in the text or for preventing long modifier ranges caused by sentence splitting problems.</p> <code>None</code> <code>max_targets</code> <code>Optional[int]</code> <p>The maximum number of targets which a modifier can modify. If None, will modify all targets in its scope.</p> <code>None</code> <code>terminated_by</code> <code>Optional[Set[str]]</code> <p>An optional collection of other modifier categories which will terminate the scope of this modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\". This helps prevent multiple conflicting modifiers from distributing too far across a sentence.</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[str, List[Dict[str, str]]]] = None,\n    direction: str = \"BIDIRECTIONAL\",\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    on_modifies: Optional[Callable[[Span, Span, Span], bool]] = None,\n    allowed_types: Optional[Set[str]] = None,\n    excluded_types: Optional[Set[str]] = None,\n    max_scope: Optional[int] = None,\n    max_targets: Optional[int] = None,\n    terminated_by: Optional[Set[str]] = None,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Creates a ConTextRule object.\n\n    The primary arguments of `literal` `category`, and `direction` define the span of text to be matched, the\n    semantic category, and the direction within the sentence in which the modifier operates.\n    Other arguments specify additional custom logic such as:\n        - Additional control over what text can be matched as a modifier (pattern and on_match)\n        - Which types of targets can be modified (allowed_types, excluded_types)\n        - The scope size and number of targets that a modifier can modify (max_targets, max_scope)\n        - Other logic for terminating a span or for allowing a modifier to modify a target (on_modifies,\n        terminated_by)\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        direction: The directionality or action of a modifier. This defines which part of a sentence a modifier will\n            include as its scope. Entities within the scope will be considered to be modified.\n            Valid values are:\n            - \"FORWARD\": Scope will begin after the end of a modifier and move to the right\n            - \"BACKWARD\": Scope will begin before the beginning of a modifier and move to the left\n            - \"BIDIRECTIONAL\": Scope will expand on either side of a modifier\n            - \"TERMINATE\": A special direction to limit any other modifiers if this phrase is in its scope. Example:\n                \"no evidence of chf but there is pneumonia\": \"but\" will prevent \"no evidence of\" from modifying\n                \"pneumonia\"\n            - \"PSEUDO\": A special direction which will not modify any targets. This can be used for differentiating\n                superstrings of modifiers. Example: A modifier with literal=\"negative attitude\" will prevent the\n                phrase \"negative\" in \"She has a negative attitude about her treatment\" from being extracted as a\n                modifier.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        on_modifies: Callback function to run when building an edge between a target and a modifier. This allows\n            specifying custom logic for allowing or preventing certain modifiers from modifying certain targets. The\n            callable should take 3 arguments:\n                target: The spaCy Span from doc.ents (ie., 'Evidence of pneumonia')\n                modifier: The spaCy Span covered in a resulting modifier (ie., 'no evidence of')\n                span_between: The Span between the target and modifier in question.\n            Should return either True or False. If returns False, then the modifier will not modify the target.\n        allowed_types: A collection of target labels to allow a modifier to modify. If None, will apply to any type\n            not specifically excluded in excluded_types. Only one of allowed_types and excluded_types can be used.\n            An error will be thrown if both are not None.\n        excluded_types: A collection of target labels which this modifier cannot modify. If None, will apply to all\n            target types unless allowed_types is not None.\n        max_scope: A number of tokens to explicitly limit the size of the modifier's scope. If None, the scope will\n            include the entire sentence in the direction of `direction` and the entire sentence for \"BIDIRECTIONAL\".\n            This is useful for requiring modifiers be very close to a concept in the text or for preventing long\n            modifier ranges caused by sentence splitting problems.\n        max_targets: The maximum number of targets which a modifier can modify. If None, will modify all targets in\n            its scope.\n        terminated_by: An optional collection of other modifier categories which will terminate the scope of this\n            modifier. If None, only \"TERMINATE\" will do this. Example: if a ConTextRule defining \"positive for\" has\n            terminated_by={\"NEGATED_EXISTENCE\"}, then in the sentence \"positive for flu, negative for RSV\", the\n            positive modifier will modify \"flu\" but will be terminated by \"negative for\" and will not modify \"RSV\".\n            This helps prevent multiple conflicting modifiers from distributing too far across a sentence.\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category.upper(), pattern, on_match, metadata)\n    self.on_modifies = on_modifies\n\n    if allowed_types is not None and excluded_types is not None:\n        raise ValueError(\n            \"A ConTextRule was instantiated with non-null values for both allowed_types and excluded_types. \"\n            \"Only one of these can be non-null.\"\n        )\n    if allowed_types is not None:\n        self.allowed_types = {label.upper() for label in allowed_types}\n    else:\n        self.allowed_types = None\n    if excluded_types is not None:\n        self.excluded_types = {label.upper() for label in excluded_types}\n    else:\n        self.excluded_types = None\n\n    if max_targets is not None and max_targets &lt;= 0:\n        raise ValueError(\"max_targets must be &gt;= 0 or None.\")\n    self.max_targets = max_targets\n    if max_scope is not None and max_scope &lt;= 0:\n        raise ValueError(\"max_scope must be &gt;= 0 or None.\")\n    self.max_scope = max_scope\n    if terminated_by is None:\n        terminated_by = set()\n    else:\n        if isinstance(terminated_by, str):\n            raise ValueError(\n                f\"terminated_by must be an iterable, such as a list or set, not {terminated_by}.\"\n            )\n        terminated_by = {string.upper() for string in terminated_by}\n\n    self.terminated_by = terminated_by\n\n    self.metadata = metadata\n\n    if direction.upper() not in self._ALLOWED_DIRECTIONS:\n        raise ValueError(\n            \"Direction {0} not recognized. Must be one of: {1}\".format(\n                direction, self._ALLOWED_DIRECTIONS\n            )\n        )\n    self.direction = direction.upper()\n</code></pre>"},{"location":"reference/medspacy/context/context_rule/#medspacy.context.context_rule.ConTextRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a ConTextRule.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <p>The dictionary to convert.</p> required <p>Returns:</p> Type Description <code>ConTextRule</code> <p>The ConTextRule created from the dictionary.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict) -&gt; ConTextRule:\n    \"\"\"\n    Reads a dictionary into a ConTextRule.\n\n    Args:\n        rule_dict: The dictionary to convert.\n\n    Returns:\n        The ConTextRule created from the dictionary.\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            \"JSON object contains invalid keys: {0}.\\n\"\n            \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n        )\n        raise ValueError(msg)\n    rule = ConTextRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"reference/medspacy/context/context_rule/#medspacy.context.context_rule.ConTextRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Reads in a lexicon of modifiers from a JSON file under the key <code>context_rules</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>The .json file containing modifier rules. Must contain <code>context_rules</code> key containing the rule JSONs.</p> required <p>Returns:</p> Type Description <code>List[ConTextRule]</code> <p>A list of ConTextRules objects read from the JSON.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath) -&gt; List[ConTextRule]:\n    \"\"\"\n    Reads in a lexicon of modifiers from a JSON file under the key `context_rules`.\n\n    Args:\n        filepath: The .json file containing modifier rules. Must contain `context_rules` key containing the rule\n            JSONs.\n\n    Returns:\n        A list of ConTextRules objects read from the JSON.\n    \"\"\"\n\n    with open(filepath) as file:\n        modifier_data = json.load(file)\n    context_rules = []\n    for data in modifier_data[\"context_rules\"]:\n        context_rules.append(ConTextRule.from_dict(data))\n    return context_rules\n</code></pre>"},{"location":"reference/medspacy/context/context_rule/#medspacy.context.context_rule.ConTextRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.</p> <p>Returns:</p> Type Description <p>The dictionary containing the ConTextRule info.</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Converts ConTextItems to a python dictionary. Used when writing context rules to a json file.\n\n    Returns:\n        The dictionary containing the ConTextRule info.\n    \"\"\"\n\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if isinstance(value, set):\n            value = list(value)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"reference/medspacy/context/context_rule/#medspacy.context.context_rule.ConTextRule.to_json","title":"<code>to_json(context_rules, filepath)</code>  <code>classmethod</code>","text":"<p>Writes ConTextItems to a json file.</p> <p>Args: context_rules: a list of ContextRules that will be written to a file. filepath: the .json file to contain modifier rules</p> Source code in <code>medspacy/context/context_rule.py</code> <pre><code>@classmethod\ndef to_json(cls, context_rules: List[ConTextRule], filepath: str):\n    \"\"\"Writes ConTextItems to a json file.\n\n        Args:\n        context_rules: a list of ContextRules that will be written to a file.\n        filepath: the .json file to contain modifier rules\n    \"\"\"\n    import json\n\n    data = {\"context_rules\": [rule.to_dict() for rule in context_rules]}\n    with open(filepath, \"w\") as file:\n        json.dump(data, file, indent=4)\n</code></pre>"},{"location":"reference/medspacy/context/util/","title":"medspacy.context.util","text":"<p>This module will contain helper functions and classes for common clinical processing tasks which will be used in medspaCy's context implementation.</p>"},{"location":"reference/medspacy/context/util/#medspacy.context.util.is_modified_by","title":"<code>is_modified_by(span, modifier_label)</code>","text":"<p>Check whether a span has a modifier of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to examine.</p> required <code>modifier_label</code> <code>str</code> <p>The type of modifier to check for.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether there is a modifier of <code>modifier_label</code> that modifies <code>span</code>.</p> Source code in <code>medspacy/context/util.py</code> <pre><code>def is_modified_by(span: Span, modifier_label: str) -&gt; bool:\n    \"\"\"\n    Check whether a span has a modifier of a specific type.\n\n    Args:\n        span: The span to examine.\n        modifier_label: The type of modifier to check for.\n\n    Returns:\n        Whether there is a modifier of `modifier_label` that modifies `span`.\n    \"\"\"\n    for modifier in span._.modifiers:\n        if modifier.category.upper() == modifier_label.upper():\n            return True\n    return False\n</code></pre>"},{"location":"reference/medspacy/custom_tokenizer/","title":"medspacy.custom_tokenizer","text":""},{"location":"reference/medspacy/custom_tokenizer/#medspacy.custom_tokenizer.create_medspacy_tokenizer","title":"<code>create_medspacy_tokenizer(nlp)</code>","text":"<p>Generates a custom tokenizer to augment the default spacy tokenizer  for situations commonly seen in clinical text.  This includes:      * Punctuation infixes.          For example, this allows the following examples to be more aggresively tokenized as :              \"Patient complains of c/o\" -&gt; [..., 'c', '/', 'o']              \"chf+cp\" -&gt; ['chf', '+', 'cp'] @param nlp: Spacy language model</p> Source code in <code>medspacy/custom_tokenizer.py</code> <pre><code>def create_medspacy_tokenizer(nlp):\n    \"\"\"Generates a custom tokenizer to augment the default spacy tokenizer\n     for situations commonly seen in clinical text.\n     This includes:\n         * Punctuation infixes.\n             For example, this allows the following examples to be more aggresively tokenized as :\n                 \"Patient complains of c/o\" -&gt; [..., 'c', '/', 'o']\n                 \"chf+cp\" -&gt; ['chf', '+', 'cp']\n    @param nlp: Spacy language model\n    \"\"\"\n\n    # augment the defaults\n    # this is not quite correct.  We do not want to break on uppercase and we do not\n    # want to break on all punctuation (periods)\n    # infixes = nlp.Defaults.infixes + (r'''[^a-z0-9]''',)\n    # escape all the punctuation we want to allow to allow to break up tokens\n\n    # get all python punctuation\n    punctuation_chars = string.punctuation\n    # remove periods so that we do not break up '1.5 mg' into '1 . 5 mg'\n    punctuation_chars = punctuation_chars.replace(\".\", \"\")\n\n    infixes = nlp.Defaults.infixes + [\n        r\"\"\"[{}]\"\"\".format(re.escape(punctuation_chars)),\n    ]\n    prefixes = nlp.Defaults.prefixes\n    suffixes = nlp.Defaults.suffixes\n\n    # compile\n    infix_re = compile_infix_regex(infixes)\n    prefix_re = compile_prefix_regex(prefixes)\n    suffix_re = compile_suffix_regex(suffixes)\n\n    # Default exceptions could be extended later\n    tokenizer_exceptions = nlp.Defaults.tokenizer_exceptions.copy()\n\n    # now create this\n    tokenizer = Tokenizer(\n        nlp.vocab,\n        tokenizer_exceptions,\n        prefix_search=prefix_re.search,\n        suffix_search=suffix_re.search,\n        infix_finditer=infix_re.finditer,\n        token_match=nlp.tokenizer.token_match,\n    )\n\n    return tokenizer\n</code></pre>"},{"location":"reference/medspacy/io/","title":"medspacy.io","text":""},{"location":"reference/medspacy/io/#medspacy.io.DbConnect","title":"<code>DbConnect</code>","text":"<p>DbConnect is a wrapper for either a pyodbc or sqlite3 connection. It can then be passed into the DbReader and DbWriter classes to retrieve/store document data.</p> Source code in <code>medspacy/io/db_connect.py</code> <pre><code>class DbConnect:\n    \"\"\"DbConnect is a wrapper for either a pyodbc or sqlite3 connection. It can then be\n    passed into the DbReader and DbWriter classes to retrieve/store document data.\n    \"\"\"\n\n    def __init__(\n        self, driver=None, server=None, db=None, user=None, pwd=None, conn=None\n    ):\n        \"\"\"Create a new DbConnect object. You can pass in either information for a pyodbc connection string\n        or directly pass in a sqlite or pyodbc connection object.\n\n        If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.\n\n        Args:\n            driver\n            server\n            db:\n            user\n            pwd\n            conn\n        \"\"\"\n        if conn is None:\n            if not all([driver, server, db, user, pwd]):\n                raise ValueError(\n                    \"If you are not passing in a connection object, \"\n                    \"you must pass in all other arguments to create a DB connection.\"\n                )\n            import pyodbc\n\n            self.conn = pyodbc.connect(\n                \"DRIVER={0};SERVER={1};DATABASE={2};USER={3};PWD={4}\".format(\n                    driver, server, db, user, pwd\n                )\n            )\n        else:\n            self.conn = conn\n        self.cursor = self.conn.cursor()\n        # according this thread, bulk insert for sqlserver need to set fast_executemany=True.\n        # https://stackoverflow.com/questions/29638136/how-to-speed-up-bulk-insert-to-ms-sql-server-using-pyodbc\n        if hasattr(self.cursor, 'fast_executemany'):\n            self.cursor.fast_executemany = True\n\n        import sqlite3\n\n        if isinstance(self.conn, sqlite3.Connection):\n            self.db_lib = \"sqlite3\"\n            self.database_exception = sqlite3.DatabaseError\n        else:\n            import pyodbc\n            if isinstance(self.conn, pyodbc.Connection):\n                self.db_lib = \"pyodbc\"\n                self.database_exception = pyodbc.DatabaseError\n            else:\n                raise ValueError(\n                    \"conn must be either a sqlite3 or pyodbc Connection object, not {0}\".format(\n                        type(self.conn)\n                    )\n                )\n\n        print(\"Opened connection to {0}.{1}\".format(server, db))\n\n    def create_table(self, query, table_name, drop_existing):\n        if drop_existing:\n            try:\n                self.cursor.execute(\"drop table if exists {0}\".format(table_name))\n            # except pyodbc.DatabaseError:\n            except self.database_exception as e:\n                pass\n            else:\n                self.conn.commit()\n        try:\n            self.cursor.execute(query)\n        except self.database_exception as e:\n            self.conn.rollback()\n            self.conn.close()\n            raise e\n        else:\n            self.conn.commit()\n            print(\"Created table {0} with query: {1}\".format(table_name, query))\n\n    def write(self, query, data):\n        try:\n            self.cursor.executemany(query, data)\n        except self.database_exception as e:\n            self.conn.rollback()\n            self.conn.close()\n            raise e\n        else:\n            self.conn.commit()\n            # print(\"Wrote {0} rows with query: {1}\".format(len(data), query))\n\n    def read(self, query):\n        self.cursor.execute(query)\n        result = self.cursor.fetchall()\n        # print(\"Read {0} rows with query: {1}\".format(len(result), query))\n        return result\n\n    def close(self):\n        self.conn.commit()\n        self.conn.close()\n        print(\"Connection closed.\")\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DbConnect.__init__","title":"<code>__init__(driver=None, server=None, db=None, user=None, pwd=None, conn=None)</code>","text":"<p>Create a new DbConnect object. You can pass in either information for a pyodbc connection string or directly pass in a sqlite or pyodbc connection object.</p> <p>If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>None</code> Source code in <code>medspacy/io/db_connect.py</code> <pre><code>def __init__(\n    self, driver=None, server=None, db=None, user=None, pwd=None, conn=None\n):\n    \"\"\"Create a new DbConnect object. You can pass in either information for a pyodbc connection string\n    or directly pass in a sqlite or pyodbc connection object.\n\n    If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.\n\n    Args:\n        driver\n        server\n        db:\n        user\n        pwd\n        conn\n    \"\"\"\n    if conn is None:\n        if not all([driver, server, db, user, pwd]):\n            raise ValueError(\n                \"If you are not passing in a connection object, \"\n                \"you must pass in all other arguments to create a DB connection.\"\n            )\n        import pyodbc\n\n        self.conn = pyodbc.connect(\n            \"DRIVER={0};SERVER={1};DATABASE={2};USER={3};PWD={4}\".format(\n                driver, server, db, user, pwd\n            )\n        )\n    else:\n        self.conn = conn\n    self.cursor = self.conn.cursor()\n    # according this thread, bulk insert for sqlserver need to set fast_executemany=True.\n    # https://stackoverflow.com/questions/29638136/how-to-speed-up-bulk-insert-to-ms-sql-server-using-pyodbc\n    if hasattr(self.cursor, 'fast_executemany'):\n        self.cursor.fast_executemany = True\n\n    import sqlite3\n\n    if isinstance(self.conn, sqlite3.Connection):\n        self.db_lib = \"sqlite3\"\n        self.database_exception = sqlite3.DatabaseError\n    else:\n        import pyodbc\n        if isinstance(self.conn, pyodbc.Connection):\n            self.db_lib = \"pyodbc\"\n            self.database_exception = pyodbc.DatabaseError\n        else:\n            raise ValueError(\n                \"conn must be either a sqlite3 or pyodbc Connection object, not {0}\".format(\n                    type(self.conn)\n                )\n            )\n\n    print(\"Opened connection to {0}.{1}\".format(server, db))\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DbWriter","title":"<code>DbWriter</code>","text":"<p>DbWriter is a utility class for writing structured data back to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>class DbWriter:\n    \"\"\"DbWriter is a utility class for writing structured data back to a database.\"\"\"\n\n    def __init__(\n            self,\n            db_conn,\n            destination_table,\n            cols=None,\n            col_types=None,\n            doc_dtype=\"ents\",\n            create_table=False,\n            drop_existing=False,\n            write_batch_size=100,\n    ):\n        \"\"\"Create a new DbWriter object.\n\n        Args:\n            db_conn: A medspacy.io.DbConnect object\n            destination_table: The name of the table to write to\n            cols (opt): The names of the columns of the destination table. These should align with attributes extracted\n                by DocConsumer and stored in doc._.data. A set of default values can be accessed by:\n                &gt;&gt;&gt; DbWriter.get_default_cols()\n            col_types (opt): The sql data types of the table columns. They should correspond 1:1 with cols.\n                A set of default values can be accesed by:\n                &gt;&gt;&gt; DbWriter.get_default_col_types()\n            doc_dtype: The type of data from DocConsumer to write from a doc.\n                Either (\"ents\", \"section\", \"context\", or \"doc\")\n            create_table (bool): Whether to create a table\n\n        \"\"\"\n        self.db = db_conn\n        self.destination_table = destination_table\n        self._create_table = create_table\n        self.drop_existing = drop_existing\n        if cols is None and col_types is None:\n            cols = DEFAULT_COLS[doc_dtype]\n            col_types = [DEFAULT_COL_TYPES[doc_dtype][col] for col in cols]\n        elif cols is None and col_types is not None:\n            raise ValueError(\"cols must be specified if col_types is not None.\")\n        self.cols = cols\n        self.col_types = col_types\n        _validate_dtypes((doc_dtype,))\n        self.doc_dtype = doc_dtype\n        self.batch_size = write_batch_size\n\n        self.insert_query = \"\"\n        if create_table:\n            self.create_table()\n        self.make_insert_query()\n\n    @classmethod\n    def get_default_col_types(cls, dtypes=None):\n\n        if dtypes is None:\n            dtypes = tuple(DEFAULT_COL_TYPES.keys())\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n\n        _validate_dtypes(dtypes)\n        dtype_col_types = {\n            dtype: col_types\n            for (dtype, col_types) in DEFAULT_COL_TYPES.items()\n            if dtype in dtypes\n        }\n        return dtype_col_types\n\n    @classmethod\n    def get_default_cols(cls, dtypes=None):\n        if dtypes is None:\n            dtypes = tuple(DEFAULT_COL_TYPES.keys())\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n        _validate_dtypes(dtypes)\n\n        dtype_cols = {\n            dtype: cols\n            for (dtype, cols) in DEFAULT_COL_TYPES.items()\n            if dtype in dtypes\n        }\n        return dtype_cols\n\n    def create_table(self):\n        query = \"CREATE TABLE {0} (\".format(self.destination_table)\n        for i, col in enumerate(self.cols):\n            query += \"{0} {1}\".format(col, self.col_types[i])\n            if i &lt; len(self.cols) - 1:\n                query += \", \"\n            else:\n                query += \")\"\n        self.db.create_table(query, self.destination_table, self.drop_existing)\n\n    def make_insert_query(self):\n        col_list = \", \".join([col for col in self.cols])\n        q_list = \", \".join([\"?\" for col in self.cols])\n        self.insert_query = \"INSERT INTO {0} ({1}) VALUES ({2})\".format(\n            self.destination_table, col_list, q_list\n        )\n\n    def write(self, docs: Union[Doc, List[Doc]]):\n        \"\"\"Write a list of docs or doc to a database.\"\"\"\n        if isinstance(docs, Doc):\n            self.write_doc(docs)\n        else:\n            self.write_docs(docs)\n\n    def write_doc(self, doc):\n        \"\"\"Write a doc to a database.\"\"\"\n        data = doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True)\n        self.write_data(data)\n\n    def write_docs(self, docs, batch_size=800):\n        \"\"\"write a list of docs to database through bulk insert\"\"\"\n        data = []\n        for doc in docs:\n            data.extend(doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True))\n            if len(data) &gt;= batch_size:\n                self.write_data(data)\n                data = []\n        if len(data) &gt; 0:\n            self.write_data(data)\n        pass\n\n    def write_data(self, data):\n        self.db.write(self.insert_query, data)\n\n    def close(self):\n        self.db.close()\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DbWriter.__init__","title":"<code>__init__(db_conn, destination_table, cols=None, col_types=None, doc_dtype='ents', create_table=False, drop_existing=False, write_batch_size=100)</code>","text":"<p>Create a new DbWriter object.</p> <p>Parameters:</p> Name Type Description Default <code>db_conn</code> <p>A medspacy.io.DbConnect object</p> required <code>destination_table</code> <p>The name of the table to write to</p> required <code>cols</code> <code>opt</code> <p>The names of the columns of the destination table. These should align with attributes extracted by DocConsumer and stored in doc._.data. A set of default values can be accessed by:</p> <p>DbWriter.get_default_cols()</p> <code>None</code> <code>col_types</code> <code>opt</code> <p>The sql data types of the table columns. They should correspond 1:1 with cols. A set of default values can be accesed by:</p> <p>DbWriter.get_default_col_types()</p> <code>None</code> <code>doc_dtype</code> <p>The type of data from DocConsumer to write from a doc. Either (\"ents\", \"section\", \"context\", or \"doc\")</p> <code>'ents'</code> <code>create_table</code> <code>bool</code> <p>Whether to create a table</p> <code>False</code> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def __init__(\n        self,\n        db_conn,\n        destination_table,\n        cols=None,\n        col_types=None,\n        doc_dtype=\"ents\",\n        create_table=False,\n        drop_existing=False,\n        write_batch_size=100,\n):\n    \"\"\"Create a new DbWriter object.\n\n    Args:\n        db_conn: A medspacy.io.DbConnect object\n        destination_table: The name of the table to write to\n        cols (opt): The names of the columns of the destination table. These should align with attributes extracted\n            by DocConsumer and stored in doc._.data. A set of default values can be accessed by:\n            &gt;&gt;&gt; DbWriter.get_default_cols()\n        col_types (opt): The sql data types of the table columns. They should correspond 1:1 with cols.\n            A set of default values can be accesed by:\n            &gt;&gt;&gt; DbWriter.get_default_col_types()\n        doc_dtype: The type of data from DocConsumer to write from a doc.\n            Either (\"ents\", \"section\", \"context\", or \"doc\")\n        create_table (bool): Whether to create a table\n\n    \"\"\"\n    self.db = db_conn\n    self.destination_table = destination_table\n    self._create_table = create_table\n    self.drop_existing = drop_existing\n    if cols is None and col_types is None:\n        cols = DEFAULT_COLS[doc_dtype]\n        col_types = [DEFAULT_COL_TYPES[doc_dtype][col] for col in cols]\n    elif cols is None and col_types is not None:\n        raise ValueError(\"cols must be specified if col_types is not None.\")\n    self.cols = cols\n    self.col_types = col_types\n    _validate_dtypes((doc_dtype,))\n    self.doc_dtype = doc_dtype\n    self.batch_size = write_batch_size\n\n    self.insert_query = \"\"\n    if create_table:\n        self.create_table()\n    self.make_insert_query()\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DbWriter.write","title":"<code>write(docs)</code>","text":"<p>Write a list of docs or doc to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write(self, docs: Union[Doc, List[Doc]]):\n    \"\"\"Write a list of docs or doc to a database.\"\"\"\n    if isinstance(docs, Doc):\n        self.write_doc(docs)\n    else:\n        self.write_docs(docs)\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DbWriter.write_doc","title":"<code>write_doc(doc)</code>","text":"<p>Write a doc to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write_doc(self, doc):\n    \"\"\"Write a doc to a database.\"\"\"\n    data = doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True)\n    self.write_data(data)\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DbWriter.write_docs","title":"<code>write_docs(docs, batch_size=800)</code>","text":"<p>write a list of docs to database through bulk insert</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write_docs(self, docs, batch_size=800):\n    \"\"\"write a list of docs to database through bulk insert\"\"\"\n    data = []\n    for doc in docs:\n        data.extend(doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True))\n        if len(data) &gt;= batch_size:\n            self.write_data(data)\n            data = []\n    if len(data) &gt; 0:\n        self.write_data(data)\n    pass\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DocConsumer","title":"<code>DocConsumer</code>","text":"<p>A DocConsumer object will consume a spacy doc and output rows based on a configuration provided by the user.</p> <p>This component extracts structured information from a Doc. Information is stored in doc._.data, which is a     nested dictionary. The outer keys represent the data type of can one or more of:         - \"ents\": data about the spans in doc.ents such as the text, label,             context attributes, section information, or custom attributes         - \"group\": data about spans in a span group with the name <code>span_group_attrs</code> section text and category         - \"context\": data about entity-modifier pairs extracted by ConText         - \"doc\": a single doc-level representation. By default only doc.text is extracted, but other attributes may             be specified</p> <pre><code>Once processed, a doc's data can be accessed either by:\n    - doc._.data\n    - doc._.get_data(dtype=...)\n    - doc._.ent_data\n    - doc._.to_dataframe(dtype=...)\n</code></pre> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>@Language.factory(\"medspacy_doc_consumer\")\nclass DocConsumer:\n    \"\"\"\n    A DocConsumer object will consume a spacy doc and output rows based on a configuration provided by the user.\n\n    This component extracts structured information from a Doc. Information is stored in doc._.data, which is a\n        nested dictionary. The outer keys represent the data type of can one or more of:\n            - \"ents\": data about the spans in doc.ents such as the text, label,\n                context attributes, section information, or custom attributes\n            - \"group\": data about spans in a span group with the name `span_group_attrs` section text and category\n            - \"context\": data about entity-modifier pairs extracted by ConText\n            - \"doc\": a single doc-level representation. By default only doc.text is extracted, but other attributes may\n                be specified\n\n        Once processed, a doc's data can be accessed either by:\n            - doc._.data\n            - doc._.get_data(dtype=...)\n            - doc._.ent_data\n            - doc._.to_dataframe(dtype=...)\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp,\n        name: str = \"medspacy_doc_consumer\",\n        dtypes: Tuple = (\"ents\",),\n        dtype_attrs: Dict = None,\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        \"\"\"\n        Creates a new DocConsumer.\n\n        Args:\n            nlp: A spaCy model\n            dtypes: Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are:\n                \"ents\", \"group\", \"section\", \"context\", \"doc\".\n            dtype_attrs: An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will\n                set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either\n                native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time.\n                Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()\n            span_group_name: the name of the span group used when dtypes contains \"group\". At this time, only one span\n                group is supported.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self._span_group_name = span_group_name\n        if not isinstance(dtypes, tuple):\n            if dtypes == \"all\":\n                dtypes = tuple(ALLOWED_DATA_TYPES)\n            else:\n                raise ValueError(\n                    \"dtypes must be either 'all' or a tuple, not {0}\".format(dtypes)\n                )\n        for dtype in dtypes:\n            if dtype not in ALLOWED_DATA_TYPES:\n                raise ValueError(\n                    \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                        ALLOWED_DATA_TYPES, dtype\n                    )\n                )\n            if dtype == \"section\":\n                self.validate_section_attrs(dtype_attrs)\n        self.dtypes = dtypes\n        self.dtype_attrs = dtype_attrs\n\n        if self.dtype_attrs is None:\n            self._set_default_attrs()\n\n    @classmethod\n    def get_default_attrs(cls, dtypes: Optional[Tuple] = None):\n        \"\"\"\n        Gets the default attributes available to each type specified.\n\n        Args:\n            dtypes: Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be\n                returned.\n\n        Returns:\n            The attributes the doc consumer will output for each of the specified types in `dtypes`.\n        \"\"\"\n        if dtypes is None:\n            dtypes = ALLOWED_DATA_TYPES\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n            for dtype in dtypes:\n                if dtype not in ALLOWED_DATA_TYPES:\n                    raise ValueError(\"Invalid dtype,\", dtype)\n        dtype_attrs = {\n            dtype: list(attrs)\n            for (dtype, attrs) in DEFAULT_ATTRS.items()\n            if dtype in dtypes\n        }\n        return dtype_attrs\n\n    def _set_default_attrs(self):\n        \"\"\"\n        Gets the default attributes.\n        \"\"\"\n        self.dtype_attrs = self.get_default_attrs(self.dtypes)\n\n    def validate_section_attrs(self, attrs):\n        \"\"\"\n        Validate that section attributes are either not specified or are valid attribute names.\n        \"\"\"\n        if attrs is None:\n            return True\n        if \"section\" not in attrs:\n            return True\n        diff = set(attrs[\"section\"]).difference(ALLOWED_SECTION_ATTRS)\n        if diff:\n            raise ValueError(\"Invalid section dtype_attrs specified: {0}\".format(diff))\n        return True\n\n    def __call__(self, doc):\n        \"\"\"\n        Call the doc consumer on a doc and assign the data.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed Doc.\n        \"\"\"\n        data = dict()\n        for dtype, attrs in self.dtype_attrs.items():\n            data.setdefault(dtype, OrderedDict())\n            for attr in attrs:\n                data[dtype][attr] = list()\n        if \"ents\" in self.dtypes:\n            for ent in doc.ents:\n                for attr in self.dtype_attrs[\"ents\"]:\n                    try:\n                        val = getattr(ent, attr)\n                    except AttributeError:\n                        val = getattr(ent._, attr)\n                    data[\"ents\"][attr].append(val)\n        if \"group\" in self.dtypes:\n            for span in doc.spans[self._span_group_name]:\n                for attr in self.dtype_attrs[\"group\"]:\n                    try:\n                        val = getattr(span, attr)\n                    except AttributeError:\n                        val = getattr(span._, attr)\n                    data[\"group\"][attr].append(val)\n        if \"context\" in self.dtypes:\n            for (ent, modifier) in doc._.context_graph.edges:\n                self.add_context_edge_attributes(ent, modifier, data[\"context\"], doc)\n        if \"section\" in self.dtypes:\n            for section in doc._.sections:\n                self.add_section_attributes(section, data[\"section\"], doc)\n        if \"doc\" in self.dtypes:\n            for attr in self.dtype_attrs[\"doc\"]:\n                try:\n                    val = getattr(doc, attr)\n                except AttributeError:\n                    val = getattr(doc._, attr)\n                data[\"doc\"][attr].append(val)\n\n        doc._.data = data\n        return doc\n\n    def add_context_edge_attributes(\n        self, ent: Span, modifier: ConTextModifier, context_data, doc\n    ):\n        span_tup = modifier.modifier_span\n        span = doc[span_tup[0] : span_tup[1]]\n        scope_tup = modifier.scope_span\n        scope = doc[scope_tup[0] : scope_tup[1]]\n        for attr in self.dtype_attrs[\"context\"]:\n            if attr == \"ent_text\":\n                context_data[\"ent_text\"].append(ent.text)\n            elif attr == \"ent_label_\":\n                context_data[\"ent_label_\"].append(ent.label_)\n            elif attr == \"ent_start_char\":\n                context_data[\"ent_start_char\"].append(ent.start_char)\n            elif attr == \"ent_end_char\":\n                context_data[\"ent_end_char\"].append(ent.end_char)\n            elif attr == \"modifier_text\":\n                context_data[\"modifier_text\"].append(span.text)\n            elif attr == \"modifier_category\":\n                context_data[\"modifier_category\"].append(modifier.category)\n            elif attr == \"modifier_direction\":\n               context_data[\"modifier_direction\"].append(modifier.direction)\n            elif attr == \"modifier_start_char\":\n                context_data[\"modifier_start_char\"].append(span.start_char)\n            elif attr == \"modifier_end_char\":\n                context_data[\"modifier_end_char\"].append(span.end_char)\n            elif attr == \"modifier_scope_start_char\":\n                context_data[\"modifier_scope_start_char\"].append(scope.start_char)\n            elif attr == \"modifier_scope_end_char\":\n                context_data[\"modifier_scope_end_char\"].append(scope.end_char)\n            else:\n            # if specified attribute is not one of these standard values, check the entity to see if it's an entity value\n                try:\n                    val = getattr(ent, attr)\n                except AttributeError:\n                    try:\n                        val = getattr(ent._, attr)\n                    except AttributeError:\n                        raise ValueError(f\"Attributes for dtype 'context' must be either \"\n                                         f\"a registered custom Span attribute (i.e., Span._.attr) or one of these pre-defined values: \"\n                                          f\"{ALLOWED_CONTEXT_ATTRS}. \\nYou passed in '{attr}'\")\n                context_data[f\"{attr}\"].append(val)\n\n    def add_section_attributes(self, section, section_data, doc):\n        # Allow for null sections\n        section_title_tup = section.title_span\n        section_body_tup = section.body_span\n        section_title = doc[section_title_tup[0] : section_title_tup[1]]\n        section_body = doc[section_body_tup[0] : section_body_tup[1]]\n        if \"section_category\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_category\"].append(section.category)\n        if section.category is not None:\n            if \"section_title_text\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_text\"].append(section_title.text)\n            if \"section_title_start_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_start_char\"].append(\n                    section_title.start_char\n                )\n            if \"section_title_end_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_end_char\"].append(section_title.end_char)\n        else:\n            if \"section_title_text\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_text\"].append(None)\n            if \"section_title_start_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_start_char\"].append(0)\n            if \"section_title_end_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_end_char\"].append(0)\n        if \"section_body\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body\"].append(section_body.text)\n        if \"section_body_start_char\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body_start_char\"].append(section_body.start_char)\n        if \"section_body_end_char\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body_end_char\"].append(section_body.end_char)\n        if \"section_parent\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_parent\"].append(section.parent)\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DocConsumer.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the doc consumer on a doc and assign the data.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <p>The processed Doc.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def __call__(self, doc):\n    \"\"\"\n    Call the doc consumer on a doc and assign the data.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed Doc.\n    \"\"\"\n    data = dict()\n    for dtype, attrs in self.dtype_attrs.items():\n        data.setdefault(dtype, OrderedDict())\n        for attr in attrs:\n            data[dtype][attr] = list()\n    if \"ents\" in self.dtypes:\n        for ent in doc.ents:\n            for attr in self.dtype_attrs[\"ents\"]:\n                try:\n                    val = getattr(ent, attr)\n                except AttributeError:\n                    val = getattr(ent._, attr)\n                data[\"ents\"][attr].append(val)\n    if \"group\" in self.dtypes:\n        for span in doc.spans[self._span_group_name]:\n            for attr in self.dtype_attrs[\"group\"]:\n                try:\n                    val = getattr(span, attr)\n                except AttributeError:\n                    val = getattr(span._, attr)\n                data[\"group\"][attr].append(val)\n    if \"context\" in self.dtypes:\n        for (ent, modifier) in doc._.context_graph.edges:\n            self.add_context_edge_attributes(ent, modifier, data[\"context\"], doc)\n    if \"section\" in self.dtypes:\n        for section in doc._.sections:\n            self.add_section_attributes(section, data[\"section\"], doc)\n    if \"doc\" in self.dtypes:\n        for attr in self.dtype_attrs[\"doc\"]:\n            try:\n                val = getattr(doc, attr)\n            except AttributeError:\n                val = getattr(doc._, attr)\n            data[\"doc\"][attr].append(val)\n\n    doc._.data = data\n    return doc\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DocConsumer.__init__","title":"<code>__init__(nlp, name='medspacy_doc_consumer', dtypes=('ents',), dtype_attrs=None, span_group_name='medspacy_spans')</code>","text":"<p>Creates a new DocConsumer.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <p>A spaCy model</p> required <code>dtypes</code> <code>Tuple</code> <p>Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are: \"ents\", \"group\", \"section\", \"context\", \"doc\".</p> <code>('ents',)</code> <code>dtype_attrs</code> <code>Dict</code> <p>An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time. Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()</p> <code>None</code> <code>span_group_name</code> <code>str</code> <p>the name of the span group used when dtypes contains \"group\". At this time, only one span group is supported.</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def __init__(\n    self,\n    nlp,\n    name: str = \"medspacy_doc_consumer\",\n    dtypes: Tuple = (\"ents\",),\n    dtype_attrs: Dict = None,\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Creates a new DocConsumer.\n\n    Args:\n        nlp: A spaCy model\n        dtypes: Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are:\n            \"ents\", \"group\", \"section\", \"context\", \"doc\".\n        dtype_attrs: An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will\n            set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either\n            native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time.\n            Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()\n        span_group_name: the name of the span group used when dtypes contains \"group\". At this time, only one span\n            group is supported.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self._span_group_name = span_group_name\n    if not isinstance(dtypes, tuple):\n        if dtypes == \"all\":\n            dtypes = tuple(ALLOWED_DATA_TYPES)\n        else:\n            raise ValueError(\n                \"dtypes must be either 'all' or a tuple, not {0}\".format(dtypes)\n            )\n    for dtype in dtypes:\n        if dtype not in ALLOWED_DATA_TYPES:\n            raise ValueError(\n                \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                    ALLOWED_DATA_TYPES, dtype\n                )\n            )\n        if dtype == \"section\":\n            self.validate_section_attrs(dtype_attrs)\n    self.dtypes = dtypes\n    self.dtype_attrs = dtype_attrs\n\n    if self.dtype_attrs is None:\n        self._set_default_attrs()\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DocConsumer._set_default_attrs","title":"<code>_set_default_attrs()</code>","text":"<p>Gets the default attributes.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def _set_default_attrs(self):\n    \"\"\"\n    Gets the default attributes.\n    \"\"\"\n    self.dtype_attrs = self.get_default_attrs(self.dtypes)\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DocConsumer.get_default_attrs","title":"<code>get_default_attrs(dtypes=None)</code>  <code>classmethod</code>","text":"<p>Gets the default attributes available to each type specified.</p> <p>Parameters:</p> Name Type Description Default <code>dtypes</code> <code>Optional[Tuple]</code> <p>Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <p>The attributes the doc consumer will output for each of the specified types in <code>dtypes</code>.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>@classmethod\ndef get_default_attrs(cls, dtypes: Optional[Tuple] = None):\n    \"\"\"\n    Gets the default attributes available to each type specified.\n\n    Args:\n        dtypes: Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be\n            returned.\n\n    Returns:\n        The attributes the doc consumer will output for each of the specified types in `dtypes`.\n    \"\"\"\n    if dtypes is None:\n        dtypes = ALLOWED_DATA_TYPES\n    else:\n        if isinstance(dtypes, str):\n            dtypes = (dtypes,)\n        for dtype in dtypes:\n            if dtype not in ALLOWED_DATA_TYPES:\n                raise ValueError(\"Invalid dtype,\", dtype)\n    dtype_attrs = {\n        dtype: list(attrs)\n        for (dtype, attrs) in DEFAULT_ATTRS.items()\n        if dtype in dtypes\n    }\n    return dtype_attrs\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.DocConsumer.validate_section_attrs","title":"<code>validate_section_attrs(attrs)</code>","text":"<p>Validate that section attributes are either not specified or are valid attribute names.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def validate_section_attrs(self, attrs):\n    \"\"\"\n    Validate that section attributes are either not specified or are valid attribute names.\n    \"\"\"\n    if attrs is None:\n        return True\n    if \"section\" not in attrs:\n        return True\n    diff = set(attrs[\"section\"]).difference(ALLOWED_SECTION_ATTRS)\n    if diff:\n        raise ValueError(\"Invalid section dtype_attrs specified: {0}\".format(diff))\n    return True\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.Pipeline","title":"<code>Pipeline</code>","text":"<p>The Pipeline class executes a batch process of reading texts, processing them with a spaCy model, and writing the results back to a database.</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>@Language.factory(\"medspacy_pipeline\")\nclass Pipeline:\n    \"\"\"The Pipeline class executes a batch process of reading texts, processing them with a spaCy model, and writing\n    the results back to a database.\n    \"\"\"\n\n    def __init__(self, nlp, reader, writer, name=\"medspacy_pipeline\", dtype=\"ent\"):\n        \"\"\"Create a new Pipeline object.\n        Args:\n            reader: A DbReader object\n            writer: A Dbwriter object\n            nlp: A spaCy model\n            dtype: The DocConsumer data type to write to a database.\n                Default \"ent\n                Valid options are (\"ent\", \"section\", \"context\", \"doc\")\n        \"\"\"\n\n        self.reader = reader\n        self.writer = writer\n        self.name = name\n        self.nlp = nlp\n        self.dtype = dtype\n        if dtype not in ALLOWED_DATA_TYPES:\n            raise ValueError(\n                \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                    ALLOWED_DATA_TYPES, dtype\n                )\n            )\n\n    def process(self):\n        \"\"\"Run a pipeline by reading a set of texts from a source table, processing them with nlp,\n        and writing doc._.data back to the destination table.\n        \"\"\"\n        query_result = self.reader.read()\n        data = None\n        while query_result:\n            if len(query_result) &gt; 0:\n                query_zip = list(zip(*query_result))\n                ids = query_zip[0]\n                texts = query_zip[1]\n\n                docs = self.nlp.pipe(texts)\n\n                for i, doc in enumerate(docs):\n                    text_id = ids[i]\n                    # Get the data as rows of tuples\n                    doc_data = doc._.get_data(self.dtype, as_rows=True)\n                    # Add the identifier column\n                    doc_data = [(text_id,) + row_data for row_data in doc_data]\n                    # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n                    # doc_data = pd.DataFrame(data=doc._.get_data(self.dtype))\n                    # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n\n                    if data is None:\n                        data = doc_data.copy()\n                    else:\n                        data += doc_data.copy()\n                    if len(data) &gt;= self.writer.batch_size:\n                        self.writer.write_data(data)\n                        data = None\n            query_result = self.reader.read()\n\n        if data is not None:\n            self.writer.write_data(data)\n            data = None\n\n        self.reader.close()\n        if self.writer.db.conn != self.reader.db.conn:\n            self.writer.close()\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.Pipeline.__init__","title":"<code>__init__(nlp, reader, writer, name='medspacy_pipeline', dtype='ent')</code>","text":"<p>Create a new Pipeline object. Args:     reader: A DbReader object     writer: A Dbwriter object     nlp: A spaCy model     dtype: The DocConsumer data type to write to a database.         Default \"ent         Valid options are (\"ent\", \"section\", \"context\", \"doc\")</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>def __init__(self, nlp, reader, writer, name=\"medspacy_pipeline\", dtype=\"ent\"):\n    \"\"\"Create a new Pipeline object.\n    Args:\n        reader: A DbReader object\n        writer: A Dbwriter object\n        nlp: A spaCy model\n        dtype: The DocConsumer data type to write to a database.\n            Default \"ent\n            Valid options are (\"ent\", \"section\", \"context\", \"doc\")\n    \"\"\"\n\n    self.reader = reader\n    self.writer = writer\n    self.name = name\n    self.nlp = nlp\n    self.dtype = dtype\n    if dtype not in ALLOWED_DATA_TYPES:\n        raise ValueError(\n            \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                ALLOWED_DATA_TYPES, dtype\n            )\n        )\n</code></pre>"},{"location":"reference/medspacy/io/#medspacy.io.Pipeline.process","title":"<code>process()</code>","text":"<p>Run a pipeline by reading a set of texts from a source table, processing them with nlp, and writing doc._.data back to the destination table.</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>def process(self):\n    \"\"\"Run a pipeline by reading a set of texts from a source table, processing them with nlp,\n    and writing doc._.data back to the destination table.\n    \"\"\"\n    query_result = self.reader.read()\n    data = None\n    while query_result:\n        if len(query_result) &gt; 0:\n            query_zip = list(zip(*query_result))\n            ids = query_zip[0]\n            texts = query_zip[1]\n\n            docs = self.nlp.pipe(texts)\n\n            for i, doc in enumerate(docs):\n                text_id = ids[i]\n                # Get the data as rows of tuples\n                doc_data = doc._.get_data(self.dtype, as_rows=True)\n                # Add the identifier column\n                doc_data = [(text_id,) + row_data for row_data in doc_data]\n                # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n                # doc_data = pd.DataFrame(data=doc._.get_data(self.dtype))\n                # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n\n                if data is None:\n                    data = doc_data.copy()\n                else:\n                    data += doc_data.copy()\n                if len(data) &gt;= self.writer.batch_size:\n                    self.writer.write_data(data)\n                    data = None\n        query_result = self.reader.read()\n\n    if data is not None:\n        self.writer.write_data(data)\n        data = None\n\n    self.reader.close()\n    if self.writer.db.conn != self.reader.db.conn:\n        self.writer.close()\n</code></pre>"},{"location":"reference/medspacy/io/config_example/","title":"medspacy.io.config_example","text":""},{"location":"reference/medspacy/io/db/","title":"medspacy.io.db","text":""},{"location":"reference/medspacy/io/db_connect/","title":"medspacy.io.db_connect","text":""},{"location":"reference/medspacy/io/db_connect/#medspacy.io.db_connect.DbConnect","title":"<code>DbConnect</code>","text":"<p>DbConnect is a wrapper for either a pyodbc or sqlite3 connection. It can then be passed into the DbReader and DbWriter classes to retrieve/store document data.</p> Source code in <code>medspacy/io/db_connect.py</code> <pre><code>class DbConnect:\n    \"\"\"DbConnect is a wrapper for either a pyodbc or sqlite3 connection. It can then be\n    passed into the DbReader and DbWriter classes to retrieve/store document data.\n    \"\"\"\n\n    def __init__(\n        self, driver=None, server=None, db=None, user=None, pwd=None, conn=None\n    ):\n        \"\"\"Create a new DbConnect object. You can pass in either information for a pyodbc connection string\n        or directly pass in a sqlite or pyodbc connection object.\n\n        If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.\n\n        Args:\n            driver\n            server\n            db:\n            user\n            pwd\n            conn\n        \"\"\"\n        if conn is None:\n            if not all([driver, server, db, user, pwd]):\n                raise ValueError(\n                    \"If you are not passing in a connection object, \"\n                    \"you must pass in all other arguments to create a DB connection.\"\n                )\n            import pyodbc\n\n            self.conn = pyodbc.connect(\n                \"DRIVER={0};SERVER={1};DATABASE={2};USER={3};PWD={4}\".format(\n                    driver, server, db, user, pwd\n                )\n            )\n        else:\n            self.conn = conn\n        self.cursor = self.conn.cursor()\n        # according this thread, bulk insert for sqlserver need to set fast_executemany=True.\n        # https://stackoverflow.com/questions/29638136/how-to-speed-up-bulk-insert-to-ms-sql-server-using-pyodbc\n        if hasattr(self.cursor, 'fast_executemany'):\n            self.cursor.fast_executemany = True\n\n        import sqlite3\n\n        if isinstance(self.conn, sqlite3.Connection):\n            self.db_lib = \"sqlite3\"\n            self.database_exception = sqlite3.DatabaseError\n        else:\n            import pyodbc\n            if isinstance(self.conn, pyodbc.Connection):\n                self.db_lib = \"pyodbc\"\n                self.database_exception = pyodbc.DatabaseError\n            else:\n                raise ValueError(\n                    \"conn must be either a sqlite3 or pyodbc Connection object, not {0}\".format(\n                        type(self.conn)\n                    )\n                )\n\n        print(\"Opened connection to {0}.{1}\".format(server, db))\n\n    def create_table(self, query, table_name, drop_existing):\n        if drop_existing:\n            try:\n                self.cursor.execute(\"drop table if exists {0}\".format(table_name))\n            # except pyodbc.DatabaseError:\n            except self.database_exception as e:\n                pass\n            else:\n                self.conn.commit()\n        try:\n            self.cursor.execute(query)\n        except self.database_exception as e:\n            self.conn.rollback()\n            self.conn.close()\n            raise e\n        else:\n            self.conn.commit()\n            print(\"Created table {0} with query: {1}\".format(table_name, query))\n\n    def write(self, query, data):\n        try:\n            self.cursor.executemany(query, data)\n        except self.database_exception as e:\n            self.conn.rollback()\n            self.conn.close()\n            raise e\n        else:\n            self.conn.commit()\n            # print(\"Wrote {0} rows with query: {1}\".format(len(data), query))\n\n    def read(self, query):\n        self.cursor.execute(query)\n        result = self.cursor.fetchall()\n        # print(\"Read {0} rows with query: {1}\".format(len(result), query))\n        return result\n\n    def close(self):\n        self.conn.commit()\n        self.conn.close()\n        print(\"Connection closed.\")\n</code></pre>"},{"location":"reference/medspacy/io/db_connect/#medspacy.io.db_connect.DbConnect.__init__","title":"<code>__init__(driver=None, server=None, db=None, user=None, pwd=None, conn=None)</code>","text":"<p>Create a new DbConnect object. You can pass in either information for a pyodbc connection string or directly pass in a sqlite or pyodbc connection object.</p> <p>If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>None</code> Source code in <code>medspacy/io/db_connect.py</code> <pre><code>def __init__(\n    self, driver=None, server=None, db=None, user=None, pwd=None, conn=None\n):\n    \"\"\"Create a new DbConnect object. You can pass in either information for a pyodbc connection string\n    or directly pass in a sqlite or pyodbc connection object.\n\n    If conn is None, all other arguments must be supplied. If conn is passed in, all other arguments will be ignored.\n\n    Args:\n        driver\n        server\n        db:\n        user\n        pwd\n        conn\n    \"\"\"\n    if conn is None:\n        if not all([driver, server, db, user, pwd]):\n            raise ValueError(\n                \"If you are not passing in a connection object, \"\n                \"you must pass in all other arguments to create a DB connection.\"\n            )\n        import pyodbc\n\n        self.conn = pyodbc.connect(\n            \"DRIVER={0};SERVER={1};DATABASE={2};USER={3};PWD={4}\".format(\n                driver, server, db, user, pwd\n            )\n        )\n    else:\n        self.conn = conn\n    self.cursor = self.conn.cursor()\n    # according this thread, bulk insert for sqlserver need to set fast_executemany=True.\n    # https://stackoverflow.com/questions/29638136/how-to-speed-up-bulk-insert-to-ms-sql-server-using-pyodbc\n    if hasattr(self.cursor, 'fast_executemany'):\n        self.cursor.fast_executemany = True\n\n    import sqlite3\n\n    if isinstance(self.conn, sqlite3.Connection):\n        self.db_lib = \"sqlite3\"\n        self.database_exception = sqlite3.DatabaseError\n    else:\n        import pyodbc\n        if isinstance(self.conn, pyodbc.Connection):\n            self.db_lib = \"pyodbc\"\n            self.database_exception = pyodbc.DatabaseError\n        else:\n            raise ValueError(\n                \"conn must be either a sqlite3 or pyodbc Connection object, not {0}\".format(\n                    type(self.conn)\n                )\n            )\n\n    print(\"Opened connection to {0}.{1}\".format(server, db))\n</code></pre>"},{"location":"reference/medspacy/io/db_reader/","title":"medspacy.io.db_reader","text":""},{"location":"reference/medspacy/io/db_writer/","title":"medspacy.io.db_writer","text":""},{"location":"reference/medspacy/io/db_writer/#medspacy.io.db_writer.DbWriter","title":"<code>DbWriter</code>","text":"<p>DbWriter is a utility class for writing structured data back to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>class DbWriter:\n    \"\"\"DbWriter is a utility class for writing structured data back to a database.\"\"\"\n\n    def __init__(\n            self,\n            db_conn,\n            destination_table,\n            cols=None,\n            col_types=None,\n            doc_dtype=\"ents\",\n            create_table=False,\n            drop_existing=False,\n            write_batch_size=100,\n    ):\n        \"\"\"Create a new DbWriter object.\n\n        Args:\n            db_conn: A medspacy.io.DbConnect object\n            destination_table: The name of the table to write to\n            cols (opt): The names of the columns of the destination table. These should align with attributes extracted\n                by DocConsumer and stored in doc._.data. A set of default values can be accessed by:\n                &gt;&gt;&gt; DbWriter.get_default_cols()\n            col_types (opt): The sql data types of the table columns. They should correspond 1:1 with cols.\n                A set of default values can be accesed by:\n                &gt;&gt;&gt; DbWriter.get_default_col_types()\n            doc_dtype: The type of data from DocConsumer to write from a doc.\n                Either (\"ents\", \"section\", \"context\", or \"doc\")\n            create_table (bool): Whether to create a table\n\n        \"\"\"\n        self.db = db_conn\n        self.destination_table = destination_table\n        self._create_table = create_table\n        self.drop_existing = drop_existing\n        if cols is None and col_types is None:\n            cols = DEFAULT_COLS[doc_dtype]\n            col_types = [DEFAULT_COL_TYPES[doc_dtype][col] for col in cols]\n        elif cols is None and col_types is not None:\n            raise ValueError(\"cols must be specified if col_types is not None.\")\n        self.cols = cols\n        self.col_types = col_types\n        _validate_dtypes((doc_dtype,))\n        self.doc_dtype = doc_dtype\n        self.batch_size = write_batch_size\n\n        self.insert_query = \"\"\n        if create_table:\n            self.create_table()\n        self.make_insert_query()\n\n    @classmethod\n    def get_default_col_types(cls, dtypes=None):\n\n        if dtypes is None:\n            dtypes = tuple(DEFAULT_COL_TYPES.keys())\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n\n        _validate_dtypes(dtypes)\n        dtype_col_types = {\n            dtype: col_types\n            for (dtype, col_types) in DEFAULT_COL_TYPES.items()\n            if dtype in dtypes\n        }\n        return dtype_col_types\n\n    @classmethod\n    def get_default_cols(cls, dtypes=None):\n        if dtypes is None:\n            dtypes = tuple(DEFAULT_COL_TYPES.keys())\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n        _validate_dtypes(dtypes)\n\n        dtype_cols = {\n            dtype: cols\n            for (dtype, cols) in DEFAULT_COL_TYPES.items()\n            if dtype in dtypes\n        }\n        return dtype_cols\n\n    def create_table(self):\n        query = \"CREATE TABLE {0} (\".format(self.destination_table)\n        for i, col in enumerate(self.cols):\n            query += \"{0} {1}\".format(col, self.col_types[i])\n            if i &lt; len(self.cols) - 1:\n                query += \", \"\n            else:\n                query += \")\"\n        self.db.create_table(query, self.destination_table, self.drop_existing)\n\n    def make_insert_query(self):\n        col_list = \", \".join([col for col in self.cols])\n        q_list = \", \".join([\"?\" for col in self.cols])\n        self.insert_query = \"INSERT INTO {0} ({1}) VALUES ({2})\".format(\n            self.destination_table, col_list, q_list\n        )\n\n    def write(self, docs: Union[Doc, List[Doc]]):\n        \"\"\"Write a list of docs or doc to a database.\"\"\"\n        if isinstance(docs, Doc):\n            self.write_doc(docs)\n        else:\n            self.write_docs(docs)\n\n    def write_doc(self, doc):\n        \"\"\"Write a doc to a database.\"\"\"\n        data = doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True)\n        self.write_data(data)\n\n    def write_docs(self, docs, batch_size=800):\n        \"\"\"write a list of docs to database through bulk insert\"\"\"\n        data = []\n        for doc in docs:\n            data.extend(doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True))\n            if len(data) &gt;= batch_size:\n                self.write_data(data)\n                data = []\n        if len(data) &gt; 0:\n            self.write_data(data)\n        pass\n\n    def write_data(self, data):\n        self.db.write(self.insert_query, data)\n\n    def close(self):\n        self.db.close()\n</code></pre>"},{"location":"reference/medspacy/io/db_writer/#medspacy.io.db_writer.DbWriter.__init__","title":"<code>__init__(db_conn, destination_table, cols=None, col_types=None, doc_dtype='ents', create_table=False, drop_existing=False, write_batch_size=100)</code>","text":"<p>Create a new DbWriter object.</p> <p>Parameters:</p> Name Type Description Default <code>db_conn</code> <p>A medspacy.io.DbConnect object</p> required <code>destination_table</code> <p>The name of the table to write to</p> required <code>cols</code> <code>opt</code> <p>The names of the columns of the destination table. These should align with attributes extracted by DocConsumer and stored in doc._.data. A set of default values can be accessed by:</p> <p>DbWriter.get_default_cols()</p> <code>None</code> <code>col_types</code> <code>opt</code> <p>The sql data types of the table columns. They should correspond 1:1 with cols. A set of default values can be accesed by:</p> <p>DbWriter.get_default_col_types()</p> <code>None</code> <code>doc_dtype</code> <p>The type of data from DocConsumer to write from a doc. Either (\"ents\", \"section\", \"context\", or \"doc\")</p> <code>'ents'</code> <code>create_table</code> <code>bool</code> <p>Whether to create a table</p> <code>False</code> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def __init__(\n        self,\n        db_conn,\n        destination_table,\n        cols=None,\n        col_types=None,\n        doc_dtype=\"ents\",\n        create_table=False,\n        drop_existing=False,\n        write_batch_size=100,\n):\n    \"\"\"Create a new DbWriter object.\n\n    Args:\n        db_conn: A medspacy.io.DbConnect object\n        destination_table: The name of the table to write to\n        cols (opt): The names of the columns of the destination table. These should align with attributes extracted\n            by DocConsumer and stored in doc._.data. A set of default values can be accessed by:\n            &gt;&gt;&gt; DbWriter.get_default_cols()\n        col_types (opt): The sql data types of the table columns. They should correspond 1:1 with cols.\n            A set of default values can be accesed by:\n            &gt;&gt;&gt; DbWriter.get_default_col_types()\n        doc_dtype: The type of data from DocConsumer to write from a doc.\n            Either (\"ents\", \"section\", \"context\", or \"doc\")\n        create_table (bool): Whether to create a table\n\n    \"\"\"\n    self.db = db_conn\n    self.destination_table = destination_table\n    self._create_table = create_table\n    self.drop_existing = drop_existing\n    if cols is None and col_types is None:\n        cols = DEFAULT_COLS[doc_dtype]\n        col_types = [DEFAULT_COL_TYPES[doc_dtype][col] for col in cols]\n    elif cols is None and col_types is not None:\n        raise ValueError(\"cols must be specified if col_types is not None.\")\n    self.cols = cols\n    self.col_types = col_types\n    _validate_dtypes((doc_dtype,))\n    self.doc_dtype = doc_dtype\n    self.batch_size = write_batch_size\n\n    self.insert_query = \"\"\n    if create_table:\n        self.create_table()\n    self.make_insert_query()\n</code></pre>"},{"location":"reference/medspacy/io/db_writer/#medspacy.io.db_writer.DbWriter.write","title":"<code>write(docs)</code>","text":"<p>Write a list of docs or doc to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write(self, docs: Union[Doc, List[Doc]]):\n    \"\"\"Write a list of docs or doc to a database.\"\"\"\n    if isinstance(docs, Doc):\n        self.write_doc(docs)\n    else:\n        self.write_docs(docs)\n</code></pre>"},{"location":"reference/medspacy/io/db_writer/#medspacy.io.db_writer.DbWriter.write_doc","title":"<code>write_doc(doc)</code>","text":"<p>Write a doc to a database.</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write_doc(self, doc):\n    \"\"\"Write a doc to a database.\"\"\"\n    data = doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True)\n    self.write_data(data)\n</code></pre>"},{"location":"reference/medspacy/io/db_writer/#medspacy.io.db_writer.DbWriter.write_docs","title":"<code>write_docs(docs, batch_size=800)</code>","text":"<p>write a list of docs to database through bulk insert</p> Source code in <code>medspacy/io/db_writer.py</code> <pre><code>def write_docs(self, docs, batch_size=800):\n    \"\"\"write a list of docs to database through bulk insert\"\"\"\n    data = []\n    for doc in docs:\n        data.extend(doc._.get_data(self.doc_dtype, attrs=self.cols, as_rows=True))\n        if len(data) &gt;= batch_size:\n            self.write_data(data)\n            data = []\n    if len(data) &gt; 0:\n        self.write_data(data)\n    pass\n</code></pre>"},{"location":"reference/medspacy/io/doc_consumer/","title":"medspacy.io.doc_consumer","text":""},{"location":"reference/medspacy/io/doc_consumer/#medspacy.io.doc_consumer.DocConsumer","title":"<code>DocConsumer</code>","text":"<p>A DocConsumer object will consume a spacy doc and output rows based on a configuration provided by the user.</p> <p>This component extracts structured information from a Doc. Information is stored in doc._.data, which is a     nested dictionary. The outer keys represent the data type of can one or more of:         - \"ents\": data about the spans in doc.ents such as the text, label,             context attributes, section information, or custom attributes         - \"group\": data about spans in a span group with the name <code>span_group_attrs</code> section text and category         - \"context\": data about entity-modifier pairs extracted by ConText         - \"doc\": a single doc-level representation. By default only doc.text is extracted, but other attributes may             be specified</p> <pre><code>Once processed, a doc's data can be accessed either by:\n    - doc._.data\n    - doc._.get_data(dtype=...)\n    - doc._.ent_data\n    - doc._.to_dataframe(dtype=...)\n</code></pre> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>@Language.factory(\"medspacy_doc_consumer\")\nclass DocConsumer:\n    \"\"\"\n    A DocConsumer object will consume a spacy doc and output rows based on a configuration provided by the user.\n\n    This component extracts structured information from a Doc. Information is stored in doc._.data, which is a\n        nested dictionary. The outer keys represent the data type of can one or more of:\n            - \"ents\": data about the spans in doc.ents such as the text, label,\n                context attributes, section information, or custom attributes\n            - \"group\": data about spans in a span group with the name `span_group_attrs` section text and category\n            - \"context\": data about entity-modifier pairs extracted by ConText\n            - \"doc\": a single doc-level representation. By default only doc.text is extracted, but other attributes may\n                be specified\n\n        Once processed, a doc's data can be accessed either by:\n            - doc._.data\n            - doc._.get_data(dtype=...)\n            - doc._.ent_data\n            - doc._.to_dataframe(dtype=...)\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp,\n        name: str = \"medspacy_doc_consumer\",\n        dtypes: Tuple = (\"ents\",),\n        dtype_attrs: Dict = None,\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        \"\"\"\n        Creates a new DocConsumer.\n\n        Args:\n            nlp: A spaCy model\n            dtypes: Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are:\n                \"ents\", \"group\", \"section\", \"context\", \"doc\".\n            dtype_attrs: An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will\n                set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either\n                native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time.\n                Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()\n            span_group_name: the name of the span group used when dtypes contains \"group\". At this time, only one span\n                group is supported.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self._span_group_name = span_group_name\n        if not isinstance(dtypes, tuple):\n            if dtypes == \"all\":\n                dtypes = tuple(ALLOWED_DATA_TYPES)\n            else:\n                raise ValueError(\n                    \"dtypes must be either 'all' or a tuple, not {0}\".format(dtypes)\n                )\n        for dtype in dtypes:\n            if dtype not in ALLOWED_DATA_TYPES:\n                raise ValueError(\n                    \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                        ALLOWED_DATA_TYPES, dtype\n                    )\n                )\n            if dtype == \"section\":\n                self.validate_section_attrs(dtype_attrs)\n        self.dtypes = dtypes\n        self.dtype_attrs = dtype_attrs\n\n        if self.dtype_attrs is None:\n            self._set_default_attrs()\n\n    @classmethod\n    def get_default_attrs(cls, dtypes: Optional[Tuple] = None):\n        \"\"\"\n        Gets the default attributes available to each type specified.\n\n        Args:\n            dtypes: Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be\n                returned.\n\n        Returns:\n            The attributes the doc consumer will output for each of the specified types in `dtypes`.\n        \"\"\"\n        if dtypes is None:\n            dtypes = ALLOWED_DATA_TYPES\n        else:\n            if isinstance(dtypes, str):\n                dtypes = (dtypes,)\n            for dtype in dtypes:\n                if dtype not in ALLOWED_DATA_TYPES:\n                    raise ValueError(\"Invalid dtype,\", dtype)\n        dtype_attrs = {\n            dtype: list(attrs)\n            for (dtype, attrs) in DEFAULT_ATTRS.items()\n            if dtype in dtypes\n        }\n        return dtype_attrs\n\n    def _set_default_attrs(self):\n        \"\"\"\n        Gets the default attributes.\n        \"\"\"\n        self.dtype_attrs = self.get_default_attrs(self.dtypes)\n\n    def validate_section_attrs(self, attrs):\n        \"\"\"\n        Validate that section attributes are either not specified or are valid attribute names.\n        \"\"\"\n        if attrs is None:\n            return True\n        if \"section\" not in attrs:\n            return True\n        diff = set(attrs[\"section\"]).difference(ALLOWED_SECTION_ATTRS)\n        if diff:\n            raise ValueError(\"Invalid section dtype_attrs specified: {0}\".format(diff))\n        return True\n\n    def __call__(self, doc):\n        \"\"\"\n        Call the doc consumer on a doc and assign the data.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed Doc.\n        \"\"\"\n        data = dict()\n        for dtype, attrs in self.dtype_attrs.items():\n            data.setdefault(dtype, OrderedDict())\n            for attr in attrs:\n                data[dtype][attr] = list()\n        if \"ents\" in self.dtypes:\n            for ent in doc.ents:\n                for attr in self.dtype_attrs[\"ents\"]:\n                    try:\n                        val = getattr(ent, attr)\n                    except AttributeError:\n                        val = getattr(ent._, attr)\n                    data[\"ents\"][attr].append(val)\n        if \"group\" in self.dtypes:\n            for span in doc.spans[self._span_group_name]:\n                for attr in self.dtype_attrs[\"group\"]:\n                    try:\n                        val = getattr(span, attr)\n                    except AttributeError:\n                        val = getattr(span._, attr)\n                    data[\"group\"][attr].append(val)\n        if \"context\" in self.dtypes:\n            for (ent, modifier) in doc._.context_graph.edges:\n                self.add_context_edge_attributes(ent, modifier, data[\"context\"], doc)\n        if \"section\" in self.dtypes:\n            for section in doc._.sections:\n                self.add_section_attributes(section, data[\"section\"], doc)\n        if \"doc\" in self.dtypes:\n            for attr in self.dtype_attrs[\"doc\"]:\n                try:\n                    val = getattr(doc, attr)\n                except AttributeError:\n                    val = getattr(doc._, attr)\n                data[\"doc\"][attr].append(val)\n\n        doc._.data = data\n        return doc\n\n    def add_context_edge_attributes(\n        self, ent: Span, modifier: ConTextModifier, context_data, doc\n    ):\n        span_tup = modifier.modifier_span\n        span = doc[span_tup[0] : span_tup[1]]\n        scope_tup = modifier.scope_span\n        scope = doc[scope_tup[0] : scope_tup[1]]\n        for attr in self.dtype_attrs[\"context\"]:\n            if attr == \"ent_text\":\n                context_data[\"ent_text\"].append(ent.text)\n            elif attr == \"ent_label_\":\n                context_data[\"ent_label_\"].append(ent.label_)\n            elif attr == \"ent_start_char\":\n                context_data[\"ent_start_char\"].append(ent.start_char)\n            elif attr == \"ent_end_char\":\n                context_data[\"ent_end_char\"].append(ent.end_char)\n            elif attr == \"modifier_text\":\n                context_data[\"modifier_text\"].append(span.text)\n            elif attr == \"modifier_category\":\n                context_data[\"modifier_category\"].append(modifier.category)\n            elif attr == \"modifier_direction\":\n               context_data[\"modifier_direction\"].append(modifier.direction)\n            elif attr == \"modifier_start_char\":\n                context_data[\"modifier_start_char\"].append(span.start_char)\n            elif attr == \"modifier_end_char\":\n                context_data[\"modifier_end_char\"].append(span.end_char)\n            elif attr == \"modifier_scope_start_char\":\n                context_data[\"modifier_scope_start_char\"].append(scope.start_char)\n            elif attr == \"modifier_scope_end_char\":\n                context_data[\"modifier_scope_end_char\"].append(scope.end_char)\n            else:\n            # if specified attribute is not one of these standard values, check the entity to see if it's an entity value\n                try:\n                    val = getattr(ent, attr)\n                except AttributeError:\n                    try:\n                        val = getattr(ent._, attr)\n                    except AttributeError:\n                        raise ValueError(f\"Attributes for dtype 'context' must be either \"\n                                         f\"a registered custom Span attribute (i.e., Span._.attr) or one of these pre-defined values: \"\n                                          f\"{ALLOWED_CONTEXT_ATTRS}. \\nYou passed in '{attr}'\")\n                context_data[f\"{attr}\"].append(val)\n\n    def add_section_attributes(self, section, section_data, doc):\n        # Allow for null sections\n        section_title_tup = section.title_span\n        section_body_tup = section.body_span\n        section_title = doc[section_title_tup[0] : section_title_tup[1]]\n        section_body = doc[section_body_tup[0] : section_body_tup[1]]\n        if \"section_category\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_category\"].append(section.category)\n        if section.category is not None:\n            if \"section_title_text\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_text\"].append(section_title.text)\n            if \"section_title_start_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_start_char\"].append(\n                    section_title.start_char\n                )\n            if \"section_title_end_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_end_char\"].append(section_title.end_char)\n        else:\n            if \"section_title_text\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_text\"].append(None)\n            if \"section_title_start_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_start_char\"].append(0)\n            if \"section_title_end_char\" in self.dtype_attrs[\"section\"]:\n                section_data[\"section_title_end_char\"].append(0)\n        if \"section_body\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body\"].append(section_body.text)\n        if \"section_body_start_char\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body_start_char\"].append(section_body.start_char)\n        if \"section_body_end_char\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_body_end_char\"].append(section_body.end_char)\n        if \"section_parent\" in self.dtype_attrs[\"section\"]:\n            section_data[\"section_parent\"].append(section.parent)\n</code></pre>"},{"location":"reference/medspacy/io/doc_consumer/#medspacy.io.doc_consumer.DocConsumer.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the doc consumer on a doc and assign the data.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <p>The processed Doc.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def __call__(self, doc):\n    \"\"\"\n    Call the doc consumer on a doc and assign the data.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed Doc.\n    \"\"\"\n    data = dict()\n    for dtype, attrs in self.dtype_attrs.items():\n        data.setdefault(dtype, OrderedDict())\n        for attr in attrs:\n            data[dtype][attr] = list()\n    if \"ents\" in self.dtypes:\n        for ent in doc.ents:\n            for attr in self.dtype_attrs[\"ents\"]:\n                try:\n                    val = getattr(ent, attr)\n                except AttributeError:\n                    val = getattr(ent._, attr)\n                data[\"ents\"][attr].append(val)\n    if \"group\" in self.dtypes:\n        for span in doc.spans[self._span_group_name]:\n            for attr in self.dtype_attrs[\"group\"]:\n                try:\n                    val = getattr(span, attr)\n                except AttributeError:\n                    val = getattr(span._, attr)\n                data[\"group\"][attr].append(val)\n    if \"context\" in self.dtypes:\n        for (ent, modifier) in doc._.context_graph.edges:\n            self.add_context_edge_attributes(ent, modifier, data[\"context\"], doc)\n    if \"section\" in self.dtypes:\n        for section in doc._.sections:\n            self.add_section_attributes(section, data[\"section\"], doc)\n    if \"doc\" in self.dtypes:\n        for attr in self.dtype_attrs[\"doc\"]:\n            try:\n                val = getattr(doc, attr)\n            except AttributeError:\n                val = getattr(doc._, attr)\n            data[\"doc\"][attr].append(val)\n\n    doc._.data = data\n    return doc\n</code></pre>"},{"location":"reference/medspacy/io/doc_consumer/#medspacy.io.doc_consumer.DocConsumer.__init__","title":"<code>__init__(nlp, name='medspacy_doc_consumer', dtypes=('ents',), dtype_attrs=None, span_group_name='medspacy_spans')</code>","text":"<p>Creates a new DocConsumer.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <p>A spaCy model</p> required <code>dtypes</code> <code>Tuple</code> <p>Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are: \"ents\", \"group\", \"section\", \"context\", \"doc\".</p> <code>('ents',)</code> <code>dtype_attrs</code> <code>Dict</code> <p>An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time. Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()</p> <code>None</code> <code>span_group_name</code> <code>str</code> <p>the name of the span group used when dtypes contains \"group\". At this time, only one span group is supported.</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def __init__(\n    self,\n    nlp,\n    name: str = \"medspacy_doc_consumer\",\n    dtypes: Tuple = (\"ents\",),\n    dtype_attrs: Dict = None,\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Creates a new DocConsumer.\n\n    Args:\n        nlp: A spaCy model\n        dtypes: Either a tuple of data types to collect or the string \"all\". Default (\"ents\",). Valid  options are:\n            \"ents\", \"group\", \"section\", \"context\", \"doc\".\n        dtype_attrs: An optional dictionary mapping the data types in dtypes to a list of attributes. If None, will\n            set defaults for each dtype. Attributes for \"ents\", \"group\", and \"doc\" may be customized be adding either\n            native or custom attributes (i.e., ent._....) \"context\" and \"section\" are not customizable at this time.\n            Default values for each dtype can be retrieved by the class method `DocConsumer.get_default_attrs()\n        span_group_name: the name of the span group used when dtypes contains \"group\". At this time, only one span\n            group is supported.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self._span_group_name = span_group_name\n    if not isinstance(dtypes, tuple):\n        if dtypes == \"all\":\n            dtypes = tuple(ALLOWED_DATA_TYPES)\n        else:\n            raise ValueError(\n                \"dtypes must be either 'all' or a tuple, not {0}\".format(dtypes)\n            )\n    for dtype in dtypes:\n        if dtype not in ALLOWED_DATA_TYPES:\n            raise ValueError(\n                \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                    ALLOWED_DATA_TYPES, dtype\n                )\n            )\n        if dtype == \"section\":\n            self.validate_section_attrs(dtype_attrs)\n    self.dtypes = dtypes\n    self.dtype_attrs = dtype_attrs\n\n    if self.dtype_attrs is None:\n        self._set_default_attrs()\n</code></pre>"},{"location":"reference/medspacy/io/doc_consumer/#medspacy.io.doc_consumer.DocConsumer._set_default_attrs","title":"<code>_set_default_attrs()</code>","text":"<p>Gets the default attributes.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def _set_default_attrs(self):\n    \"\"\"\n    Gets the default attributes.\n    \"\"\"\n    self.dtype_attrs = self.get_default_attrs(self.dtypes)\n</code></pre>"},{"location":"reference/medspacy/io/doc_consumer/#medspacy.io.doc_consumer.DocConsumer.get_default_attrs","title":"<code>get_default_attrs(dtypes=None)</code>  <code>classmethod</code>","text":"<p>Gets the default attributes available to each type specified.</p> <p>Parameters:</p> Name Type Description Default <code>dtypes</code> <code>Optional[Tuple]</code> <p>Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <p>The attributes the doc consumer will output for each of the specified types in <code>dtypes</code>.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>@classmethod\ndef get_default_attrs(cls, dtypes: Optional[Tuple] = None):\n    \"\"\"\n    Gets the default attributes available to each type specified.\n\n    Args:\n        dtypes: Optional tuple containing \"ents\", \"group\", \"context\", \"section\", or \"doc\". If None, all will be\n            returned.\n\n    Returns:\n        The attributes the doc consumer will output for each of the specified types in `dtypes`.\n    \"\"\"\n    if dtypes is None:\n        dtypes = ALLOWED_DATA_TYPES\n    else:\n        if isinstance(dtypes, str):\n            dtypes = (dtypes,)\n        for dtype in dtypes:\n            if dtype not in ALLOWED_DATA_TYPES:\n                raise ValueError(\"Invalid dtype,\", dtype)\n    dtype_attrs = {\n        dtype: list(attrs)\n        for (dtype, attrs) in DEFAULT_ATTRS.items()\n        if dtype in dtypes\n    }\n    return dtype_attrs\n</code></pre>"},{"location":"reference/medspacy/io/doc_consumer/#medspacy.io.doc_consumer.DocConsumer.validate_section_attrs","title":"<code>validate_section_attrs(attrs)</code>","text":"<p>Validate that section attributes are either not specified or are valid attribute names.</p> Source code in <code>medspacy/io/doc_consumer.py</code> <pre><code>def validate_section_attrs(self, attrs):\n    \"\"\"\n    Validate that section attributes are either not specified or are valid attribute names.\n    \"\"\"\n    if attrs is None:\n        return True\n    if \"section\" not in attrs:\n        return True\n    diff = set(attrs[\"section\"]).difference(ALLOWED_SECTION_ATTRS)\n    if diff:\n        raise ValueError(\"Invalid section dtype_attrs specified: {0}\".format(diff))\n    return True\n</code></pre>"},{"location":"reference/medspacy/io/pipeline/","title":"medspacy.io.pipeline","text":""},{"location":"reference/medspacy/io/pipeline/#medspacy.io.pipeline.Pipeline","title":"<code>Pipeline</code>","text":"<p>The Pipeline class executes a batch process of reading texts, processing them with a spaCy model, and writing the results back to a database.</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>@Language.factory(\"medspacy_pipeline\")\nclass Pipeline:\n    \"\"\"The Pipeline class executes a batch process of reading texts, processing them with a spaCy model, and writing\n    the results back to a database.\n    \"\"\"\n\n    def __init__(self, nlp, reader, writer, name=\"medspacy_pipeline\", dtype=\"ent\"):\n        \"\"\"Create a new Pipeline object.\n        Args:\n            reader: A DbReader object\n            writer: A Dbwriter object\n            nlp: A spaCy model\n            dtype: The DocConsumer data type to write to a database.\n                Default \"ent\n                Valid options are (\"ent\", \"section\", \"context\", \"doc\")\n        \"\"\"\n\n        self.reader = reader\n        self.writer = writer\n        self.name = name\n        self.nlp = nlp\n        self.dtype = dtype\n        if dtype not in ALLOWED_DATA_TYPES:\n            raise ValueError(\n                \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                    ALLOWED_DATA_TYPES, dtype\n                )\n            )\n\n    def process(self):\n        \"\"\"Run a pipeline by reading a set of texts from a source table, processing them with nlp,\n        and writing doc._.data back to the destination table.\n        \"\"\"\n        query_result = self.reader.read()\n        data = None\n        while query_result:\n            if len(query_result) &gt; 0:\n                query_zip = list(zip(*query_result))\n                ids = query_zip[0]\n                texts = query_zip[1]\n\n                docs = self.nlp.pipe(texts)\n\n                for i, doc in enumerate(docs):\n                    text_id = ids[i]\n                    # Get the data as rows of tuples\n                    doc_data = doc._.get_data(self.dtype, as_rows=True)\n                    # Add the identifier column\n                    doc_data = [(text_id,) + row_data for row_data in doc_data]\n                    # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n                    # doc_data = pd.DataFrame(data=doc._.get_data(self.dtype))\n                    # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n\n                    if data is None:\n                        data = doc_data.copy()\n                    else:\n                        data += doc_data.copy()\n                    if len(data) &gt;= self.writer.batch_size:\n                        self.writer.write_data(data)\n                        data = None\n            query_result = self.reader.read()\n\n        if data is not None:\n            self.writer.write_data(data)\n            data = None\n\n        self.reader.close()\n        if self.writer.db.conn != self.reader.db.conn:\n            self.writer.close()\n</code></pre>"},{"location":"reference/medspacy/io/pipeline/#medspacy.io.pipeline.Pipeline.__init__","title":"<code>__init__(nlp, reader, writer, name='medspacy_pipeline', dtype='ent')</code>","text":"<p>Create a new Pipeline object. Args:     reader: A DbReader object     writer: A Dbwriter object     nlp: A spaCy model     dtype: The DocConsumer data type to write to a database.         Default \"ent         Valid options are (\"ent\", \"section\", \"context\", \"doc\")</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>def __init__(self, nlp, reader, writer, name=\"medspacy_pipeline\", dtype=\"ent\"):\n    \"\"\"Create a new Pipeline object.\n    Args:\n        reader: A DbReader object\n        writer: A Dbwriter object\n        nlp: A spaCy model\n        dtype: The DocConsumer data type to write to a database.\n            Default \"ent\n            Valid options are (\"ent\", \"section\", \"context\", \"doc\")\n    \"\"\"\n\n    self.reader = reader\n    self.writer = writer\n    self.name = name\n    self.nlp = nlp\n    self.dtype = dtype\n    if dtype not in ALLOWED_DATA_TYPES:\n        raise ValueError(\n            \"Invalid dtypes. Supported dtypes are {0}, not {1}\".format(\n                ALLOWED_DATA_TYPES, dtype\n            )\n        )\n</code></pre>"},{"location":"reference/medspacy/io/pipeline/#medspacy.io.pipeline.Pipeline.process","title":"<code>process()</code>","text":"<p>Run a pipeline by reading a set of texts from a source table, processing them with nlp, and writing doc._.data back to the destination table.</p> Source code in <code>medspacy/io/pipeline.py</code> <pre><code>def process(self):\n    \"\"\"Run a pipeline by reading a set of texts from a source table, processing them with nlp,\n    and writing doc._.data back to the destination table.\n    \"\"\"\n    query_result = self.reader.read()\n    data = None\n    while query_result:\n        if len(query_result) &gt; 0:\n            query_zip = list(zip(*query_result))\n            ids = query_zip[0]\n            texts = query_zip[1]\n\n            docs = self.nlp.pipe(texts)\n\n            for i, doc in enumerate(docs):\n                text_id = ids[i]\n                # Get the data as rows of tuples\n                doc_data = doc._.get_data(self.dtype, as_rows=True)\n                # Add the identifier column\n                doc_data = [(text_id,) + row_data for row_data in doc_data]\n                # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n                # doc_data = pd.DataFrame(data=doc._.get_data(self.dtype))\n                # doc_data.insert(0, self.writer.cols[0], [text_id for _ in range(len(doc_data))])\n\n                if data is None:\n                    data = doc_data.copy()\n                else:\n                    data += doc_data.copy()\n                if len(data) &gt;= self.writer.batch_size:\n                    self.writer.write_data(data)\n                    data = None\n        query_result = self.reader.read()\n\n    if data is not None:\n        self.writer.write_data(data)\n        data = None\n\n    self.reader.close()\n    if self.writer.db.conn != self.reader.db.conn:\n        self.writer.close()\n</code></pre>"},{"location":"reference/medspacy/ner/","title":"medspacy.ner","text":""},{"location":"reference/medspacy/postprocess/","title":"medspacy.postprocess","text":""},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.PostprocessingPattern","title":"<code>PostprocessingPattern</code>","text":"<p>PostprocessingPatterns are callable functions and equality values wrapped together that will create triggers in the later Postprocessor as part of PostprocessingRules.</p> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>class PostprocessingPattern:\n    \"\"\"\n    PostprocessingPatterns are callable functions and equality values wrapped together that will create triggers\n    in the later Postprocessor as part of PostprocessingRules.\n    \"\"\"\n\n    def __init__(self, condition: Callable, success_value: Any = True, **kwargs):\n        \"\"\"\n        A PostprocessingPattern defines a single condition to check against an entity.\n\n        Args:\n            condition: A function to call on an entity. If the result of the function call equals success_value, then\n                the pattern passes.\n            success_value: The value which should be returned by condition(ent) in order for the pattern to pass. Must\n                have == defined for condition(ent) == success_value.\n            kwargs: Optional keyword arguments to call with condition(ent, **kwargs).\n        \"\"\"\n        self.condition = condition\n        self.success_value = success_value\n        self.kwargs = kwargs\n\n    def __call__(self, ent: Span) -&gt; bool:\n        \"\"\"\n        Call the PostprocessingPattern on the span specified.\n\n        Args:\n            ent: the span to process.\n\n        Returns:\n            Whether calling `condition` on the entity specified is `success_value`.\n        \"\"\"\n        if self.kwargs:\n            result = self.condition(ent, **self.kwargs)\n        else:\n            result = self.condition(ent)\n        return result == self.success_value\n</code></pre>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.PostprocessingPattern.__call__","title":"<code>__call__(ent)</code>","text":"<p>Call the PostprocessingPattern on the span specified.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>the span to process.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether calling <code>condition</code> on the entity specified is <code>success_value</code>.</p> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>def __call__(self, ent: Span) -&gt; bool:\n    \"\"\"\n    Call the PostprocessingPattern on the span specified.\n\n    Args:\n        ent: the span to process.\n\n    Returns:\n        Whether calling `condition` on the entity specified is `success_value`.\n    \"\"\"\n    if self.kwargs:\n        result = self.condition(ent, **self.kwargs)\n    else:\n        result = self.condition(ent)\n    return result == self.success_value\n</code></pre>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.PostprocessingPattern.__init__","title":"<code>__init__(condition, success_value=True, **kwargs)</code>","text":"<p>A PostprocessingPattern defines a single condition to check against an entity.</p> <p>Parameters:</p> Name Type Description Default <code>condition</code> <code>Callable</code> <p>A function to call on an entity. If the result of the function call equals success_value, then the pattern passes.</p> required <code>success_value</code> <code>Any</code> <p>The value which should be returned by condition(ent) in order for the pattern to pass. Must have == defined for condition(ent) == success_value.</p> <code>True</code> <code>kwargs</code> <p>Optional keyword arguments to call with condition(ent, **kwargs).</p> <code>{}</code> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>def __init__(self, condition: Callable, success_value: Any = True, **kwargs):\n    \"\"\"\n    A PostprocessingPattern defines a single condition to check against an entity.\n\n    Args:\n        condition: A function to call on an entity. If the result of the function call equals success_value, then\n            the pattern passes.\n        success_value: The value which should be returned by condition(ent) in order for the pattern to pass. Must\n            have == defined for condition(ent) == success_value.\n        kwargs: Optional keyword arguments to call with condition(ent, **kwargs).\n    \"\"\"\n    self.condition = condition\n    self.success_value = success_value\n    self.kwargs = kwargs\n</code></pre>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.PostprocessingRule","title":"<code>PostprocessingRule</code>","text":"Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>class PostprocessingRule:\n    def __init__(\n        self,\n        patterns: Iterable[PostprocessingPattern],\n        action: Callable,\n        name: str = None,\n        description: str = None,\n        span_group_name: str = \"medspacy_spans\",\n        **kwargs,\n    ):\n        \"\"\"\n        A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.\n\n        patterns: A list of PostprocessingPatterns, each of which check a condition of an entity.\n        action: A function to call with the entity as an argument. This function should take the following arguments:\n            ent: The spacy span\n            i: The index of ent\n            input_span_type: \"ents\" or \"group\". Describes where to look for spans.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\".\n            kwargs: Any additional keyword arguments for action.\n        name: Optional name of direction.\n        description: Optional description of the direction.\n        kwargs: Optional keyword arguments to send to `action`.\n\n        \"\"\"\n        self.patterns = patterns\n        self.action = action\n        self.name = name\n        self.description = description\n        self.input_span_type = None\n        self.span_group_name = span_group_name\n        self.kwargs = kwargs\n\n    def __call__(self, ent, i, debug=False):\n        \"\"\"\n        Iterate through all the rules in self.rules.\n        If any pattern does not pass (ie., return True), then returns False.\n        If they all pass, execute self.action and return True.\n        \"\"\"\n        for pattern in self.patterns:\n            # If this is a tuple, at least one has to pass\n            if isinstance(pattern, tuple):\n                passed = False\n                for subpattern in pattern:\n                    rslt = subpattern(ent)\n                    if rslt is True:\n                        passed = True\n                        break\n                if passed is False:\n                    return False\n            # Otherwise just check a single value\n            else:\n                rslt = pattern(ent)\n                if rslt is False:\n                    return False\n\n        # Every pattern passed - do the action\n        if debug:\n            print(\"Passed:\", self, \"on ent:\", ent, ent.sent)\n\n        try:\n            if self.kwargs:\n                self.action(\n                    ent, i, self.input_span_type, self.span_group_name, **self.kwargs\n                )\n            else:\n                self.action(ent, i, self.input_span_type, self.span_group_name)\n        except TypeError:\n            _raise_action_error(\n                self.action,\n                (ent, i, self.input_span_type, self.span_group_name, self.kwargs),\n            )\n\n    def __repr__(self):\n        return f\"PostprocessingRule: {self.name} - {self.description}\"\n</code></pre>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.PostprocessingRule.__call__","title":"<code>__call__(ent, i, debug=False)</code>","text":"<p>Iterate through all the rules in self.rules. If any pattern does not pass (ie., return True), then returns False. If they all pass, execute self.action and return True.</p> Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>def __call__(self, ent, i, debug=False):\n    \"\"\"\n    Iterate through all the rules in self.rules.\n    If any pattern does not pass (ie., return True), then returns False.\n    If they all pass, execute self.action and return True.\n    \"\"\"\n    for pattern in self.patterns:\n        # If this is a tuple, at least one has to pass\n        if isinstance(pattern, tuple):\n            passed = False\n            for subpattern in pattern:\n                rslt = subpattern(ent)\n                if rslt is True:\n                    passed = True\n                    break\n            if passed is False:\n                return False\n        # Otherwise just check a single value\n        else:\n            rslt = pattern(ent)\n            if rslt is False:\n                return False\n\n    # Every pattern passed - do the action\n    if debug:\n        print(\"Passed:\", self, \"on ent:\", ent, ent.sent)\n\n    try:\n        if self.kwargs:\n            self.action(\n                ent, i, self.input_span_type, self.span_group_name, **self.kwargs\n            )\n        else:\n            self.action(ent, i, self.input_span_type, self.span_group_name)\n    except TypeError:\n        _raise_action_error(\n            self.action,\n            (ent, i, self.input_span_type, self.span_group_name, self.kwargs),\n        )\n</code></pre>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.PostprocessingRule.__init__","title":"<code>__init__(patterns, action, name=None, description=None, span_group_name='medspacy_spans', **kwargs)</code>","text":"<p>A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.</p> <p>patterns: A list of PostprocessingPatterns, each of which check a condition of an entity. action: A function to call with the entity as an argument. This function should take the following arguments:     ent: The spacy span     i: The index of ent     input_span_type: \"ents\" or \"group\". Describes where to look for spans.     span_group_name: The name of the span group used when <code>input_span_type</code> is \"group\".     kwargs: Any additional keyword arguments for action. name: Optional name of direction. description: Optional description of the direction. kwargs: Optional keyword arguments to send to <code>action</code>.</p> Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>def __init__(\n    self,\n    patterns: Iterable[PostprocessingPattern],\n    action: Callable,\n    name: str = None,\n    description: str = None,\n    span_group_name: str = \"medspacy_spans\",\n    **kwargs,\n):\n    \"\"\"\n    A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.\n\n    patterns: A list of PostprocessingPatterns, each of which check a condition of an entity.\n    action: A function to call with the entity as an argument. This function should take the following arguments:\n        ent: The spacy span\n        i: The index of ent\n        input_span_type: \"ents\" or \"group\". Describes where to look for spans.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\".\n        kwargs: Any additional keyword arguments for action.\n    name: Optional name of direction.\n    description: Optional description of the direction.\n    kwargs: Optional keyword arguments to send to `action`.\n\n    \"\"\"\n    self.patterns = patterns\n    self.action = action\n    self.name = name\n    self.description = description\n    self.input_span_type = None\n    self.span_group_name = span_group_name\n    self.kwargs = kwargs\n</code></pre>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.Postprocessor","title":"<code>Postprocessor</code>","text":"Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>@Language.factory(\"medspacy_postprocessor\")\nclass Postprocessor:\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_postprocessor\",\n        rules: Iterable[PostprocessingRule] = None,\n        debug: bool = False,\n        input_span_type: Literal[\"ents\", \"group\"] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        self.nlp = nlp\n        self.name = name\n        self._rules = []\n        self.debug = debug\n        self._input_span_type = input_span_type\n        self._span_group_name = span_group_name\n\n        if rules:\n            self.add(rules)\n\n    @property\n    def rules(self) -&gt; List[PostprocessingRule]:\n        \"\"\"\n        Gets the rules.\n\n        Returns:\n            The list of PostprocessingRules available to the Postprocessor.\n        \"\"\"\n        return self._rules\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_span_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_span_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules: Union[PostprocessingRule, Iterable[PostprocessingRule]]):\n        \"\"\"\n        Adds PostprocessingRules to the Postprocessor.\n\n        Args:\n            rules: A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.\n        \"\"\"\n        if isinstance(rules, PostprocessingRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, PostprocessingRule):\n                raise TypeError(\n                    f\"Rules must be type PostprocessingRule, not {type(rule)}.\"\n                )\n            if rule.input_span_type is None:\n                rule.input_span_type = self.input_span_type\n        self._rules += rules\n\n    def __call__(self, doc: Doc):\n        \"\"\"\n        Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed Doc.\n        \"\"\"\n        # Iterate through the entities in reversed order\n        if self._input_span_type == \"ents\":\n            spans = doc.ents\n        else:\n            spans = doc.spans[self._span_group_name]\n\n        for i in range(len(spans) - 1, -1, -1):\n            ent = spans[i]\n            if self.debug:\n                print(ent)\n\n            # let's keep track of whether the rule makes a change to spans\n            span_count_before_rule = None\n            if self._input_span_type == \"ents\":\n                span_count_before_rule = len(doc.ents)\n            else:\n                span_count_before_rule = len(doc.spans[self.span_group_name])\n\n            for rule in self.rules:\n                rule(ent, i, debug=self.debug)\n                # Check if the entity was removed based on span counts before and after rule execution\n                # if it was, skip to the next entity\n                try:\n                    if self._input_span_type == \"ents\":\n                        if len(doc.ents) != span_count_before_rule:\n                            break\n                    else:\n                        if len(doc.spans[self.span_group_name]) != span_count_before_rule:\n                            break\n                except IndexError:\n                    break\n            # if self.debug:\n            #     print()\n        return doc\n</code></pre>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.Postprocessor.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.Postprocessor.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets the rules.</p> <p>Returns:</p> Type Description <code>List[PostprocessingRule]</code> <p>The list of PostprocessingRules available to the Postprocessor.</p>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.Postprocessor.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_span_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.Postprocessor.__call__","title":"<code>__call__(doc)</code>","text":"<p>Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <p>The processed Doc.</p> Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>def __call__(self, doc: Doc):\n    \"\"\"\n    Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed Doc.\n    \"\"\"\n    # Iterate through the entities in reversed order\n    if self._input_span_type == \"ents\":\n        spans = doc.ents\n    else:\n        spans = doc.spans[self._span_group_name]\n\n    for i in range(len(spans) - 1, -1, -1):\n        ent = spans[i]\n        if self.debug:\n            print(ent)\n\n        # let's keep track of whether the rule makes a change to spans\n        span_count_before_rule = None\n        if self._input_span_type == \"ents\":\n            span_count_before_rule = len(doc.ents)\n        else:\n            span_count_before_rule = len(doc.spans[self.span_group_name])\n\n        for rule in self.rules:\n            rule(ent, i, debug=self.debug)\n            # Check if the entity was removed based on span counts before and after rule execution\n            # if it was, skip to the next entity\n            try:\n                if self._input_span_type == \"ents\":\n                    if len(doc.ents) != span_count_before_rule:\n                        break\n                else:\n                    if len(doc.spans[self.span_group_name]) != span_count_before_rule:\n                        break\n            except IndexError:\n                break\n        # if self.debug:\n        #     print()\n    return doc\n</code></pre>"},{"location":"reference/medspacy/postprocess/#medspacy.postprocess.Postprocessor.add","title":"<code>add(rules)</code>","text":"<p>Adds PostprocessingRules to the Postprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[PostprocessingRule, Iterable[PostprocessingRule]]</code> <p>A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.</p> required Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>def add(self, rules: Union[PostprocessingRule, Iterable[PostprocessingRule]]):\n    \"\"\"\n    Adds PostprocessingRules to the Postprocessor.\n\n    Args:\n        rules: A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.\n    \"\"\"\n    if isinstance(rules, PostprocessingRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, PostprocessingRule):\n            raise TypeError(\n                f\"Rules must be type PostprocessingRule, not {type(rule)}.\"\n            )\n        if rule.input_span_type is None:\n            rule.input_span_type = self.input_span_type\n    self._rules += rules\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/","title":"medspacy.postprocess.postprocessing_functions","text":"<p>This module contains some simple functions that can be used as action or condition functions for postprocessing rules.</p>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.ent_contains","title":"<code>ent_contains(ent, target, regex=True)</code>","text":"<p>Check if an entity occurs in the same sentence as another span of text. Case-insensitive.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>A string or a collection of strings that will be searched inside <code>ent</code>.</p> required <code>regex</code> <code>bool</code> <p>If the <code>target</code> specified is a regex pattern. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the target is contained in the ent.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def ent_contains(\n    ent: Span, target: Union[str, Iterable[str]], regex: bool = True\n) -&gt; bool:\n    \"\"\"\n    Check if an entity occurs in the same sentence as another span of text. Case-insensitive.\n\n    Args:\n        ent: The span to check.\n        target: A string or a collection of strings that will be searched inside `ent`.\n        regex: If the `target` specified is a regex pattern. Default is True.\n\n    Returns:\n        Whether the target is contained in the ent.\n    \"\"\"\n    return span_contains(ent, target, regex)\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.is_family","title":"<code>is_family(span)</code>","text":"<p>Returns whether a span is marked as family.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_family set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_family(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as family.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_family set to True.\n    \"\"\"\n    return span._.is_family\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.is_followed_by","title":"<code>is_followed_by(ent, target, window=1)</code>","text":"<p>Checks if an entity is followed by a target word within a certain window. If any phrases in target are more than one token long, this may not capture it if window is smaller than the number of tokens. Case-insensitive.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>A string or a collection of strings that will be searched for in the text following <code>ent</code>.</p> required <code>window</code> <code>int</code> <p>The number of tokens to search for <code>target</code> following <code>ent</code>. Default is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the entity specified is followed by a target.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_followed_by(\n    ent: Span, target: Union[str, Iterable[str]], window: int = 1\n) -&gt; bool:\n    \"\"\"\n    Checks if an entity is followed by a target word within a certain window. If any phrases in target are more than one\n    token long, this may not capture it if window is smaller than the number of tokens. Case-insensitive.\n\n    Args:\n        ent: The span to check.\n        target: A string or a collection of strings that will be searched for in the text following `ent`.\n        window: The number of tokens to search for `target` following `ent`. Default is 1.\n\n    Returns:\n        Whether the entity specified is followed by a target.\n    \"\"\"\n    following_span = ent.doc[ent.end : ent.end + window]\n    following_string = \" \".join([token.text.lower() for token in following_span])\n    if isinstance(target, str):\n        return target.lower() in following_string\n    for string in target:\n        if string.lower() in following_string:\n            return True\n    return False\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.is_historical","title":"<code>is_historical(span)</code>","text":"<p>Returns whether a span is marked as historical.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_historical set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_historical(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as historical.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_historical set to True.\n    \"\"\"\n    return span._.is_historical\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.is_hypothetical","title":"<code>is_hypothetical(span)</code>","text":"<p>Returns whether a span is marked as hypothetical.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_hypothetical set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_hypothetical(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as hypothetical.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_hypothetical set to True.\n    \"\"\"\n    return span._.is_hypothetical\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.is_modified_by_category","title":"<code>is_modified_by_category(span, category)</code>","text":"<p>Returns whether a span is modified by a ConTextModifier of that type.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <code>category</code> <code>str</code> <p>The category to check whether a ConTextModifier of that type modifies the span.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has the specified modifier type.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_modified_by_category(span: Span, category: str) -&gt; bool:\n    \"\"\"\n    Returns whether a span is modified by a ConTextModifier of that type.\n\n    Args:\n        span: The span to check.\n        category: The category to check whether a ConTextModifier of that type modifies the span.\n\n    Returns:\n        Whether the specified span has the specified modifier type.\n    \"\"\"\n    for modifier in span._.modifiers:\n        if modifier.category.upper() == category.upper():\n            return True\n    return False\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.is_modified_by_text","title":"<code>is_modified_by_text(span, target, regex=True)</code>","text":"<p>Returns whether a span is modified by a ConTextModifier with the specified text.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>The category to check whether a ConTextModifier with this text modifies the span.</p> required <code>regex</code> <code>bool</code> <p>If the <code>target</code> specified is a regex pattern. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has the specified modifier type.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_modified_by_text(\n    span: Span, target: Union[str, Iterable[str]], regex: bool = True\n) -&gt; bool:\n    \"\"\"\n    Returns whether a span is modified by a ConTextModifier with the specified text.\n\n    Args:\n        span: The span to check.\n        target: The category to check whether a ConTextModifier with this text modifies the span.\n        regex: If the `target` specified is a regex pattern. Default is True.\n\n    Returns:\n        Whether the specified span has the specified modifier type.\n    \"\"\"\n    for modifier in span._.modifiers:\n        if span_contains(modifier.span, target, regex):\n            return True\n    return False\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.is_negated","title":"<code>is_negated(span)</code>","text":"<p>Returns whether a span is marked as negated.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_negated set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_negated(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as negated.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_negated set to True.\n    \"\"\"\n    return span._.is_negated\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.is_preceded_by","title":"<code>is_preceded_by(ent, target, window=1)</code>","text":"<p>Checks if an entity is preceded by a target word within a certain window. If any phrases in target are more than one token long, this may not capture it if window is smaller than the number of tokens. Case-insensitive.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>A string or a collection of strings that will be searched for in the text preceding <code>ent</code>.</p> required <code>window</code> <code>int</code> <p>The number of tokens to search for <code>target</code> preceding <code>ent</code>. Default is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the entity specified is preceded by a target.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_preceded_by(\n    ent: Span, target: Union[str, Iterable[str]], window: int = 1\n) -&gt; bool:\n    \"\"\"\n    Checks if an entity is preceded by a target word within a certain window. If any phrases in target are more than one\n    token long, this may not capture it if window is smaller than the number of tokens. Case-insensitive.\n\n    Args:\n        ent: The span to check.\n        target: A string or a collection of strings that will be searched for in the text preceding `ent`.\n        window: The number of tokens to search for `target` preceding `ent`. Default is 1.\n\n    Returns:\n        Whether the entity specified is preceded by a target.\n    \"\"\"\n    preceding_span = ent.doc[ent.start - window : ent.start]\n    preceding_string = \" \".join([token.text.lower() for token in preceding_span])\n    if isinstance(target, str):\n        return target.lower() in preceding_string\n    for string in target:\n        if string.lower() in preceding_string:\n            return True\n    return False\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.is_uncertain","title":"<code>is_uncertain(span)</code>","text":"<p>Returns whether a span is marked as uncertain.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>Span</code> <p>The span to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the specified span has span._.is_uncertain set to True.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def is_uncertain(span: Span) -&gt; bool:\n    \"\"\"\n    Returns whether a span is marked as uncertain.\n\n    Args:\n        span: The span to check.\n\n    Returns:\n        Whether the specified span has span._.is_uncertain set to True.\n    \"\"\"\n    return span._.is_uncertain\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.remove_ent","title":"<code>remove_ent(ent, i, input_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Remove an entity at position [i] from doc.ents.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The entity to remove.</p> required <code>i</code> <code>int</code> <p>The index of <code>ent</code> in its source list.</p> required <code>input_type</code> <code>Literal['ents', 'group']</code> <p>The source of the entity, either \"ents\" or \"group\".</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>If <code>input_type</code> is \"group\", the name of the span group.</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def remove_ent(\n    ent: Span,\n    i: int,\n    input_type: Literal[\"ents\", \"group\"] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n):\n    \"\"\"\n    Remove an entity at position [i] from doc.ents.\n\n    Args:\n        ent: The entity to remove.\n        i: The index of `ent` in its source list.\n        input_type: The source of the entity, either \"ents\" or \"group\".\n        span_group_name: If `input_type` is \"group\", the name of the span group.\n    \"\"\"\n    doc = ent.doc\n    if input_type == \"ents\":\n        doc.ents = doc.ents[:i] + doc.ents[i + 1 :]\n    elif input_type == \"group\":\n        t = list(doc.spans[span_group_name])\n        doc.spans[span_group_name] = t[:i] + t[i + 1 :]\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.sentence_contains","title":"<code>sentence_contains(ent, target, regex=True)</code>","text":"<p>Check if an entity occurs in the same sentence as another span of text.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>The span to check.</p> required <code>target</code> <code>Union[str, Iterable[str]]</code> <p>A string or a collection of strings that will be searched for in the text of the sentence containing <code>ent</code>.</p> required <code>regex</code> <p>If the <code>target</code> specified is a regex pattern. Default is True.</p> <code>True</code> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def sentence_contains(ent: Span, target: Union[str, Iterable[str]], regex=True) -&gt; bool:\n    \"\"\"\n    Check if an entity occurs in the same sentence as another span of text.\n\n    Args:\n        ent: The span to check.\n        target: A string or a collection of strings that will be searched for in the text of the sentence containing\n            `ent`.\n        regex: If the `target` specified is a regex pattern. Default is True.\n    \"\"\"\n    return span_contains(ent.sent, target, regex)\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.set_family","title":"<code>set_family(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_family to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_family(ent, i, value=True):\n    \"Set the value of ent._.is_family to value.\"\n    ent._.is_hypothetical = value\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.set_historical","title":"<code>set_historical(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_historical to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_historical(ent, i, value=True):\n    \"\"\"Set the value of ent._.is_historical to value.\"\"\"\n    ent._.is_historical = value\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.set_hypothetical","title":"<code>set_hypothetical(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_hypothetical to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_hypothetical(ent, i, value=True):\n    \"\"\"Set the value of ent._.is_hypothetical to value.\"\"\"\n    ent._.is_hypothetical = value\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.set_label","title":"<code>set_label(ent, i, input_type='ents', span_group_name='medspacy_spans', **kwargs)</code>","text":"<p>Creates a copy of the entity with a new label.</p> <p>WARNING: This is not fully safe, as spaCy does not allow modifying the label of a span. Instead, this creates a new copy and attempts to copy existing attributes, but this is not totally reliable.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <p>The entity to MODIFY.</p> required <code>i</code> <p>The index of <code>ent</code> in its source list.</p> required <code>input_type</code> <code>Literal['ents', 'group']</code> <p>The source of the entity, either \"ents\" or \"group\".</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>If <code>input_type</code> is \"group\", the name of the span group.</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_label(\n    ent,\n    i,\n    input_type: Literal[\"ents\", \"group\"] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n    **kwargs\n):\n    \"\"\"\n    Creates a copy of the entity with a new label.\n\n    WARNING: This is not fully safe, as spaCy does not allow modifying the label of a span. Instead, this creates a new\n    copy and attempts to copy existing attributes, but this is not totally reliable.\n\n    Args:\n        ent: The entity to MODIFY.\n        i: The index of `ent` in its source list.\n        input_type: The source of the entity, either \"ents\" or \"group\".\n        span_group_name: If `input_type` is \"group\", the name of the span group.\n    \"\"\"\n    from spacy.tokens import Span\n\n    new_ent = Span(ent.doc, ent.start, ent.end, label=kwargs[\"label\"])\n    # Copy any additional attributes\n    # NOTE: This may not be complete and should be used with caution\n    for (attr, values) in ent._.__dict__[\"_extensions\"].items():\n        setattr(new_ent._, attr, values[0])\n    if input_type == \"ents\":\n        if len(ent.doc.ents) == 1:\n            ent.doc.ents = (new_ent,)\n        else:\n            ent.doc.ents = ent.doc.ents[:i] + (new_ent,) + ent.doc.ents[i + 1 :]\n    else:\n        if len(ent.doc.spans[span_group_name] == 1):\n            ent.doc.spans[span_group_name] = (new_ent,)\n        else:\n            ent.doc.spans[span_group_name] = (\n                ent.doc.spans[span_group_name][:i]\n                + (new_ent,)\n                + ent.doc.spans[span_group_name][i + 1 :]\n            )\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.set_negated","title":"<code>set_negated(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_negated to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_negated(ent, i, value=True):\n    \"\"\"Set the value of ent._.is_negated to value.\"\"\"\n    ent._.is_negated = value\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_functions/#medspacy.postprocess.postprocessing_functions.set_uncertain","title":"<code>set_uncertain(ent, i, value=True)</code>","text":"<p>Set the value of ent._.is_uncertain to value.</p> Source code in <code>medspacy/postprocess/postprocessing_functions.py</code> <pre><code>def set_uncertain(ent, i, value=True):\n    \"\"\"Set the value of ent._.is_uncertain to value.\"\"\"\n    ent._.is_uncertain = value\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_pattern/","title":"medspacy.postprocess.postprocessing_pattern","text":""},{"location":"reference/medspacy/postprocess/postprocessing_pattern/#medspacy.postprocess.postprocessing_pattern.PostprocessingPattern","title":"<code>PostprocessingPattern</code>","text":"<p>PostprocessingPatterns are callable functions and equality values wrapped together that will create triggers in the later Postprocessor as part of PostprocessingRules.</p> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>class PostprocessingPattern:\n    \"\"\"\n    PostprocessingPatterns are callable functions and equality values wrapped together that will create triggers\n    in the later Postprocessor as part of PostprocessingRules.\n    \"\"\"\n\n    def __init__(self, condition: Callable, success_value: Any = True, **kwargs):\n        \"\"\"\n        A PostprocessingPattern defines a single condition to check against an entity.\n\n        Args:\n            condition: A function to call on an entity. If the result of the function call equals success_value, then\n                the pattern passes.\n            success_value: The value which should be returned by condition(ent) in order for the pattern to pass. Must\n                have == defined for condition(ent) == success_value.\n            kwargs: Optional keyword arguments to call with condition(ent, **kwargs).\n        \"\"\"\n        self.condition = condition\n        self.success_value = success_value\n        self.kwargs = kwargs\n\n    def __call__(self, ent: Span) -&gt; bool:\n        \"\"\"\n        Call the PostprocessingPattern on the span specified.\n\n        Args:\n            ent: the span to process.\n\n        Returns:\n            Whether calling `condition` on the entity specified is `success_value`.\n        \"\"\"\n        if self.kwargs:\n            result = self.condition(ent, **self.kwargs)\n        else:\n            result = self.condition(ent)\n        return result == self.success_value\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_pattern/#medspacy.postprocess.postprocessing_pattern.PostprocessingPattern.__call__","title":"<code>__call__(ent)</code>","text":"<p>Call the PostprocessingPattern on the span specified.</p> <p>Parameters:</p> Name Type Description Default <code>ent</code> <code>Span</code> <p>the span to process.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether calling <code>condition</code> on the entity specified is <code>success_value</code>.</p> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>def __call__(self, ent: Span) -&gt; bool:\n    \"\"\"\n    Call the PostprocessingPattern on the span specified.\n\n    Args:\n        ent: the span to process.\n\n    Returns:\n        Whether calling `condition` on the entity specified is `success_value`.\n    \"\"\"\n    if self.kwargs:\n        result = self.condition(ent, **self.kwargs)\n    else:\n        result = self.condition(ent)\n    return result == self.success_value\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_pattern/#medspacy.postprocess.postprocessing_pattern.PostprocessingPattern.__init__","title":"<code>__init__(condition, success_value=True, **kwargs)</code>","text":"<p>A PostprocessingPattern defines a single condition to check against an entity.</p> <p>Parameters:</p> Name Type Description Default <code>condition</code> <code>Callable</code> <p>A function to call on an entity. If the result of the function call equals success_value, then the pattern passes.</p> required <code>success_value</code> <code>Any</code> <p>The value which should be returned by condition(ent) in order for the pattern to pass. Must have == defined for condition(ent) == success_value.</p> <code>True</code> <code>kwargs</code> <p>Optional keyword arguments to call with condition(ent, **kwargs).</p> <code>{}</code> Source code in <code>medspacy/postprocess/postprocessing_pattern.py</code> <pre><code>def __init__(self, condition: Callable, success_value: Any = True, **kwargs):\n    \"\"\"\n    A PostprocessingPattern defines a single condition to check against an entity.\n\n    Args:\n        condition: A function to call on an entity. If the result of the function call equals success_value, then\n            the pattern passes.\n        success_value: The value which should be returned by condition(ent) in order for the pattern to pass. Must\n            have == defined for condition(ent) == success_value.\n        kwargs: Optional keyword arguments to call with condition(ent, **kwargs).\n    \"\"\"\n    self.condition = condition\n    self.success_value = success_value\n    self.kwargs = kwargs\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_rule/","title":"medspacy.postprocess.postprocessing_rule","text":""},{"location":"reference/medspacy/postprocess/postprocessing_rule/#medspacy.postprocess.postprocessing_rule.PostprocessingRule","title":"<code>PostprocessingRule</code>","text":"Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>class PostprocessingRule:\n    def __init__(\n        self,\n        patterns: Iterable[PostprocessingPattern],\n        action: Callable,\n        name: str = None,\n        description: str = None,\n        span_group_name: str = \"medspacy_spans\",\n        **kwargs,\n    ):\n        \"\"\"\n        A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.\n\n        patterns: A list of PostprocessingPatterns, each of which check a condition of an entity.\n        action: A function to call with the entity as an argument. This function should take the following arguments:\n            ent: The spacy span\n            i: The index of ent\n            input_span_type: \"ents\" or \"group\". Describes where to look for spans.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\".\n            kwargs: Any additional keyword arguments for action.\n        name: Optional name of direction.\n        description: Optional description of the direction.\n        kwargs: Optional keyword arguments to send to `action`.\n\n        \"\"\"\n        self.patterns = patterns\n        self.action = action\n        self.name = name\n        self.description = description\n        self.input_span_type = None\n        self.span_group_name = span_group_name\n        self.kwargs = kwargs\n\n    def __call__(self, ent, i, debug=False):\n        \"\"\"\n        Iterate through all the rules in self.rules.\n        If any pattern does not pass (ie., return True), then returns False.\n        If they all pass, execute self.action and return True.\n        \"\"\"\n        for pattern in self.patterns:\n            # If this is a tuple, at least one has to pass\n            if isinstance(pattern, tuple):\n                passed = False\n                for subpattern in pattern:\n                    rslt = subpattern(ent)\n                    if rslt is True:\n                        passed = True\n                        break\n                if passed is False:\n                    return False\n            # Otherwise just check a single value\n            else:\n                rslt = pattern(ent)\n                if rslt is False:\n                    return False\n\n        # Every pattern passed - do the action\n        if debug:\n            print(\"Passed:\", self, \"on ent:\", ent, ent.sent)\n\n        try:\n            if self.kwargs:\n                self.action(\n                    ent, i, self.input_span_type, self.span_group_name, **self.kwargs\n                )\n            else:\n                self.action(ent, i, self.input_span_type, self.span_group_name)\n        except TypeError:\n            _raise_action_error(\n                self.action,\n                (ent, i, self.input_span_type, self.span_group_name, self.kwargs),\n            )\n\n    def __repr__(self):\n        return f\"PostprocessingRule: {self.name} - {self.description}\"\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_rule/#medspacy.postprocess.postprocessing_rule.PostprocessingRule.__call__","title":"<code>__call__(ent, i, debug=False)</code>","text":"<p>Iterate through all the rules in self.rules. If any pattern does not pass (ie., return True), then returns False. If they all pass, execute self.action and return True.</p> Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>def __call__(self, ent, i, debug=False):\n    \"\"\"\n    Iterate through all the rules in self.rules.\n    If any pattern does not pass (ie., return True), then returns False.\n    If they all pass, execute self.action and return True.\n    \"\"\"\n    for pattern in self.patterns:\n        # If this is a tuple, at least one has to pass\n        if isinstance(pattern, tuple):\n            passed = False\n            for subpattern in pattern:\n                rslt = subpattern(ent)\n                if rslt is True:\n                    passed = True\n                    break\n            if passed is False:\n                return False\n        # Otherwise just check a single value\n        else:\n            rslt = pattern(ent)\n            if rslt is False:\n                return False\n\n    # Every pattern passed - do the action\n    if debug:\n        print(\"Passed:\", self, \"on ent:\", ent, ent.sent)\n\n    try:\n        if self.kwargs:\n            self.action(\n                ent, i, self.input_span_type, self.span_group_name, **self.kwargs\n            )\n        else:\n            self.action(ent, i, self.input_span_type, self.span_group_name)\n    except TypeError:\n        _raise_action_error(\n            self.action,\n            (ent, i, self.input_span_type, self.span_group_name, self.kwargs),\n        )\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessing_rule/#medspacy.postprocess.postprocessing_rule.PostprocessingRule.__init__","title":"<code>__init__(patterns, action, name=None, description=None, span_group_name='medspacy_spans', **kwargs)</code>","text":"<p>A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.</p> <p>patterns: A list of PostprocessingPatterns, each of which check a condition of an entity. action: A function to call with the entity as an argument. This function should take the following arguments:     ent: The spacy span     i: The index of ent     input_span_type: \"ents\" or \"group\". Describes where to look for spans.     span_group_name: The name of the span group used when <code>input_span_type</code> is \"group\".     kwargs: Any additional keyword arguments for action. name: Optional name of direction. description: Optional description of the direction. kwargs: Optional keyword arguments to send to <code>action</code>.</p> Source code in <code>medspacy/postprocess/postprocessing_rule.py</code> <pre><code>def __init__(\n    self,\n    patterns: Iterable[PostprocessingPattern],\n    action: Callable,\n    name: str = None,\n    description: str = None,\n    span_group_name: str = \"medspacy_spans\",\n    **kwargs,\n):\n    \"\"\"\n    A PostprocessingRule checks conditions of a spaCy Span entity and executes some action if all rules are met.\n\n    patterns: A list of PostprocessingPatterns, each of which check a condition of an entity.\n    action: A function to call with the entity as an argument. This function should take the following arguments:\n        ent: The spacy span\n        i: The index of ent\n        input_span_type: \"ents\" or \"group\". Describes where to look for spans.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\".\n        kwargs: Any additional keyword arguments for action.\n    name: Optional name of direction.\n    description: Optional description of the direction.\n    kwargs: Optional keyword arguments to send to `action`.\n\n    \"\"\"\n    self.patterns = patterns\n    self.action = action\n    self.name = name\n    self.description = description\n    self.input_span_type = None\n    self.span_group_name = span_group_name\n    self.kwargs = kwargs\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessor/","title":"medspacy.postprocess.postprocessor","text":""},{"location":"reference/medspacy/postprocess/postprocessor/#medspacy.postprocess.postprocessor.Postprocessor","title":"<code>Postprocessor</code>","text":"Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>@Language.factory(\"medspacy_postprocessor\")\nclass Postprocessor:\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_postprocessor\",\n        rules: Iterable[PostprocessingRule] = None,\n        debug: bool = False,\n        input_span_type: Literal[\"ents\", \"group\"] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n    ):\n        self.nlp = nlp\n        self.name = name\n        self._rules = []\n        self.debug = debug\n        self._input_span_type = input_span_type\n        self._span_group_name = span_group_name\n\n        if rules:\n            self.add(rules)\n\n    @property\n    def rules(self) -&gt; List[PostprocessingRule]:\n        \"\"\"\n        Gets the rules.\n\n        Returns:\n            The list of PostprocessingRules available to the Postprocessor.\n        \"\"\"\n        return self._rules\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_span_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_span_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules: Union[PostprocessingRule, Iterable[PostprocessingRule]]):\n        \"\"\"\n        Adds PostprocessingRules to the Postprocessor.\n\n        Args:\n            rules: A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.\n        \"\"\"\n        if isinstance(rules, PostprocessingRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, PostprocessingRule):\n                raise TypeError(\n                    f\"Rules must be type PostprocessingRule, not {type(rule)}.\"\n                )\n            if rule.input_span_type is None:\n                rule.input_span_type = self.input_span_type\n        self._rules += rules\n\n    def __call__(self, doc: Doc):\n        \"\"\"\n        Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed Doc.\n        \"\"\"\n        # Iterate through the entities in reversed order\n        if self._input_span_type == \"ents\":\n            spans = doc.ents\n        else:\n            spans = doc.spans[self._span_group_name]\n\n        for i in range(len(spans) - 1, -1, -1):\n            ent = spans[i]\n            if self.debug:\n                print(ent)\n\n            # let's keep track of whether the rule makes a change to spans\n            span_count_before_rule = None\n            if self._input_span_type == \"ents\":\n                span_count_before_rule = len(doc.ents)\n            else:\n                span_count_before_rule = len(doc.spans[self.span_group_name])\n\n            for rule in self.rules:\n                rule(ent, i, debug=self.debug)\n                # Check if the entity was removed based on span counts before and after rule execution\n                # if it was, skip to the next entity\n                try:\n                    if self._input_span_type == \"ents\":\n                        if len(doc.ents) != span_count_before_rule:\n                            break\n                    else:\n                        if len(doc.spans[self.span_group_name]) != span_count_before_rule:\n                            break\n                except IndexError:\n                    break\n            # if self.debug:\n            #     print()\n        return doc\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessor/#medspacy.postprocess.postprocessor.Postprocessor.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"reference/medspacy/postprocess/postprocessor/#medspacy.postprocess.postprocessor.Postprocessor.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets the rules.</p> <p>Returns:</p> Type Description <code>List[PostprocessingRule]</code> <p>The list of PostprocessingRules available to the Postprocessor.</p>"},{"location":"reference/medspacy/postprocess/postprocessor/#medspacy.postprocess.postprocessor.Postprocessor.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_span_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"reference/medspacy/postprocess/postprocessor/#medspacy.postprocess.postprocessor.Postprocessor.__call__","title":"<code>__call__(doc)</code>","text":"<p>Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <p>The processed Doc.</p> Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>def __call__(self, doc: Doc):\n    \"\"\"\n    Calls the Postprocessor on a spaCy doc. This will call each PostprocessingRule on the doc.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed Doc.\n    \"\"\"\n    # Iterate through the entities in reversed order\n    if self._input_span_type == \"ents\":\n        spans = doc.ents\n    else:\n        spans = doc.spans[self._span_group_name]\n\n    for i in range(len(spans) - 1, -1, -1):\n        ent = spans[i]\n        if self.debug:\n            print(ent)\n\n        # let's keep track of whether the rule makes a change to spans\n        span_count_before_rule = None\n        if self._input_span_type == \"ents\":\n            span_count_before_rule = len(doc.ents)\n        else:\n            span_count_before_rule = len(doc.spans[self.span_group_name])\n\n        for rule in self.rules:\n            rule(ent, i, debug=self.debug)\n            # Check if the entity was removed based on span counts before and after rule execution\n            # if it was, skip to the next entity\n            try:\n                if self._input_span_type == \"ents\":\n                    if len(doc.ents) != span_count_before_rule:\n                        break\n                else:\n                    if len(doc.spans[self.span_group_name]) != span_count_before_rule:\n                        break\n            except IndexError:\n                break\n        # if self.debug:\n        #     print()\n    return doc\n</code></pre>"},{"location":"reference/medspacy/postprocess/postprocessor/#medspacy.postprocess.postprocessor.Postprocessor.add","title":"<code>add(rules)</code>","text":"<p>Adds PostprocessingRules to the Postprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[PostprocessingRule, Iterable[PostprocessingRule]]</code> <p>A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.</p> required Source code in <code>medspacy/postprocess/postprocessor.py</code> <pre><code>def add(self, rules: Union[PostprocessingRule, Iterable[PostprocessingRule]]):\n    \"\"\"\n    Adds PostprocessingRules to the Postprocessor.\n\n    Args:\n        rules: A single PostprocessingRule or a collection of PostprocessingRules to add to the Postprocessor.\n    \"\"\"\n    if isinstance(rules, PostprocessingRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, PostprocessingRule):\n            raise TypeError(\n                f\"Rules must be type PostprocessingRule, not {type(rule)}.\"\n            )\n        if rule.input_span_type is None:\n            rule.input_span_type = self.input_span_type\n    self._rules += rules\n</code></pre>"},{"location":"reference/medspacy/preprocess/","title":"medspacy.preprocess","text":""},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.PreprocessingRule","title":"<code>PreprocessingRule</code>","text":"<p>This is a rule for handling preprocessing in the medspaCy Preprocessor. This class does not inherit from BaseRule, as it cannot be used in a spaCy pipeline. The Preprocessor and PreprocessingRules are designed to preprocess text before entering a spaCy pipeline to allow for destructive preprocessing, such as stripping or replacing text.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>class PreprocessingRule:\n    \"\"\"\n    This is a rule for handling preprocessing in the medspaCy Preprocessor. This class does not inherit from BaseRule,\n    as it cannot be used in a spaCy pipeline. The Preprocessor and PreprocessingRules are designed to preprocess text\n    before entering a spaCy pipeline to allow for destructive preprocessing, such as stripping or replacing text.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\"pattern\", \"repl\", \"desc\", \"pattern\", \"flags\"}\n\n    def __init__(\n        self,\n        pattern: str,\n        repl: Union[str, Callable[[re.Match], Any]] = \"\",\n        flags: re.RegexFlag = re.IGNORECASE,\n        callback: Optional[Callable[[str, re.Match], str]] = None,\n        desc: Optional[str] = None,\n    ):\n        \"\"\"\n        Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally\n        replaced from the text underneath a doc.\n\n        Args:\n            pattern: The text pattern to match and replace in a doc. Must be a string, which will be compiled as\n                a regular expression. The patterns will lead to re.Match objects.\n            repl: The text to replace a matched string with. By default, repl is an empty string. If repl is a function,\n                sends function to re.sub and it will be called on each Match object. More info here\n                https://docs.python.org/3/library/re.html#re.sub\n            flags: A regex compilation flag. Default is re.IGNORECASE.\n            callback: An optional callable which takes the raw text and a Match and returns the new copy of the text,\n                rather than just replacing strings for the matched text. This can allow larger text manipulation, such\n                as stripping out an entire section based on a header.\n            desc: An optional description.\n        \"\"\"\n        self.pattern = re.compile(pattern, flags=flags)\n        self.repl = repl\n        self.callback = callback\n        self.desc = desc\n\n    @classmethod\n    def from_dict(cls, d: Dict) -&gt; PreprocessingRule:\n        \"\"\"\n        Creates a PreprocessingRule from a dictionary.\n\n        Args:\n            d: The dict to read.\n\n        Returns:\n            A PreprocessingRule from the dictionary.\n        \"\"\"\n        return PreprocessingRule(\n            d[\"pattern\"],\n            repl=d[\"repl\"],\n            flags=d[\"flags\"],\n            callback=d[\"callback\"],\n            desc=d.get(\"desc\", None),\n        )\n\n    def to_dict(self):\n        \"\"\"\n        Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.\n\n        Returns:\n            A dictionary containing the PreprocessingRule's data.\n        \"\"\"\n        d = {\n            \"pattern\": self.pattern.pattern,\n            \"repl\": self.repl,\n            \"callback\": self.callback,\n            \"desc\": self.desc,\n            \"flags\": self.pattern.flags,\n        }\n        return d\n\n    @classmethod\n    def from_json(cls, filepath):\n        \"\"\"\n        Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".\n\n        Args:\n            filepath: The filepath of the JSON to read.\n\n        Returns:\n            A list of PreprocessingRules from the JSON file.\n        \"\"\"\n        import json\n\n        with open(filepath) as f:\n            data = json.load(f)\n        return [\n            PreprocessingRule.from_dict(rule) for rule in data[\"preprocessing_rules\"]\n        ]\n\n    def __call__(self, text):\n        \"\"\"\n        Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string\n        using the direction sub method. If callback is not None, then callback function will be executed using\n        the resulting match as an argument.\n        \"\"\"\n        # If the direction just has a repl attribute,\n        # Just return a simple re.sub\n        if self.callback is None:\n            return self.pattern.sub(self.repl, text)\n\n        match = self.pattern.search(text)\n        if match is None:\n            return text\n        return self.callback(text, match)\n\n    def __repr__(self):\n        return (\n            f\"PreprocessingRule(pattern={self.pattern.pattern}, flags={self.pattern.flags}, repl={self.repl}, \"\n            f\"callback={self.callback}, desc={self.desc})\"\n        )\n</code></pre>"},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.PreprocessingRule.__call__","title":"<code>__call__(text)</code>","text":"<p>Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string using the direction sub method. If callback is not None, then callback function will be executed using the resulting match as an argument.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def __call__(self, text):\n    \"\"\"\n    Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string\n    using the direction sub method. If callback is not None, then callback function will be executed using\n    the resulting match as an argument.\n    \"\"\"\n    # If the direction just has a repl attribute,\n    # Just return a simple re.sub\n    if self.callback is None:\n        return self.pattern.sub(self.repl, text)\n\n    match = self.pattern.search(text)\n    if match is None:\n        return text\n    return self.callback(text, match)\n</code></pre>"},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.PreprocessingRule.__init__","title":"<code>__init__(pattern, repl='', flags=re.IGNORECASE, callback=None, desc=None)</code>","text":"<p>Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally replaced from the text underneath a doc.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>The text pattern to match and replace in a doc. Must be a string, which will be compiled as a regular expression. The patterns will lead to re.Match objects.</p> required <code>repl</code> <code>Union[str, Callable[[Match], Any]]</code> <p>The text to replace a matched string with. By default, repl is an empty string. If repl is a function, sends function to re.sub and it will be called on each Match object. More info here https://docs.python.org/3/library/re.html#re.sub</p> <code>''</code> <code>flags</code> <code>RegexFlag</code> <p>A regex compilation flag. Default is re.IGNORECASE.</p> <code>IGNORECASE</code> <code>callback</code> <code>Optional[Callable[[str, Match], str]]</code> <p>An optional callable which takes the raw text and a Match and returns the new copy of the text, rather than just replacing strings for the matched text. This can allow larger text manipulation, such as stripping out an entire section based on a header.</p> <code>None</code> <code>desc</code> <code>Optional[str]</code> <p>An optional description.</p> <code>None</code> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def __init__(\n    self,\n    pattern: str,\n    repl: Union[str, Callable[[re.Match], Any]] = \"\",\n    flags: re.RegexFlag = re.IGNORECASE,\n    callback: Optional[Callable[[str, re.Match], str]] = None,\n    desc: Optional[str] = None,\n):\n    \"\"\"\n    Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally\n    replaced from the text underneath a doc.\n\n    Args:\n        pattern: The text pattern to match and replace in a doc. Must be a string, which will be compiled as\n            a regular expression. The patterns will lead to re.Match objects.\n        repl: The text to replace a matched string with. By default, repl is an empty string. If repl is a function,\n            sends function to re.sub and it will be called on each Match object. More info here\n            https://docs.python.org/3/library/re.html#re.sub\n        flags: A regex compilation flag. Default is re.IGNORECASE.\n        callback: An optional callable which takes the raw text and a Match and returns the new copy of the text,\n            rather than just replacing strings for the matched text. This can allow larger text manipulation, such\n            as stripping out an entire section based on a header.\n        desc: An optional description.\n    \"\"\"\n    self.pattern = re.compile(pattern, flags=flags)\n    self.repl = repl\n    self.callback = callback\n    self.desc = desc\n</code></pre>"},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.PreprocessingRule.from_dict","title":"<code>from_dict(d)</code>  <code>classmethod</code>","text":"<p>Creates a PreprocessingRule from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Dict</code> <p>The dict to read.</p> required <p>Returns:</p> Type Description <code>PreprocessingRule</code> <p>A PreprocessingRule from the dictionary.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, d: Dict) -&gt; PreprocessingRule:\n    \"\"\"\n    Creates a PreprocessingRule from a dictionary.\n\n    Args:\n        d: The dict to read.\n\n    Returns:\n        A PreprocessingRule from the dictionary.\n    \"\"\"\n    return PreprocessingRule(\n        d[\"pattern\"],\n        repl=d[\"repl\"],\n        flags=d[\"flags\"],\n        callback=d[\"callback\"],\n        desc=d.get(\"desc\", None),\n    )\n</code></pre>"},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.PreprocessingRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>The filepath of the JSON to read.</p> required <p>Returns:</p> Type Description <p>A list of PreprocessingRules from the JSON file.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath):\n    \"\"\"\n    Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".\n\n    Args:\n        filepath: The filepath of the JSON to read.\n\n    Returns:\n        A list of PreprocessingRules from the JSON file.\n    \"\"\"\n    import json\n\n    with open(filepath) as f:\n        data = json.load(f)\n    return [\n        PreprocessingRule.from_dict(rule) for rule in data[\"preprocessing_rules\"]\n    ]\n</code></pre>"},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.PreprocessingRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.</p> <p>Returns:</p> Type Description <p>A dictionary containing the PreprocessingRule's data.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.\n\n    Returns:\n        A dictionary containing the PreprocessingRule's data.\n    \"\"\"\n    d = {\n        \"pattern\": self.pattern.pattern,\n        \"repl\": self.repl,\n        \"callback\": self.callback,\n        \"desc\": self.desc,\n        \"flags\": self.pattern.flags,\n    }\n    return d\n</code></pre>"},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.Preprocessor","title":"<code>Preprocessor</code>","text":"<p>This is the medspacy Preprocessor class. It is designed as a wrapper for destructive preprocessing rules such as stripping or replacing text in a document before the text enters a spaCy pipeline.</p> <p>This is NOT a spaCy component and cannot be added to a spaCy pipeline. Please use the preprocessor before calling <code>nlp(\"your text here\")</code>. SpaCy only allows for non-destructive processing on the text, but that is not always advisable for every project, so this enables destructive preprocessing when required.</p> Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>class Preprocessor:\n    \"\"\"\n    This is the medspacy Preprocessor class. It is designed as a wrapper for destructive preprocessing rules such as\n    stripping or replacing text in a document before the text enters a spaCy pipeline.\n\n    This is NOT a spaCy component and cannot be added to a spaCy pipeline. Please use the preprocessor before\n    calling `nlp(\"your text here\")`. SpaCy only allows for non-destructive processing on the text, but that is not\n    always advisable for every project, so this enables destructive preprocessing when required.\n    \"\"\"\n\n    def __init__(self, tokenizer):\n        \"\"\"\n\n        Args:\n            tokenizer:\n        \"\"\"\n        self.tokenizer = tokenizer\n        self._rules = []\n\n    def add(self, rules: Union[PreprocessingRule, Iterable[PreprocessingRule]]):\n        \"\"\"\n        Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.\n\n        Args:\n            rules: A single PreprocessingRule or a collection of PreprocessingRules to add.\n        \"\"\"\n        if isinstance(rules, PreprocessingRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, PreprocessingRule):\n                raise TypeError(\n                    f\"Each rule must be an instance of PreprocessingRule, not {type(rule)}.\"\n                )\n        self._rules += rules\n\n    def __call__(self, text, tokenize=True) -&gt; Union[str, Doc]:\n        \"\"\"\n\n        Args:\n            text:\n            tokenize:\n\n        Returns:\n\n        \"\"\"\n        for rule in self._rules:\n            text = rule(text)\n\n        if not tokenize:\n            return text\n\n        return self.tokenizer(text)\n</code></pre>"},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.Preprocessor.__call__","title":"<code>__call__(text, tokenize=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>text</code> required <code>tokenize</code> <code>True</code> <p>Returns:</p> Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def __call__(self, text, tokenize=True) -&gt; Union[str, Doc]:\n    \"\"\"\n\n    Args:\n        text:\n        tokenize:\n\n    Returns:\n\n    \"\"\"\n    for rule in self._rules:\n        text = rule(text)\n\n    if not tokenize:\n        return text\n\n    return self.tokenizer(text)\n</code></pre>"},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.Preprocessor.__init__","title":"<code>__init__(tokenizer)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>tokenizer</code> required Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def __init__(self, tokenizer):\n    \"\"\"\n\n    Args:\n        tokenizer:\n    \"\"\"\n    self.tokenizer = tokenizer\n    self._rules = []\n</code></pre>"},{"location":"reference/medspacy/preprocess/#medspacy.preprocess.Preprocessor.add","title":"<code>add(rules)</code>","text":"<p>Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[PreprocessingRule, Iterable[PreprocessingRule]]</code> <p>A single PreprocessingRule or a collection of PreprocessingRules to add.</p> required Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def add(self, rules: Union[PreprocessingRule, Iterable[PreprocessingRule]]):\n    \"\"\"\n    Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.\n\n    Args:\n        rules: A single PreprocessingRule or a collection of PreprocessingRules to add.\n    \"\"\"\n    if isinstance(rules, PreprocessingRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, PreprocessingRule):\n            raise TypeError(\n                f\"Each rule must be an instance of PreprocessingRule, not {type(rule)}.\"\n            )\n    self._rules += rules\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessing_rule/","title":"medspacy.preprocess.preprocessing_rule","text":""},{"location":"reference/medspacy/preprocess/preprocessing_rule/#medspacy.preprocess.preprocessing_rule.PreprocessingRule","title":"<code>PreprocessingRule</code>","text":"<p>This is a rule for handling preprocessing in the medspaCy Preprocessor. This class does not inherit from BaseRule, as it cannot be used in a spaCy pipeline. The Preprocessor and PreprocessingRules are designed to preprocess text before entering a spaCy pipeline to allow for destructive preprocessing, such as stripping or replacing text.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>class PreprocessingRule:\n    \"\"\"\n    This is a rule for handling preprocessing in the medspaCy Preprocessor. This class does not inherit from BaseRule,\n    as it cannot be used in a spaCy pipeline. The Preprocessor and PreprocessingRules are designed to preprocess text\n    before entering a spaCy pipeline to allow for destructive preprocessing, such as stripping or replacing text.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\"pattern\", \"repl\", \"desc\", \"pattern\", \"flags\"}\n\n    def __init__(\n        self,\n        pattern: str,\n        repl: Union[str, Callable[[re.Match], Any]] = \"\",\n        flags: re.RegexFlag = re.IGNORECASE,\n        callback: Optional[Callable[[str, re.Match], str]] = None,\n        desc: Optional[str] = None,\n    ):\n        \"\"\"\n        Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally\n        replaced from the text underneath a doc.\n\n        Args:\n            pattern: The text pattern to match and replace in a doc. Must be a string, which will be compiled as\n                a regular expression. The patterns will lead to re.Match objects.\n            repl: The text to replace a matched string with. By default, repl is an empty string. If repl is a function,\n                sends function to re.sub and it will be called on each Match object. More info here\n                https://docs.python.org/3/library/re.html#re.sub\n            flags: A regex compilation flag. Default is re.IGNORECASE.\n            callback: An optional callable which takes the raw text and a Match and returns the new copy of the text,\n                rather than just replacing strings for the matched text. This can allow larger text manipulation, such\n                as stripping out an entire section based on a header.\n            desc: An optional description.\n        \"\"\"\n        self.pattern = re.compile(pattern, flags=flags)\n        self.repl = repl\n        self.callback = callback\n        self.desc = desc\n\n    @classmethod\n    def from_dict(cls, d: Dict) -&gt; PreprocessingRule:\n        \"\"\"\n        Creates a PreprocessingRule from a dictionary.\n\n        Args:\n            d: The dict to read.\n\n        Returns:\n            A PreprocessingRule from the dictionary.\n        \"\"\"\n        return PreprocessingRule(\n            d[\"pattern\"],\n            repl=d[\"repl\"],\n            flags=d[\"flags\"],\n            callback=d[\"callback\"],\n            desc=d.get(\"desc\", None),\n        )\n\n    def to_dict(self):\n        \"\"\"\n        Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.\n\n        Returns:\n            A dictionary containing the PreprocessingRule's data.\n        \"\"\"\n        d = {\n            \"pattern\": self.pattern.pattern,\n            \"repl\": self.repl,\n            \"callback\": self.callback,\n            \"desc\": self.desc,\n            \"flags\": self.pattern.flags,\n        }\n        return d\n\n    @classmethod\n    def from_json(cls, filepath):\n        \"\"\"\n        Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".\n\n        Args:\n            filepath: The filepath of the JSON to read.\n\n        Returns:\n            A list of PreprocessingRules from the JSON file.\n        \"\"\"\n        import json\n\n        with open(filepath) as f:\n            data = json.load(f)\n        return [\n            PreprocessingRule.from_dict(rule) for rule in data[\"preprocessing_rules\"]\n        ]\n\n    def __call__(self, text):\n        \"\"\"\n        Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string\n        using the direction sub method. If callback is not None, then callback function will be executed using\n        the resulting match as an argument.\n        \"\"\"\n        # If the direction just has a repl attribute,\n        # Just return a simple re.sub\n        if self.callback is None:\n            return self.pattern.sub(self.repl, text)\n\n        match = self.pattern.search(text)\n        if match is None:\n            return text\n        return self.callback(text, match)\n\n    def __repr__(self):\n        return (\n            f\"PreprocessingRule(pattern={self.pattern.pattern}, flags={self.pattern.flags}, repl={self.repl}, \"\n            f\"callback={self.callback}, desc={self.desc})\"\n        )\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessing_rule/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.__call__","title":"<code>__call__(text)</code>","text":"<p>Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string using the direction sub method. If callback is not None, then callback function will be executed using the resulting match as an argument.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def __call__(self, text):\n    \"\"\"\n    Apply a preprocessing direction. If the callback attribute of direction is None, then it will return a string\n    using the direction sub method. If callback is not None, then callback function will be executed using\n    the resulting match as an argument.\n    \"\"\"\n    # If the direction just has a repl attribute,\n    # Just return a simple re.sub\n    if self.callback is None:\n        return self.pattern.sub(self.repl, text)\n\n    match = self.pattern.search(text)\n    if match is None:\n        return text\n    return self.callback(text, match)\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessing_rule/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.__init__","title":"<code>__init__(pattern, repl='', flags=re.IGNORECASE, callback=None, desc=None)</code>","text":"<p>Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally replaced from the text underneath a doc.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>The text pattern to match and replace in a doc. Must be a string, which will be compiled as a regular expression. The patterns will lead to re.Match objects.</p> required <code>repl</code> <code>Union[str, Callable[[Match], Any]]</code> <p>The text to replace a matched string with. By default, repl is an empty string. If repl is a function, sends function to re.sub and it will be called on each Match object. More info here https://docs.python.org/3/library/re.html#re.sub</p> <code>''</code> <code>flags</code> <code>RegexFlag</code> <p>A regex compilation flag. Default is re.IGNORECASE.</p> <code>IGNORECASE</code> <code>callback</code> <code>Optional[Callable[[str, Match], str]]</code> <p>An optional callable which takes the raw text and a Match and returns the new copy of the text, rather than just replacing strings for the matched text. This can allow larger text manipulation, such as stripping out an entire section based on a header.</p> <code>None</code> <code>desc</code> <code>Optional[str]</code> <p>An optional description.</p> <code>None</code> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def __init__(\n    self,\n    pattern: str,\n    repl: Union[str, Callable[[re.Match], Any]] = \"\",\n    flags: re.RegexFlag = re.IGNORECASE,\n    callback: Optional[Callable[[str, re.Match], str]] = None,\n    desc: Optional[str] = None,\n):\n    \"\"\"\n    Creates a new PreprocessingRule. Preprocessing rules define spans of text to be removed and optionally\n    replaced from the text underneath a doc.\n\n    Args:\n        pattern: The text pattern to match and replace in a doc. Must be a string, which will be compiled as\n            a regular expression. The patterns will lead to re.Match objects.\n        repl: The text to replace a matched string with. By default, repl is an empty string. If repl is a function,\n            sends function to re.sub and it will be called on each Match object. More info here\n            https://docs.python.org/3/library/re.html#re.sub\n        flags: A regex compilation flag. Default is re.IGNORECASE.\n        callback: An optional callable which takes the raw text and a Match and returns the new copy of the text,\n            rather than just replacing strings for the matched text. This can allow larger text manipulation, such\n            as stripping out an entire section based on a header.\n        desc: An optional description.\n    \"\"\"\n    self.pattern = re.compile(pattern, flags=flags)\n    self.repl = repl\n    self.callback = callback\n    self.desc = desc\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessing_rule/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.from_dict","title":"<code>from_dict(d)</code>  <code>classmethod</code>","text":"<p>Creates a PreprocessingRule from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Dict</code> <p>The dict to read.</p> required <p>Returns:</p> Type Description <code>PreprocessingRule</code> <p>A PreprocessingRule from the dictionary.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, d: Dict) -&gt; PreprocessingRule:\n    \"\"\"\n    Creates a PreprocessingRule from a dictionary.\n\n    Args:\n        d: The dict to read.\n\n    Returns:\n        A PreprocessingRule from the dictionary.\n    \"\"\"\n    return PreprocessingRule(\n        d[\"pattern\"],\n        repl=d[\"repl\"],\n        flags=d[\"flags\"],\n        callback=d[\"callback\"],\n        desc=d.get(\"desc\", None),\n    )\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessing_rule/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>The filepath of the JSON to read.</p> required <p>Returns:</p> Type Description <p>A list of PreprocessingRules from the JSON file.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath):\n    \"\"\"\n    Read a JSON file containing PreprocessingRule data at the key \"preprocessing_rules\".\n\n    Args:\n        filepath: The filepath of the JSON to read.\n\n    Returns:\n        A list of PreprocessingRules from the JSON file.\n    \"\"\"\n    import json\n\n    with open(filepath) as f:\n        data = json.load(f)\n    return [\n        PreprocessingRule.from_dict(rule) for rule in data[\"preprocessing_rules\"]\n    ]\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessing_rule/#medspacy.preprocess.preprocessing_rule.PreprocessingRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.</p> <p>Returns:</p> Type Description <p>A dictionary containing the PreprocessingRule's data.</p> Source code in <code>medspacy/preprocess/preprocessing_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Writes a preprocessing rule to a dictionary. Useful for writing all rules to a json later.\n\n    Returns:\n        A dictionary containing the PreprocessingRule's data.\n    \"\"\"\n    d = {\n        \"pattern\": self.pattern.pattern,\n        \"repl\": self.repl,\n        \"callback\": self.callback,\n        \"desc\": self.desc,\n        \"flags\": self.pattern.flags,\n    }\n    return d\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessor/","title":"medspacy.preprocess.preprocessor","text":""},{"location":"reference/medspacy/preprocess/preprocessor/#medspacy.preprocess.preprocessor.Preprocessor","title":"<code>Preprocessor</code>","text":"<p>This is the medspacy Preprocessor class. It is designed as a wrapper for destructive preprocessing rules such as stripping or replacing text in a document before the text enters a spaCy pipeline.</p> <p>This is NOT a spaCy component and cannot be added to a spaCy pipeline. Please use the preprocessor before calling <code>nlp(\"your text here\")</code>. SpaCy only allows for non-destructive processing on the text, but that is not always advisable for every project, so this enables destructive preprocessing when required.</p> Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>class Preprocessor:\n    \"\"\"\n    This is the medspacy Preprocessor class. It is designed as a wrapper for destructive preprocessing rules such as\n    stripping or replacing text in a document before the text enters a spaCy pipeline.\n\n    This is NOT a spaCy component and cannot be added to a spaCy pipeline. Please use the preprocessor before\n    calling `nlp(\"your text here\")`. SpaCy only allows for non-destructive processing on the text, but that is not\n    always advisable for every project, so this enables destructive preprocessing when required.\n    \"\"\"\n\n    def __init__(self, tokenizer):\n        \"\"\"\n\n        Args:\n            tokenizer:\n        \"\"\"\n        self.tokenizer = tokenizer\n        self._rules = []\n\n    def add(self, rules: Union[PreprocessingRule, Iterable[PreprocessingRule]]):\n        \"\"\"\n        Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.\n\n        Args:\n            rules: A single PreprocessingRule or a collection of PreprocessingRules to add.\n        \"\"\"\n        if isinstance(rules, PreprocessingRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, PreprocessingRule):\n                raise TypeError(\n                    f\"Each rule must be an instance of PreprocessingRule, not {type(rule)}.\"\n                )\n        self._rules += rules\n\n    def __call__(self, text, tokenize=True) -&gt; Union[str, Doc]:\n        \"\"\"\n\n        Args:\n            text:\n            tokenize:\n\n        Returns:\n\n        \"\"\"\n        for rule in self._rules:\n            text = rule(text)\n\n        if not tokenize:\n            return text\n\n        return self.tokenizer(text)\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessor/#medspacy.preprocess.preprocessor.Preprocessor.__call__","title":"<code>__call__(text, tokenize=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>text</code> required <code>tokenize</code> <code>True</code> <p>Returns:</p> Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def __call__(self, text, tokenize=True) -&gt; Union[str, Doc]:\n    \"\"\"\n\n    Args:\n        text:\n        tokenize:\n\n    Returns:\n\n    \"\"\"\n    for rule in self._rules:\n        text = rule(text)\n\n    if not tokenize:\n        return text\n\n    return self.tokenizer(text)\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessor/#medspacy.preprocess.preprocessor.Preprocessor.__init__","title":"<code>__init__(tokenizer)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>tokenizer</code> required Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def __init__(self, tokenizer):\n    \"\"\"\n\n    Args:\n        tokenizer:\n    \"\"\"\n    self.tokenizer = tokenizer\n    self._rules = []\n</code></pre>"},{"location":"reference/medspacy/preprocess/preprocessor/#medspacy.preprocess.preprocessor.Preprocessor.add","title":"<code>add(rules)</code>","text":"<p>Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[PreprocessingRule, Iterable[PreprocessingRule]]</code> <p>A single PreprocessingRule or a collection of PreprocessingRules to add.</p> required Source code in <code>medspacy/preprocess/preprocessor.py</code> <pre><code>def add(self, rules: Union[PreprocessingRule, Iterable[PreprocessingRule]]):\n    \"\"\"\n    Adds a PreprocessingRule or collection of PreprocessingRules to the Preprocessor.\n\n    Args:\n        rules: A single PreprocessingRule or a collection of PreprocessingRules to add.\n    \"\"\"\n    if isinstance(rules, PreprocessingRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, PreprocessingRule):\n            raise TypeError(\n                f\"Each rule must be an instance of PreprocessingRule, not {type(rule)}.\"\n            )\n    self._rules += rules\n</code></pre>"},{"location":"reference/medspacy/section_detection/","title":"medspacy.section_detection","text":""},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Section","title":"<code>Section</code>","text":"<p>               Bases: <code>object</code></p> <p>Section is the object that stores the result of processing by the Sectionizer class. A Section contains information describing the section's category, title span, body span, parent, and the rule that created it.</p> <p>Section <code>category</code> is equivalent to <code>label_</code> in a basic spaCy entity. It is a normalized name for the section type determined on initialization, either created manually or through the Sectionizer pipeline component.</p> <p>Section title, defined with <code>title_start</code>, <code>title_end</code>, and <code>title_span</code> represents the section title or header matched with the rule. In the text \"Past medical history: stroke and high blood pressure\", \"Past medical history:\" would be the title.</p> <p>Section body is defined with <code>body_start</code>, <code>body_end</code>, and <code>body_span</code>. It represents the text between the end of the current section's title and the start of the title for the next Section or when scope is set in the rule or by the Sectionizer. In the text \"Past medical history: stroke and high blood pressure\", \"stroke and high blood pressure\" would be the body.</p> <p>Parent is a string that represents the conceptual \"parent\" section in a section-&gt;subsection-&gt;subsubsection hierarchy. Candidates are determined by category in the rule and matched at runtime.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>class Section(object):\n    \"\"\"\n    Section is the object that stores the result of processing by the Sectionizer class. A Section contains information\n    describing the section's category, title span, body span, parent, and the rule that created it.\n\n    Section `category` is equivalent to `label_` in a basic spaCy entity. It is a normalized name for the section type\n    determined on initialization, either created manually or through the Sectionizer pipeline component.\n\n    Section title, defined with `title_start`, `title_end`, and `title_span` represents the section title or header\n    matched with the rule. In the text \"Past medical history: stroke and high blood pressure\", \"Past medical history:\"\n    would be the title.\n\n    Section body is defined with `body_start`, `body_end`, and `body_span`. It represents the text between the end of\n    the current section's title and the start of the title for the next Section or when scope is set in the rule or by\n    the Sectionizer. In the text \"Past medical history: stroke and high blood pressure\", \"stroke and high blood\n    pressure\" would be the body.\n\n    Parent is a string that represents the conceptual \"parent\" section in a section-&gt;subsection-&gt;subsubsection\n    hierarchy. Candidates are determined by category in the rule and matched at runtime.\n    \"\"\"\n\n    def __init__(\n        self,\n        category: Union[str, None],\n        title_start: int,\n        title_end: int,\n        body_start: int,\n        body_end: int,\n        parent: Optional[str] = None,\n        rule: Optional[SectionRule] = None,\n    ):\n        \"\"\"\n        Create a new Section object.\n\n        Args:\n            category: A normalized name for the section. Equivalent to `label_` for basic spaCy entities.\n            title_start: Index of the first token of the section title.\n            title_end: Index of the last token of the section title.\n            body_start: Index of the first token of the section body.\n            body_end: Index of the last token of the section body.\n            parent: The category of the parent section.\n            rule: The SectionRule that generated the section.\n        \"\"\"\n        self.category = category\n        self.title_start = title_start\n        self.title_end = title_end\n        self.body_start = body_start\n        self.body_end = body_end\n        self.parent = parent\n        self.rule = rule\n\n    def __repr__(self):\n        return (\n            f\"Section(category={self.category} at {self.title_start} : {self.title_end} in the doc with a body at \"\n            f\"{self.body_start} : {self.body_end} based on the rule {self.rule}\"\n        )\n\n    @property\n    def title_span(self):\n        \"\"\"\n        Gets the span of the section title.\n\n        Returns:\n            A tuple (int,int) containing the start and end indexes of the section title.\n        \"\"\"\n        return self.title_start, self.title_end\n\n    @property\n    def body_span(self):\n        \"\"\"\n        Gets the span of the section body.\n\n        Returns:\n            A tuple (int,int) containing the start and end indexes of the section body.\n        \"\"\"\n        return self.body_start, self.body_end\n\n    @property\n    def section_span(self):\n        \"\"\"\n        Gets the span of the entire section, from title start to body end.\n\n        Returns:\n            A tuple (int,int) containing the start index of the section title and the end index of the section body.\n        \"\"\"\n        return self.title_start, self.body_end\n\n    def serialized_representation(self):\n        \"\"\"\n        Serialize the Section.\n\n        Returns:\n            A json-serialized representation of the section.\n        \"\"\"\n        rule = self.rule\n\n        return {\n            \"category\": self.category,\n            \"title_start\": self.title_start,\n            \"title_end\": self.title_end,\n            \"body_start\": self.body_start,\n            \"body_end\": self.body_end,\n            \"parent\": self.parent,\n            \"rule\": rule.to_dict() if rule is not None else None,\n        }\n\n    @classmethod\n    def from_serialized_representation(cls, serialized_representation: Dict[str, str]):\n        \"\"\"\n        Load the section from a json-serialized form.\n\n        Args:\n            serialized_representation: The dictionary form of the section object to load.\n\n        Returns:\n            A Section object containing the data from the dictionary provided.\n        \"\"\"\n        rule = SectionRule.from_dict(serialized_representation[\"rule\"])\n        section = Section(\n            **{k: v for k, v in serialized_representation.items() if k not in [\"rule\"]}\n        )\n        section.rule = rule\n\n        return section\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Section.body_span","title":"<code>body_span</code>  <code>property</code>","text":"<p>Gets the span of the section body.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start and end indexes of the section body.</p>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Section.section_span","title":"<code>section_span</code>  <code>property</code>","text":"<p>Gets the span of the entire section, from title start to body end.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start index of the section title and the end index of the section body.</p>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Section.title_span","title":"<code>title_span</code>  <code>property</code>","text":"<p>Gets the span of the section title.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start and end indexes of the section title.</p>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Section.__init__","title":"<code>__init__(category, title_start, title_end, body_start, body_end, parent=None, rule=None)</code>","text":"<p>Create a new Section object.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>Union[str, None]</code> <p>A normalized name for the section. Equivalent to <code>label_</code> for basic spaCy entities.</p> required <code>title_start</code> <code>int</code> <p>Index of the first token of the section title.</p> required <code>title_end</code> <code>int</code> <p>Index of the last token of the section title.</p> required <code>body_start</code> <code>int</code> <p>Index of the first token of the section body.</p> required <code>body_end</code> <code>int</code> <p>Index of the last token of the section body.</p> required <code>parent</code> <code>Optional[str]</code> <p>The category of the parent section.</p> <code>None</code> <code>rule</code> <code>Optional[SectionRule]</code> <p>The SectionRule that generated the section.</p> <code>None</code> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>def __init__(\n    self,\n    category: Union[str, None],\n    title_start: int,\n    title_end: int,\n    body_start: int,\n    body_end: int,\n    parent: Optional[str] = None,\n    rule: Optional[SectionRule] = None,\n):\n    \"\"\"\n    Create a new Section object.\n\n    Args:\n        category: A normalized name for the section. Equivalent to `label_` for basic spaCy entities.\n        title_start: Index of the first token of the section title.\n        title_end: Index of the last token of the section title.\n        body_start: Index of the first token of the section body.\n        body_end: Index of the last token of the section body.\n        parent: The category of the parent section.\n        rule: The SectionRule that generated the section.\n    \"\"\"\n    self.category = category\n    self.title_start = title_start\n    self.title_end = title_end\n    self.body_start = body_start\n    self.body_end = body_end\n    self.parent = parent\n    self.rule = rule\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Section.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Load the section from a json-serialized form.</p> <p>Parameters:</p> Name Type Description Default <code>serialized_representation</code> <code>Dict[str, str]</code> <p>The dictionary form of the section object to load.</p> required <p>Returns:</p> Type Description <p>A Section object containing the data from the dictionary provided.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>@classmethod\ndef from_serialized_representation(cls, serialized_representation: Dict[str, str]):\n    \"\"\"\n    Load the section from a json-serialized form.\n\n    Args:\n        serialized_representation: The dictionary form of the section object to load.\n\n    Returns:\n        A Section object containing the data from the dictionary provided.\n    \"\"\"\n    rule = SectionRule.from_dict(serialized_representation[\"rule\"])\n    section = Section(\n        **{k: v for k, v in serialized_representation.items() if k not in [\"rule\"]}\n    )\n    section.rule = rule\n\n    return section\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Section.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Serialize the Section.</p> <p>Returns:</p> Type Description <p>A json-serialized representation of the section.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>def serialized_representation(self):\n    \"\"\"\n    Serialize the Section.\n\n    Returns:\n        A json-serialized representation of the section.\n    \"\"\"\n    rule = self.rule\n\n    return {\n        \"category\": self.category,\n        \"title_start\": self.title_start,\n        \"title_end\": self.title_end,\n        \"body_start\": self.body_start,\n        \"body_end\": self.body_end,\n        \"parent\": self.parent,\n        \"rule\": rule.to_dict() if rule is not None else None,\n    }\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.SectionRule","title":"<code>SectionRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>SectionRule defines rules for extracting entities from text using the Sectionizer.</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>class SectionRule(BaseRule):\n    \"\"\"\n    SectionRule defines rules for extracting entities from text using the Sectionizer.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"parents\",\n        \"parent_required\",\n        \"max_scope\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        max_scope: Optional[int] = None,\n        parents: Optional[List[str]] = None,\n        parent_required: bool = False,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Class for defining rules for extracting entities from text using TargetMatcher.\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            max_scope: A number of tokens to explicitly limit the size of a section body. If None, the scope will\n                include the entire doc up until either the next section header or the end of the doc. This variable can\n                also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the\n                rule scope will take precedence. If not None, this will be the number of tokens following the matched\n                section header\n                    Example:\n                        In the text \"Past Medical History: Pt has hx of pneumonia\",\n                        SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but\n                        SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section\n                            to be \"Past Medical History: Pt has\"\n                This can be useful for limiting certain sections which are known to be short or allowing others to be\n                longer than the regular global max_scope.\n            parents: A list of candidate parents for determining subsections\n            parent_required: Whether a parent is required for the section to exist in the final output. If true and no\n                parent is identified, the section will be removed.\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category, pattern, on_match, metadata)\n        self.max_scope = max_scope\n        self.parents = parents\n        if parent_required:\n            if not parents:\n                raise ValueError(\n                    f\"Jsonl file incorrectly formatted for pattern name {category}. \"\n                    f\"If parents are required, then at least one parent must be specified.\"\n                )\n        self.parent_required = parent_required\n\n    @classmethod\n    def from_json(cls, filepath) -&gt; List[SectionRule]:\n        \"\"\"\n        Read in a lexicon of modifiers from a JSON file.\n\n        Args:\n            filepath: the .json file containing modifier rules\n\n        Returns:\n            section_rules: a list of SectionRule objects\n        \"\"\"\n        import json\n\n        with open(filepath) as file:\n            section_data = json.load(file)\n        section_rules = []\n        for data in section_data[\"section_rules\"]:\n            section_rules.append(SectionRule.from_dict(data))\n        return section_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict):\n        \"\"\"\n        Reads a dictionary into a SectionRule list. Used when reading from a json file.\n\n        Args:\n            rule_dict: the dictionary to convert\n\n        Returns:\n            item: the SectionRule created from the dictionary\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                f\"JSON object contains invalid keys: {invalid_keys}. \"\n                f\"Must be one of: {cls._ALLOWED_KEYS}\"\n            )\n            raise ValueError(msg)\n        rule = SectionRule(**rule_dict)\n        return rule\n\n    def to_dict(self):\n        \"\"\"\n        Converts TargetRules to a python dictionary. Used when writing section rules to a json file.\n\n        Returns:\n            rule_dict: the dictionary containing the TargetRule info.\n        \"\"\"\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    def __repr__(self):\n        return f\"\"\"SectionRule(literal=\"{self.literal}\", category=\"{self.category}\", pattern={self.pattern}, on_match={self.on_match}, parents={self.parents}, parent_required={self.parent_required})\"\"\"\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.SectionRule.__init__","title":"<code>__init__(literal, category, pattern=None, on_match=None, max_scope=None, parents=None, parent_required=False, metadata=None)</code>","text":"<p>Class for defining rules for extracting entities from text using TargetMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[List[Dict[str, str]], str]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>A number of tokens to explicitly limit the size of a section body. If None, the scope will include the entire doc up until either the next section header or the end of the doc. This variable can also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the rule scope will take precedence. If not None, this will be the number of tokens following the matched section header     Example:         In the text \"Past Medical History: Pt has hx of pneumonia\",         SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but         SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section             to be \"Past Medical History: Pt has\" This can be useful for limiting certain sections which are known to be short or allowing others to be longer than the regular global max_scope.</p> <code>None</code> <code>parents</code> <code>Optional[List[str]]</code> <p>A list of candidate parents for determining subsections</p> <code>None</code> <code>parent_required</code> <code>bool</code> <p>Whether a parent is required for the section to exist in the final output. If true and no parent is identified, the section will be removed.</p> <code>False</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    max_scope: Optional[int] = None,\n    parents: Optional[List[str]] = None,\n    parent_required: bool = False,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Class for defining rules for extracting entities from text using TargetMatcher.\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        max_scope: A number of tokens to explicitly limit the size of a section body. If None, the scope will\n            include the entire doc up until either the next section header or the end of the doc. This variable can\n            also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the\n            rule scope will take precedence. If not None, this will be the number of tokens following the matched\n            section header\n                Example:\n                    In the text \"Past Medical History: Pt has hx of pneumonia\",\n                    SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but\n                    SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section\n                        to be \"Past Medical History: Pt has\"\n            This can be useful for limiting certain sections which are known to be short or allowing others to be\n            longer than the regular global max_scope.\n        parents: A list of candidate parents for determining subsections\n        parent_required: Whether a parent is required for the section to exist in the final output. If true and no\n            parent is identified, the section will be removed.\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category, pattern, on_match, metadata)\n    self.max_scope = max_scope\n    self.parents = parents\n    if parent_required:\n        if not parents:\n            raise ValueError(\n                f\"Jsonl file incorrectly formatted for pattern name {category}. \"\n                f\"If parents are required, then at least one parent must be specified.\"\n            )\n    self.parent_required = parent_required\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.SectionRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a SectionRule list. Used when reading from a json file.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <p>the dictionary to convert</p> required <p>Returns:</p> Name Type Description <code>item</code> <p>the SectionRule created from the dictionary</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict):\n    \"\"\"\n    Reads a dictionary into a SectionRule list. Used when reading from a json file.\n\n    Args:\n        rule_dict: the dictionary to convert\n\n    Returns:\n        item: the SectionRule created from the dictionary\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            f\"JSON object contains invalid keys: {invalid_keys}. \"\n            f\"Must be one of: {cls._ALLOWED_KEYS}\"\n        )\n        raise ValueError(msg)\n    rule = SectionRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.SectionRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read in a lexicon of modifiers from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>the .json file containing modifier rules</p> required <p>Returns:</p> Name Type Description <code>section_rules</code> <code>List[SectionRule]</code> <p>a list of SectionRule objects</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath) -&gt; List[SectionRule]:\n    \"\"\"\n    Read in a lexicon of modifiers from a JSON file.\n\n    Args:\n        filepath: the .json file containing modifier rules\n\n    Returns:\n        section_rules: a list of SectionRule objects\n    \"\"\"\n    import json\n\n    with open(filepath) as file:\n        section_data = json.load(file)\n    section_rules = []\n    for data in section_data[\"section_rules\"]:\n        section_rules.append(SectionRule.from_dict(data))\n    return section_rules\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.SectionRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts TargetRules to a python dictionary. Used when writing section rules to a json file.</p> <p>Returns:</p> Name Type Description <code>rule_dict</code> <p>the dictionary containing the TargetRule info.</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Converts TargetRules to a python dictionary. Used when writing section rules to a json file.\n\n    Returns:\n        rule_dict: the dictionary containing the TargetRule info.\n    \"\"\"\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer","title":"<code>Sectionizer</code>","text":"<p>The Sectionizer will search for spans in the text which match section header rules, such as 'Past Medical History:'. Sections will be represented in custom attributes as:     category: A normalized title of the section. Example: 'past_medical_history'     section_title: The Span of the doc which was matched as a section header.         Example: 'Past Medical History:'     section_span: The entire section of the note, starting with section_header and up until the end         of the section, which will be either the start of the next section header of some pre-specified         scope. Example: 'Past Medical History: Type II DM'</p> <p>Section attributes will be registered for each Doc, Span, and Token in the following attributes:     Doc..sections: A list of namedtuples of type Section with 4 elements:         - section_title         - section_header         - section_parent         - section_span.     A Doc will also have attributes corresponding to lists of each         (ie., Doc..section_titles, Doc..section_headers, Doc..section_parents, Doc..section_list)     (Span|Token)..section_title     (Span|Token)..section_header     (Span|Token)..section_parent     (Span|Token)._.section_span</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>@Language.factory(\"medspacy_sectionizer\")\nclass Sectionizer:\n    \"\"\"\n    The Sectionizer will search for spans in the text which match section header rules, such as 'Past Medical History:'.\n    Sections will be represented in custom attributes as:\n        category: A normalized title of the section. Example: 'past_medical_history'\n        section_title: The Span of the doc which was matched as a section header.\n            Example: 'Past Medical History:'\n        section_span: The entire section of the note, starting with section_header and up until the end\n            of the section, which will be either the start of the next section header of some pre-specified\n            scope. Example: 'Past Medical History: Type II DM'\n\n    Section attributes will be registered for each Doc, Span, and Token in the following attributes:\n        Doc._.sections: A list of namedtuples of type Section with 4 elements:\n            - section_title\n            - section_header\n            - section_parent\n            - section_span.\n        A Doc will also have attributes corresponding to lists of each\n            (ie., Doc._.section_titles, Doc._.section_headers, Doc._.section_parents, Doc._.section_list)\n        (Span|Token)._.section_title\n        (Span|Token)._.section_header\n        (Span|Token)._.section_parent\n        (Span|Token)._.section_span\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_sectionizer\",\n        rules: Optional[str] = \"default\",\n        language_code: str = 'en',\n        max_section_length: Optional[int] = None,\n        phrase_matcher_attr: str = \"LOWER\",\n        require_start_line: bool = False,\n        require_end_line: bool = False,\n        newline_pattern: str = r\"[\\n\\r]+[\\s]*$\",\n        input_span_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n        span_attrs: Union[\n            Literal[\"default\"], Dict[str, Dict[str, Any]], None\n        ] = \"default\",\n        apply_sentence_boundary: bool = False,\n    ):\n        \"\"\"\n        Create a new Sectionizer component.\n\n        Args:\n            nlp: A SpaCy Language object.\n            name: The name of the component.\n            rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n                SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n                are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n                `Sectionizer.add`.\n            language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n                and also the /resources directory to see which resources might be available in each language.\n                Default is \"en\" for English.\n            max_section_length: Optional argument specifying the maximum number of tokens following a section header\n                which can be included in a section body. This can be useful if you think your section rules are\n                incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n                the scope of a section will be until either the next section header or the end of the document.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            require_start_line: Optionally require a section header to start on a new line. Default False.\n            require_end_line: Optionally require a section header to end with a new line. Default False.\n            newline_pattern: Regular expression to match the new line either preceding or following a header\n                if either require_start_line or require_end_line are True. Default is r\"[\\n\\r]+[\\s]*$\"\n            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n                `DEFAULT_ATTRIBUTES`. If a dictionary of custom attributes, format is a dictionary mapping section\n                categories to a dictionary containing the attribute name and the value to set the attribute to when a\n                span is contained in a section of that category. Custom attributes must be assigned with\n                `Span.set_extension` before creating the Sectionizer. If None, sectionizer will not modify span\n                attributes.\n            input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans\n                contained in a section if `span_attrs` is not None. \"ents\" will modify attributes of spans in doc.ents.\n                \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n                \"medspacy_spans\".\n            apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures\n                the section header is considered its own sentence.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self.max_section_length = max_section_length\n        self.require_start_line = require_start_line\n        self.require_end_line = require_end_line\n        self.newline_pattern = re.compile(newline_pattern)\n        self.assertion_attributes_mapping = None\n        self._parent_sections = {}\n        self._parent_required = {}\n        self._input_span_type = input_span_type\n        self._span_group_name = span_group_name\n        self._apply_sentence_boundary = apply_sentence_boundary\n\n        self.__matcher = MedspacyMatcher(\n            nlp, name=name, phrase_matcher_attr=phrase_matcher_attr\n        )\n\n        self.DEFAULT_RULES_FILEPATH = path.join(\n            Path(__file__).resolve().parents[2],\n            \"resources\",\n            language_code.lower(),\n            \"section_patterns.json\",\n        )\n\n        rule_path = None\n        if rules == \"default\":\n            rule_path = self.DEFAULT_RULES_FILEPATH\n        else:\n            rule_path = rules\n\n        if rule_path:\n            self.add(SectionRule.from_json(rule_path))\n\n        if span_attrs == \"default\":\n            self.assertion_attributes_mapping = DEFAULT_ATTRS\n            self.register_default_attributes()\n        elif span_attrs:\n            for _, attr_dict in span_attrs.items():\n                for attr_name in attr_dict.keys():\n                    if not Span.has_extension(attr_name):\n                        raise ValueError(\n                            f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                            f\"called for your pipeline's custom extensions.\"\n                        )\n            self.assertion_attributes_mapping = span_attrs\n\n    @property\n    def rules(self) -&gt; List[SectionRule]:\n        \"\"\"\n        Gets list of rules associated with the Sectionizer.\n\n        Returns:\n            The list of SectionRules associated with the Sectionizer.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def section_categories(self) -&gt; Set[str]:\n        \"\"\"\n        Gets a list of categories used in the Sectionizer.\n\n        Returns:\n                The list of all section categories available to the Sectionizer.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    @classmethod\n    def register_default_attributes(cls):\n        \"\"\"\n        Register the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n        \"\"\"\n        for attr_name in [\n            \"is_negated\",\n            \"is_uncertain\",\n            \"is_historical\",\n            \"is_hypothetical\",\n            \"is_family\",\n        ]:\n            try:\n                Span.set_extension(attr_name, default=False)\n            except ValueError:  # Extension already set\n                pass\n\n    def add(self, rules):\n        \"\"\"\n        Adds SectionRules to the Sectionizer.\n\n        Args:\n            rules: A single SectionRule or a collection of SectionRules to add to the Sectionizer.\n        \"\"\"\n        if isinstance(rules, SectionRule):\n            rules = [rules]\n\n        for rule in rules:\n            if not isinstance(rule, SectionRule):\n                raise TypeError(\"Rules must be type SectionRule, not\", type(rule))\n\n        self.__matcher.add(rules)\n\n        for rule in rules:\n            name = rule.category\n            parents = rule.parents\n            parent_required = rule.parent_required\n            if parents:\n                if name in self._parent_sections.keys():\n                    warnings.warn(\n                        f\"Duplicate section title {name}. Merging parents. \"\n                        f\"If this is not intended, please specify distinct titles.\",\n                        RuntimeWarning,\n                    )\n                    self._parent_sections[name].update(parents)\n                else:\n                    self._parent_sections[name] = set(parents)\n\n            if (\n                name in self._parent_required.keys()\n                and self._parent_required[name] != parent_required\n            ):\n                warnings.warn(\n                    f\"Duplicate section title {name} has different parent_required option. \"\n                    f\"Setting parent_required to False.\",\n                    RuntimeWarning,\n                )\n                self._parent_required[name] = False\n            else:\n                self._parent_required[name] = parent_required\n\n    def set_parent_sections(\n        self, sections: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int, int]]:\n        \"\"\"\n        Determine the legal parent-child section relationships from the list\n        of in-order sections of a document and the possible parents of each\n        section as specified during direction creation.\n\n        Args:\n            sections: a list of spacy match tuples found in the doc\n\n        Returns:\n            A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input\n            and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a\n            smaller list than the input due to pruning with `parent_required`.\n        \"\"\"\n        sections_final = []\n        removed_sections = 0\n        for i, (match_id, start, end) in enumerate(sections):\n            name = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]].category\n            required = self._parent_required[name]\n            i_a = i - removed_sections  # adjusted index for removed values\n            if required and i_a == 0:\n                removed_sections += 1\n                continue\n            elif i_a == 0 or name not in self._parent_sections.keys():\n                sections_final.append((match_id, start, end, None))\n            else:\n                parents = self._parent_sections[name]\n                identified_parent = None\n                for parent in parents:\n                    # go backwards through the section \"tree\" until you hit a root or the start of the list\n                    candidate = self.__matcher.rule_map[\n                        self.nlp.vocab.strings[sections_final[i_a - 1][0]]\n                    ].category\n                    candidates_parent_idx = sections_final[i_a - 1][3]\n                    if candidates_parent_idx is not None:\n                        candidates_parent = self.__matcher.rule_map[\n                            self.nlp.vocab.strings[\n                                sections_final[candidates_parent_idx][0]\n                            ]\n                        ].category\n                    else:\n                        candidates_parent = None\n                    candidate_i = i_a - 1\n                    while candidate:\n                        if candidate == parent:\n                            identified_parent = candidate_i\n                            candidate = None\n                        else:\n                            # if you are at the end of the list... no parent\n                            if candidate_i &lt; 1:\n                                candidate = None\n                                continue\n                            # if the current candidate has no parent... no parent exists\n                            if not candidates_parent:\n                                candidate = None\n                                continue\n                            # otherwise get the previous item in the list\n                            temp = self.__matcher.rule_map[\n                                self.nlp.vocab.strings[\n                                    sections_final[candidate_i - 1][0]\n                                ]\n                            ].category\n                            temp_parent_idx = sections_final[candidate_i - 1][3]\n                            if temp_parent_idx is not None:\n                                temp_parent = self.__matcher.rule_map[\n                                    self.nlp.vocab.strings[\n                                        sections_final[temp_parent_idx][0]\n                                    ]\n                                ].category\n                            else:\n                                temp_parent = None\n                            # if the previous item is the parent of the current item\n                            # OR if the previous item is a sibling of the current item\n                            # continue to search\n                            if (\n                                temp == candidates_parent\n                                or temp_parent == candidates_parent\n                            ):\n                                candidate = temp\n                                candidates_parent = temp_parent\n                                candidate_i -= 1\n                            # otherwise, there is no further tree traversal\n                            else:\n                                candidate = None\n\n                # if a parent is required, then add\n                if identified_parent is not None or not required:\n                    # if the parent is identified, add section\n                    # if the parent is not required, add section\n                    # if parent is not identified and required, do not add the section\n                    sections_final.append((match_id, start, end, identified_parent))\n                else:\n                    removed_sections += 1\n        return sections_final\n\n    def set_assertion_attributes(self, spans: Iterable[Span]):\n        \"\"\"\n        Add Span-level attributes to entities based on which section they occur in.\n\n        Args:\n            spans: the spans to modify.\n        \"\"\"\n        for span in spans:\n            if (\n                span._.section\n                and span._.section.category in self.assertion_attributes_mapping\n            ):\n                attr_dict = self.assertion_attributes_mapping[span._.section.category]\n                for (attr_name, attr_value) in attr_dict.items():\n                    setattr(span._, attr_name, attr_value)\n\n    def __call__(self, doc: Doc) -&gt; Doc:\n        \"\"\"\n        Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any\n        section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections\n        the entities spans in.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed spaCy Doc.\n        \"\"\"\n        matches = self.__matcher(doc)\n        if self.require_start_line:\n            matches = self.filter_start_lines(doc, matches)\n        if self.require_end_line:\n            matches = self.filter_end_lines(doc, matches)\n        if self._parent_sections:\n            matches = self.set_parent_sections(matches)\n\n        # If this has already been processed by the sectionizer, reset the sections\n        doc._.sections = []\n        # if there were no matches, return the doc as one section\n        if len(matches) == 0:\n            doc._.sections.append(Section(None, 0, 0, 0, len(doc)))\n            return doc\n\n        section_list = []\n        # if the first match does not begin at token 0, handle the first section\n        first_match = matches[0]\n        if first_match[1] != 0:\n            section_list.append(Section(None, 0, 0, 0, first_match[1]))\n\n        # handle section spans\n        for i, match in enumerate(matches):\n            parent = None\n            if len(match) == 4:\n                (match_id, start, end, parent_idx) = match\n                if parent_idx is not None:\n                    parent = section_list[parent_idx]\n            else:\n                # IDEs will warn here about match shape disagreeing w/ type hinting, but this if is only used if\n                # parent sections were never set, so parent_idx does not exist\n                (match_id, start, end) = match\n\n            # Make section header its own sentence\n            if self._apply_sentence_boundary:\n                # Section headers should be considered the start of a sentence\n                doc[start].sent_start = True\n                # Text following the header should also be considered a new sentence\n                if end &lt; len(doc):\n                    doc[end].sent_start = True\n\n            rule = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]]\n            category = rule.category\n            # If this is the last match, it should include the rest of the doc\n            if i == len(matches) - 1:\n                # If there is no scope limitation, go until the end of the doc\n                if self.max_section_length is None and rule.max_scope is None:\n                    section_list.append(\n                        Section(category, start, end, end, len(doc), parent, rule)\n                    )\n                else:\n                    # If the rule has a max_scope, use that as a precedence\n                    if rule.max_scope is not None:\n                        scope_end = min(end + rule.max_scope, doc[-1].i + 1)\n                    else:\n                        scope_end = min(end + self.max_section_length, doc[-1].i + 1)\n\n                    section_list.append(\n                        Section(category, start, end, end, scope_end, parent, rule)\n                    )\n            # Otherwise, go until the next section header\n            else:\n                next_match = matches[i + 1]\n                if len(match) == 4:\n                    _, next_start, _, _ = next_match\n                else:\n                    _, next_start, _ = next_match\n                if self.max_section_length is None and rule.max_scope is None:\n                    section_list.append(\n                        Section(category, start, end, end, next_start, parent, rule)\n                    )\n                else:\n                    if rule.max_scope is not None:\n                        scope_end = min(end + rule.max_scope, next_start)\n                    else:\n                        scope_end = min(end + self.max_section_length, next_start)\n                    section_list.append(\n                        Section(category, start, end, end, scope_end, parent, rule)\n                    )\n\n        for section in section_list:\n            doc._.sections.append(section)\n            start, end = section.section_span\n            for token in doc[start:end]:\n                token._.section = section\n\n        # If it is specified to add assertion attributes,\n        # iterate through the entities in doc and add them\n        if self.assertion_attributes_mapping:\n            if self._input_span_type.lower() == \"ents\":\n                self.set_assertion_attributes(doc.ents)\n            elif self._input_span_type.lower() == \"group\":\n                self.set_assertion_attributes(doc.spans[self._span_group_name])\n\n        return doc\n\n    def filter_start_lines(\n        self, doc: Doc, matches: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Filter a list of matches to only contain spans where the start token is the beginning of a new line.\n\n        Returns:\n            A list of match tuples (match_id, start, end) that meet the filter criteria.\n        \"\"\"\n        return [\n            m for m in matches if util.is_start_line(m[1], doc, self.newline_pattern)\n        ]\n\n    def filter_end_lines(\n        self, doc: Doc, matches: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Filter a list of matches to only contain spans where the start token is followed by a new line.\n\n        Returns:\n            A list of match tuples (match_id, start, end) that meet the filter criteria.\n        \"\"\"\n        return [\n            m for m in matches if util.is_end_line(m[2] - 1, doc, self.newline_pattern)\n        ]\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets list of rules associated with the Sectionizer.</p> <p>Returns:</p> Type Description <code>List[SectionRule]</code> <p>The list of SectionRules associated with the Sectionizer.</p>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.section_categories","title":"<code>section_categories</code>  <code>property</code>","text":"<p>Gets a list of categories used in the Sectionizer.</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>The list of all section categories available to the Sectionizer.</p>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections the entities spans in.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <code>Doc</code> <p>The processed spaCy Doc.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; Doc:\n    \"\"\"\n    Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any\n    section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections\n    the entities spans in.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed spaCy Doc.\n    \"\"\"\n    matches = self.__matcher(doc)\n    if self.require_start_line:\n        matches = self.filter_start_lines(doc, matches)\n    if self.require_end_line:\n        matches = self.filter_end_lines(doc, matches)\n    if self._parent_sections:\n        matches = self.set_parent_sections(matches)\n\n    # If this has already been processed by the sectionizer, reset the sections\n    doc._.sections = []\n    # if there were no matches, return the doc as one section\n    if len(matches) == 0:\n        doc._.sections.append(Section(None, 0, 0, 0, len(doc)))\n        return doc\n\n    section_list = []\n    # if the first match does not begin at token 0, handle the first section\n    first_match = matches[0]\n    if first_match[1] != 0:\n        section_list.append(Section(None, 0, 0, 0, first_match[1]))\n\n    # handle section spans\n    for i, match in enumerate(matches):\n        parent = None\n        if len(match) == 4:\n            (match_id, start, end, parent_idx) = match\n            if parent_idx is not None:\n                parent = section_list[parent_idx]\n        else:\n            # IDEs will warn here about match shape disagreeing w/ type hinting, but this if is only used if\n            # parent sections were never set, so parent_idx does not exist\n            (match_id, start, end) = match\n\n        # Make section header its own sentence\n        if self._apply_sentence_boundary:\n            # Section headers should be considered the start of a sentence\n            doc[start].sent_start = True\n            # Text following the header should also be considered a new sentence\n            if end &lt; len(doc):\n                doc[end].sent_start = True\n\n        rule = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]]\n        category = rule.category\n        # If this is the last match, it should include the rest of the doc\n        if i == len(matches) - 1:\n            # If there is no scope limitation, go until the end of the doc\n            if self.max_section_length is None and rule.max_scope is None:\n                section_list.append(\n                    Section(category, start, end, end, len(doc), parent, rule)\n                )\n            else:\n                # If the rule has a max_scope, use that as a precedence\n                if rule.max_scope is not None:\n                    scope_end = min(end + rule.max_scope, doc[-1].i + 1)\n                else:\n                    scope_end = min(end + self.max_section_length, doc[-1].i + 1)\n\n                section_list.append(\n                    Section(category, start, end, end, scope_end, parent, rule)\n                )\n        # Otherwise, go until the next section header\n        else:\n            next_match = matches[i + 1]\n            if len(match) == 4:\n                _, next_start, _, _ = next_match\n            else:\n                _, next_start, _ = next_match\n            if self.max_section_length is None and rule.max_scope is None:\n                section_list.append(\n                    Section(category, start, end, end, next_start, parent, rule)\n                )\n            else:\n                if rule.max_scope is not None:\n                    scope_end = min(end + rule.max_scope, next_start)\n                else:\n                    scope_end = min(end + self.max_section_length, next_start)\n                section_list.append(\n                    Section(category, start, end, end, scope_end, parent, rule)\n                )\n\n    for section in section_list:\n        doc._.sections.append(section)\n        start, end = section.section_span\n        for token in doc[start:end]:\n            token._.section = section\n\n    # If it is specified to add assertion attributes,\n    # iterate through the entities in doc and add them\n    if self.assertion_attributes_mapping:\n        if self._input_span_type.lower() == \"ents\":\n            self.set_assertion_attributes(doc.ents)\n        elif self._input_span_type.lower() == \"group\":\n            self.set_assertion_attributes(doc.spans[self._span_group_name])\n\n    return doc\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.__init__","title":"<code>__init__(nlp, name='medspacy_sectionizer', rules='default', language_code='en', max_section_length=None, phrase_matcher_attr='LOWER', require_start_line=False, require_end_line=False, newline_pattern='[\\\\n\\\\r]+[\\\\s]*$', input_span_type='ents', span_group_name='medspacy_spans', span_attrs='default', apply_sentence_boundary=False)</code>","text":"<pre><code>   Create a new Sectionizer component.\n\n   Args:\n       nlp: A SpaCy Language object.\n       name: The name of the component.\n       rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n           SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n           are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n           `Sectionizer.add`.\n       language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n           and also the /resources directory to see which resources might be available in each language.\n           Default is \"en\" for English.\n       max_section_length: Optional argument specifying the maximum number of tokens following a section header\n           which can be included in a section body. This can be useful if you think your section rules are\n           incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n           the scope of a section will be until either the next section header or the end of the document.\n       phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n           is 'LOWER'.\n       require_start_line: Optionally require a section header to start on a new line. Default False.\n       require_end_line: Optionally require a section header to end with a new line. Default False.\n       newline_pattern: Regular expression to match the new line either preceding or following a header\n           if either require_start_line or require_end_line are True. Default is r\"[\n</code></pre> <p>]+[\\s]*$\"            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in                <code>DEFAULT_ATTRIBUTES</code>. If a dictionary of custom attributes, format is a dictionary mapping section                categories to a dictionary containing the attribute name and the value to set the attribute to when a                span is contained in a section of that category. Custom attributes must be assigned with                <code>Span.set_extension</code> before creating the Sectionizer. If None, sectionizer will not modify span                attributes.            input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans                contained in a section if <code>span_attrs</code> is not None. \"ents\" will modify attributes of spans in doc.ents.                \"group\" will modify attributes of spans in the span group specified by <code>span_group_name</code>.            span_group_name: The name of the span group used when <code>input_span_type</code> is \"group\". Default is                \"medspacy_spans\".            apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures                the section header is considered its own sentence.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_sectionizer\",\n    rules: Optional[str] = \"default\",\n    language_code: str = 'en',\n    max_section_length: Optional[int] = None,\n    phrase_matcher_attr: str = \"LOWER\",\n    require_start_line: bool = False,\n    require_end_line: bool = False,\n    newline_pattern: str = r\"[\\n\\r]+[\\s]*$\",\n    input_span_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n    span_attrs: Union[\n        Literal[\"default\"], Dict[str, Dict[str, Any]], None\n    ] = \"default\",\n    apply_sentence_boundary: bool = False,\n):\n    \"\"\"\n    Create a new Sectionizer component.\n\n    Args:\n        nlp: A SpaCy Language object.\n        name: The name of the component.\n        rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n            SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n            are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n            `Sectionizer.add`.\n        language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        max_section_length: Optional argument specifying the maximum number of tokens following a section header\n            which can be included in a section body. This can be useful if you think your section rules are\n            incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n            the scope of a section will be until either the next section header or the end of the document.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        require_start_line: Optionally require a section header to start on a new line. Default False.\n        require_end_line: Optionally require a section header to end with a new line. Default False.\n        newline_pattern: Regular expression to match the new line either preceding or following a header\n            if either require_start_line or require_end_line are True. Default is r\"[\\n\\r]+[\\s]*$\"\n        span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n            `DEFAULT_ATTRIBUTES`. If a dictionary of custom attributes, format is a dictionary mapping section\n            categories to a dictionary containing the attribute name and the value to set the attribute to when a\n            span is contained in a section of that category. Custom attributes must be assigned with\n            `Span.set_extension` before creating the Sectionizer. If None, sectionizer will not modify span\n            attributes.\n        input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans\n            contained in a section if `span_attrs` is not None. \"ents\" will modify attributes of spans in doc.ents.\n            \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n            \"medspacy_spans\".\n        apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures\n            the section header is considered its own sentence.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self.max_section_length = max_section_length\n    self.require_start_line = require_start_line\n    self.require_end_line = require_end_line\n    self.newline_pattern = re.compile(newline_pattern)\n    self.assertion_attributes_mapping = None\n    self._parent_sections = {}\n    self._parent_required = {}\n    self._input_span_type = input_span_type\n    self._span_group_name = span_group_name\n    self._apply_sentence_boundary = apply_sentence_boundary\n\n    self.__matcher = MedspacyMatcher(\n        nlp, name=name, phrase_matcher_attr=phrase_matcher_attr\n    )\n\n    self.DEFAULT_RULES_FILEPATH = path.join(\n        Path(__file__).resolve().parents[2],\n        \"resources\",\n        language_code.lower(),\n        \"section_patterns.json\",\n    )\n\n    rule_path = None\n    if rules == \"default\":\n        rule_path = self.DEFAULT_RULES_FILEPATH\n    else:\n        rule_path = rules\n\n    if rule_path:\n        self.add(SectionRule.from_json(rule_path))\n\n    if span_attrs == \"default\":\n        self.assertion_attributes_mapping = DEFAULT_ATTRS\n        self.register_default_attributes()\n    elif span_attrs:\n        for _, attr_dict in span_attrs.items():\n            for attr_name in attr_dict.keys():\n                if not Span.has_extension(attr_name):\n                    raise ValueError(\n                        f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                        f\"called for your pipeline's custom extensions.\"\n                    )\n        self.assertion_attributes_mapping = span_attrs\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.add","title":"<code>add(rules)</code>","text":"<p>Adds SectionRules to the Sectionizer.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <p>A single SectionRule or a collection of SectionRules to add to the Sectionizer.</p> required Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def add(self, rules):\n    \"\"\"\n    Adds SectionRules to the Sectionizer.\n\n    Args:\n        rules: A single SectionRule or a collection of SectionRules to add to the Sectionizer.\n    \"\"\"\n    if isinstance(rules, SectionRule):\n        rules = [rules]\n\n    for rule in rules:\n        if not isinstance(rule, SectionRule):\n            raise TypeError(\"Rules must be type SectionRule, not\", type(rule))\n\n    self.__matcher.add(rules)\n\n    for rule in rules:\n        name = rule.category\n        parents = rule.parents\n        parent_required = rule.parent_required\n        if parents:\n            if name in self._parent_sections.keys():\n                warnings.warn(\n                    f\"Duplicate section title {name}. Merging parents. \"\n                    f\"If this is not intended, please specify distinct titles.\",\n                    RuntimeWarning,\n                )\n                self._parent_sections[name].update(parents)\n            else:\n                self._parent_sections[name] = set(parents)\n\n        if (\n            name in self._parent_required.keys()\n            and self._parent_required[name] != parent_required\n        ):\n            warnings.warn(\n                f\"Duplicate section title {name} has different parent_required option. \"\n                f\"Setting parent_required to False.\",\n                RuntimeWarning,\n            )\n            self._parent_required[name] = False\n        else:\n            self._parent_required[name] = parent_required\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.filter_end_lines","title":"<code>filter_end_lines(doc, matches)</code>","text":"<p>Filter a list of matches to only contain spans where the start token is followed by a new line.</p> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples (match_id, start, end) that meet the filter criteria.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def filter_end_lines(\n    self, doc: Doc, matches: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Filter a list of matches to only contain spans where the start token is followed by a new line.\n\n    Returns:\n        A list of match tuples (match_id, start, end) that meet the filter criteria.\n    \"\"\"\n    return [\n        m for m in matches if util.is_end_line(m[2] - 1, doc, self.newline_pattern)\n    ]\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.filter_start_lines","title":"<code>filter_start_lines(doc, matches)</code>","text":"<p>Filter a list of matches to only contain spans where the start token is the beginning of a new line.</p> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples (match_id, start, end) that meet the filter criteria.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def filter_start_lines(\n    self, doc: Doc, matches: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Filter a list of matches to only contain spans where the start token is the beginning of a new line.\n\n    Returns:\n        A list of match tuples (match_id, start, end) that meet the filter criteria.\n    \"\"\"\n    return [\n        m for m in matches if util.is_start_line(m[1], doc, self.newline_pattern)\n    ]\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.register_default_attributes","title":"<code>register_default_attributes()</code>  <code>classmethod</code>","text":"<p>Register the default values for the Span attributes defined in <code>DEFAULT_ATTRIBUTES</code>.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>@classmethod\ndef register_default_attributes(cls):\n    \"\"\"\n    Register the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n    \"\"\"\n    for attr_name in [\n        \"is_negated\",\n        \"is_uncertain\",\n        \"is_historical\",\n        \"is_hypothetical\",\n        \"is_family\",\n    ]:\n        try:\n            Span.set_extension(attr_name, default=False)\n        except ValueError:  # Extension already set\n            pass\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.set_assertion_attributes","title":"<code>set_assertion_attributes(spans)</code>","text":"<p>Add Span-level attributes to entities based on which section they occur in.</p> <p>Parameters:</p> Name Type Description Default <code>spans</code> <code>Iterable[Span]</code> <p>the spans to modify.</p> required Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def set_assertion_attributes(self, spans: Iterable[Span]):\n    \"\"\"\n    Add Span-level attributes to entities based on which section they occur in.\n\n    Args:\n        spans: the spans to modify.\n    \"\"\"\n    for span in spans:\n        if (\n            span._.section\n            and span._.section.category in self.assertion_attributes_mapping\n        ):\n            attr_dict = self.assertion_attributes_mapping[span._.section.category]\n            for (attr_name, attr_value) in attr_dict.items():\n                setattr(span._, attr_name, attr_value)\n</code></pre>"},{"location":"reference/medspacy/section_detection/#medspacy.section_detection.Sectionizer.set_parent_sections","title":"<code>set_parent_sections(sections)</code>","text":"<p>Determine the legal parent-child section relationships from the list of in-order sections of a document and the possible parents of each section as specified during direction creation.</p> <p>Parameters:</p> Name Type Description Default <code>sections</code> <code>List[Tuple[int, int, int]]</code> <p>a list of spacy match tuples found in the doc</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int, int, int]]</code> <p>A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input</p> <code>List[Tuple[int, int, int, int]]</code> <p>and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a</p> <code>List[Tuple[int, int, int, int]]</code> <p>smaller list than the input due to pruning with <code>parent_required</code>.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def set_parent_sections(\n    self, sections: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int, int]]:\n    \"\"\"\n    Determine the legal parent-child section relationships from the list\n    of in-order sections of a document and the possible parents of each\n    section as specified during direction creation.\n\n    Args:\n        sections: a list of spacy match tuples found in the doc\n\n    Returns:\n        A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input\n        and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a\n        smaller list than the input due to pruning with `parent_required`.\n    \"\"\"\n    sections_final = []\n    removed_sections = 0\n    for i, (match_id, start, end) in enumerate(sections):\n        name = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]].category\n        required = self._parent_required[name]\n        i_a = i - removed_sections  # adjusted index for removed values\n        if required and i_a == 0:\n            removed_sections += 1\n            continue\n        elif i_a == 0 or name not in self._parent_sections.keys():\n            sections_final.append((match_id, start, end, None))\n        else:\n            parents = self._parent_sections[name]\n            identified_parent = None\n            for parent in parents:\n                # go backwards through the section \"tree\" until you hit a root or the start of the list\n                candidate = self.__matcher.rule_map[\n                    self.nlp.vocab.strings[sections_final[i_a - 1][0]]\n                ].category\n                candidates_parent_idx = sections_final[i_a - 1][3]\n                if candidates_parent_idx is not None:\n                    candidates_parent = self.__matcher.rule_map[\n                        self.nlp.vocab.strings[\n                            sections_final[candidates_parent_idx][0]\n                        ]\n                    ].category\n                else:\n                    candidates_parent = None\n                candidate_i = i_a - 1\n                while candidate:\n                    if candidate == parent:\n                        identified_parent = candidate_i\n                        candidate = None\n                    else:\n                        # if you are at the end of the list... no parent\n                        if candidate_i &lt; 1:\n                            candidate = None\n                            continue\n                        # if the current candidate has no parent... no parent exists\n                        if not candidates_parent:\n                            candidate = None\n                            continue\n                        # otherwise get the previous item in the list\n                        temp = self.__matcher.rule_map[\n                            self.nlp.vocab.strings[\n                                sections_final[candidate_i - 1][0]\n                            ]\n                        ].category\n                        temp_parent_idx = sections_final[candidate_i - 1][3]\n                        if temp_parent_idx is not None:\n                            temp_parent = self.__matcher.rule_map[\n                                self.nlp.vocab.strings[\n                                    sections_final[temp_parent_idx][0]\n                                ]\n                            ].category\n                        else:\n                            temp_parent = None\n                        # if the previous item is the parent of the current item\n                        # OR if the previous item is a sibling of the current item\n                        # continue to search\n                        if (\n                            temp == candidates_parent\n                            or temp_parent == candidates_parent\n                        ):\n                            candidate = temp\n                            candidates_parent = temp_parent\n                            candidate_i -= 1\n                        # otherwise, there is no further tree traversal\n                        else:\n                            candidate = None\n\n            # if a parent is required, then add\n            if identified_parent is not None or not required:\n                # if the parent is identified, add section\n                # if the parent is not required, add section\n                # if parent is not identified and required, do not add the section\n                sections_final.append((match_id, start, end, identified_parent))\n            else:\n                removed_sections += 1\n    return sections_final\n</code></pre>"},{"location":"reference/medspacy/section_detection/section/","title":"medspacy.section_detection.section","text":""},{"location":"reference/medspacy/section_detection/section/#medspacy.section_detection.section.Section","title":"<code>Section</code>","text":"<p>               Bases: <code>object</code></p> <p>Section is the object that stores the result of processing by the Sectionizer class. A Section contains information describing the section's category, title span, body span, parent, and the rule that created it.</p> <p>Section <code>category</code> is equivalent to <code>label_</code> in a basic spaCy entity. It is a normalized name for the section type determined on initialization, either created manually or through the Sectionizer pipeline component.</p> <p>Section title, defined with <code>title_start</code>, <code>title_end</code>, and <code>title_span</code> represents the section title or header matched with the rule. In the text \"Past medical history: stroke and high blood pressure\", \"Past medical history:\" would be the title.</p> <p>Section body is defined with <code>body_start</code>, <code>body_end</code>, and <code>body_span</code>. It represents the text between the end of the current section's title and the start of the title for the next Section or when scope is set in the rule or by the Sectionizer. In the text \"Past medical history: stroke and high blood pressure\", \"stroke and high blood pressure\" would be the body.</p> <p>Parent is a string that represents the conceptual \"parent\" section in a section-&gt;subsection-&gt;subsubsection hierarchy. Candidates are determined by category in the rule and matched at runtime.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>class Section(object):\n    \"\"\"\n    Section is the object that stores the result of processing by the Sectionizer class. A Section contains information\n    describing the section's category, title span, body span, parent, and the rule that created it.\n\n    Section `category` is equivalent to `label_` in a basic spaCy entity. It is a normalized name for the section type\n    determined on initialization, either created manually or through the Sectionizer pipeline component.\n\n    Section title, defined with `title_start`, `title_end`, and `title_span` represents the section title or header\n    matched with the rule. In the text \"Past medical history: stroke and high blood pressure\", \"Past medical history:\"\n    would be the title.\n\n    Section body is defined with `body_start`, `body_end`, and `body_span`. It represents the text between the end of\n    the current section's title and the start of the title for the next Section or when scope is set in the rule or by\n    the Sectionizer. In the text \"Past medical history: stroke and high blood pressure\", \"stroke and high blood\n    pressure\" would be the body.\n\n    Parent is a string that represents the conceptual \"parent\" section in a section-&gt;subsection-&gt;subsubsection\n    hierarchy. Candidates are determined by category in the rule and matched at runtime.\n    \"\"\"\n\n    def __init__(\n        self,\n        category: Union[str, None],\n        title_start: int,\n        title_end: int,\n        body_start: int,\n        body_end: int,\n        parent: Optional[str] = None,\n        rule: Optional[SectionRule] = None,\n    ):\n        \"\"\"\n        Create a new Section object.\n\n        Args:\n            category: A normalized name for the section. Equivalent to `label_` for basic spaCy entities.\n            title_start: Index of the first token of the section title.\n            title_end: Index of the last token of the section title.\n            body_start: Index of the first token of the section body.\n            body_end: Index of the last token of the section body.\n            parent: The category of the parent section.\n            rule: The SectionRule that generated the section.\n        \"\"\"\n        self.category = category\n        self.title_start = title_start\n        self.title_end = title_end\n        self.body_start = body_start\n        self.body_end = body_end\n        self.parent = parent\n        self.rule = rule\n\n    def __repr__(self):\n        return (\n            f\"Section(category={self.category} at {self.title_start} : {self.title_end} in the doc with a body at \"\n            f\"{self.body_start} : {self.body_end} based on the rule {self.rule}\"\n        )\n\n    @property\n    def title_span(self):\n        \"\"\"\n        Gets the span of the section title.\n\n        Returns:\n            A tuple (int,int) containing the start and end indexes of the section title.\n        \"\"\"\n        return self.title_start, self.title_end\n\n    @property\n    def body_span(self):\n        \"\"\"\n        Gets the span of the section body.\n\n        Returns:\n            A tuple (int,int) containing the start and end indexes of the section body.\n        \"\"\"\n        return self.body_start, self.body_end\n\n    @property\n    def section_span(self):\n        \"\"\"\n        Gets the span of the entire section, from title start to body end.\n\n        Returns:\n            A tuple (int,int) containing the start index of the section title and the end index of the section body.\n        \"\"\"\n        return self.title_start, self.body_end\n\n    def serialized_representation(self):\n        \"\"\"\n        Serialize the Section.\n\n        Returns:\n            A json-serialized representation of the section.\n        \"\"\"\n        rule = self.rule\n\n        return {\n            \"category\": self.category,\n            \"title_start\": self.title_start,\n            \"title_end\": self.title_end,\n            \"body_start\": self.body_start,\n            \"body_end\": self.body_end,\n            \"parent\": self.parent,\n            \"rule\": rule.to_dict() if rule is not None else None,\n        }\n\n    @classmethod\n    def from_serialized_representation(cls, serialized_representation: Dict[str, str]):\n        \"\"\"\n        Load the section from a json-serialized form.\n\n        Args:\n            serialized_representation: The dictionary form of the section object to load.\n\n        Returns:\n            A Section object containing the data from the dictionary provided.\n        \"\"\"\n        rule = SectionRule.from_dict(serialized_representation[\"rule\"])\n        section = Section(\n            **{k: v for k, v in serialized_representation.items() if k not in [\"rule\"]}\n        )\n        section.rule = rule\n\n        return section\n</code></pre>"},{"location":"reference/medspacy/section_detection/section/#medspacy.section_detection.section.Section.body_span","title":"<code>body_span</code>  <code>property</code>","text":"<p>Gets the span of the section body.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start and end indexes of the section body.</p>"},{"location":"reference/medspacy/section_detection/section/#medspacy.section_detection.section.Section.section_span","title":"<code>section_span</code>  <code>property</code>","text":"<p>Gets the span of the entire section, from title start to body end.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start index of the section title and the end index of the section body.</p>"},{"location":"reference/medspacy/section_detection/section/#medspacy.section_detection.section.Section.title_span","title":"<code>title_span</code>  <code>property</code>","text":"<p>Gets the span of the section title.</p> <p>Returns:</p> Type Description <p>A tuple (int,int) containing the start and end indexes of the section title.</p>"},{"location":"reference/medspacy/section_detection/section/#medspacy.section_detection.section.Section.__init__","title":"<code>__init__(category, title_start, title_end, body_start, body_end, parent=None, rule=None)</code>","text":"<p>Create a new Section object.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>Union[str, None]</code> <p>A normalized name for the section. Equivalent to <code>label_</code> for basic spaCy entities.</p> required <code>title_start</code> <code>int</code> <p>Index of the first token of the section title.</p> required <code>title_end</code> <code>int</code> <p>Index of the last token of the section title.</p> required <code>body_start</code> <code>int</code> <p>Index of the first token of the section body.</p> required <code>body_end</code> <code>int</code> <p>Index of the last token of the section body.</p> required <code>parent</code> <code>Optional[str]</code> <p>The category of the parent section.</p> <code>None</code> <code>rule</code> <code>Optional[SectionRule]</code> <p>The SectionRule that generated the section.</p> <code>None</code> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>def __init__(\n    self,\n    category: Union[str, None],\n    title_start: int,\n    title_end: int,\n    body_start: int,\n    body_end: int,\n    parent: Optional[str] = None,\n    rule: Optional[SectionRule] = None,\n):\n    \"\"\"\n    Create a new Section object.\n\n    Args:\n        category: A normalized name for the section. Equivalent to `label_` for basic spaCy entities.\n        title_start: Index of the first token of the section title.\n        title_end: Index of the last token of the section title.\n        body_start: Index of the first token of the section body.\n        body_end: Index of the last token of the section body.\n        parent: The category of the parent section.\n        rule: The SectionRule that generated the section.\n    \"\"\"\n    self.category = category\n    self.title_start = title_start\n    self.title_end = title_end\n    self.body_start = body_start\n    self.body_end = body_end\n    self.parent = parent\n    self.rule = rule\n</code></pre>"},{"location":"reference/medspacy/section_detection/section/#medspacy.section_detection.section.Section.from_serialized_representation","title":"<code>from_serialized_representation(serialized_representation)</code>  <code>classmethod</code>","text":"<p>Load the section from a json-serialized form.</p> <p>Parameters:</p> Name Type Description Default <code>serialized_representation</code> <code>Dict[str, str]</code> <p>The dictionary form of the section object to load.</p> required <p>Returns:</p> Type Description <p>A Section object containing the data from the dictionary provided.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>@classmethod\ndef from_serialized_representation(cls, serialized_representation: Dict[str, str]):\n    \"\"\"\n    Load the section from a json-serialized form.\n\n    Args:\n        serialized_representation: The dictionary form of the section object to load.\n\n    Returns:\n        A Section object containing the data from the dictionary provided.\n    \"\"\"\n    rule = SectionRule.from_dict(serialized_representation[\"rule\"])\n    section = Section(\n        **{k: v for k, v in serialized_representation.items() if k not in [\"rule\"]}\n    )\n    section.rule = rule\n\n    return section\n</code></pre>"},{"location":"reference/medspacy/section_detection/section/#medspacy.section_detection.section.Section.serialized_representation","title":"<code>serialized_representation()</code>","text":"<p>Serialize the Section.</p> <p>Returns:</p> Type Description <p>A json-serialized representation of the section.</p> Source code in <code>medspacy/section_detection/section.py</code> <pre><code>def serialized_representation(self):\n    \"\"\"\n    Serialize the Section.\n\n    Returns:\n        A json-serialized representation of the section.\n    \"\"\"\n    rule = self.rule\n\n    return {\n        \"category\": self.category,\n        \"title_start\": self.title_start,\n        \"title_end\": self.title_end,\n        \"body_start\": self.body_start,\n        \"body_end\": self.body_end,\n        \"parent\": self.parent,\n        \"rule\": rule.to_dict() if rule is not None else None,\n    }\n</code></pre>"},{"location":"reference/medspacy/section_detection/section_rule/","title":"medspacy.section_detection.section_rule","text":""},{"location":"reference/medspacy/section_detection/section_rule/#medspacy.section_detection.section_rule.SectionRule","title":"<code>SectionRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>SectionRule defines rules for extracting entities from text using the Sectionizer.</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>class SectionRule(BaseRule):\n    \"\"\"\n    SectionRule defines rules for extracting entities from text using the Sectionizer.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"parents\",\n        \"parent_required\",\n        \"max_scope\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        max_scope: Optional[int] = None,\n        parents: Optional[List[str]] = None,\n        parent_required: bool = False,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Class for defining rules for extracting entities from text using TargetMatcher.\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            max_scope: A number of tokens to explicitly limit the size of a section body. If None, the scope will\n                include the entire doc up until either the next section header or the end of the doc. This variable can\n                also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the\n                rule scope will take precedence. If not None, this will be the number of tokens following the matched\n                section header\n                    Example:\n                        In the text \"Past Medical History: Pt has hx of pneumonia\",\n                        SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but\n                        SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section\n                            to be \"Past Medical History: Pt has\"\n                This can be useful for limiting certain sections which are known to be short or allowing others to be\n                longer than the regular global max_scope.\n            parents: A list of candidate parents for determining subsections\n            parent_required: Whether a parent is required for the section to exist in the final output. If true and no\n                parent is identified, the section will be removed.\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category, pattern, on_match, metadata)\n        self.max_scope = max_scope\n        self.parents = parents\n        if parent_required:\n            if not parents:\n                raise ValueError(\n                    f\"Jsonl file incorrectly formatted for pattern name {category}. \"\n                    f\"If parents are required, then at least one parent must be specified.\"\n                )\n        self.parent_required = parent_required\n\n    @classmethod\n    def from_json(cls, filepath) -&gt; List[SectionRule]:\n        \"\"\"\n        Read in a lexicon of modifiers from a JSON file.\n\n        Args:\n            filepath: the .json file containing modifier rules\n\n        Returns:\n            section_rules: a list of SectionRule objects\n        \"\"\"\n        import json\n\n        with open(filepath) as file:\n            section_data = json.load(file)\n        section_rules = []\n        for data in section_data[\"section_rules\"]:\n            section_rules.append(SectionRule.from_dict(data))\n        return section_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict):\n        \"\"\"\n        Reads a dictionary into a SectionRule list. Used when reading from a json file.\n\n        Args:\n            rule_dict: the dictionary to convert\n\n        Returns:\n            item: the SectionRule created from the dictionary\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                f\"JSON object contains invalid keys: {invalid_keys}. \"\n                f\"Must be one of: {cls._ALLOWED_KEYS}\"\n            )\n            raise ValueError(msg)\n        rule = SectionRule(**rule_dict)\n        return rule\n\n    def to_dict(self):\n        \"\"\"\n        Converts TargetRules to a python dictionary. Used when writing section rules to a json file.\n\n        Returns:\n            rule_dict: the dictionary containing the TargetRule info.\n        \"\"\"\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    def __repr__(self):\n        return f\"\"\"SectionRule(literal=\"{self.literal}\", category=\"{self.category}\", pattern={self.pattern}, on_match={self.on_match}, parents={self.parents}, parent_required={self.parent_required})\"\"\"\n</code></pre>"},{"location":"reference/medspacy/section_detection/section_rule/#medspacy.section_detection.section_rule.SectionRule.__init__","title":"<code>__init__(literal, category, pattern=None, on_match=None, max_scope=None, parents=None, parent_required=False, metadata=None)</code>","text":"<p>Class for defining rules for extracting entities from text using TargetMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[List[Dict[str, str]], str]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>max_scope</code> <code>Optional[int]</code> <p>A number of tokens to explicitly limit the size of a section body. If None, the scope will include the entire doc up until either the next section header or the end of the doc. This variable can also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the rule scope will take precedence. If not None, this will be the number of tokens following the matched section header     Example:         In the text \"Past Medical History: Pt has hx of pneumonia\",         SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but         SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section             to be \"Past Medical History: Pt has\" This can be useful for limiting certain sections which are known to be short or allowing others to be longer than the regular global max_scope.</p> <code>None</code> <code>parents</code> <code>Optional[List[str]]</code> <p>A list of candidate parents for determining subsections</p> <code>None</code> <code>parent_required</code> <code>bool</code> <p>Whether a parent is required for the section to exist in the final output. If true and no parent is identified, the section will be removed.</p> <code>False</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    max_scope: Optional[int] = None,\n    parents: Optional[List[str]] = None,\n    parent_required: bool = False,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Class for defining rules for extracting entities from text using TargetMatcher.\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        max_scope: A number of tokens to explicitly limit the size of a section body. If None, the scope will\n            include the entire doc up until either the next section header or the end of the doc. This variable can\n            also be set at a global level as `Sectionizer(nlp, max_scope=...), but if the attribute is set here, the\n            rule scope will take precedence. If not None, this will be the number of tokens following the matched\n            section header\n                Example:\n                    In the text \"Past Medical History: Pt has hx of pneumonia\",\n                    SectionRule(\"Past Medical History:\", \"pmh\", max_scope=None) will include the entire doc, but\n                    SectionRule(\"Past Medical History:\", \"pmh\", max_scope=2) will limit the section\n                        to be \"Past Medical History: Pt has\"\n            This can be useful for limiting certain sections which are known to be short or allowing others to be\n            longer than the regular global max_scope.\n        parents: A list of candidate parents for determining subsections\n        parent_required: Whether a parent is required for the section to exist in the final output. If true and no\n            parent is identified, the section will be removed.\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category, pattern, on_match, metadata)\n    self.max_scope = max_scope\n    self.parents = parents\n    if parent_required:\n        if not parents:\n            raise ValueError(\n                f\"Jsonl file incorrectly formatted for pattern name {category}. \"\n                f\"If parents are required, then at least one parent must be specified.\"\n            )\n    self.parent_required = parent_required\n</code></pre>"},{"location":"reference/medspacy/section_detection/section_rule/#medspacy.section_detection.section_rule.SectionRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a SectionRule list. Used when reading from a json file.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <p>the dictionary to convert</p> required <p>Returns:</p> Name Type Description <code>item</code> <p>the SectionRule created from the dictionary</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict):\n    \"\"\"\n    Reads a dictionary into a SectionRule list. Used when reading from a json file.\n\n    Args:\n        rule_dict: the dictionary to convert\n\n    Returns:\n        item: the SectionRule created from the dictionary\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            f\"JSON object contains invalid keys: {invalid_keys}. \"\n            f\"Must be one of: {cls._ALLOWED_KEYS}\"\n        )\n        raise ValueError(msg)\n    rule = SectionRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"reference/medspacy/section_detection/section_rule/#medspacy.section_detection.section_rule.SectionRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read in a lexicon of modifiers from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>the .json file containing modifier rules</p> required <p>Returns:</p> Name Type Description <code>section_rules</code> <code>List[SectionRule]</code> <p>a list of SectionRule objects</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath) -&gt; List[SectionRule]:\n    \"\"\"\n    Read in a lexicon of modifiers from a JSON file.\n\n    Args:\n        filepath: the .json file containing modifier rules\n\n    Returns:\n        section_rules: a list of SectionRule objects\n    \"\"\"\n    import json\n\n    with open(filepath) as file:\n        section_data = json.load(file)\n    section_rules = []\n    for data in section_data[\"section_rules\"]:\n        section_rules.append(SectionRule.from_dict(data))\n    return section_rules\n</code></pre>"},{"location":"reference/medspacy/section_detection/section_rule/#medspacy.section_detection.section_rule.SectionRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts TargetRules to a python dictionary. Used when writing section rules to a json file.</p> <p>Returns:</p> Name Type Description <code>rule_dict</code> <p>the dictionary containing the TargetRule info.</p> Source code in <code>medspacy/section_detection/section_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"\n    Converts TargetRules to a python dictionary. Used when writing section rules to a json file.\n\n    Returns:\n        rule_dict: the dictionary containing the TargetRule info.\n    \"\"\"\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"reference/medspacy/section_detection/sectionizer/","title":"medspacy.section_detection.sectionizer","text":""},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer","title":"<code>Sectionizer</code>","text":"<p>The Sectionizer will search for spans in the text which match section header rules, such as 'Past Medical History:'. Sections will be represented in custom attributes as:     category: A normalized title of the section. Example: 'past_medical_history'     section_title: The Span of the doc which was matched as a section header.         Example: 'Past Medical History:'     section_span: The entire section of the note, starting with section_header and up until the end         of the section, which will be either the start of the next section header of some pre-specified         scope. Example: 'Past Medical History: Type II DM'</p> <p>Section attributes will be registered for each Doc, Span, and Token in the following attributes:     Doc..sections: A list of namedtuples of type Section with 4 elements:         - section_title         - section_header         - section_parent         - section_span.     A Doc will also have attributes corresponding to lists of each         (ie., Doc..section_titles, Doc..section_headers, Doc..section_parents, Doc..section_list)     (Span|Token)..section_title     (Span|Token)..section_header     (Span|Token)..section_parent     (Span|Token)._.section_span</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>@Language.factory(\"medspacy_sectionizer\")\nclass Sectionizer:\n    \"\"\"\n    The Sectionizer will search for spans in the text which match section header rules, such as 'Past Medical History:'.\n    Sections will be represented in custom attributes as:\n        category: A normalized title of the section. Example: 'past_medical_history'\n        section_title: The Span of the doc which was matched as a section header.\n            Example: 'Past Medical History:'\n        section_span: The entire section of the note, starting with section_header and up until the end\n            of the section, which will be either the start of the next section header of some pre-specified\n            scope. Example: 'Past Medical History: Type II DM'\n\n    Section attributes will be registered for each Doc, Span, and Token in the following attributes:\n        Doc._.sections: A list of namedtuples of type Section with 4 elements:\n            - section_title\n            - section_header\n            - section_parent\n            - section_span.\n        A Doc will also have attributes corresponding to lists of each\n            (ie., Doc._.section_titles, Doc._.section_headers, Doc._.section_parents, Doc._.section_list)\n        (Span|Token)._.section_title\n        (Span|Token)._.section_header\n        (Span|Token)._.section_parent\n        (Span|Token)._.section_span\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_sectionizer\",\n        rules: Optional[str] = \"default\",\n        language_code: str = 'en',\n        max_section_length: Optional[int] = None,\n        phrase_matcher_attr: str = \"LOWER\",\n        require_start_line: bool = False,\n        require_end_line: bool = False,\n        newline_pattern: str = r\"[\\n\\r]+[\\s]*$\",\n        input_span_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n        span_attrs: Union[\n            Literal[\"default\"], Dict[str, Dict[str, Any]], None\n        ] = \"default\",\n        apply_sentence_boundary: bool = False,\n    ):\n        \"\"\"\n        Create a new Sectionizer component.\n\n        Args:\n            nlp: A SpaCy Language object.\n            name: The name of the component.\n            rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n                SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n                are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n                `Sectionizer.add`.\n            language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n                and also the /resources directory to see which resources might be available in each language.\n                Default is \"en\" for English.\n            max_section_length: Optional argument specifying the maximum number of tokens following a section header\n                which can be included in a section body. This can be useful if you think your section rules are\n                incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n                the scope of a section will be until either the next section header or the end of the document.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            require_start_line: Optionally require a section header to start on a new line. Default False.\n            require_end_line: Optionally require a section header to end with a new line. Default False.\n            newline_pattern: Regular expression to match the new line either preceding or following a header\n                if either require_start_line or require_end_line are True. Default is r\"[\\n\\r]+[\\s]*$\"\n            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n                `DEFAULT_ATTRIBUTES`. If a dictionary of custom attributes, format is a dictionary mapping section\n                categories to a dictionary containing the attribute name and the value to set the attribute to when a\n                span is contained in a section of that category. Custom attributes must be assigned with\n                `Span.set_extension` before creating the Sectionizer. If None, sectionizer will not modify span\n                attributes.\n            input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans\n                contained in a section if `span_attrs` is not None. \"ents\" will modify attributes of spans in doc.ents.\n                \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n            span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n                \"medspacy_spans\".\n            apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures\n                the section header is considered its own sentence.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self.max_section_length = max_section_length\n        self.require_start_line = require_start_line\n        self.require_end_line = require_end_line\n        self.newline_pattern = re.compile(newline_pattern)\n        self.assertion_attributes_mapping = None\n        self._parent_sections = {}\n        self._parent_required = {}\n        self._input_span_type = input_span_type\n        self._span_group_name = span_group_name\n        self._apply_sentence_boundary = apply_sentence_boundary\n\n        self.__matcher = MedspacyMatcher(\n            nlp, name=name, phrase_matcher_attr=phrase_matcher_attr\n        )\n\n        self.DEFAULT_RULES_FILEPATH = path.join(\n            Path(__file__).resolve().parents[2],\n            \"resources\",\n            language_code.lower(),\n            \"section_patterns.json\",\n        )\n\n        rule_path = None\n        if rules == \"default\":\n            rule_path = self.DEFAULT_RULES_FILEPATH\n        else:\n            rule_path = rules\n\n        if rule_path:\n            self.add(SectionRule.from_json(rule_path))\n\n        if span_attrs == \"default\":\n            self.assertion_attributes_mapping = DEFAULT_ATTRS\n            self.register_default_attributes()\n        elif span_attrs:\n            for _, attr_dict in span_attrs.items():\n                for attr_name in attr_dict.keys():\n                    if not Span.has_extension(attr_name):\n                        raise ValueError(\n                            f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                            f\"called for your pipeline's custom extensions.\"\n                        )\n            self.assertion_attributes_mapping = span_attrs\n\n    @property\n    def rules(self) -&gt; List[SectionRule]:\n        \"\"\"\n        Gets list of rules associated with the Sectionizer.\n\n        Returns:\n            The list of SectionRules associated with the Sectionizer.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def section_categories(self) -&gt; Set[str]:\n        \"\"\"\n        Gets a list of categories used in the Sectionizer.\n\n        Returns:\n                The list of all section categories available to the Sectionizer.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def input_span_type(self):\n        \"\"\"\n        The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for\n        a spaCy span group.\n\n        Returns:\n            The input type, \"ents\" or \"group\".\n        \"\"\"\n        return self._input_span_type\n\n    @input_span_type.setter\n    def input_span_type(self, val):\n        if not (val == \"ents\" or val == \"group\"):\n            raise ValueError('input_type must be \"ents\" or \"group\".')\n        self._input_span_type = val\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `input_type` is \"group\", calling this component will\n        use spans in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    @classmethod\n    def register_default_attributes(cls):\n        \"\"\"\n        Register the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n        \"\"\"\n        for attr_name in [\n            \"is_negated\",\n            \"is_uncertain\",\n            \"is_historical\",\n            \"is_hypothetical\",\n            \"is_family\",\n        ]:\n            try:\n                Span.set_extension(attr_name, default=False)\n            except ValueError:  # Extension already set\n                pass\n\n    def add(self, rules):\n        \"\"\"\n        Adds SectionRules to the Sectionizer.\n\n        Args:\n            rules: A single SectionRule or a collection of SectionRules to add to the Sectionizer.\n        \"\"\"\n        if isinstance(rules, SectionRule):\n            rules = [rules]\n\n        for rule in rules:\n            if not isinstance(rule, SectionRule):\n                raise TypeError(\"Rules must be type SectionRule, not\", type(rule))\n\n        self.__matcher.add(rules)\n\n        for rule in rules:\n            name = rule.category\n            parents = rule.parents\n            parent_required = rule.parent_required\n            if parents:\n                if name in self._parent_sections.keys():\n                    warnings.warn(\n                        f\"Duplicate section title {name}. Merging parents. \"\n                        f\"If this is not intended, please specify distinct titles.\",\n                        RuntimeWarning,\n                    )\n                    self._parent_sections[name].update(parents)\n                else:\n                    self._parent_sections[name] = set(parents)\n\n            if (\n                name in self._parent_required.keys()\n                and self._parent_required[name] != parent_required\n            ):\n                warnings.warn(\n                    f\"Duplicate section title {name} has different parent_required option. \"\n                    f\"Setting parent_required to False.\",\n                    RuntimeWarning,\n                )\n                self._parent_required[name] = False\n            else:\n                self._parent_required[name] = parent_required\n\n    def set_parent_sections(\n        self, sections: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int, int]]:\n        \"\"\"\n        Determine the legal parent-child section relationships from the list\n        of in-order sections of a document and the possible parents of each\n        section as specified during direction creation.\n\n        Args:\n            sections: a list of spacy match tuples found in the doc\n\n        Returns:\n            A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input\n            and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a\n            smaller list than the input due to pruning with `parent_required`.\n        \"\"\"\n        sections_final = []\n        removed_sections = 0\n        for i, (match_id, start, end) in enumerate(sections):\n            name = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]].category\n            required = self._parent_required[name]\n            i_a = i - removed_sections  # adjusted index for removed values\n            if required and i_a == 0:\n                removed_sections += 1\n                continue\n            elif i_a == 0 or name not in self._parent_sections.keys():\n                sections_final.append((match_id, start, end, None))\n            else:\n                parents = self._parent_sections[name]\n                identified_parent = None\n                for parent in parents:\n                    # go backwards through the section \"tree\" until you hit a root or the start of the list\n                    candidate = self.__matcher.rule_map[\n                        self.nlp.vocab.strings[sections_final[i_a - 1][0]]\n                    ].category\n                    candidates_parent_idx = sections_final[i_a - 1][3]\n                    if candidates_parent_idx is not None:\n                        candidates_parent = self.__matcher.rule_map[\n                            self.nlp.vocab.strings[\n                                sections_final[candidates_parent_idx][0]\n                            ]\n                        ].category\n                    else:\n                        candidates_parent = None\n                    candidate_i = i_a - 1\n                    while candidate:\n                        if candidate == parent:\n                            identified_parent = candidate_i\n                            candidate = None\n                        else:\n                            # if you are at the end of the list... no parent\n                            if candidate_i &lt; 1:\n                                candidate = None\n                                continue\n                            # if the current candidate has no parent... no parent exists\n                            if not candidates_parent:\n                                candidate = None\n                                continue\n                            # otherwise get the previous item in the list\n                            temp = self.__matcher.rule_map[\n                                self.nlp.vocab.strings[\n                                    sections_final[candidate_i - 1][0]\n                                ]\n                            ].category\n                            temp_parent_idx = sections_final[candidate_i - 1][3]\n                            if temp_parent_idx is not None:\n                                temp_parent = self.__matcher.rule_map[\n                                    self.nlp.vocab.strings[\n                                        sections_final[temp_parent_idx][0]\n                                    ]\n                                ].category\n                            else:\n                                temp_parent = None\n                            # if the previous item is the parent of the current item\n                            # OR if the previous item is a sibling of the current item\n                            # continue to search\n                            if (\n                                temp == candidates_parent\n                                or temp_parent == candidates_parent\n                            ):\n                                candidate = temp\n                                candidates_parent = temp_parent\n                                candidate_i -= 1\n                            # otherwise, there is no further tree traversal\n                            else:\n                                candidate = None\n\n                # if a parent is required, then add\n                if identified_parent is not None or not required:\n                    # if the parent is identified, add section\n                    # if the parent is not required, add section\n                    # if parent is not identified and required, do not add the section\n                    sections_final.append((match_id, start, end, identified_parent))\n                else:\n                    removed_sections += 1\n        return sections_final\n\n    def set_assertion_attributes(self, spans: Iterable[Span]):\n        \"\"\"\n        Add Span-level attributes to entities based on which section they occur in.\n\n        Args:\n            spans: the spans to modify.\n        \"\"\"\n        for span in spans:\n            if (\n                span._.section\n                and span._.section.category in self.assertion_attributes_mapping\n            ):\n                attr_dict = self.assertion_attributes_mapping[span._.section.category]\n                for (attr_name, attr_value) in attr_dict.items():\n                    setattr(span._, attr_name, attr_value)\n\n    def __call__(self, doc: Doc) -&gt; Doc:\n        \"\"\"\n        Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any\n        section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections\n        the entities spans in.\n\n        Args:\n            doc: The Doc to process.\n\n        Returns:\n            The processed spaCy Doc.\n        \"\"\"\n        matches = self.__matcher(doc)\n        if self.require_start_line:\n            matches = self.filter_start_lines(doc, matches)\n        if self.require_end_line:\n            matches = self.filter_end_lines(doc, matches)\n        if self._parent_sections:\n            matches = self.set_parent_sections(matches)\n\n        # If this has already been processed by the sectionizer, reset the sections\n        doc._.sections = []\n        # if there were no matches, return the doc as one section\n        if len(matches) == 0:\n            doc._.sections.append(Section(None, 0, 0, 0, len(doc)))\n            return doc\n\n        section_list = []\n        # if the first match does not begin at token 0, handle the first section\n        first_match = matches[0]\n        if first_match[1] != 0:\n            section_list.append(Section(None, 0, 0, 0, first_match[1]))\n\n        # handle section spans\n        for i, match in enumerate(matches):\n            parent = None\n            if len(match) == 4:\n                (match_id, start, end, parent_idx) = match\n                if parent_idx is not None:\n                    parent = section_list[parent_idx]\n            else:\n                # IDEs will warn here about match shape disagreeing w/ type hinting, but this if is only used if\n                # parent sections were never set, so parent_idx does not exist\n                (match_id, start, end) = match\n\n            # Make section header its own sentence\n            if self._apply_sentence_boundary:\n                # Section headers should be considered the start of a sentence\n                doc[start].sent_start = True\n                # Text following the header should also be considered a new sentence\n                if end &lt; len(doc):\n                    doc[end].sent_start = True\n\n            rule = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]]\n            category = rule.category\n            # If this is the last match, it should include the rest of the doc\n            if i == len(matches) - 1:\n                # If there is no scope limitation, go until the end of the doc\n                if self.max_section_length is None and rule.max_scope is None:\n                    section_list.append(\n                        Section(category, start, end, end, len(doc), parent, rule)\n                    )\n                else:\n                    # If the rule has a max_scope, use that as a precedence\n                    if rule.max_scope is not None:\n                        scope_end = min(end + rule.max_scope, doc[-1].i + 1)\n                    else:\n                        scope_end = min(end + self.max_section_length, doc[-1].i + 1)\n\n                    section_list.append(\n                        Section(category, start, end, end, scope_end, parent, rule)\n                    )\n            # Otherwise, go until the next section header\n            else:\n                next_match = matches[i + 1]\n                if len(match) == 4:\n                    _, next_start, _, _ = next_match\n                else:\n                    _, next_start, _ = next_match\n                if self.max_section_length is None and rule.max_scope is None:\n                    section_list.append(\n                        Section(category, start, end, end, next_start, parent, rule)\n                    )\n                else:\n                    if rule.max_scope is not None:\n                        scope_end = min(end + rule.max_scope, next_start)\n                    else:\n                        scope_end = min(end + self.max_section_length, next_start)\n                    section_list.append(\n                        Section(category, start, end, end, scope_end, parent, rule)\n                    )\n\n        for section in section_list:\n            doc._.sections.append(section)\n            start, end = section.section_span\n            for token in doc[start:end]:\n                token._.section = section\n\n        # If it is specified to add assertion attributes,\n        # iterate through the entities in doc and add them\n        if self.assertion_attributes_mapping:\n            if self._input_span_type.lower() == \"ents\":\n                self.set_assertion_attributes(doc.ents)\n            elif self._input_span_type.lower() == \"group\":\n                self.set_assertion_attributes(doc.spans[self._span_group_name])\n\n        return doc\n\n    def filter_start_lines(\n        self, doc: Doc, matches: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Filter a list of matches to only contain spans where the start token is the beginning of a new line.\n\n        Returns:\n            A list of match tuples (match_id, start, end) that meet the filter criteria.\n        \"\"\"\n        return [\n            m for m in matches if util.is_start_line(m[1], doc, self.newline_pattern)\n        ]\n\n    def filter_end_lines(\n        self, doc: Doc, matches: List[Tuple[int, int, int]]\n    ) -&gt; List[Tuple[int, int, int]]:\n        \"\"\"\n        Filter a list of matches to only contain spans where the start token is followed by a new line.\n\n        Returns:\n            A list of match tuples (match_id, start, end) that meet the filter criteria.\n        \"\"\"\n        return [\n            m for m in matches if util.is_end_line(m[2] - 1, doc, self.newline_pattern)\n        ]\n</code></pre>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.input_span_type","title":"<code>input_span_type</code>  <code>property</code> <code>writable</code>","text":"<p>The input source of entities for the component. Must be either \"ents\" corresponding to doc.ents or \"group\" for a spaCy span group.</p> <p>Returns:</p> Type Description <p>The input type, \"ents\" or \"group\".</p>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets list of rules associated with the Sectionizer.</p> <p>Returns:</p> Type Description <code>List[SectionRule]</code> <p>The list of SectionRules associated with the Sectionizer.</p>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.section_categories","title":"<code>section_categories</code>  <code>property</code>","text":"<p>Gets a list of categories used in the Sectionizer.</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>The list of all section categories available to the Sectionizer.</p>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>input_type</code> is \"group\", calling this component will use spans in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections the entities spans in.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The Doc to process.</p> required <p>Returns:</p> Type Description <code>Doc</code> <p>The processed spaCy Doc.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; Doc:\n    \"\"\"\n    Call the Sectionizer on a spaCy doc. Sectionizer will identify sections using provided rules, then evaluate any\n    section hierarchy as needed, create section spans, and modify attributes on existing spans based on the sections\n    the entities spans in.\n\n    Args:\n        doc: The Doc to process.\n\n    Returns:\n        The processed spaCy Doc.\n    \"\"\"\n    matches = self.__matcher(doc)\n    if self.require_start_line:\n        matches = self.filter_start_lines(doc, matches)\n    if self.require_end_line:\n        matches = self.filter_end_lines(doc, matches)\n    if self._parent_sections:\n        matches = self.set_parent_sections(matches)\n\n    # If this has already been processed by the sectionizer, reset the sections\n    doc._.sections = []\n    # if there were no matches, return the doc as one section\n    if len(matches) == 0:\n        doc._.sections.append(Section(None, 0, 0, 0, len(doc)))\n        return doc\n\n    section_list = []\n    # if the first match does not begin at token 0, handle the first section\n    first_match = matches[0]\n    if first_match[1] != 0:\n        section_list.append(Section(None, 0, 0, 0, first_match[1]))\n\n    # handle section spans\n    for i, match in enumerate(matches):\n        parent = None\n        if len(match) == 4:\n            (match_id, start, end, parent_idx) = match\n            if parent_idx is not None:\n                parent = section_list[parent_idx]\n        else:\n            # IDEs will warn here about match shape disagreeing w/ type hinting, but this if is only used if\n            # parent sections were never set, so parent_idx does not exist\n            (match_id, start, end) = match\n\n        # Make section header its own sentence\n        if self._apply_sentence_boundary:\n            # Section headers should be considered the start of a sentence\n            doc[start].sent_start = True\n            # Text following the header should also be considered a new sentence\n            if end &lt; len(doc):\n                doc[end].sent_start = True\n\n        rule = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]]\n        category = rule.category\n        # If this is the last match, it should include the rest of the doc\n        if i == len(matches) - 1:\n            # If there is no scope limitation, go until the end of the doc\n            if self.max_section_length is None and rule.max_scope is None:\n                section_list.append(\n                    Section(category, start, end, end, len(doc), parent, rule)\n                )\n            else:\n                # If the rule has a max_scope, use that as a precedence\n                if rule.max_scope is not None:\n                    scope_end = min(end + rule.max_scope, doc[-1].i + 1)\n                else:\n                    scope_end = min(end + self.max_section_length, doc[-1].i + 1)\n\n                section_list.append(\n                    Section(category, start, end, end, scope_end, parent, rule)\n                )\n        # Otherwise, go until the next section header\n        else:\n            next_match = matches[i + 1]\n            if len(match) == 4:\n                _, next_start, _, _ = next_match\n            else:\n                _, next_start, _ = next_match\n            if self.max_section_length is None and rule.max_scope is None:\n                section_list.append(\n                    Section(category, start, end, end, next_start, parent, rule)\n                )\n            else:\n                if rule.max_scope is not None:\n                    scope_end = min(end + rule.max_scope, next_start)\n                else:\n                    scope_end = min(end + self.max_section_length, next_start)\n                section_list.append(\n                    Section(category, start, end, end, scope_end, parent, rule)\n                )\n\n    for section in section_list:\n        doc._.sections.append(section)\n        start, end = section.section_span\n        for token in doc[start:end]:\n            token._.section = section\n\n    # If it is specified to add assertion attributes,\n    # iterate through the entities in doc and add them\n    if self.assertion_attributes_mapping:\n        if self._input_span_type.lower() == \"ents\":\n            self.set_assertion_attributes(doc.ents)\n        elif self._input_span_type.lower() == \"group\":\n            self.set_assertion_attributes(doc.spans[self._span_group_name])\n\n    return doc\n</code></pre>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.__init__","title":"<code>__init__(nlp, name='medspacy_sectionizer', rules='default', language_code='en', max_section_length=None, phrase_matcher_attr='LOWER', require_start_line=False, require_end_line=False, newline_pattern='[\\\\n\\\\r]+[\\\\s]*$', input_span_type='ents', span_group_name='medspacy_spans', span_attrs='default', apply_sentence_boundary=False)</code>","text":"<pre><code>   Create a new Sectionizer component.\n\n   Args:\n       nlp: A SpaCy Language object.\n       name: The name of the component.\n       rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n           SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n           are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n           `Sectionizer.add`.\n       language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n           and also the /resources directory to see which resources might be available in each language.\n           Default is \"en\" for English.\n       max_section_length: Optional argument specifying the maximum number of tokens following a section header\n           which can be included in a section body. This can be useful if you think your section rules are\n           incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n           the scope of a section will be until either the next section header or the end of the document.\n       phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n           is 'LOWER'.\n       require_start_line: Optionally require a section header to start on a new line. Default False.\n       require_end_line: Optionally require a section header to end with a new line. Default False.\n       newline_pattern: Regular expression to match the new line either preceding or following a header\n           if either require_start_line or require_end_line are True. Default is r\"[\n</code></pre> <p>]+[\\s]*$\"            span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in                <code>DEFAULT_ATTRIBUTES</code>. If a dictionary of custom attributes, format is a dictionary mapping section                categories to a dictionary containing the attribute name and the value to set the attribute to when a                span is contained in a section of that category. Custom attributes must be assigned with                <code>Span.set_extension</code> before creating the Sectionizer. If None, sectionizer will not modify span                attributes.            input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans                contained in a section if <code>span_attrs</code> is not None. \"ents\" will modify attributes of spans in doc.ents.                \"group\" will modify attributes of spans in the span group specified by <code>span_group_name</code>.            span_group_name: The name of the span group used when <code>input_span_type</code> is \"group\". Default is                \"medspacy_spans\".            apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures                the section header is considered its own sentence.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_sectionizer\",\n    rules: Optional[str] = \"default\",\n    language_code: str = 'en',\n    max_section_length: Optional[int] = None,\n    phrase_matcher_attr: str = \"LOWER\",\n    require_start_line: bool = False,\n    require_end_line: bool = False,\n    newline_pattern: str = r\"[\\n\\r]+[\\s]*$\",\n    input_span_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n    span_attrs: Union[\n        Literal[\"default\"], Dict[str, Dict[str, Any]], None\n    ] = \"default\",\n    apply_sentence_boundary: bool = False,\n):\n    \"\"\"\n    Create a new Sectionizer component.\n\n    Args:\n        nlp: A SpaCy Language object.\n        name: The name of the component.\n        rules: The rules to load. Default is \"default\", loads rules packaged with medspaCy that are derived from\n            SecTag, MIMIC-III, and practical refinement at the US Department of Veterans Affairs. If None, no rules\n            are loaded. Otherwise, must be a path to a json file containing rules. Add SectionRules directly through\n            `Sectionizer.add`.\n        language_code: Language code to use (ISO code) as a default for loading resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        max_section_length: Optional argument specifying the maximum number of tokens following a section header\n            which can be included in a section body. This can be useful if you think your section rules are\n            incomplete and want to prevent sections from running too long in the note. Default is None, meaning that\n            the scope of a section will be until either the next section header or the end of the document.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        require_start_line: Optionally require a section header to start on a new line. Default False.\n        require_end_line: Optionally require a section header to end with a new line. Default False.\n        newline_pattern: Regular expression to match the new line either preceding or following a header\n            if either require_start_line or require_end_line are True. Default is r\"[\\n\\r]+[\\s]*$\"\n        span_attrs: The optional span attributes to modify. Default option \"default\" uses attributes in\n            `DEFAULT_ATTRIBUTES`. If a dictionary of custom attributes, format is a dictionary mapping section\n            categories to a dictionary containing the attribute name and the value to set the attribute to when a\n            span is contained in a section of that category. Custom attributes must be assigned with\n            `Span.set_extension` before creating the Sectionizer. If None, sectionizer will not modify span\n            attributes.\n        input_span_type: \"ents\" or \"group\". Where to look for spans when modifying attributes of spans\n            contained in a section if `span_attrs` is not None. \"ents\" will modify attributes of spans in doc.ents.\n            \"group\" will modify attributes of spans in the span group specified by `span_group_name`.\n        span_group_name: The name of the span group used when `input_span_type` is \"group\". Default is\n            \"medspacy_spans\".\n        apply_sentence_boundary: Optionally end sentence before and after section header boundary. This ensures\n            the section header is considered its own sentence.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self.max_section_length = max_section_length\n    self.require_start_line = require_start_line\n    self.require_end_line = require_end_line\n    self.newline_pattern = re.compile(newline_pattern)\n    self.assertion_attributes_mapping = None\n    self._parent_sections = {}\n    self._parent_required = {}\n    self._input_span_type = input_span_type\n    self._span_group_name = span_group_name\n    self._apply_sentence_boundary = apply_sentence_boundary\n\n    self.__matcher = MedspacyMatcher(\n        nlp, name=name, phrase_matcher_attr=phrase_matcher_attr\n    )\n\n    self.DEFAULT_RULES_FILEPATH = path.join(\n        Path(__file__).resolve().parents[2],\n        \"resources\",\n        language_code.lower(),\n        \"section_patterns.json\",\n    )\n\n    rule_path = None\n    if rules == \"default\":\n        rule_path = self.DEFAULT_RULES_FILEPATH\n    else:\n        rule_path = rules\n\n    if rule_path:\n        self.add(SectionRule.from_json(rule_path))\n\n    if span_attrs == \"default\":\n        self.assertion_attributes_mapping = DEFAULT_ATTRS\n        self.register_default_attributes()\n    elif span_attrs:\n        for _, attr_dict in span_attrs.items():\n            for attr_name in attr_dict.keys():\n                if not Span.has_extension(attr_name):\n                    raise ValueError(\n                        f\"Custom extension {attr_name} has not been set. Please ensure Span.set_extension is \"\n                        f\"called for your pipeline's custom extensions.\"\n                    )\n        self.assertion_attributes_mapping = span_attrs\n</code></pre>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.add","title":"<code>add(rules)</code>","text":"<p>Adds SectionRules to the Sectionizer.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <p>A single SectionRule or a collection of SectionRules to add to the Sectionizer.</p> required Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def add(self, rules):\n    \"\"\"\n    Adds SectionRules to the Sectionizer.\n\n    Args:\n        rules: A single SectionRule or a collection of SectionRules to add to the Sectionizer.\n    \"\"\"\n    if isinstance(rules, SectionRule):\n        rules = [rules]\n\n    for rule in rules:\n        if not isinstance(rule, SectionRule):\n            raise TypeError(\"Rules must be type SectionRule, not\", type(rule))\n\n    self.__matcher.add(rules)\n\n    for rule in rules:\n        name = rule.category\n        parents = rule.parents\n        parent_required = rule.parent_required\n        if parents:\n            if name in self._parent_sections.keys():\n                warnings.warn(\n                    f\"Duplicate section title {name}. Merging parents. \"\n                    f\"If this is not intended, please specify distinct titles.\",\n                    RuntimeWarning,\n                )\n                self._parent_sections[name].update(parents)\n            else:\n                self._parent_sections[name] = set(parents)\n\n        if (\n            name in self._parent_required.keys()\n            and self._parent_required[name] != parent_required\n        ):\n            warnings.warn(\n                f\"Duplicate section title {name} has different parent_required option. \"\n                f\"Setting parent_required to False.\",\n                RuntimeWarning,\n            )\n            self._parent_required[name] = False\n        else:\n            self._parent_required[name] = parent_required\n</code></pre>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.filter_end_lines","title":"<code>filter_end_lines(doc, matches)</code>","text":"<p>Filter a list of matches to only contain spans where the start token is followed by a new line.</p> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples (match_id, start, end) that meet the filter criteria.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def filter_end_lines(\n    self, doc: Doc, matches: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Filter a list of matches to only contain spans where the start token is followed by a new line.\n\n    Returns:\n        A list of match tuples (match_id, start, end) that meet the filter criteria.\n    \"\"\"\n    return [\n        m for m in matches if util.is_end_line(m[2] - 1, doc, self.newline_pattern)\n    ]\n</code></pre>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.filter_start_lines","title":"<code>filter_start_lines(doc, matches)</code>","text":"<p>Filter a list of matches to only contain spans where the start token is the beginning of a new line.</p> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int]]</code> <p>A list of match tuples (match_id, start, end) that meet the filter criteria.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def filter_start_lines(\n    self, doc: Doc, matches: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Filter a list of matches to only contain spans where the start token is the beginning of a new line.\n\n    Returns:\n        A list of match tuples (match_id, start, end) that meet the filter criteria.\n    \"\"\"\n    return [\n        m for m in matches if util.is_start_line(m[1], doc, self.newline_pattern)\n    ]\n</code></pre>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.register_default_attributes","title":"<code>register_default_attributes()</code>  <code>classmethod</code>","text":"<p>Register the default values for the Span attributes defined in <code>DEFAULT_ATTRIBUTES</code>.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>@classmethod\ndef register_default_attributes(cls):\n    \"\"\"\n    Register the default values for the Span attributes defined in `DEFAULT_ATTRIBUTES`.\n    \"\"\"\n    for attr_name in [\n        \"is_negated\",\n        \"is_uncertain\",\n        \"is_historical\",\n        \"is_hypothetical\",\n        \"is_family\",\n    ]:\n        try:\n            Span.set_extension(attr_name, default=False)\n        except ValueError:  # Extension already set\n            pass\n</code></pre>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.set_assertion_attributes","title":"<code>set_assertion_attributes(spans)</code>","text":"<p>Add Span-level attributes to entities based on which section they occur in.</p> <p>Parameters:</p> Name Type Description Default <code>spans</code> <code>Iterable[Span]</code> <p>the spans to modify.</p> required Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def set_assertion_attributes(self, spans: Iterable[Span]):\n    \"\"\"\n    Add Span-level attributes to entities based on which section they occur in.\n\n    Args:\n        spans: the spans to modify.\n    \"\"\"\n    for span in spans:\n        if (\n            span._.section\n            and span._.section.category in self.assertion_attributes_mapping\n        ):\n            attr_dict = self.assertion_attributes_mapping[span._.section.category]\n            for (attr_name, attr_value) in attr_dict.items():\n                setattr(span._, attr_name, attr_value)\n</code></pre>"},{"location":"reference/medspacy/section_detection/sectionizer/#medspacy.section_detection.sectionizer.Sectionizer.set_parent_sections","title":"<code>set_parent_sections(sections)</code>","text":"<p>Determine the legal parent-child section relationships from the list of in-order sections of a document and the possible parents of each section as specified during direction creation.</p> <p>Parameters:</p> Name Type Description Default <code>sections</code> <code>List[Tuple[int, int, int]]</code> <p>a list of spacy match tuples found in the doc</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int, int, int]]</code> <p>A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input</p> <code>List[Tuple[int, int, int, int]]</code> <p>and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a</p> <code>List[Tuple[int, int, int, int]]</code> <p>smaller list than the input due to pruning with <code>parent_required</code>.</p> Source code in <code>medspacy/section_detection/sectionizer.py</code> <pre><code>def set_parent_sections(\n    self, sections: List[Tuple[int, int, int]]\n) -&gt; List[Tuple[int, int, int, int]]:\n    \"\"\"\n    Determine the legal parent-child section relationships from the list\n    of in-order sections of a document and the possible parents of each\n    section as specified during direction creation.\n\n    Args:\n        sections: a list of spacy match tuples found in the doc\n\n    Returns:\n        A list of tuples (match_id, start, end, parent_idx) where the first three indices are the same as the input\n        and the added parent_idx represents the index in the list that corresponds to the parent section. Might be a\n        smaller list than the input due to pruning with `parent_required`.\n    \"\"\"\n    sections_final = []\n    removed_sections = 0\n    for i, (match_id, start, end) in enumerate(sections):\n        name = self.__matcher.rule_map[self.nlp.vocab.strings[match_id]].category\n        required = self._parent_required[name]\n        i_a = i - removed_sections  # adjusted index for removed values\n        if required and i_a == 0:\n            removed_sections += 1\n            continue\n        elif i_a == 0 or name not in self._parent_sections.keys():\n            sections_final.append((match_id, start, end, None))\n        else:\n            parents = self._parent_sections[name]\n            identified_parent = None\n            for parent in parents:\n                # go backwards through the section \"tree\" until you hit a root or the start of the list\n                candidate = self.__matcher.rule_map[\n                    self.nlp.vocab.strings[sections_final[i_a - 1][0]]\n                ].category\n                candidates_parent_idx = sections_final[i_a - 1][3]\n                if candidates_parent_idx is not None:\n                    candidates_parent = self.__matcher.rule_map[\n                        self.nlp.vocab.strings[\n                            sections_final[candidates_parent_idx][0]\n                        ]\n                    ].category\n                else:\n                    candidates_parent = None\n                candidate_i = i_a - 1\n                while candidate:\n                    if candidate == parent:\n                        identified_parent = candidate_i\n                        candidate = None\n                    else:\n                        # if you are at the end of the list... no parent\n                        if candidate_i &lt; 1:\n                            candidate = None\n                            continue\n                        # if the current candidate has no parent... no parent exists\n                        if not candidates_parent:\n                            candidate = None\n                            continue\n                        # otherwise get the previous item in the list\n                        temp = self.__matcher.rule_map[\n                            self.nlp.vocab.strings[\n                                sections_final[candidate_i - 1][0]\n                            ]\n                        ].category\n                        temp_parent_idx = sections_final[candidate_i - 1][3]\n                        if temp_parent_idx is not None:\n                            temp_parent = self.__matcher.rule_map[\n                                self.nlp.vocab.strings[\n                                    sections_final[temp_parent_idx][0]\n                                ]\n                            ].category\n                        else:\n                            temp_parent = None\n                        # if the previous item is the parent of the current item\n                        # OR if the previous item is a sibling of the current item\n                        # continue to search\n                        if (\n                            temp == candidates_parent\n                            or temp_parent == candidates_parent\n                        ):\n                            candidate = temp\n                            candidates_parent = temp_parent\n                            candidate_i -= 1\n                        # otherwise, there is no further tree traversal\n                        else:\n                            candidate = None\n\n            # if a parent is required, then add\n            if identified_parent is not None or not required:\n                # if the parent is identified, add section\n                # if the parent is not required, add section\n                # if parent is not identified and required, do not add the section\n                sections_final.append((match_id, start, end, identified_parent))\n            else:\n                removed_sections += 1\n    return sections_final\n</code></pre>"},{"location":"reference/medspacy/section_detection/util/","title":"medspacy.section_detection.util","text":"<p>This module will contain helper functions and classes for common clinical processing tasks which will be used in medspaCy's sectionizer.</p>"},{"location":"reference/medspacy/section_detection/util/#medspacy.section_detection.util.is_end_line","title":"<code>is_end_line(idx, doc, pattern)</code>","text":"<p>Check whether the token at idx occurs at the end of the line.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The token index to check.</p> required <code>doc</code> <code>Doc</code> <p>The doc to check in.</p> required <code>pattern</code> <code>Pattern</code> <p>The newline pattern to check with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the token occurs at the end of a line.</p> Source code in <code>medspacy/section_detection/util.py</code> <pre><code>def is_end_line(idx: int, doc: Doc, pattern: re.Pattern) -&gt; bool:\n    \"\"\"\n    Check whether the token at idx occurs at the end of the line.\n\n    Args:\n        idx: The token index to check.\n        doc: The doc to check in.\n        pattern: The newline pattern to check with.\n\n    Returns:\n        Whether the token occurs at the end of a line.\n    \"\"\"\n    # If it's the end of the doc, return True\n    if idx == len(doc) - 1:\n        return True\n\n    # Check if either the token has trailing newlines,\n    # or if the next token is a newline\n    text = doc[idx].text_with_ws\n    if pattern.search(text) is not None:\n        return True\n    following_text = doc[idx + 1].text_with_ws\n    return pattern.search(following_text) is not None\n</code></pre>"},{"location":"reference/medspacy/section_detection/util/#medspacy.section_detection.util.is_start_line","title":"<code>is_start_line(idx, doc, pattern)</code>","text":"<p>Check whether the token at idx occurs at the start of the line.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The token index to check.</p> required <code>doc</code> <code>Doc</code> <p>The doc to check in.</p> required <code>pattern</code> <code>Pattern</code> <p>The newline pattern to check with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the token occurs at the start of a line.</p> Source code in <code>medspacy/section_detection/util.py</code> <pre><code>def is_start_line(idx: int, doc: Doc, pattern: re.Pattern) -&gt; bool:\n    \"\"\"\n    Check whether the token at idx occurs at the start of the line.\n\n    Args:\n        idx: The token index to check.\n        doc: The doc to check in.\n        pattern: The newline pattern to check with.\n\n    Returns:\n        Whether the token occurs at the start of a line.\n    \"\"\"\n    # If it's the start of the doc, return True\n    if idx == 0:\n        return True\n    # Otherwise, check if the preceding token ends with newlines\n    preceding_text = doc[idx - 1].text_with_ws\n    return pattern.search(preceding_text) is not None\n</code></pre>"},{"location":"reference/medspacy/sentence_splitting/","title":"medspacy.sentence_splitting","text":""},{"location":"reference/medspacy/sentence_splitting/#medspacy.sentence_splitting.PySBDSentenceSplitter","title":"<code>PySBDSentenceSplitter</code>","text":"Source code in <code>medspacy/sentence_splitting.py</code> <pre><code>@Language.factory(\"medspacy_pysbd\")\nclass PySBDSentenceSplitter:\n    def __init__(self, name, nlp, clean=False):\n        self.name = name\n        self.nlp = nlp\n        self.seg = pysbd.Segmenter(language=\"en\", clean=clean, char_span=True)\n\n    def __call__(self, doc):\n        \"\"\"\n        Spacy component based on: https://github.com/nipunsadvilkar/pySBD improved to work with spacy 3.0\n        \"\"\"\n        sents_char_spans = self.seg.segment(doc.text_with_ws)\n        start_token_ids = [sent.start for sent in sents_char_spans]\n        for token in doc:\n            token.is_sent_start = True if token.idx in start_token_ids else False\n        return doc\n</code></pre>"},{"location":"reference/medspacy/sentence_splitting/#medspacy.sentence_splitting.PySBDSentenceSplitter.__call__","title":"<code>__call__(doc)</code>","text":"<p>Spacy component based on: https://github.com/nipunsadvilkar/pySBD improved to work with spacy 3.0</p> Source code in <code>medspacy/sentence_splitting.py</code> <pre><code>def __call__(self, doc):\n    \"\"\"\n    Spacy component based on: https://github.com/nipunsadvilkar/pySBD improved to work with spacy 3.0\n    \"\"\"\n    sents_char_spans = self.seg.segment(doc.text_with_ws)\n    start_token_ids = [sent.start for sent in sents_char_spans]\n    for token in doc:\n        token.is_sent_start = True if token.idx in start_token_ids else False\n    return doc\n</code></pre>"},{"location":"reference/medspacy/target_matcher/","title":"medspacy.target_matcher","text":""},{"location":"reference/medspacy/target_matcher/concept_tagger/","title":"medspacy.target_matcher.concept_tagger","text":""},{"location":"reference/medspacy/target_matcher/concept_tagger/#medspacy.target_matcher.concept_tagger.ConceptTagger","title":"<code>ConceptTagger</code>","text":"<p>ConceptTagger is a component for setting an attribute on tokens contained in spans extracted by TargetRules. This can be used for tasks such as semantic labeling or for normalizing tokens, making downstream extraction simpler.</p> <p>A common use case is when a single concept can have many synonyms or variants and downstream rules would be simplified by matching on a unified token tag for those synonyms rather than including the entire synonym list in each downstream rule.</p> Source code in <code>medspacy/target_matcher/concept_tagger.py</code> <pre><code>@Language.factory(\"medspacy_concept_tagger\")\nclass ConceptTagger:\n    \"\"\"ConceptTagger is a component for setting an attribute on tokens contained in spans extracted by TargetRules. This\n    can be used for tasks such as semantic labeling or for normalizing tokens, making downstream extraction simpler.\n\n    A common use case is when a single concept can have many synonyms or variants and downstream rules would be\n    simplified by matching on a unified token tag for those synonyms rather than including the entire synonym list in\n    each downstream rule.\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_concept_tagger\",\n        attr_name: str = \"concept_tag\",\n    ):\n        \"\"\"\n        Creates a new ConceptTagger.\n\n        Args:\n            nlp: A spaCy Language model.\n            name: The name of the ConceptTagger component. Must be a valid python variable name.\n            attr_name: The name of the attribute to set to tokens.\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self._attr_name = attr_name\n        self.__matcher = MedspacyMatcher(nlp, name=name)\n\n        # If the token attribute hasn't been registered, add it now\n        # If it has already been set, then we can pass.\n        # This will happen, for example, if you've already instantiated\n        # the ConceptTagger and it registered the attribute.\n        if not Token.has_extension(attr_name):\n            Token.set_extension(attr_name, default=\"\")\n\n    @property\n    def attr_name(self) -&gt; str:\n        \"\"\"\n        The name of the attribute that will be set on each matched token.\n\n        Returns:\n            The attribute name.\n        \"\"\"\n        return self._attr_name\n\n    def add(self, rules: Union[TargetRule, List[TargetRule]]):\n        \"\"\"\n        Adds a single TargetRule or a list of TargetRules to the ConceptTagger.\n\n        Args:\n            rules: A single TargetRule or a collection of TargetRules.\n        \"\"\"\n        self.__matcher.add(rules)\n\n    def __call__(self, doc: Doc) -&gt; Doc:\n        \"\"\"\n        Call ConceptTagger on a doc. Matches spans and assigns attributes to all tokens contained in those spans, but\n        does not preserve the spans themselves.\n\n        Args:\n            doc: The spaCy Doc to process.\n\n        Returns:\n            The spaCy Doc processed.\n        \"\"\"\n        matches = self.__matcher(doc)\n        for (rule_id, start, end) in matches:\n            rule = self.__matcher.rule_map[self.nlp.vocab.strings[rule_id]]\n            for i in range(start, end):\n                setattr(doc[i]._, self.attr_name, rule.category)\n\n        return doc\n</code></pre>"},{"location":"reference/medspacy/target_matcher/concept_tagger/#medspacy.target_matcher.concept_tagger.ConceptTagger.attr_name","title":"<code>attr_name</code>  <code>property</code>","text":"<p>The name of the attribute that will be set on each matched token.</p> <p>Returns:</p> Type Description <code>str</code> <p>The attribute name.</p>"},{"location":"reference/medspacy/target_matcher/concept_tagger/#medspacy.target_matcher.concept_tagger.ConceptTagger.__call__","title":"<code>__call__(doc)</code>","text":"<p>Call ConceptTagger on a doc. Matches spans and assigns attributes to all tokens contained in those spans, but does not preserve the spans themselves.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy Doc to process.</p> required <p>Returns:</p> Type Description <code>Doc</code> <p>The spaCy Doc processed.</p> Source code in <code>medspacy/target_matcher/concept_tagger.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; Doc:\n    \"\"\"\n    Call ConceptTagger on a doc. Matches spans and assigns attributes to all tokens contained in those spans, but\n    does not preserve the spans themselves.\n\n    Args:\n        doc: The spaCy Doc to process.\n\n    Returns:\n        The spaCy Doc processed.\n    \"\"\"\n    matches = self.__matcher(doc)\n    for (rule_id, start, end) in matches:\n        rule = self.__matcher.rule_map[self.nlp.vocab.strings[rule_id]]\n        for i in range(start, end):\n            setattr(doc[i]._, self.attr_name, rule.category)\n\n    return doc\n</code></pre>"},{"location":"reference/medspacy/target_matcher/concept_tagger/#medspacy.target_matcher.concept_tagger.ConceptTagger.__init__","title":"<code>__init__(nlp, name='medspacy_concept_tagger', attr_name='concept_tag')</code>","text":"<p>Creates a new ConceptTagger.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A spaCy Language model.</p> required <code>name</code> <code>str</code> <p>The name of the ConceptTagger component. Must be a valid python variable name.</p> <code>'medspacy_concept_tagger'</code> <code>attr_name</code> <code>str</code> <p>The name of the attribute to set to tokens.</p> <code>'concept_tag'</code> Source code in <code>medspacy/target_matcher/concept_tagger.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_concept_tagger\",\n    attr_name: str = \"concept_tag\",\n):\n    \"\"\"\n    Creates a new ConceptTagger.\n\n    Args:\n        nlp: A spaCy Language model.\n        name: The name of the ConceptTagger component. Must be a valid python variable name.\n        attr_name: The name of the attribute to set to tokens.\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self._attr_name = attr_name\n    self.__matcher = MedspacyMatcher(nlp, name=name)\n\n    # If the token attribute hasn't been registered, add it now\n    # If it has already been set, then we can pass.\n    # This will happen, for example, if you've already instantiated\n    # the ConceptTagger and it registered the attribute.\n    if not Token.has_extension(attr_name):\n        Token.set_extension(attr_name, default=\"\")\n</code></pre>"},{"location":"reference/medspacy/target_matcher/concept_tagger/#medspacy.target_matcher.concept_tagger.ConceptTagger.add","title":"<code>add(rules)</code>","text":"<p>Adds a single TargetRule or a list of TargetRules to the ConceptTagger.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[TargetRule, List[TargetRule]]</code> <p>A single TargetRule or a collection of TargetRules.</p> required Source code in <code>medspacy/target_matcher/concept_tagger.py</code> <pre><code>def add(self, rules: Union[TargetRule, List[TargetRule]]):\n    \"\"\"\n    Adds a single TargetRule or a list of TargetRules to the ConceptTagger.\n\n    Args:\n        rules: A single TargetRule or a collection of TargetRules.\n    \"\"\"\n    self.__matcher.add(rules)\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_matcher/","title":"medspacy.target_matcher.target_matcher","text":""},{"location":"reference/medspacy/target_matcher/target_matcher/#medspacy.target_matcher.target_matcher.TargetMatcher","title":"<code>TargetMatcher</code>","text":"<p>TargetMatcher is a component for advanced direction-based text extraction. Rules are defined using <code>medspacy.target_matcher.TargetRule</code>.</p> <p>A <code>TargetMatcher</code> will use the added <code>TargetRule</code> objects to identify matches in the text and apply labels or modify attributes. It will either modify the input spaCy <code>Doc</code> with the result or return the spans as a list.</p> <p>In addition to extracting spans of text and setting labels, TargetRules can also define setting custom attributes and metadata. Additionally, each resulting span has an attribute span._.target_rule which maps a span to the TargetRule which set it.</p> Source code in <code>medspacy/target_matcher/target_matcher.py</code> <pre><code>@Language.factory(\"medspacy_target_matcher\")\nclass TargetMatcher:\n    \"\"\"\n    TargetMatcher is a component for advanced direction-based text extraction. Rules are defined using\n    `medspacy.target_matcher.TargetRule`.\n\n    A `TargetMatcher` will use the added `TargetRule` objects to identify matches in the text and apply labels or modify\n    attributes. It will either modify the input spaCy `Doc` with the result or return the spans as a list.\n\n    In addition to extracting spans of text and setting labels, TargetRules can also define setting custom attributes\n    and metadata. Additionally, each resulting span has an attribute span._.target_rule which maps a span to the\n    TargetRule which set it.\n    \"\"\"\n\n    def __init__(\n        self,\n        nlp: Language,\n        name: str = \"medspacy_target_matcher\",\n        rules: Optional[str] = None,\n        phrase_matcher_attr: str = \"LOWER\",\n        result_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n        span_group_name: str = \"medspacy_spans\",\n        prune: bool = True\n    ):\n        \"\"\"\n        Creates a new TargetMatcher.\n\n        Args:\n            nlp: A spaCy Language model.\n            name: The name of the TargetMatcher component\n            rules: An optional filepath containing a JSON of TargetRules. If None, then no rules will be added. Default\n                None.\n            phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n                is 'LOWER'.\n            result_type: \"ents\" (default), \"group\", or None. Determines where TargetMatcher will put the matched spans.\n                \"ents\" will add spans to doc.ents and add to any existing entities. If conflicts appear, existing\n                entities will take precedence. \"group\" will add spans to doc.spans under the specified group name. None\n                will return the list of spans rather than saving to the Doc.\n            span_group_name: The name of the span group used to store results when result_type is \"group\". Default is\n                \"medspacy_spans\".\n        \"\"\"\n        self.nlp = nlp\n        self.name = name\n        self._result_type = result_type\n        self._span_group_name = span_group_name\n        self._prune = prune\n\n        if rules:\n            self.add(TargetRule.from_json(rules))\n\n        self.__matcher = MedspacyMatcher(\n            nlp, name=name, phrase_matcher_attr=phrase_matcher_attr, prune=self._prune\n        )\n\n    @property\n    def rules(self) -&gt; List[TargetRule]:\n        \"\"\"\n        Gets the list of TargetRules for the TargetMatcher.\n\n        Returns:\n            A list of TargetRules.\n        \"\"\"\n        return self.__matcher.rules\n\n    @property\n    def labels(self) -&gt; Set[str]:\n        \"\"\"\n        Gets the list of labels for the TargetMatcher. Based on rules added to the TargetMatcher.\n\n        Returns:\n            A list of all labels that the TargetMatcher can produce.\n        \"\"\"\n        return self.__matcher.labels\n\n    @property\n    def result_type(self) -&gt; Union[str, None]:\n        \"\"\"\n        The result type of the TargetMatcher. \"ents\" indicates that calling TargetMatcher will store the results in\n        doc.ents, \"group\" indicates that the results will be stored in the span group indicated by `span_group_name`,\n        and None indicates that spans will be returned in a list.\n\n        Returns:\n            The result type string.\n        \"\"\"\n        return self._result_type\n\n    @result_type.setter\n    def result_type(self, result_type: Literal[\"ents\", \"group\"]):\n        if not (not result_type or result_type == \"group\" or result_type == \"ents\"):\n            raise ValueError('result_type must be \"ents\", \"group\" or None.')\n        self._result_type = result_type\n\n    @property\n    def span_group_name(self) -&gt; str:\n        \"\"\"\n        The name of the span group used by this component. If `result_type` is \"group\", calling this component will\n        place results in the span group with this name.\n\n        Returns:\n            The span group name.\n        \"\"\"\n        return self._span_group_name\n\n    @span_group_name.setter\n    def span_group_name(self, name: str):\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Span group name must be a string.\")\n        self._span_group_name = name\n\n    def add(self, rules: Union[TargetRule, Iterable[TargetRule]]):\n        \"\"\"\n        Adds a single TargetRule or a list of TargetRules to the TargetMatcher.\n\n        Args:\n            rules: A single TargetRule or a collection of TargetRules.\n        \"\"\"\n        if isinstance(rules, TargetRule):\n            rules = [rules]\n        for rule in rules:\n            if not isinstance(rule, TargetRule):\n                raise TypeError(\"Rules must be TargetRule, not\", type(rule))\n        self.__matcher.add(rules)\n\n    def __call__(self, doc: Doc) -&gt; Union[Doc, List[Span]]:\n        \"\"\"\n        Calls TargetMatcher on a Doc. By default and when `result_type` is \"ents\", adds results to doc.ents. If\n        `result_type` is \"group\", adds results to the span group specified by `span_group_name`. If `result_type` is\n        None, then returns a list of the matched Spans.\n\n        Args:\n            doc: The spaCy Doc to process.\n\n        Returns:\n            Returns a modified `doc` when `TargetMatcher.result_type` is \"ents\" or \"group\". Returns a list of\n            `Span` objects if `TargetMatcher.result_type` is None.\n        \"\"\"\n        matches = self.__matcher(doc)\n        spans = []\n        for rule_id, start, end in matches:\n            rule = self.__matcher.rule_map[self.nlp.vocab.strings[rule_id]]\n            span = Span(doc, start=start, end=end, label=rule.category)\n            span._.target_rule = rule\n            if rule.attributes is not None:\n                for attribute, value in rule.attributes.items():\n                    try:\n                        setattr(span._, attribute, value)\n                    except AttributeError as e:\n                        raise e\n            spans.append(span)\n\n        if not self.result_type:\n            return spans\n        elif self.result_type.lower() == \"ents\":\n            for span in spans:\n                try:\n                    doc.ents += (span,)\n                except ValueError:\n                    # spaCy will raise a value error if the token in span are already part of an entity (i.e., as part\n                    # of an upstream component). In that case, let the existing span supersede this one.\n                    warnings.warn(\n                        f'The result \"\"{span}\"\" conflicts with a pre-existing entity in doc.ents. This result has been '\n                        f\"skipped.\",\n                        RuntimeWarning,\n                    )\n            return doc\n        elif self.result_type.lower() == \"group\":\n            if self.span_group_name in doc.spans.keys():\n                doc.spans[self.span_group_name] += spans\n            else:\n                doc.spans[self.span_group_name] = spans\n            return doc\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_matcher/#medspacy.target_matcher.target_matcher.TargetMatcher.labels","title":"<code>labels</code>  <code>property</code>","text":"<p>Gets the list of labels for the TargetMatcher. Based on rules added to the TargetMatcher.</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>A list of all labels that the TargetMatcher can produce.</p>"},{"location":"reference/medspacy/target_matcher/target_matcher/#medspacy.target_matcher.target_matcher.TargetMatcher.result_type","title":"<code>result_type</code>  <code>property</code> <code>writable</code>","text":"<p>The result type of the TargetMatcher. \"ents\" indicates that calling TargetMatcher will store the results in doc.ents, \"group\" indicates that the results will be stored in the span group indicated by <code>span_group_name</code>, and None indicates that spans will be returned in a list.</p> <p>Returns:</p> Type Description <code>Union[str, None]</code> <p>The result type string.</p>"},{"location":"reference/medspacy/target_matcher/target_matcher/#medspacy.target_matcher.target_matcher.TargetMatcher.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Gets the list of TargetRules for the TargetMatcher.</p> <p>Returns:</p> Type Description <code>List[TargetRule]</code> <p>A list of TargetRules.</p>"},{"location":"reference/medspacy/target_matcher/target_matcher/#medspacy.target_matcher.target_matcher.TargetMatcher.span_group_name","title":"<code>span_group_name</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the span group used by this component. If <code>result_type</code> is \"group\", calling this component will place results in the span group with this name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The span group name.</p>"},{"location":"reference/medspacy/target_matcher/target_matcher/#medspacy.target_matcher.target_matcher.TargetMatcher.__call__","title":"<code>__call__(doc)</code>","text":"<p>Calls TargetMatcher on a Doc. By default and when <code>result_type</code> is \"ents\", adds results to doc.ents. If <code>result_type</code> is \"group\", adds results to the span group specified by <code>span_group_name</code>. If <code>result_type</code> is None, then returns a list of the matched Spans.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spaCy Doc to process.</p> required <p>Returns:</p> Type Description <code>Union[Doc, List[Span]]</code> <p>Returns a modified <code>doc</code> when <code>TargetMatcher.result_type</code> is \"ents\" or \"group\". Returns a list of</p> <code>Union[Doc, List[Span]]</code> <p><code>Span</code> objects if <code>TargetMatcher.result_type</code> is None.</p> Source code in <code>medspacy/target_matcher/target_matcher.py</code> <pre><code>def __call__(self, doc: Doc) -&gt; Union[Doc, List[Span]]:\n    \"\"\"\n    Calls TargetMatcher on a Doc. By default and when `result_type` is \"ents\", adds results to doc.ents. If\n    `result_type` is \"group\", adds results to the span group specified by `span_group_name`. If `result_type` is\n    None, then returns a list of the matched Spans.\n\n    Args:\n        doc: The spaCy Doc to process.\n\n    Returns:\n        Returns a modified `doc` when `TargetMatcher.result_type` is \"ents\" or \"group\". Returns a list of\n        `Span` objects if `TargetMatcher.result_type` is None.\n    \"\"\"\n    matches = self.__matcher(doc)\n    spans = []\n    for rule_id, start, end in matches:\n        rule = self.__matcher.rule_map[self.nlp.vocab.strings[rule_id]]\n        span = Span(doc, start=start, end=end, label=rule.category)\n        span._.target_rule = rule\n        if rule.attributes is not None:\n            for attribute, value in rule.attributes.items():\n                try:\n                    setattr(span._, attribute, value)\n                except AttributeError as e:\n                    raise e\n        spans.append(span)\n\n    if not self.result_type:\n        return spans\n    elif self.result_type.lower() == \"ents\":\n        for span in spans:\n            try:\n                doc.ents += (span,)\n            except ValueError:\n                # spaCy will raise a value error if the token in span are already part of an entity (i.e., as part\n                # of an upstream component). In that case, let the existing span supersede this one.\n                warnings.warn(\n                    f'The result \"\"{span}\"\" conflicts with a pre-existing entity in doc.ents. This result has been '\n                    f\"skipped.\",\n                    RuntimeWarning,\n                )\n        return doc\n    elif self.result_type.lower() == \"group\":\n        if self.span_group_name in doc.spans.keys():\n            doc.spans[self.span_group_name] += spans\n        else:\n            doc.spans[self.span_group_name] = spans\n        return doc\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_matcher/#medspacy.target_matcher.target_matcher.TargetMatcher.__init__","title":"<code>__init__(nlp, name='medspacy_target_matcher', rules=None, phrase_matcher_attr='LOWER', result_type='ents', span_group_name='medspacy_spans', prune=True)</code>","text":"<p>Creates a new TargetMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>A spaCy Language model.</p> required <code>name</code> <code>str</code> <p>The name of the TargetMatcher component</p> <code>'medspacy_target_matcher'</code> <code>rules</code> <code>Optional[str]</code> <p>An optional filepath containing a JSON of TargetRules. If None, then no rules will be added. Default None.</p> <code>None</code> <code>phrase_matcher_attr</code> <code>str</code> <p>The token attribute to use for PhraseMatcher for rules where <code>pattern</code> is None. Default is 'LOWER'.</p> <code>'LOWER'</code> <code>result_type</code> <code>Union[Literal['ents', 'group'], None]</code> <p>\"ents\" (default), \"group\", or None. Determines where TargetMatcher will put the matched spans. \"ents\" will add spans to doc.ents and add to any existing entities. If conflicts appear, existing entities will take precedence. \"group\" will add spans to doc.spans under the specified group name. None will return the list of spans rather than saving to the Doc.</p> <code>'ents'</code> <code>span_group_name</code> <code>str</code> <p>The name of the span group used to store results when result_type is \"group\". Default is \"medspacy_spans\".</p> <code>'medspacy_spans'</code> Source code in <code>medspacy/target_matcher/target_matcher.py</code> <pre><code>def __init__(\n    self,\n    nlp: Language,\n    name: str = \"medspacy_target_matcher\",\n    rules: Optional[str] = None,\n    phrase_matcher_attr: str = \"LOWER\",\n    result_type: Union[Literal[\"ents\", \"group\"], None] = \"ents\",\n    span_group_name: str = \"medspacy_spans\",\n    prune: bool = True\n):\n    \"\"\"\n    Creates a new TargetMatcher.\n\n    Args:\n        nlp: A spaCy Language model.\n        name: The name of the TargetMatcher component\n        rules: An optional filepath containing a JSON of TargetRules. If None, then no rules will be added. Default\n            None.\n        phrase_matcher_attr: The token attribute to use for PhraseMatcher for rules where `pattern` is None. Default\n            is 'LOWER'.\n        result_type: \"ents\" (default), \"group\", or None. Determines where TargetMatcher will put the matched spans.\n            \"ents\" will add spans to doc.ents and add to any existing entities. If conflicts appear, existing\n            entities will take precedence. \"group\" will add spans to doc.spans under the specified group name. None\n            will return the list of spans rather than saving to the Doc.\n        span_group_name: The name of the span group used to store results when result_type is \"group\". Default is\n            \"medspacy_spans\".\n    \"\"\"\n    self.nlp = nlp\n    self.name = name\n    self._result_type = result_type\n    self._span_group_name = span_group_name\n    self._prune = prune\n\n    if rules:\n        self.add(TargetRule.from_json(rules))\n\n    self.__matcher = MedspacyMatcher(\n        nlp, name=name, phrase_matcher_attr=phrase_matcher_attr, prune=self._prune\n    )\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_matcher/#medspacy.target_matcher.target_matcher.TargetMatcher.add","title":"<code>add(rules)</code>","text":"<p>Adds a single TargetRule or a list of TargetRules to the TargetMatcher.</p> <p>Parameters:</p> Name Type Description Default <code>rules</code> <code>Union[TargetRule, Iterable[TargetRule]]</code> <p>A single TargetRule or a collection of TargetRules.</p> required Source code in <code>medspacy/target_matcher/target_matcher.py</code> <pre><code>def add(self, rules: Union[TargetRule, Iterable[TargetRule]]):\n    \"\"\"\n    Adds a single TargetRule or a list of TargetRules to the TargetMatcher.\n\n    Args:\n        rules: A single TargetRule or a collection of TargetRules.\n    \"\"\"\n    if isinstance(rules, TargetRule):\n        rules = [rules]\n    for rule in rules:\n        if not isinstance(rule, TargetRule):\n            raise TypeError(\"Rules must be TargetRule, not\", type(rule))\n    self.__matcher.add(rules)\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_rule/","title":"medspacy.target_matcher.target_rule","text":""},{"location":"reference/medspacy/target_matcher/target_rule/#medspacy.target_matcher.target_rule.TargetRule","title":"<code>TargetRule</code>","text":"<p>               Bases: <code>BaseRule</code></p> <p>TargetRule defines rules for extracting entities from text using the TargetMatcher.</p> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>class TargetRule(BaseRule):\n    \"\"\"\n    TargetRule defines rules for extracting entities from text using the TargetMatcher.\n    \"\"\"\n\n    _ALLOWED_KEYS = {\n        \"literal\",\n        \"pattern\",\n        \"category\",\n        \"metadata\",\n        \"attributes\",\n    }\n\n    def __init__(\n        self,\n        literal: str,\n        category: str,\n        pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n        on_match: Optional[\n            Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n        ] = None,\n        attributes: Optional[Dict[str, Any]] = None,\n        metadata: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"\n        Creates a new TargetRule.\n\n        Args:\n            literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n                matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n                but can be used as a reference as the rule name.\n            category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n            pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n                token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n                RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n                https://spacy.io/usage/rule-based-matching.\n            on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n                matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n            attributes: Optional custom attribute names to set for a Span matched by the direction. These attribute\n                names are stored under Span._.[attribute_name]. For example, if `attributes={'is_historical':True}`,\n                then any spans matched by this direction will have span._.is_historical = True\n            metadata: Optional dictionary of any extra metadata.\n        \"\"\"\n        super().__init__(literal, category, pattern, on_match, metadata)\n        self.attributes = attributes\n        self._rule_id = None\n\n    @classmethod\n    def from_json(cls, filepath: str) -&gt; List[TargetRule]:\n        \"\"\"Read in a lexicon of modifiers from a JSON file.\n\n        Args:\n            filepath: the .json file containing modifier rules\n\n        Returns:\n            context_item: A list of ConTextRule objects.\n\n        Raises:\n            KeyError: If the dictionary contains any keys other than\n                those accepted by ConTextRule.__init__\n        \"\"\"\n        import json\n\n        with open(filepath) as file:\n            target_data = json.load(file)\n        target_rules = []\n        for data in target_data[\"target_rules\"]:\n            target_rules.append(TargetRule.from_dict(data))\n        return target_rules\n\n    @classmethod\n    def from_dict(cls, rule_dict: Dict) -&gt; TargetRule:\n        \"\"\"Reads a dictionary into a ConTextRule. Used when reading from a json file.\n\n        Args:\n            rule_dict: the dictionary to convert\n\n        Returns:\n            The ConTextRule created from the dictionary\n\n        Raises:\n            ValueError: if the json is invalid\n        \"\"\"\n        keys = set(rule_dict.keys())\n        invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n        if invalid_keys:\n            msg = (\n                \"JSON object contains invalid keys: {0}.\\n\"\n                \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n            )\n            raise ValueError(msg)\n        rule = TargetRule(**rule_dict)\n        return rule\n\n    @classmethod\n    def to_json(cls, target_rules: List[TargetRule], filepath: str):\n        \"\"\"Writes ConTextItems to a json file.\n\n        Args:\n            target_rules: a list of TargetRules that will be written to a file.\n            filepath: the .json file to contain modifier rules\n        \"\"\"\n        import json\n\n        data = {\"target_rules\": [rule.to_dict() for rule in target_rules]}\n        with open(filepath, \"w\") as file:\n            json.dump(data, file, indent=4)\n\n    def to_dict(self):\n        \"\"\"Converts TargetRules to a python dictionary. Used when writing target rules to a json file.\n\n        Returns:\n            The dictionary containing the TargetRule info.\n        \"\"\"\n        rule_dict = {}\n        for key in self._ALLOWED_KEYS:\n            value = self.__dict__.get(key)\n            if value is not None:\n                rule_dict[key] = value\n        return rule_dict\n\n    def __repr__(self):\n        return f\"\"\"TargetRule(literal=\"{self.literal}\", category=\"{self.category}\", pattern={self.pattern}, attributes={self.attributes}, on_match={self.on_match})\"\"\"\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_rule/#medspacy.target_matcher.target_rule.TargetRule.__init__","title":"<code>__init__(literal, category, pattern=None, on_match=None, attributes=None, metadata=None)</code>","text":"<p>Creates a new TargetRule.</p> <p>Parameters:</p> Name Type Description Default <code>literal</code> <code>str</code> <p>The string representation of a concept. If <code>pattern</code> is None, this string will be lower-cased and matched to the lower-case string. If <code>pattern</code> is not None, this argument will not be used for matching but can be used as a reference as the rule name.</p> required <code>category</code> <code>str</code> <p>The semantic class of the matched span. This corresponds to the <code>label_</code> attribute of an entity.</p> required <code>pattern</code> <code>Optional[Union[List[Dict[str, str]], str]]</code> <p>A list or string to use as a spaCy pattern rather than <code>literal</code>. If a list, will use spaCy token-based pattern matching to match using token attributes. If a string, will use medspaCy's RegexMatcher. If None, will use <code>literal</code> as the pattern for phrase matching. For more information, see https://spacy.io/usage/rule-based-matching.</p> <code>None</code> <code>on_match</code> <code>Optional[Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]]</code> <p>An optional callback function or other callable which takes 4 arguments: <code>(matcher, doc, i, matches)</code>. For more information, see https://spacy.io/usage/rule-based-matching#on_match</p> <code>None</code> <code>attributes</code> <code>Optional[Dict[str, Any]]</code> <p>Optional custom attribute names to set for a Span matched by the direction. These attribute names are stored under Span..[attribute_name]. For example, if <code>attributes={'is_historical':True}</code>, then any spans matched by this direction will have span..is_historical = True</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[Any, Any]]</code> <p>Optional dictionary of any extra metadata.</p> <code>None</code> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>def __init__(\n    self,\n    literal: str,\n    category: str,\n    pattern: Optional[Union[List[Dict[str, str]], str]] = None,\n    on_match: Optional[\n        Callable[[Matcher, Doc, int, List[Tuple[int, int, int]]], Any]\n    ] = None,\n    attributes: Optional[Dict[str, Any]] = None,\n    metadata: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"\n    Creates a new TargetRule.\n\n    Args:\n        literal: The string representation of a concept. If `pattern` is None, this string will be lower-cased and\n            matched to the lower-case string. If `pattern` is not None, this argument will not be used for matching\n            but can be used as a reference as the rule name.\n        category: The semantic class of the matched span. This corresponds to the `label_` attribute of an entity.\n        pattern: A list or string to use as a spaCy pattern rather than `literal`. If a list, will use spaCy\n            token-based pattern matching to match using token attributes. If a string, will use medspaCy's\n            RegexMatcher. If None, will use `literal` as the pattern for phrase matching. For more information, see\n            https://spacy.io/usage/rule-based-matching.\n        on_match: An optional callback function or other callable which takes 4 arguments: `(matcher, doc, i,\n            matches)`. For more information, see https://spacy.io/usage/rule-based-matching#on_match\n        attributes: Optional custom attribute names to set for a Span matched by the direction. These attribute\n            names are stored under Span._.[attribute_name]. For example, if `attributes={'is_historical':True}`,\n            then any spans matched by this direction will have span._.is_historical = True\n        metadata: Optional dictionary of any extra metadata.\n    \"\"\"\n    super().__init__(literal, category, pattern, on_match, metadata)\n    self.attributes = attributes\n    self._rule_id = None\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_rule/#medspacy.target_matcher.target_rule.TargetRule.from_dict","title":"<code>from_dict(rule_dict)</code>  <code>classmethod</code>","text":"<p>Reads a dictionary into a ConTextRule. Used when reading from a json file.</p> <p>Parameters:</p> Name Type Description Default <code>rule_dict</code> <code>Dict</code> <p>the dictionary to convert</p> required <p>Returns:</p> Type Description <code>TargetRule</code> <p>The ConTextRule created from the dictionary</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the json is invalid</p> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>@classmethod\ndef from_dict(cls, rule_dict: Dict) -&gt; TargetRule:\n    \"\"\"Reads a dictionary into a ConTextRule. Used when reading from a json file.\n\n    Args:\n        rule_dict: the dictionary to convert\n\n    Returns:\n        The ConTextRule created from the dictionary\n\n    Raises:\n        ValueError: if the json is invalid\n    \"\"\"\n    keys = set(rule_dict.keys())\n    invalid_keys = keys.difference(cls._ALLOWED_KEYS)\n    if invalid_keys:\n        msg = (\n            \"JSON object contains invalid keys: {0}.\\n\"\n            \"Must be one of: {1}\".format(invalid_keys, cls._ALLOWED_KEYS)\n        )\n        raise ValueError(msg)\n    rule = TargetRule(**rule_dict)\n    return rule\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_rule/#medspacy.target_matcher.target_rule.TargetRule.from_json","title":"<code>from_json(filepath)</code>  <code>classmethod</code>","text":"<p>Read in a lexicon of modifiers from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>the .json file containing modifier rules</p> required <p>Returns:</p> Name Type Description <code>context_item</code> <code>List[TargetRule]</code> <p>A list of ConTextRule objects.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the dictionary contains any keys other than those accepted by ConTextRule.init</p> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>@classmethod\ndef from_json(cls, filepath: str) -&gt; List[TargetRule]:\n    \"\"\"Read in a lexicon of modifiers from a JSON file.\n\n    Args:\n        filepath: the .json file containing modifier rules\n\n    Returns:\n        context_item: A list of ConTextRule objects.\n\n    Raises:\n        KeyError: If the dictionary contains any keys other than\n            those accepted by ConTextRule.__init__\n    \"\"\"\n    import json\n\n    with open(filepath) as file:\n        target_data = json.load(file)\n    target_rules = []\n    for data in target_data[\"target_rules\"]:\n        target_rules.append(TargetRule.from_dict(data))\n    return target_rules\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_rule/#medspacy.target_matcher.target_rule.TargetRule.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts TargetRules to a python dictionary. Used when writing target rules to a json file.</p> <p>Returns:</p> Type Description <p>The dictionary containing the TargetRule info.</p> Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>def to_dict(self):\n    \"\"\"Converts TargetRules to a python dictionary. Used when writing target rules to a json file.\n\n    Returns:\n        The dictionary containing the TargetRule info.\n    \"\"\"\n    rule_dict = {}\n    for key in self._ALLOWED_KEYS:\n        value = self.__dict__.get(key)\n        if value is not None:\n            rule_dict[key] = value\n    return rule_dict\n</code></pre>"},{"location":"reference/medspacy/target_matcher/target_rule/#medspacy.target_matcher.target_rule.TargetRule.to_json","title":"<code>to_json(target_rules, filepath)</code>  <code>classmethod</code>","text":"<p>Writes ConTextItems to a json file.</p> <p>Parameters:</p> Name Type Description Default <code>target_rules</code> <code>List[TargetRule]</code> <p>a list of TargetRules that will be written to a file.</p> required <code>filepath</code> <code>str</code> <p>the .json file to contain modifier rules</p> required Source code in <code>medspacy/target_matcher/target_rule.py</code> <pre><code>@classmethod\ndef to_json(cls, target_rules: List[TargetRule], filepath: str):\n    \"\"\"Writes ConTextItems to a json file.\n\n    Args:\n        target_rules: a list of TargetRules that will be written to a file.\n        filepath: the .json file to contain modifier rules\n    \"\"\"\n    import json\n\n    data = {\"target_rules\": [rule.to_dict() for rule in target_rules]}\n    with open(filepath, \"w\") as file:\n        json.dump(data, file, indent=4)\n</code></pre>"},{"location":"reference/medspacy/util/","title":"medspacy.util","text":"<p>This module will contain helper functions and classes for common clinical processing tasks which will be used in many medspaCy components.</p>"},{"location":"reference/medspacy/util/#medspacy.util._build_pipe_names","title":"<code>_build_pipe_names(enable, disable=None)</code>","text":"<p>Implement logic based on the pipenames defined in 'enable' and 'disable'. If enable and disable are both None, then it will load the default pipenames. Otherwise, will allow custom selection of components.</p> <p>Parameters:</p> Name Type Description Default <code>enable</code> <code>Union[str, Iterable[str]]</code> <p>\"all\" loads components from ALL_PIPE_NAMES. \"default\" loads components from DEFAULT_PIPE_NAMES. Otherwise, loads he list of components as components.</p> required <code>disable</code> <code>Optional[Iterable[str]]</code> <p>The optional list of components to disable. Set difference of enable.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Set[str], Set[str]]</code> <p>A complete list of enabled and disabled components, with all components listed and empty intersection.</p> Source code in <code>medspacy/util.py</code> <pre><code>def _build_pipe_names(\n    enable: Union[str, Iterable[str]], disable: Optional[Iterable[str]] = None\n) -&gt; Tuple[Set[str], Set[str]]:\n    \"\"\"\n    Implement logic based on the pipenames defined in 'enable' and 'disable'. If enable and disable are both None,\n    then it will load the default pipenames. Otherwise, will allow custom selection of components.\n\n    Args:\n        enable: \"all\" loads components from ALL_PIPE_NAMES. \"default\" loads components from DEFAULT_PIPE_NAMES.\n            Otherwise, loads he list of components as components.\n        disable: The optional list of components to disable. Set difference of enable.\n\n    Returns:\n        A complete list of enabled and disabled components, with all components listed and empty intersection.\n    \"\"\"\n    if not enable:\n        raise ValueError(\n            \"Enable cannot be none, please specify 'all', 'default' or a list of components.\"\n        )\n\n    # cannot allow lists of enabled and disabled components, what happens if \"context\" is both enabled and disabled?\n    if (not isinstance(enable, str) and isinstance(enable, Iterable)) and isinstance(\n        disable, Iterable\n    ):\n        raise ValueError(\"Both enable and disable cannot be collections of components.\")\n\n    # set which components are enabled first\n    if enable == \"all\":\n        enable = ALL_PIPE_NAMES\n    elif enable == \"default\":\n        enable = DEFAULT_PIPE_NAMES\n    else:\n        enable = set(enable)\n\n    # then find the difference with deactivated components\n    if disable is not None:\n        enable = enable.difference(set(disable))\n    else:\n        disable = set()  # otherwise disable is empty\n\n    return enable, disable\n</code></pre>"},{"location":"reference/medspacy/util/#medspacy.util.load","title":"<code>load(model='default', medspacy_enable='default', medspacy_disable=None, language_code='en', load_rules=True, quickumls_path=None, **model_kwargs)</code>","text":"<p>Load a spaCy language object with medSpaCy pipeline components. By default, the base model will be a blank 'en' model with the following components:     - \"medspacy_tokenizer\": A customized, more aggressive tokenizer than the default spaCy tokenizer. This is set to         <code>nlp.tokenizer</code> and is not loaded as a pipeline component.     - \"medspacy_pyrush\": PyRuSH Sentencizer for sentence splitting     - \"medspacy_target_matcher\": TargetMatcher for extended pattern matching     - \"medspacy_context\": ConText for attribute assertion     - \"medspacy_quickumls\": QuickUMLS for UMLS concept mapping Args:     model: The base spaCy model to load. If 'default', will instantiate from a blank 'en' model. If it is a spaCy         language model, then it will simply add medspaCy components to the existing pipeline. If it is a string         other than 'default', passes the string to spacy.load(model, **model_kwargs).     medspacy_enable: Specifies which components to enable in the medspacy pipeline. If \"default\", will load all components         found in <code>DEFAULT_PIPE_NAMES</code>. These represent the simplest components used in a clinical NLP pipeline:         tokenization, sentence detection, concept identification, and ConText. If \"all\", all components in medspaCy         will be loaded. If a collection of strings, the components specified will be loaded.     medspacy_disable: A collection of component names to exclude. Requires \"all\" is the value for <code>enable</code>.     language_code: Language code to use (ISO code) as a default for loading additional resources.  See documentation         and also the /resources directory to see which resources might be available in each language.         Default is \"en\" for English.     load_rules: Whether to include default rules for available components. If True, sectionizer and context will         both be loaded with default rules. Default is True.     quickumls_path: Path to QuickUMLS dictionaries if it is included in the pipeline.     model_kwargs: Optional model keyword arguments to pass to spacy.load().</p> <p>Returns:</p> Type Description <p>A spaCy Language object containing the specified medspacy components.</p> Source code in <code>medspacy/util.py</code> <pre><code>def load(\n    model: Union[Literal[\"default\"], str, Language] = \"default\",\n    medspacy_enable: Union[Literal[\"all\", \"default\"], Iterable[str]] = \"default\",\n    medspacy_disable: Optional[Iterable[str]] = None,\n    language_code: str = \"en\",\n    load_rules: bool = True,\n    quickumls_path: Optional[str] = None,\n    **model_kwargs,\n):\n    \"\"\"Load a spaCy language object with medSpaCy pipeline components.\n    By default, the base model will be a blank 'en' model with the\n    following components:\n        - \"medspacy_tokenizer\": A customized, more aggressive tokenizer than the default spaCy tokenizer. This is set to\n            `nlp.tokenizer` and is not loaded as a pipeline component.\n        - \"medspacy_pyrush\": PyRuSH Sentencizer for sentence splitting\n        - \"medspacy_target_matcher\": TargetMatcher for extended pattern matching\n        - \"medspacy_context\": ConText for attribute assertion\n        - \"medspacy_quickumls\": QuickUMLS for UMLS concept mapping\n    Args:\n        model: The base spaCy model to load. If 'default', will instantiate from a blank 'en' model. If it is a spaCy\n            language model, then it will simply add medspaCy components to the existing pipeline. If it is a string\n            other than 'default', passes the string to spacy.load(model, **model_kwargs).\n        medspacy_enable: Specifies which components to enable in the medspacy pipeline. If \"default\", will load all components\n            found in `DEFAULT_PIPE_NAMES`. These represent the simplest components used in a clinical NLP pipeline:\n            tokenization, sentence detection, concept identification, and ConText. If \"all\", all components in medspaCy\n            will be loaded. If a collection of strings, the components specified will be loaded.\n        medspacy_disable: A collection of component names to exclude. Requires \"all\" is the value for `enable`.\n        language_code: Language code to use (ISO code) as a default for loading additional resources.  See documentation\n            and also the /resources directory to see which resources might be available in each language.\n            Default is \"en\" for English.\n        load_rules: Whether to include default rules for available components. If True, sectionizer and context will\n            both be loaded with default rules. Default is True.\n        quickumls_path: Path to QuickUMLS dictionaries if it is included in the pipeline.\n        model_kwargs: Optional model keyword arguments to pass to spacy.load().\n\n    Returns:\n        A spaCy Language object containing the specified medspacy components.\n    \"\"\"\n\n    medspacy_enable, medspacy_disable = _build_pipe_names(\n        medspacy_enable, medspacy_disable\n    )\n\n    if model == \"default\":\n        nlp = spacy.blank(\"en\")\n    elif isinstance(model, Language):\n        nlp = model\n    elif isinstance(model, str):\n        nlp = spacy.load(model, **model_kwargs)\n    else:\n        raise ValueError(\n            \"model must be either 'default' or an actual spaCy Language object, not \",\n            type(model),\n        )\n\n    if \"medspacy_tokenizer\" in medspacy_enable:\n        from .custom_tokenizer import create_medspacy_tokenizer\n\n        medspacy_tokenizer = create_medspacy_tokenizer(nlp)\n        nlp.tokenizer = medspacy_tokenizer\n\n    if \"medspacy_preprocessor\" in medspacy_enable:\n        from .preprocess import Preprocessor\n\n        preprocessor = Preprocessor(nlp.tokenizer)\n        nlp.tokenizer = preprocessor\n\n    if \"medspacy_pyrush\" in medspacy_enable:\n        pyrush_path = path.join(\n            Path(__file__).resolve().parents[1], \"resources\", language_code.lower(), \"rush_rules.tsv\"\n        )\n        nlp.add_pipe(\"medspacy_pyrush\", config={\"rules_path\": pyrush_path})\n\n    if \"medspacy_target_matcher\" in medspacy_enable:\n        nlp.add_pipe(\"medspacy_target_matcher\")\n\n    if \"medspacy_quickumls\" in medspacy_enable:\n        if quickumls_path is None:\n            quickumls_path = get_quickumls_demo_dir(language_code)\n\n            print(\n                \"Loading QuickUMLS resources from a Medspacy-distributed SAMPLE of UMLS data from here: {}\".format(\n                    quickumls_path\n                )\n            )\n\n        nlp.add_pipe(\"medspacy_quickumls\", config={\"quickumls_fp\": quickumls_path})\n\n    if \"medspacy_context\" in medspacy_enable:\n        if load_rules is True:\n            config = {'language_code': language_code}\n        else:\n            config = {\"rules\": None,\n                      'language_code': language_code}\n        nlp.add_pipe(\"medspacy_context\", config=config)\n\n    if \"medspacy_sectionizer\" in medspacy_enable:\n        if load_rules is True:\n            config = {'language_code': language_code}\n        else:\n            config = {\"rules\": None,\n                      'language_code': language_code}\n        nlp.add_pipe(\"medspacy_sectionizer\", config=config)\n\n    if \"medspacy_postprocessor\" in medspacy_enable:\n        nlp.add_pipe(\"medspacy_postprocessor\")\n\n    if \"medspacy_doc_consumer\" in medspacy_enable:\n        nlp.add_pipe(\"medspacy_doc_consumer\")\n\n    return nlp\n</code></pre>"},{"location":"reference/medspacy/util/#medspacy.util.tuple_overlaps","title":"<code>tuple_overlaps(a, b)</code>","text":"<p>Calculates whether two tuples overlap. Assumes tuples are sorted to be like spans (start, end)</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Tuple[int, int]</code> <p>A tuple representing a span (start, end).</p> required <code>b</code> <code>Tuple[int, int]</code> <p>A tuple representing a span (start, end).</p> required <p>Returns:</p> Type Description <p>Whether the tuples overlap.</p> Source code in <code>medspacy/util.py</code> <pre><code>def tuple_overlaps(a: Tuple[int, int], b: Tuple[int, int]):\n    \"\"\"\n    Calculates whether two tuples overlap. Assumes tuples are sorted to be like spans (start, end)\n\n    Args:\n        a: A tuple representing a span (start, end).\n        b: A tuple representing a span (start, end).\n\n    Returns:\n        Whether the tuples overlap.\n    \"\"\"\n    return a[0] &lt;= b[0] &lt; a[1] or a[0] &lt; b[1] &lt;= a[1]\n</code></pre>"},{"location":"reference/medspacy/visualization/","title":"medspacy.visualization","text":""},{"location":"reference/medspacy/visualization/#medspacy.visualization.MedspaCyVisualizerWidget","title":"<code>MedspaCyVisualizerWidget</code>","text":"Source code in <code>medspacy/visualization.py</code> <pre><code>class MedspaCyVisualizerWidget:\n    def __init__(self, docs, target_span_type: str = \"ents\", span_group_name: str = \"medspacy_spans\"):\n\n        \"\"\"Create an IPython Widget Box displaying medspaCy's visualizers.\n        The widget allows selecting visualization style (\"Ent\", \"Dep\", or \"Both\")\n        and a slider for selecting the index of docs.\n\n        For more information on IPython widgets, see:\n            https://ipywidgets.readthedocs.io/en/latest/index.html\n\n        Parameters:\n            docs: A list of docs processed by a medspaCy pipeline\n\n        \"\"\"\n\n        import ipywidgets as widgets\n\n        self.docs = docs\n        self.target_span_type = target_span_type \n        self.span_group_name = span_group_name\n        self.slider = widgets.IntSlider(\n            value=0,\n            min=0,\n            max=len(docs) - 1,\n            step=1,\n            description=\"Doc:\",\n            disabled=False,\n            continuous_update=False,\n            orientation=\"horizontal\",\n            readout=True,\n            readout_format=\"d\",\n        )\n        self.radio = widgets.RadioButtons(options=[\"Ent\", \"Dep\", \"Both\"])\n        self.layout = widgets.Layout(\n            display=\"flex\", flex_flow=\"column\", align_items=\"stretch\", width=\"100%\"\n        )\n        self.radio.observe(self._change_handler)\n        self.slider.observe(self._change_handler)\n        self.next_button = widgets.Button(description=\"Next\")\n        self.next_button.on_click(self._on_click_next)\n        self.previous_button = widgets.Button(description=\"Previous\")\n        self.previous_button.on_click(self._on_click_prev)\n        self.output = widgets.Output()\n        self.box = widgets.Box(\n            [\n                widgets.HBox([self.radio, self.previous_button, self.next_button]),\n                self.slider,\n                self.output,\n            ],\n            layout=self.layout,\n        )\n\n        self.display()\n        with self.output:\n            self._visualize_doc()\n\n    def display(self):\n        \"\"\"Display the Box widget in the current IPython cell.\"\"\"\n        from IPython.display import display as ipydisplay\n\n        ipydisplay(self.box)\n\n    def _change_handler(self, change):\n\n        with self.output:\n            self._visualize_doc()\n\n    def _visualize_doc(self):\n        self.output.clear_output()\n        doc = self.docs[self.slider.value]\n        if self.radio.value.lower() in (\"dep\", \"both\"):\n            visualize_dep(doc)\n        if self.radio.value.lower() in (\"ent\", \"both\"):\n            visualize_ent(doc, target_span_type=self.target_span_type, span_group_name=self.span_group_name)\n\n    def _on_click_next(self, b):\n        if self.slider.value &lt; len(self.docs) - 1:\n            self.slider.value += 1\n\n    def _on_click_prev(self, b):\n        if self.slider.value &gt; 0:\n            self.slider.value -= 1\n\n    def set_docs(self, docs):\n        \"Replace the list of docs to be visualized.\"\n        self.docs = docs\n        self._visualize_doc(self.docs[0])\n</code></pre>"},{"location":"reference/medspacy/visualization/#medspacy.visualization.MedspaCyVisualizerWidget.__init__","title":"<code>__init__(docs, target_span_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Create an IPython Widget Box displaying medspaCy's visualizers. The widget allows selecting visualization style (\"Ent\", \"Dep\", or \"Both\") and a slider for selecting the index of docs.</p> <p>For more information on IPython widgets, see:     https://ipywidgets.readthedocs.io/en/latest/index.html</p> <p>Parameters:</p> Name Type Description Default <code>docs</code> <p>A list of docs processed by a medspaCy pipeline</p> required Source code in <code>medspacy/visualization.py</code> <pre><code>def __init__(self, docs, target_span_type: str = \"ents\", span_group_name: str = \"medspacy_spans\"):\n\n    \"\"\"Create an IPython Widget Box displaying medspaCy's visualizers.\n    The widget allows selecting visualization style (\"Ent\", \"Dep\", or \"Both\")\n    and a slider for selecting the index of docs.\n\n    For more information on IPython widgets, see:\n        https://ipywidgets.readthedocs.io/en/latest/index.html\n\n    Parameters:\n        docs: A list of docs processed by a medspaCy pipeline\n\n    \"\"\"\n\n    import ipywidgets as widgets\n\n    self.docs = docs\n    self.target_span_type = target_span_type \n    self.span_group_name = span_group_name\n    self.slider = widgets.IntSlider(\n        value=0,\n        min=0,\n        max=len(docs) - 1,\n        step=1,\n        description=\"Doc:\",\n        disabled=False,\n        continuous_update=False,\n        orientation=\"horizontal\",\n        readout=True,\n        readout_format=\"d\",\n    )\n    self.radio = widgets.RadioButtons(options=[\"Ent\", \"Dep\", \"Both\"])\n    self.layout = widgets.Layout(\n        display=\"flex\", flex_flow=\"column\", align_items=\"stretch\", width=\"100%\"\n    )\n    self.radio.observe(self._change_handler)\n    self.slider.observe(self._change_handler)\n    self.next_button = widgets.Button(description=\"Next\")\n    self.next_button.on_click(self._on_click_next)\n    self.previous_button = widgets.Button(description=\"Previous\")\n    self.previous_button.on_click(self._on_click_prev)\n    self.output = widgets.Output()\n    self.box = widgets.Box(\n        [\n            widgets.HBox([self.radio, self.previous_button, self.next_button]),\n            self.slider,\n            self.output,\n        ],\n        layout=self.layout,\n    )\n\n    self.display()\n    with self.output:\n        self._visualize_doc()\n</code></pre>"},{"location":"reference/medspacy/visualization/#medspacy.visualization.MedspaCyVisualizerWidget.display","title":"<code>display()</code>","text":"<p>Display the Box widget in the current IPython cell.</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def display(self):\n    \"\"\"Display the Box widget in the current IPython cell.\"\"\"\n    from IPython.display import display as ipydisplay\n\n    ipydisplay(self.box)\n</code></pre>"},{"location":"reference/medspacy/visualization/#medspacy.visualization.MedspaCyVisualizerWidget.set_docs","title":"<code>set_docs(docs)</code>","text":"<p>Replace the list of docs to be visualized.</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def set_docs(self, docs):\n    \"Replace the list of docs to be visualized.\"\n    self.docs = docs\n    self._visualize_doc(self.docs[0])\n</code></pre>"},{"location":"reference/medspacy/visualization/#medspacy.visualization._create_color_generator","title":"<code>_create_color_generator()</code>","text":"<p>Create a generator which will cycle through a list of default matplotlib colors</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def _create_color_generator():\n    \"\"\"Create a generator which will cycle through a list of\n    default matplotlib colors\"\"\"\n    from itertools import cycle\n\n    colors = [\n        \"#1f77b4\",\n        \"#ff7f0e\",\n        \"#2ca02c\",\n        \"#d62728\",\n        \"#9467bd\",\n        \"#8c564b\",\n        \"#e377c2\",\n        \"#7f7f7f\",\n        \"#bcbd22\",\n        \"#17becf\",\n    ]\n    return cycle(colors)\n</code></pre>"},{"location":"reference/medspacy/visualization/#medspacy.visualization.visualize_dep","title":"<code>visualize_dep(doc, jupyter=True)</code>","text":"<p>Create a dependency-style visualization for ConText targets and modifiers in doc. This will show the relationships between entities in doc and contextual modifiers.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>The spacy Doc to visualize.</p> required <code>jupyter</code> <code>bool</code> <p>Whether it is being rendered in a jupyter notebook.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>The visualization.</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def visualize_dep(doc: Doc, jupyter: bool = True) -&gt; str:\n    \"\"\"\n    Create a dependency-style visualization for ConText targets and modifiers in doc. This will show the relationships\n    between entities in doc and contextual modifiers.\n\n    Args:\n        doc: The spacy Doc to visualize.\n        jupyter: Whether it is being rendered in a jupyter notebook.\n\n    Returns:\n        The visualization.\n    \"\"\"\n    token_data = []\n    token_data_mapping = {}\n    for token in doc:\n        data = {\"text\": token.text, \"tag\": \"\", \"index\": token.i}\n        token_data.append(data)\n        token_data_mapping[token] = data\n\n    # Merge phrases\n    # targets_and_modifiers = [*doc._.context_graph.targets]\n    existing_tokens = set()\n    targets_and_modifiers = []\n    # Used to prevent duplication of token in targets or modifiers that appear twice due to being in a span group or, appearing twice as a modifier\n    for target_or_modifier in (list(doc._.context_graph.targets) + doc._.context_graph.modifiers):\n        if isinstance (target_or_modifier, Span):\n            span=target_or_modifier\n        else:\n            span=doc[target_or_modifier._start : target_or_modifier._end]\n        already_seen = False \n        for token in span:\n            if token in existing_tokens:\n                already_seen = True \n                break \n        if not already_seen:\n            targets_and_modifiers.append(target_or_modifier)\n            existing_tokens.update({token for token in span}) \n\n    for obj in targets_and_modifiers:\n        if isinstance(obj, Span):\n            first_token = obj[0]\n            data = token_data_mapping[first_token]\n            data[\"tag\"] = obj.label_\n            if len(obj) &gt; 1:\n                idx = data[\"index\"]\n                for other_token in obj[1:]:\n                    # Add the text to the display data for the first word\n                    # and remove the subsequent token\n                    data[\"text\"] += \" \" + other_token.text\n                    # Remove this token from the list of display data\n                    token_data.pop(idx + 1)\n                for other_data in token_data[idx + 1:]:\n                    other_data[\"index\"] -= len(obj) - 1\n        else:\n            span_tup = obj.modifier_span\n            first_token = doc[span_tup[0]]\n            data = token_data_mapping[first_token]\n            data[\"tag\"] = obj.category\n            if span_tup[1] - span_tup[0] &gt; 1:\n                span = doc[span_tup[0]: span_tup[1]]\n                idx = data[\"index\"]\n                for other_token in span[1:]:\n                    # Add the text to the display data for the first word\n                    # and remove the subsequent token\n                    data[\"text\"] += \" \" + other_token.text\n                    # Remove this token from the list of display data\n                    token_data.pop(idx + 1)\n                for other_data in token_data[idx + 1:]:\n                    other_data[\"index\"] -= len(span) - 1\n\n        # if len(span) == 1:\n        #     continue\n        #\n        # idx = data[\"index\"]\n        # for other_token in span[1:]:\n        #     # Add the text to the display data for the first word\n        #     # and remove the subsequent token\n        #     data[\"text\"] += \" \" + other_token.text\n        #     # Remove this token from the list of display data\n        #     token_data.pop(idx + 1)\n        #\n        # # Lower the index of the following tokens\n        # for other_data in token_data[idx + 1 :]:\n        #     other_data[\"index\"] -= len(span) - 1\n\n    dep_data = {\"words\": token_data, \"arcs\": []}\n\n    # Gather the edges between targets and modifiers\n    for target, modifier in doc._.context_graph.edges:\n        target_data = token_data_mapping[target[0]]\n        modifier_data = token_data_mapping[doc[modifier.modifier_span[0]]]\n        dep_data[\"arcs\"].append(\n            {\n                \"start\": min(target_data[\"index\"], modifier_data[\"index\"]),\n                \"end\": max(target_data[\"index\"], modifier_data[\"index\"]),\n                \"label\": modifier.category,\n                \"dir\": \"right\"\n                if target &gt; doc[modifier.modifier_span[0] : modifier.modifier_span[1]]\n                else \"left\",\n            }\n        )\n\n    return displacy.render(dep_data, manual=True, jupyter=jupyter)\n</code></pre>"},{"location":"reference/medspacy/visualization/#medspacy.visualization.visualize_ent","title":"<code>visualize_ent(doc, context=True, sections=True, jupyter=True, colors=None, target_span_type='ents', span_group_name='medspacy_spans')</code>","text":"<p>Creates a NER-style visualization for targets and modifiers in Doc.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Doc</code> <p>A spacy doc to visualize.</p> required <code>context</code> <code>bool</code> <p>Whether to display the modifiers generated by medSpaCy's cycontext. If the doc has not been processed by context, this will be automatically changed to False. Default True.</p> <code>True</code> <code>sections</code> <code>bool</code> <p>Whether to display the section titles generated by medSpaCy's sectionizer (still in development). If the doc has not been processed by sectionizer , this will be automatically changed to False. This may also have some overlap with cycontext, in which case duplicate spans will be displayed. Default True.</p> <code>True</code> <code>jupyter</code> <code>bool</code> <p>If True, will render directly in a Jupyter notebook. If False, will return the HTML. Default True.</p> <code>True</code> <code>colors</code> <code>Dict[str, str]</code> <p>An optional dictionary which maps labels of targets and modifiers to color strings to be rendered. If None, will create a generator which cycles through the default matplotlib colors for ent and modifier labels and uses a light gray for section headers. Default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The visualization.</p> Source code in <code>medspacy/visualization.py</code> <pre><code>def visualize_ent(\n    doc: Doc,\n    context: bool = True,\n    sections: bool = True,\n    jupyter: bool = True,\n    colors: Dict[str, str] = None,\n    target_span_type: str = \"ents\",\n    span_group_name: str = \"medspacy_spans\"\n) -&gt; str:\n    \"\"\"\n    Creates a NER-style visualization for targets and modifiers in Doc.\n\n    Args:\n        doc: A spacy doc to visualize.\n        context: Whether to display the modifiers generated by medSpaCy's cycontext. If the doc has not been processed\n            by context, this will be automatically changed to False. Default True.\n        sections: Whether to display the section titles generated by medSpaCy's sectionizer (still in development). If\n            the doc has not been processed by sectionizer , this will be automatically changed to False. This may also\n            have some overlap with cycontext, in which case duplicate spans will be displayed. Default True.\n        jupyter: If True, will render directly in a Jupyter notebook. If False, will return the HTML. Default True.\n        colors: An optional dictionary which maps labels of targets and modifiers to color strings to be rendered. If\n            None, will create a generator which cycles through the default matplotlib colors for ent and modifier labels\n            and uses a light gray for section headers. Default None.\n\n    Returns:\n        The visualization.\n    \"\"\"\n    # Make sure that doc has the custom medSpaCy attributes registered\n    if not hasattr(doc._, \"context_graph\"):\n        context = False\n    if not hasattr(doc._, \"sections\"):\n        sections = False\n\n    ents_data = []\n\n    if target_span_type == \"ents\":\n        targets = doc.ents\n    elif target_span_type == \"group\":\n        targets = doc.spans[span_group_name]\n    else:\n        raise ValueError(\"Target span type must be either ents or group.\")\n\n    for target in targets:\n        ent_data = {\n            \"start\": target.start_char,\n            \"end\": target.end_char,\n            \"label\": target.label_.upper(),\n        }\n        ents_data.append((ent_data, \"ent\"))\n\n    if context:\n        visualized_modifiers = set()\n        for target in doc.ents:\n            for modifier in target._.modifiers:\n                if modifier in visualized_modifiers:\n                    continue\n                span = doc[modifier.modifier_span[0]: modifier.modifier_span[1]]\n                ent_data = {\n                    \"start\": span.start_char,\n                    \"end\": span.end_char,\n                    \"label\": modifier.category,\n                }\n                ents_data.append((ent_data, \"modifier\"))\n                visualized_modifiers.add(modifier)\n    if sections:\n        for section in doc._.sections:\n            category = section.category\n            if category is None:\n                continue\n            span = doc[section.title_span[0]: section.title_span[1]]\n            ent_data = {\n                \"start\": span.start_char,\n                \"end\": span.end_char,\n                \"label\": f\"&lt;&lt; {category.upper()} &gt;&gt;\",\n            }\n            ents_data.append((ent_data, \"section\"))\n    if len(ents_data) == 0:  # No data to display\n        viz_data = [{\"text\": doc.text, \"ents\": []}]\n        options = dict()\n    else:\n        ents_data = sorted(ents_data, key=lambda x: x[0][\"start\"])\n\n        # If colors aren't defined, generate color mappings for each entity\n        # and modifier label and set all section titles to a light gray\n        if colors is None:\n            labels = set()\n            section_titles = set()\n            for (ent_data, ent_type) in ents_data:\n                if ent_type in (\"ent\", \"modifier\"):\n                    labels.add(ent_data[\"label\"])\n                elif ent_type == \"section\":\n                    section_titles.add(ent_data[\"label\"])\n            colors = _create_color_mapping(labels)\n            for title in section_titles:\n                colors[title] = \"#dee0e3\"\n        ents_display_data, _ = zip(*ents_data)\n        viz_data = [\n            {\n                \"text\": doc.text,\n                \"ents\": ents_display_data,\n            }\n        ]\n\n        options = {\n            \"colors\": colors,\n        }\n    return displacy.render(\n        viz_data, style=\"ent\", manual=True, options=options, jupyter=jupyter\n    )\n</code></pre>"}]}